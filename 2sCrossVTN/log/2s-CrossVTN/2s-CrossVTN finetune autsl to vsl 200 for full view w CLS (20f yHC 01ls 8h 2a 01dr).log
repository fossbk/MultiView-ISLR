2025-01-12 14:34:35,814 [INFO] Starting 2s-CrossVTN/2s-CrossVTN finetune autsl to vsl 200 for full view w CLS (20f yHC 01ls 8h 2a 01dr)...


2025-01-12 14:35:39,009 [INFO] Starting 2s-CrossVTN/2s-CrossVTN finetune autsl to vsl 200 for full view w CLS (20f yHC 01ls 8h 2a 01dr)...


2025-01-12 14:36:29,656 [INFO] Starting 2s-CrossVTN/2s-CrossVTN finetune autsl to vsl 200 for full view w CLS (20f yHC 01ls 8h 2a 01dr)...


2025-01-12 14:36:43,878 [INFO] Step[50/4316]: training loss : 0.8944154238700867 TRAIN  loss dict:  {'classification_loss': 0.8944154238700867}
2025-01-12 14:36:53,561 [INFO] Step[100/4316]: training loss : 0.9380357837677002 TRAIN  loss dict:  {'classification_loss': 0.9380357837677002}
2025-01-12 14:37:22,855 [INFO] Starting 2s-CrossVTN/2s-CrossVTN finetune autsl to vsl 200 for full view w CLS (20f yHC 01ls 8h 2a 01dr)...


2025-01-12 14:37:45,851 [INFO] Step[50/1439]: training loss : 0.8972078275680542 TRAIN  loss dict:  {'classification_loss': 0.8972078275680542}
2025-01-12 14:37:57,306 [INFO] Step[100/1439]: training loss : 0.9091867101192475 TRAIN  loss dict:  {'classification_loss': 0.9091867101192475}
2025-01-12 14:38:08,890 [INFO] Step[150/1439]: training loss : 0.9227341747283936 TRAIN  loss dict:  {'classification_loss': 0.9227341747283936}
2025-01-12 14:38:20,378 [INFO] Step[200/1439]: training loss : 0.907113116979599 TRAIN  loss dict:  {'classification_loss': 0.907113116979599}
2025-01-12 14:38:31,946 [INFO] Step[250/1439]: training loss : 0.915919017791748 TRAIN  loss dict:  {'classification_loss': 0.915919017791748}
2025-01-12 14:38:43,498 [INFO] Step[300/1439]: training loss : 0.9290475177764893 TRAIN  loss dict:  {'classification_loss': 0.9290475177764893}
2025-01-12 14:38:55,180 [INFO] Step[350/1439]: training loss : 0.9378185498714448 TRAIN  loss dict:  {'classification_loss': 0.9378185498714448}
2025-01-12 14:39:06,720 [INFO] Step[400/1439]: training loss : 0.9181206524372101 TRAIN  loss dict:  {'classification_loss': 0.9181206524372101}
2025-01-12 14:39:18,306 [INFO] Step[450/1439]: training loss : 0.9063855266571045 TRAIN  loss dict:  {'classification_loss': 0.9063855266571045}
2025-01-12 14:39:29,879 [INFO] Step[500/1439]: training loss : 0.9474801874160766 TRAIN  loss dict:  {'classification_loss': 0.9474801874160766}
2025-01-12 14:39:41,447 [INFO] Step[550/1439]: training loss : 0.9161973798274994 TRAIN  loss dict:  {'classification_loss': 0.9161973798274994}
2025-01-12 14:39:53,079 [INFO] Step[600/1439]: training loss : 0.9269309651851654 TRAIN  loss dict:  {'classification_loss': 0.9269309651851654}
2025-01-12 14:40:04,751 [INFO] Step[650/1439]: training loss : 0.9388919925689697 TRAIN  loss dict:  {'classification_loss': 0.9388919925689697}
2025-01-12 14:40:16,351 [INFO] Step[700/1439]: training loss : 0.9272653424739837 TRAIN  loss dict:  {'classification_loss': 0.9272653424739837}
2025-01-12 14:40:27,897 [INFO] Step[750/1439]: training loss : 0.9271754229068756 TRAIN  loss dict:  {'classification_loss': 0.9271754229068756}
2025-01-12 14:40:39,509 [INFO] Step[800/1439]: training loss : 0.9238150632381439 TRAIN  loss dict:  {'classification_loss': 0.9238150632381439}
2025-01-12 14:40:51,168 [INFO] Step[850/1439]: training loss : 0.9227680563926697 TRAIN  loss dict:  {'classification_loss': 0.9227680563926697}
2025-01-12 14:41:02,808 [INFO] Step[900/1439]: training loss : 0.9304599869251251 TRAIN  loss dict:  {'classification_loss': 0.9304599869251251}
2025-01-12 14:41:14,468 [INFO] Step[950/1439]: training loss : 0.9237015926837921 TRAIN  loss dict:  {'classification_loss': 0.9237015926837921}
2025-01-12 14:41:26,072 [INFO] Step[1000/1439]: training loss : 0.9253339970111847 TRAIN  loss dict:  {'classification_loss': 0.9253339970111847}
2025-01-12 14:41:37,670 [INFO] Step[1050/1439]: training loss : 0.9211400616168975 TRAIN  loss dict:  {'classification_loss': 0.9211400616168975}
2025-01-12 14:41:49,328 [INFO] Step[1100/1439]: training loss : 0.951894336938858 TRAIN  loss dict:  {'classification_loss': 0.951894336938858}
2025-01-12 14:42:01,075 [INFO] Step[1150/1439]: training loss : 0.9539786946773529 TRAIN  loss dict:  {'classification_loss': 0.9539786946773529}
2025-01-12 14:42:12,613 [INFO] Step[1200/1439]: training loss : 0.9812466621398925 TRAIN  loss dict:  {'classification_loss': 0.9812466621398925}
2025-01-12 14:42:24,291 [INFO] Step[1250/1439]: training loss : 0.9995808351039887 TRAIN  loss dict:  {'classification_loss': 0.9995808351039887}
2025-01-12 14:42:35,923 [INFO] Step[1300/1439]: training loss : 0.9398232269287109 TRAIN  loss dict:  {'classification_loss': 0.9398232269287109}
2025-01-12 14:42:47,628 [INFO] Step[1350/1439]: training loss : 0.942943720817566 TRAIN  loss dict:  {'classification_loss': 0.942943720817566}
2025-01-12 14:42:59,253 [INFO] Step[1400/1439]: training loss : 0.9357335352897644 TRAIN  loss dict:  {'classification_loss': 0.9357335352897644}
2025-01-12 14:43:49,116 [INFO] Label accuracies statistics:
2025-01-12 14:43:49,117 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.25, 8: 0.25, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.75, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 1.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.5, 55: 0.75, 56: 1.0, 57: 0.5, 58: 0.75, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 1.0, 88: 0.75, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.5, 114: 0.5, 115: 0.75, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.75, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.5, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 1.0, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.75, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 1.0, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 1.0, 191: 0.5, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.75}

2025-01-12 14:43:50,140 [INFO] [1] TRAIN  loss: 0.9336757406416331 acc: 0.9935125115848007
2025-01-12 14:43:50,140 [INFO] [1] TRAIN  loss dict: {'classification_loss': 0.9336757406416331}
2025-01-12 14:43:50,140 [INFO] [1] VALIDATION loss: 1.5896706585631226 VALIDATION acc: 0.8194444444444444
2025-01-12 14:43:50,140 [INFO] [1] VALIDATION loss dict: {'classification_loss': 1.5896706585631226}
2025-01-12 14:43:50,140 [INFO] 
2025-01-12 14:44:06,553 [INFO] Step[50/1439]: training loss : 0.9246439850330352 TRAIN  loss dict:  {'classification_loss': 0.9246439850330352}
2025-01-12 14:44:18,142 [INFO] Step[100/1439]: training loss : 0.9504537236690521 TRAIN  loss dict:  {'classification_loss': 0.9504537236690521}
2025-01-12 14:45:11,753 [INFO] Starting 2s-CrossVTN/2s-CrossVTN finetune autsl to vsl 200 for full view w CLS (20f yHC 01ls 8h 2a 01dr)...


2025-01-12 14:47:03,186 [INFO] Starting 2s-CrossVTN/2s-CrossVTN finetune autsl to vsl 200 for full view w CLS (20f yHC 01ls 8h 2a 01dr)...


2025-01-12 14:47:26,352 [INFO] Step[50/4329]: training loss : 2.9608855879306795 TRAIN  loss dict:  {'classification_loss': 2.9608855879306795}
2025-01-12 14:47:37,940 [INFO] Step[100/4329]: training loss : 2.583092577457428 TRAIN  loss dict:  {'classification_loss': 2.583092577457428}
2025-01-12 14:47:49,518 [INFO] Step[150/4329]: training loss : 2.74430845618248 TRAIN  loss dict:  {'classification_loss': 2.74430845618248}
2025-01-12 14:48:01,116 [INFO] Step[200/4329]: training loss : 2.7047007191181183 TRAIN  loss dict:  {'classification_loss': 2.7047007191181183}
2025-01-12 14:48:12,755 [INFO] Step[250/4329]: training loss : 2.7694322764873505 TRAIN  loss dict:  {'classification_loss': 2.7694322764873505}
2025-01-12 14:48:24,242 [INFO] Step[300/4329]: training loss : 2.5245638525485994 TRAIN  loss dict:  {'classification_loss': 2.5245638525485994}
2025-01-12 14:48:35,818 [INFO] Step[350/4329]: training loss : 2.4079332733154297 TRAIN  loss dict:  {'classification_loss': 2.4079332733154297}
2025-01-12 14:48:47,371 [INFO] Step[400/4329]: training loss : 2.4130732941627504 TRAIN  loss dict:  {'classification_loss': 2.4130732941627504}
2025-01-12 14:48:59,010 [INFO] Step[450/4329]: training loss : 2.1611488234996794 TRAIN  loss dict:  {'classification_loss': 2.1611488234996794}
2025-01-12 14:49:10,640 [INFO] Step[500/4329]: training loss : 2.256370471715927 TRAIN  loss dict:  {'classification_loss': 2.256370471715927}
2025-01-12 14:49:22,204 [INFO] Step[550/4329]: training loss : 2.357829703092575 TRAIN  loss dict:  {'classification_loss': 2.357829703092575}
2025-01-12 14:49:33,851 [INFO] Step[600/4329]: training loss : 2.1164348757267 TRAIN  loss dict:  {'classification_loss': 2.1164348757267}
2025-01-12 14:49:45,492 [INFO] Step[650/4329]: training loss : 2.3707960331439972 TRAIN  loss dict:  {'classification_loss': 2.3707960331439972}
2025-01-12 14:49:57,090 [INFO] Step[700/4329]: training loss : 2.386483473777771 TRAIN  loss dict:  {'classification_loss': 2.386483473777771}
2025-01-12 14:50:08,752 [INFO] Step[750/4329]: training loss : 2.2667611908912657 TRAIN  loss dict:  {'classification_loss': 2.2667611908912657}
2025-01-12 14:50:20,412 [INFO] Step[800/4329]: training loss : 2.4587872779369353 TRAIN  loss dict:  {'classification_loss': 2.4587872779369353}
2025-01-12 14:50:32,045 [INFO] Step[850/4329]: training loss : 2.1013990986347197 TRAIN  loss dict:  {'classification_loss': 2.1013990986347197}
2025-01-12 14:50:43,656 [INFO] Step[900/4329]: training loss : 2.141310418844223 TRAIN  loss dict:  {'classification_loss': 2.141310418844223}
2025-01-12 14:50:55,282 [INFO] Step[950/4329]: training loss : 2.0907970023155213 TRAIN  loss dict:  {'classification_loss': 2.0907970023155213}
2025-01-12 14:51:06,954 [INFO] Step[1000/4329]: training loss : 2.3047454416751862 TRAIN  loss dict:  {'classification_loss': 2.3047454416751862}
2025-01-12 14:51:18,582 [INFO] Step[1050/4329]: training loss : 2.1895255029201506 TRAIN  loss dict:  {'classification_loss': 2.1895255029201506}
2025-01-12 14:51:30,262 [INFO] Step[1100/4329]: training loss : 2.1737354505062103 TRAIN  loss dict:  {'classification_loss': 2.1737354505062103}
2025-01-12 14:51:41,946 [INFO] Step[1150/4329]: training loss : 2.171911976337433 TRAIN  loss dict:  {'classification_loss': 2.171911976337433}
2025-01-12 14:51:53,623 [INFO] Step[1200/4329]: training loss : 2.15991366147995 TRAIN  loss dict:  {'classification_loss': 2.15991366147995}
2025-01-12 14:52:05,283 [INFO] Step[1250/4329]: training loss : 1.9768213367462157 TRAIN  loss dict:  {'classification_loss': 1.9768213367462157}
2025-01-12 14:52:16,972 [INFO] Step[1300/4329]: training loss : 2.1123171925544737 TRAIN  loss dict:  {'classification_loss': 2.1123171925544737}
2025-01-12 14:52:28,654 [INFO] Step[1350/4329]: training loss : 1.9001565563678742 TRAIN  loss dict:  {'classification_loss': 1.9001565563678742}
2025-01-12 14:52:40,261 [INFO] Step[1400/4329]: training loss : 2.067857069969177 TRAIN  loss dict:  {'classification_loss': 2.067857069969177}
2025-01-12 14:52:51,903 [INFO] Step[1450/4329]: training loss : 1.743787944316864 TRAIN  loss dict:  {'classification_loss': 1.743787944316864}
2025-01-12 14:53:03,528 [INFO] Step[1500/4329]: training loss : 2.2352974152565004 TRAIN  loss dict:  {'classification_loss': 2.2352974152565004}
2025-01-12 14:53:15,209 [INFO] Step[1550/4329]: training loss : 2.0443090486526487 TRAIN  loss dict:  {'classification_loss': 2.0443090486526487}
2025-01-12 14:53:26,880 [INFO] Step[1600/4329]: training loss : 2.1283803367614746 TRAIN  loss dict:  {'classification_loss': 2.1283803367614746}
2025-01-12 14:53:38,577 [INFO] Step[1650/4329]: training loss : 2.1167396652698516 TRAIN  loss dict:  {'classification_loss': 2.1167396652698516}
2025-01-12 14:53:50,215 [INFO] Step[1700/4329]: training loss : 2.1032002961635587 TRAIN  loss dict:  {'classification_loss': 2.1032002961635587}
2025-01-12 14:54:01,783 [INFO] Step[1750/4329]: training loss : 1.9413639724254608 TRAIN  loss dict:  {'classification_loss': 1.9413639724254608}
2025-01-12 14:54:13,371 [INFO] Step[1800/4329]: training loss : 1.7595617330074311 TRAIN  loss dict:  {'classification_loss': 1.7595617330074311}
2025-01-12 14:54:25,010 [INFO] Step[1850/4329]: training loss : 2.2552166533470155 TRAIN  loss dict:  {'classification_loss': 2.2552166533470155}
2025-01-12 14:54:36,589 [INFO] Step[1900/4329]: training loss : 1.9782478618621826 TRAIN  loss dict:  {'classification_loss': 1.9782478618621826}
2025-01-12 14:54:48,254 [INFO] Step[1950/4329]: training loss : 1.928483544588089 TRAIN  loss dict:  {'classification_loss': 1.928483544588089}
2025-01-12 14:54:59,805 [INFO] Step[2000/4329]: training loss : 1.872721140384674 TRAIN  loss dict:  {'classification_loss': 1.872721140384674}
2025-01-12 14:55:11,473 [INFO] Step[2050/4329]: training loss : 2.0617009103298187 TRAIN  loss dict:  {'classification_loss': 2.0617009103298187}
2025-01-12 14:55:23,201 [INFO] Step[2100/4329]: training loss : 1.9019883954524994 TRAIN  loss dict:  {'classification_loss': 1.9019883954524994}
2025-01-12 14:55:34,883 [INFO] Step[2150/4329]: training loss : 1.8941982007026672 TRAIN  loss dict:  {'classification_loss': 1.8941982007026672}
2025-01-12 14:55:46,489 [INFO] Step[2200/4329]: training loss : 2.070150138139725 TRAIN  loss dict:  {'classification_loss': 2.070150138139725}
2025-01-12 14:55:58,159 [INFO] Step[2250/4329]: training loss : 2.045565152168274 TRAIN  loss dict:  {'classification_loss': 2.045565152168274}
2025-01-12 14:56:09,844 [INFO] Step[2300/4329]: training loss : 1.9469077503681183 TRAIN  loss dict:  {'classification_loss': 1.9469077503681183}
2025-01-12 14:56:21,496 [INFO] Step[2350/4329]: training loss : 1.992631219625473 TRAIN  loss dict:  {'classification_loss': 1.992631219625473}
2025-01-12 14:56:33,150 [INFO] Step[2400/4329]: training loss : 2.1317667675018313 TRAIN  loss dict:  {'classification_loss': 2.1317667675018313}
2025-01-12 14:56:44,819 [INFO] Step[2450/4329]: training loss : 1.998935421705246 TRAIN  loss dict:  {'classification_loss': 1.998935421705246}
2025-01-12 14:56:56,454 [INFO] Step[2500/4329]: training loss : 1.9690265989303588 TRAIN  loss dict:  {'classification_loss': 1.9690265989303588}
2025-01-12 14:57:08,038 [INFO] Step[2550/4329]: training loss : 2.0181914412975313 TRAIN  loss dict:  {'classification_loss': 2.0181914412975313}
2025-01-12 14:57:19,608 [INFO] Step[2600/4329]: training loss : 1.8823834598064422 TRAIN  loss dict:  {'classification_loss': 1.8823834598064422}
2025-01-12 14:57:31,213 [INFO] Step[2650/4329]: training loss : 1.979282579421997 TRAIN  loss dict:  {'classification_loss': 1.979282579421997}
2025-01-12 14:57:42,784 [INFO] Step[2700/4329]: training loss : 1.7754652965068818 TRAIN  loss dict:  {'classification_loss': 1.7754652965068818}
2025-01-12 14:57:54,447 [INFO] Step[2750/4329]: training loss : 1.8915590310096742 TRAIN  loss dict:  {'classification_loss': 1.8915590310096742}
2025-01-12 14:58:06,052 [INFO] Step[2800/4329]: training loss : 2.041388567686081 TRAIN  loss dict:  {'classification_loss': 2.041388567686081}
2025-01-12 14:58:17,708 [INFO] Step[2850/4329]: training loss : 2.075341742038727 TRAIN  loss dict:  {'classification_loss': 2.075341742038727}
2025-01-12 14:58:29,344 [INFO] Step[2900/4329]: training loss : 1.9886594009399414 TRAIN  loss dict:  {'classification_loss': 1.9886594009399414}
2025-01-12 14:58:40,943 [INFO] Step[2950/4329]: training loss : 1.8196467089653015 TRAIN  loss dict:  {'classification_loss': 1.8196467089653015}
2025-01-12 14:58:52,572 [INFO] Step[3000/4329]: training loss : 1.8766312861442567 TRAIN  loss dict:  {'classification_loss': 1.8766312861442567}
2025-01-12 14:59:04,185 [INFO] Step[3050/4329]: training loss : 1.7680019700527192 TRAIN  loss dict:  {'classification_loss': 1.7680019700527192}
2025-01-12 14:59:15,968 [INFO] Step[3100/4329]: training loss : 2.0026153111457825 TRAIN  loss dict:  {'classification_loss': 2.0026153111457825}
2025-01-12 14:59:27,774 [INFO] Step[3150/4329]: training loss : 1.848157455921173 TRAIN  loss dict:  {'classification_loss': 1.848157455921173}
2025-01-12 14:59:39,405 [INFO] Step[3200/4329]: training loss : 1.696170951128006 TRAIN  loss dict:  {'classification_loss': 1.696170951128006}
2025-01-12 14:59:51,016 [INFO] Step[3250/4329]: training loss : 1.6842860305309295 TRAIN  loss dict:  {'classification_loss': 1.6842860305309295}
2025-01-12 15:00:02,638 [INFO] Step[3300/4329]: training loss : 1.9981748902797698 TRAIN  loss dict:  {'classification_loss': 1.9981748902797698}
2025-01-12 15:00:14,253 [INFO] Step[3350/4329]: training loss : 1.9168448734283448 TRAIN  loss dict:  {'classification_loss': 1.9168448734283448}
2025-01-12 15:00:25,825 [INFO] Step[3400/4329]: training loss : 1.9865946972370148 TRAIN  loss dict:  {'classification_loss': 1.9865946972370148}
2025-01-12 15:00:37,417 [INFO] Step[3450/4329]: training loss : 1.8989971745014191 TRAIN  loss dict:  {'classification_loss': 1.8989971745014191}
2025-01-12 15:00:49,007 [INFO] Step[3500/4329]: training loss : 1.960901894569397 TRAIN  loss dict:  {'classification_loss': 1.960901894569397}
2025-01-12 15:01:00,614 [INFO] Step[3550/4329]: training loss : 1.7956029653549195 TRAIN  loss dict:  {'classification_loss': 1.7956029653549195}
2025-01-12 15:01:12,229 [INFO] Step[3600/4329]: training loss : 1.9353842449188232 TRAIN  loss dict:  {'classification_loss': 1.9353842449188232}
2025-01-12 15:01:23,865 [INFO] Step[3650/4329]: training loss : 1.9458871853351594 TRAIN  loss dict:  {'classification_loss': 1.9458871853351594}
2025-01-12 15:01:35,446 [INFO] Step[3700/4329]: training loss : 1.595032753944397 TRAIN  loss dict:  {'classification_loss': 1.595032753944397}
2025-01-12 15:01:47,064 [INFO] Step[3750/4329]: training loss : 1.911572812795639 TRAIN  loss dict:  {'classification_loss': 1.911572812795639}
2025-01-12 15:01:58,681 [INFO] Step[3800/4329]: training loss : 1.8316861915588378 TRAIN  loss dict:  {'classification_loss': 1.8316861915588378}
2025-01-12 15:02:10,307 [INFO] Step[3850/4329]: training loss : 1.9680459260940553 TRAIN  loss dict:  {'classification_loss': 1.9680459260940553}
2025-01-12 15:02:21,921 [INFO] Step[3900/4329]: training loss : 1.915942414999008 TRAIN  loss dict:  {'classification_loss': 1.915942414999008}
2025-01-12 15:02:33,578 [INFO] Step[3950/4329]: training loss : 1.9565272223949433 TRAIN  loss dict:  {'classification_loss': 1.9565272223949433}
2025-01-12 15:02:45,264 [INFO] Step[4000/4329]: training loss : 1.8713339841365815 TRAIN  loss dict:  {'classification_loss': 1.8713339841365815}
2025-01-12 15:02:56,905 [INFO] Step[4050/4329]: training loss : 1.61675590634346 TRAIN  loss dict:  {'classification_loss': 1.61675590634346}
2025-01-12 15:03:08,616 [INFO] Step[4100/4329]: training loss : 1.8375702273845673 TRAIN  loss dict:  {'classification_loss': 1.8375702273845673}
2025-01-12 15:03:20,261 [INFO] Step[4150/4329]: training loss : 1.8484772551059723 TRAIN  loss dict:  {'classification_loss': 1.8484772551059723}
2025-01-12 15:03:31,919 [INFO] Step[4200/4329]: training loss : 1.862398555278778 TRAIN  loss dict:  {'classification_loss': 1.862398555278778}
2025-01-12 15:03:43,544 [INFO] Step[4250/4329]: training loss : 1.8449099957942963 TRAIN  loss dict:  {'classification_loss': 1.8449099957942963}
2025-01-12 15:03:55,176 [INFO] Step[4300/4329]: training loss : 1.7411724352836608 TRAIN  loss dict:  {'classification_loss': 1.7411724352836608}
2025-01-12 15:06:25,548 [INFO] Label accuracies statistics:
2025-01-12 15:06:25,549 [INFO] {0: 0.4444444444444444, 1: 0.8888888888888888, 2: 0.5833333333333334, 3: 0.75, 4: 0.3333333333333333, 5: 0.9166666666666666, 6: 0.5, 7: 0.16666666666666666, 8: 0.08333333333333333, 9: 0.5833333333333334, 10: 0.9166666666666666, 11: 0.8333333333333334, 12: 0.4166666666666667, 13: 0.5833333333333334, 14: 0.5833333333333334, 15: 0.5555555555555556, 16: 0.25, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.4166666666666667, 20: 0.5, 21: 0.3333333333333333, 22: 0.6666666666666666, 23: 0.9166666666666666, 24: 1.0, 25: 0.6666666666666666, 26: 0.75, 27: 0.4166666666666667, 28: 0.6666666666666666, 29: 1.0, 30: 0.4166666666666667, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.4166666666666667, 37: 1.0, 38: 0.75, 39: 0.8333333333333334, 40: 0.8333333333333334, 41: 0.3333333333333333, 42: 0.5, 43: 0.75, 44: 0.4166666666666667, 45: 0.75, 46: 0.9166666666666666, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.4166666666666667, 51: 0.6666666666666666, 52: 0.9166666666666666, 53: 0.6666666666666666, 54: 0.08333333333333333, 55: 0.5833333333333334, 56: 0.6666666666666666, 57: 0.5833333333333334, 58: 0.25, 59: 0.8333333333333334, 60: 0.4166666666666667, 61: 0.75, 62: 0.75, 63: 0.4166666666666667, 64: 1.0, 65: 0.8333333333333334, 66: 0.25, 67: 0.4166666666666667, 68: 0.4166666666666667, 69: 0.5833333333333334, 70: 0.3333333333333333, 71: 0.4166666666666667, 72: 0.75, 73: 0.75, 74: 0.75, 75: 0.9166666666666666, 76: 0.3333333333333333, 77: 0.5833333333333334, 78: 0.75, 79: 0.4166666666666667, 80: 0.8333333333333334, 81: 0.75, 82: 0.5833333333333334, 83: 0.4166666666666667, 84: 0.3333333333333333, 85: 0.5, 86: 0.5, 87: 0.75, 88: 0.5833333333333334, 89: 0.5, 90: 0.3333333333333333, 91: 0.9166666666666666, 92: 1.0, 93: 0.8333333333333334, 94: 0.5, 95: 0.6666666666666666, 96: 0.16666666666666666, 97: 0.3333333333333333, 98: 0.75, 99: 0.8, 100: 0.6666666666666666, 101: 0.6666666666666666, 102: 1.0, 103: 0.9166666666666666, 104: 0.9166666666666666, 105: 0.8333333333333334, 106: 0.5833333333333334, 107: 0.4166666666666667, 108: 0.5833333333333334, 109: 0.6666666666666666, 110: 0.75, 111: 0.8333333333333334, 112: 0.8333333333333334, 113: 0.16666666666666666, 114: 0.8333333333333334, 115: 0.5833333333333334, 116: 0.8333333333333334, 117: 0.75, 118: 0.8333333333333334, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.5, 123: 0.8333333333333334, 124: 0.9166666666666666, 125: 0.5, 126: 0.9166666666666666, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.8333333333333334, 131: 0.75, 132: 0.3333333333333333, 133: 0.9166666666666666, 134: 0.5, 135: 0.9166666666666666, 136: 0.75, 137: 0.75, 138: 0.75, 139: 0.6666666666666666, 140: 0.75, 141: 0.6666666666666666, 142: 0.6666666666666666, 143: 1.0, 144: 0.6666666666666666, 145: 0.8333333333333334, 146: 1.0, 147: 0.9166666666666666, 148: 0.6666666666666666, 149: 0.6666666666666666, 150: 0.5, 151: 0.9166666666666666, 152: 0.75, 153: 0.8333333333333334, 154: 0.9166666666666666, 155: 0.8333333333333334, 156: 0.6666666666666666, 157: 0.75, 158: 0.5555555555555556, 159: 0.9166666666666666, 160: 0.25, 161: 0.5, 162: 0.8333333333333334, 163: 0.9166666666666666, 164: 0.5, 165: 0.3333333333333333, 166: 0.3333333333333333, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.9166666666666666, 173: 0.9166666666666666, 174: 1.0, 175: 0.6666666666666666, 176: 0.75, 177: 0.5, 178: 0.75, 179: 0.3333333333333333, 180: 0.6666666666666666, 181: 0.8333333333333334, 182: 0.4166666666666667, 183: 0.9166666666666666, 184: 0.5833333333333334, 185: 1.0, 186: 0.5833333333333334, 187: 0.9166666666666666, 188: 0.5833333333333334, 189: 0.5833333333333334, 190: 0.25, 191: 0.16666666666666666, 192: 1.0, 193: 0.9166666666666666, 194: 0.8333333333333334, 195: 1.0, 196: 0.9166666666666666, 197: 0.4166666666666667, 198: 0.75}

2025-01-12 15:06:52,586 [INFO] [1] TRAIN  loss: 2.053570001443117 acc: 0.6722624364700447
2025-01-12 15:06:52,586 [INFO] [1] TRAIN  loss dict: {'classification_loss': 2.053570001443117}
2025-01-12 15:06:52,586 [INFO] [1] VALIDATION loss: 2.087215873027089 VALIDATION acc: 0.6611952861952862
2025-01-12 15:06:52,587 [INFO] [1] VALIDATION loss dict: {'classification_loss': 2.087215873027089}
2025-01-12 15:06:52,587 [INFO] 
2025-01-12 15:07:10,714 [INFO] Step[50/4329]: training loss : 1.6102003169059753 TRAIN  loss dict:  {'classification_loss': 1.6102003169059753}
2025-01-12 15:07:22,301 [INFO] Step[100/4329]: training loss : 1.7016228437423706 TRAIN  loss dict:  {'classification_loss': 1.7016228437423706}
2025-01-12 15:07:33,910 [INFO] Step[150/4329]: training loss : 1.5722349286079407 TRAIN  loss dict:  {'classification_loss': 1.5722349286079407}
2025-01-12 15:07:45,617 [INFO] Step[200/4329]: training loss : 1.6416864395141602 TRAIN  loss dict:  {'classification_loss': 1.6416864395141602}
2025-01-12 15:07:57,254 [INFO] Step[250/4329]: training loss : 1.6046493530273438 TRAIN  loss dict:  {'classification_loss': 1.6046493530273438}
2025-01-12 15:08:08,906 [INFO] Step[300/4329]: training loss : 1.566607335805893 TRAIN  loss dict:  {'classification_loss': 1.566607335805893}
2025-01-12 15:08:20,613 [INFO] Step[350/4329]: training loss : 1.5785026085376739 TRAIN  loss dict:  {'classification_loss': 1.5785026085376739}
2025-01-12 15:08:32,251 [INFO] Step[400/4329]: training loss : 1.629854018688202 TRAIN  loss dict:  {'classification_loss': 1.629854018688202}
2025-01-12 15:08:43,835 [INFO] Step[450/4329]: training loss : 1.6261291849613189 TRAIN  loss dict:  {'classification_loss': 1.6261291849613189}
2025-01-12 15:08:55,459 [INFO] Step[500/4329]: training loss : 1.6335463309288025 TRAIN  loss dict:  {'classification_loss': 1.6335463309288025}
2025-01-12 15:09:07,090 [INFO] Step[550/4329]: training loss : 1.5974964559078217 TRAIN  loss dict:  {'classification_loss': 1.5974964559078217}
2025-01-12 15:09:18,752 [INFO] Step[600/4329]: training loss : 1.6836013770103455 TRAIN  loss dict:  {'classification_loss': 1.6836013770103455}
2025-01-12 15:09:30,422 [INFO] Step[650/4329]: training loss : 1.6481682193279266 TRAIN  loss dict:  {'classification_loss': 1.6481682193279266}
2025-01-12 15:09:42,086 [INFO] Step[700/4329]: training loss : 1.6581491816043854 TRAIN  loss dict:  {'classification_loss': 1.6581491816043854}
2025-01-12 15:09:53,767 [INFO] Step[750/4329]: training loss : 1.662239489555359 TRAIN  loss dict:  {'classification_loss': 1.662239489555359}
2025-01-12 15:10:05,411 [INFO] Step[800/4329]: training loss : 1.745615335702896 TRAIN  loss dict:  {'classification_loss': 1.745615335702896}
2025-01-12 15:10:17,050 [INFO] Step[850/4329]: training loss : 1.7352463209629059 TRAIN  loss dict:  {'classification_loss': 1.7352463209629059}
2025-01-12 15:10:28,767 [INFO] Step[900/4329]: training loss : 1.644807198047638 TRAIN  loss dict:  {'classification_loss': 1.644807198047638}
2025-01-12 15:10:40,820 [INFO] Step[950/4329]: training loss : 1.551595652103424 TRAIN  loss dict:  {'classification_loss': 1.551595652103424}
2025-01-12 15:10:53,168 [INFO] Step[1000/4329]: training loss : 1.6986775636672973 TRAIN  loss dict:  {'classification_loss': 1.6986775636672973}
2025-01-12 15:11:05,593 [INFO] Step[1050/4329]: training loss : 1.6527872788906097 TRAIN  loss dict:  {'classification_loss': 1.6527872788906097}
2025-01-12 15:11:18,692 [INFO] Step[1100/4329]: training loss : 1.5793108975887298 TRAIN  loss dict:  {'classification_loss': 1.5793108975887298}
2025-01-12 15:11:33,346 [INFO] Step[1150/4329]: training loss : 1.6355546402931214 TRAIN  loss dict:  {'classification_loss': 1.6355546402931214}
2025-01-12 15:11:45,414 [INFO] Step[1200/4329]: training loss : 1.5872095465660094 TRAIN  loss dict:  {'classification_loss': 1.5872095465660094}
2025-01-12 15:11:57,245 [INFO] Step[1250/4329]: training loss : 1.4848429703712462 TRAIN  loss dict:  {'classification_loss': 1.4848429703712462}
2025-01-12 15:12:09,085 [INFO] Step[1300/4329]: training loss : 1.596432443857193 TRAIN  loss dict:  {'classification_loss': 1.596432443857193}
2025-01-12 15:12:20,778 [INFO] Step[1350/4329]: training loss : 1.6653939592838287 TRAIN  loss dict:  {'classification_loss': 1.6653939592838287}
2025-01-12 15:12:32,432 [INFO] Step[1400/4329]: training loss : 1.4791604888439178 TRAIN  loss dict:  {'classification_loss': 1.4791604888439178}
2025-01-12 15:12:44,065 [INFO] Step[1450/4329]: training loss : 1.6326619935035707 TRAIN  loss dict:  {'classification_loss': 1.6326619935035707}
2025-01-12 15:12:55,674 [INFO] Step[1500/4329]: training loss : 1.5470019209384918 TRAIN  loss dict:  {'classification_loss': 1.5470019209384918}
2025-01-12 15:13:07,337 [INFO] Step[1550/4329]: training loss : 1.8168659818172455 TRAIN  loss dict:  {'classification_loss': 1.8168659818172455}
2025-01-12 15:13:18,997 [INFO] Step[1600/4329]: training loss : 1.6101676964759826 TRAIN  loss dict:  {'classification_loss': 1.6101676964759826}
2025-01-12 15:13:30,657 [INFO] Step[1650/4329]: training loss : 1.5224817371368409 TRAIN  loss dict:  {'classification_loss': 1.5224817371368409}
2025-01-12 15:13:42,347 [INFO] Step[1700/4329]: training loss : 1.7753594255447387 TRAIN  loss dict:  {'classification_loss': 1.7753594255447387}
2025-01-12 15:13:53,977 [INFO] Step[1750/4329]: training loss : 1.6333409464359283 TRAIN  loss dict:  {'classification_loss': 1.6333409464359283}
2025-01-12 15:14:05,590 [INFO] Step[1800/4329]: training loss : 1.6554006552696228 TRAIN  loss dict:  {'classification_loss': 1.6554006552696228}
2025-01-12 15:14:17,217 [INFO] Step[1850/4329]: training loss : 1.6550348162651063 TRAIN  loss dict:  {'classification_loss': 1.6550348162651063}
2025-01-12 15:14:28,836 [INFO] Step[1900/4329]: training loss : 1.6070330834388733 TRAIN  loss dict:  {'classification_loss': 1.6070330834388733}
2025-01-12 15:14:40,478 [INFO] Step[1950/4329]: training loss : 1.6744632971286775 TRAIN  loss dict:  {'classification_loss': 1.6744632971286775}
2025-01-12 15:14:52,074 [INFO] Step[2000/4329]: training loss : 1.7608322501182556 TRAIN  loss dict:  {'classification_loss': 1.7608322501182556}
2025-01-12 15:15:03,711 [INFO] Step[2050/4329]: training loss : 1.6430417025089263 TRAIN  loss dict:  {'classification_loss': 1.6430417025089263}
2025-01-12 15:15:15,370 [INFO] Step[2100/4329]: training loss : 1.5164730167388916 TRAIN  loss dict:  {'classification_loss': 1.5164730167388916}
2025-01-12 15:15:26,995 [INFO] Step[2150/4329]: training loss : 1.6432950460910798 TRAIN  loss dict:  {'classification_loss': 1.6432950460910798}
2025-01-12 15:15:38,626 [INFO] Step[2200/4329]: training loss : 1.5790871131420134 TRAIN  loss dict:  {'classification_loss': 1.5790871131420134}
2025-01-12 15:15:50,276 [INFO] Step[2250/4329]: training loss : 1.7111421823501587 TRAIN  loss dict:  {'classification_loss': 1.7111421823501587}
2025-01-12 15:16:01,944 [INFO] Step[2300/4329]: training loss : 1.6839973831176758 TRAIN  loss dict:  {'classification_loss': 1.6839973831176758}
2025-01-12 15:16:13,581 [INFO] Step[2350/4329]: training loss : 1.511881753206253 TRAIN  loss dict:  {'classification_loss': 1.511881753206253}
2025-01-12 15:16:25,205 [INFO] Step[2400/4329]: training loss : 1.7755617928504943 TRAIN  loss dict:  {'classification_loss': 1.7755617928504943}
2025-01-12 15:16:36,837 [INFO] Step[2450/4329]: training loss : 1.5908506190776825 TRAIN  loss dict:  {'classification_loss': 1.5908506190776825}
2025-01-12 15:16:48,492 [INFO] Step[2500/4329]: training loss : 1.5354466211795808 TRAIN  loss dict:  {'classification_loss': 1.5354466211795808}
2025-01-12 15:17:00,188 [INFO] Step[2550/4329]: training loss : 1.5086335575580596 TRAIN  loss dict:  {'classification_loss': 1.5086335575580596}
2025-01-12 15:17:11,833 [INFO] Step[2600/4329]: training loss : 1.6125895726680755 TRAIN  loss dict:  {'classification_loss': 1.6125895726680755}
2025-01-12 15:17:23,483 [INFO] Step[2650/4329]: training loss : 1.5034087014198303 TRAIN  loss dict:  {'classification_loss': 1.5034087014198303}
2025-01-12 15:17:35,199 [INFO] Step[2700/4329]: training loss : 1.7839150309562684 TRAIN  loss dict:  {'classification_loss': 1.7839150309562684}
2025-01-12 15:17:46,890 [INFO] Step[2750/4329]: training loss : 1.7013540518283845 TRAIN  loss dict:  {'classification_loss': 1.7013540518283845}
2025-01-12 15:17:58,553 [INFO] Step[2800/4329]: training loss : 1.6435689210891724 TRAIN  loss dict:  {'classification_loss': 1.6435689210891724}
2025-01-12 15:18:10,233 [INFO] Step[2850/4329]: training loss : 1.6651378750801087 TRAIN  loss dict:  {'classification_loss': 1.6651378750801087}
2025-01-12 15:18:21,850 [INFO] Step[2900/4329]: training loss : 1.6813511145114899 TRAIN  loss dict:  {'classification_loss': 1.6813511145114899}
2025-01-12 15:18:33,526 [INFO] Step[2950/4329]: training loss : 1.7437405586242676 TRAIN  loss dict:  {'classification_loss': 1.7437405586242676}
2025-01-12 15:18:45,187 [INFO] Step[3000/4329]: training loss : 1.8551276314258576 TRAIN  loss dict:  {'classification_loss': 1.8551276314258576}
2025-01-12 15:18:56,875 [INFO] Step[3050/4329]: training loss : 1.5222823762893676 TRAIN  loss dict:  {'classification_loss': 1.5222823762893676}
2025-01-12 15:19:08,591 [INFO] Step[3100/4329]: training loss : 1.5518959009647368 TRAIN  loss dict:  {'classification_loss': 1.5518959009647368}
2025-01-12 15:19:20,371 [INFO] Step[3150/4329]: training loss : 1.6789430630207063 TRAIN  loss dict:  {'classification_loss': 1.6789430630207063}
2025-01-12 15:19:32,053 [INFO] Step[3200/4329]: training loss : 1.6027533972263337 TRAIN  loss dict:  {'classification_loss': 1.6027533972263337}
2025-01-12 15:19:43,895 [INFO] Step[3250/4329]: training loss : 1.6960165679454804 TRAIN  loss dict:  {'classification_loss': 1.6960165679454804}
2025-01-12 15:19:55,618 [INFO] Step[3300/4329]: training loss : 1.604347550868988 TRAIN  loss dict:  {'classification_loss': 1.604347550868988}
2025-01-12 15:20:07,256 [INFO] Step[3350/4329]: training loss : 1.599860360622406 TRAIN  loss dict:  {'classification_loss': 1.599860360622406}
2025-01-12 15:20:18,896 [INFO] Step[3400/4329]: training loss : 1.5978273773193359 TRAIN  loss dict:  {'classification_loss': 1.5978273773193359}
2025-01-12 15:20:30,546 [INFO] Step[3450/4329]: training loss : 1.6576077771186828 TRAIN  loss dict:  {'classification_loss': 1.6576077771186828}
2025-01-12 15:20:42,194 [INFO] Step[3500/4329]: training loss : 1.578442999124527 TRAIN  loss dict:  {'classification_loss': 1.578442999124527}
2025-01-12 15:20:53,863 [INFO] Step[3550/4329]: training loss : 1.7030668210983277 TRAIN  loss dict:  {'classification_loss': 1.7030668210983277}
2025-01-12 15:21:05,483 [INFO] Step[3600/4329]: training loss : 1.5114975202083587 TRAIN  loss dict:  {'classification_loss': 1.5114975202083587}
2025-01-12 15:21:17,122 [INFO] Step[3650/4329]: training loss : 1.7159549462795258 TRAIN  loss dict:  {'classification_loss': 1.7159549462795258}
2025-01-12 15:21:28,766 [INFO] Step[3700/4329]: training loss : 1.4919047117233277 TRAIN  loss dict:  {'classification_loss': 1.4919047117233277}
2025-01-12 15:21:40,391 [INFO] Step[3750/4329]: training loss : 1.4824641680717467 TRAIN  loss dict:  {'classification_loss': 1.4824641680717467}
2025-01-12 15:21:52,032 [INFO] Step[3800/4329]: training loss : 1.9063160872459413 TRAIN  loss dict:  {'classification_loss': 1.9063160872459413}
2025-01-12 15:22:03,688 [INFO] Step[3850/4329]: training loss : 1.5822993946075439 TRAIN  loss dict:  {'classification_loss': 1.5822993946075439}
2025-01-12 15:22:15,292 [INFO] Step[3900/4329]: training loss : 1.606761051416397 TRAIN  loss dict:  {'classification_loss': 1.606761051416397}
2025-01-12 15:22:26,904 [INFO] Step[3950/4329]: training loss : 1.6430408024787904 TRAIN  loss dict:  {'classification_loss': 1.6430408024787904}
2025-01-12 15:22:38,567 [INFO] Step[4000/4329]: training loss : 1.5765453732013703 TRAIN  loss dict:  {'classification_loss': 1.5765453732013703}
2025-01-12 15:22:50,265 [INFO] Step[4050/4329]: training loss : 1.636326913833618 TRAIN  loss dict:  {'classification_loss': 1.636326913833618}
2025-01-12 15:23:01,917 [INFO] Step[4100/4329]: training loss : 1.5593631601333617 TRAIN  loss dict:  {'classification_loss': 1.5593631601333617}
2025-01-12 15:23:13,594 [INFO] Step[4150/4329]: training loss : 1.6969862067699433 TRAIN  loss dict:  {'classification_loss': 1.6969862067699433}
2025-01-12 15:23:25,649 [INFO] Step[4200/4329]: training loss : 1.7236489033699036 TRAIN  loss dict:  {'classification_loss': 1.7236489033699036}
2025-01-12 15:23:37,891 [INFO] Step[4250/4329]: training loss : 1.5756835806369782 TRAIN  loss dict:  {'classification_loss': 1.5756835806369782}
2025-01-12 15:23:50,074 [INFO] Step[4300/4329]: training loss : 1.734038816690445 TRAIN  loss dict:  {'classification_loss': 1.734038816690445}
2025-01-12 15:26:19,633 [INFO] Label accuracies statistics:
2025-01-12 15:26:19,633 [INFO] {0: 0.5555555555555556, 1: 0.7777777777777778, 2: 0.6666666666666666, 3: 0.75, 4: 0.4166666666666667, 5: 0.8333333333333334, 6: 0.5, 7: 0.3333333333333333, 8: 0.25, 9: 0.5833333333333334, 10: 0.8333333333333334, 11: 1.0, 12: 0.3333333333333333, 13: 0.4166666666666667, 14: 0.5833333333333334, 15: 0.4444444444444444, 16: 0.5833333333333334, 17: 0.25, 18: 0.5, 19: 0.5833333333333334, 20: 0.3333333333333333, 21: 0.3333333333333333, 22: 0.5833333333333334, 23: 0.8333333333333334, 24: 0.8333333333333334, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.16666666666666666, 31: 0.4166666666666667, 32: 0.5, 33: 0.6666666666666666, 34: 0.5, 35: 0.75, 36: 0.3333333333333333, 37: 1.0, 38: 0.8333333333333334, 39: 0.9166666666666666, 40: 0.75, 41: 0.3333333333333333, 42: 0.6666666666666666, 43: 0.8333333333333334, 44: 0.4166666666666667, 45: 0.6666666666666666, 46: 1.0, 47: 0.5833333333333334, 48: 0.9166666666666666, 49: 0.9166666666666666, 50: 0.5833333333333334, 51: 0.75, 52: 0.75, 53: 0.3333333333333333, 54: 0.25, 55: 0.5833333333333334, 56: 0.5833333333333334, 57: 0.5833333333333334, 58: 0.25, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.6666666666666666, 63: 0.25, 64: 1.0, 65: 0.9166666666666666, 66: 0.5833333333333334, 67: 0.5833333333333334, 68: 0.3333333333333333, 69: 0.5, 70: 0.5, 71: 0.3333333333333333, 72: 0.5833333333333334, 73: 0.6666666666666666, 74: 0.5, 75: 0.8333333333333334, 76: 0.4166666666666667, 77: 0.5833333333333334, 78: 0.8333333333333334, 79: 0.5833333333333334, 80: 0.9166666666666666, 81: 0.9166666666666666, 82: 0.6666666666666666, 83: 0.5833333333333334, 84: 0.25, 85: 0.8333333333333334, 86: 0.3333333333333333, 87: 0.8333333333333334, 88: 0.3333333333333333, 89: 0.5833333333333334, 90: 0.25, 91: 0.6666666666666666, 92: 1.0, 93: 1.0, 94: 0.25, 95: 0.6666666666666666, 96: 0.4166666666666667, 97: 0.75, 98: 0.6666666666666666, 99: 0.8666666666666667, 100: 0.6666666666666666, 101: 0.75, 102: 0.8333333333333334, 103: 0.8333333333333334, 104: 1.0, 105: 0.8333333333333334, 106: 0.9166666666666666, 107: 0.8333333333333334, 108: 0.75, 109: 0.5833333333333334, 110: 0.75, 111: 0.8333333333333334, 112: 0.4166666666666667, 113: 0.5, 114: 0.4166666666666667, 115: 0.75, 116: 0.5, 117: 0.6666666666666666, 118: 0.8333333333333334, 119: 0.8333333333333334, 120: 0.6666666666666666, 121: 0.6666666666666666, 122: 0.75, 123: 1.0, 124: 0.5833333333333334, 125: 0.8333333333333334, 126: 0.9166666666666666, 127: 0.5833333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.8333333333333334, 132: 0.4166666666666667, 133: 0.9166666666666666, 134: 0.6666666666666666, 135: 0.9166666666666666, 136: 0.75, 137: 0.6666666666666666, 138: 0.75, 139: 0.8333333333333334, 140: 0.8333333333333334, 141: 0.8333333333333334, 142: 0.5833333333333334, 143: 1.0, 144: 0.6666666666666666, 145: 0.75, 146: 0.9166666666666666, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.3333333333333333, 151: 0.9166666666666666, 152: 0.75, 153: 0.8333333333333334, 154: 0.8333333333333334, 155: 0.9166666666666666, 156: 0.0, 157: 0.5, 158: 0.4444444444444444, 159: 0.8333333333333334, 160: 0.3333333333333333, 161: 0.9166666666666666, 162: 0.75, 163: 0.9166666666666666, 164: 0.4166666666666667, 165: 0.3333333333333333, 166: 0.8333333333333334, 167: 0.6666666666666666, 168: 0.4166666666666667, 169: 0.6666666666666666, 170: 0.9166666666666666, 171: 0.3333333333333333, 172: 0.9166666666666666, 173: 0.6666666666666666, 174: 1.0, 175: 0.8333333333333334, 176: 1.0, 177: 0.8333333333333334, 178: 0.75, 179: 0.2222222222222222, 180: 0.4166666666666667, 181: 0.75, 182: 0.4166666666666667, 183: 0.5, 184: 0.3333333333333333, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.5, 189: 1.0, 190: 0.4166666666666667, 191: 0.3333333333333333, 192: 1.0, 193: 0.9166666666666666, 194: 0.8333333333333334, 195: 1.0, 196: 0.9166666666666666, 197: 0.75, 198: 0.6666666666666666}

2025-01-12 15:26:21,603 [INFO] [2] TRAIN  loss: 1.6324639166026558 acc: 0.7740643770214076
2025-01-12 15:26:21,603 [INFO] [2] TRAIN  loss dict: {'classification_loss': 1.6324639166026558}
2025-01-12 15:26:21,604 [INFO] [2] VALIDATION loss: 2.0808349132838875 VALIDATION acc: 0.664983164983165
2025-01-12 15:26:21,604 [INFO] [2] VALIDATION loss dict: {'classification_loss': 2.0808349132838875}
2025-01-12 15:26:21,604 [INFO] 
2025-01-12 15:26:38,626 [INFO] Step[50/4329]: training loss : 1.313049283027649 TRAIN  loss dict:  {'classification_loss': 1.313049283027649}
2025-01-12 15:26:50,214 [INFO] Step[100/4329]: training loss : 1.522749891281128 TRAIN  loss dict:  {'classification_loss': 1.522749891281128}
2025-01-12 15:27:01,780 [INFO] Step[150/4329]: training loss : 1.4106302177906036 TRAIN  loss dict:  {'classification_loss': 1.4106302177906036}
2025-01-12 15:27:13,378 [INFO] Step[200/4329]: training loss : 1.5568988668918609 TRAIN  loss dict:  {'classification_loss': 1.5568988668918609}
2025-01-12 15:27:25,014 [INFO] Step[250/4329]: training loss : 1.4772605299949646 TRAIN  loss dict:  {'classification_loss': 1.4772605299949646}
2025-01-12 15:27:36,646 [INFO] Step[300/4329]: training loss : 1.5068294680118561 TRAIN  loss dict:  {'classification_loss': 1.5068294680118561}
2025-01-12 15:27:48,288 [INFO] Step[350/4329]: training loss : 1.5329253494739532 TRAIN  loss dict:  {'classification_loss': 1.5329253494739532}
2025-01-12 15:27:59,974 [INFO] Step[400/4329]: training loss : 1.5711373364925385 TRAIN  loss dict:  {'classification_loss': 1.5711373364925385}
2025-01-12 15:28:11,625 [INFO] Step[450/4329]: training loss : 1.3832872915267944 TRAIN  loss dict:  {'classification_loss': 1.3832872915267944}
2025-01-12 15:28:23,312 [INFO] Step[500/4329]: training loss : 1.4112454307079316 TRAIN  loss dict:  {'classification_loss': 1.4112454307079316}
2025-01-12 15:28:35,004 [INFO] Step[550/4329]: training loss : 1.3693063807487489 TRAIN  loss dict:  {'classification_loss': 1.3693063807487489}
2025-01-12 15:28:46,614 [INFO] Step[600/4329]: training loss : 1.4115506148338317 TRAIN  loss dict:  {'classification_loss': 1.4115506148338317}
2025-01-12 15:28:58,260 [INFO] Step[650/4329]: training loss : 1.4100032353401184 TRAIN  loss dict:  {'classification_loss': 1.4100032353401184}
2025-01-12 15:29:09,910 [INFO] Step[700/4329]: training loss : 1.4977230167388915 TRAIN  loss dict:  {'classification_loss': 1.4977230167388915}
2025-01-12 15:29:21,573 [INFO] Step[750/4329]: training loss : 1.54652059674263 TRAIN  loss dict:  {'classification_loss': 1.54652059674263}
2025-01-12 15:29:33,223 [INFO] Step[800/4329]: training loss : 1.518167358636856 TRAIN  loss dict:  {'classification_loss': 1.518167358636856}
2025-01-12 15:29:44,906 [INFO] Step[850/4329]: training loss : 1.4700721645355224 TRAIN  loss dict:  {'classification_loss': 1.4700721645355224}
2025-01-12 15:29:56,594 [INFO] Step[900/4329]: training loss : 1.4859081971645356 TRAIN  loss dict:  {'classification_loss': 1.4859081971645356}
2025-01-12 15:30:08,230 [INFO] Step[950/4329]: training loss : 1.4015810704231262 TRAIN  loss dict:  {'classification_loss': 1.4015810704231262}
2025-01-12 15:30:19,878 [INFO] Step[1000/4329]: training loss : 1.5427628147602082 TRAIN  loss dict:  {'classification_loss': 1.5427628147602082}
2025-01-12 15:30:31,530 [INFO] Step[1050/4329]: training loss : 1.3752416944503785 TRAIN  loss dict:  {'classification_loss': 1.3752416944503785}
2025-01-12 15:30:43,198 [INFO] Step[1100/4329]: training loss : 1.5222489464282989 TRAIN  loss dict:  {'classification_loss': 1.5222489464282989}
2025-01-12 15:30:54,856 [INFO] Step[1150/4329]: training loss : 1.3978538024425506 TRAIN  loss dict:  {'classification_loss': 1.3978538024425506}
2025-01-12 15:31:06,524 [INFO] Step[1200/4329]: training loss : 1.4964690840244292 TRAIN  loss dict:  {'classification_loss': 1.4964690840244292}
2025-01-12 15:31:18,156 [INFO] Step[1250/4329]: training loss : 1.5858865582942963 TRAIN  loss dict:  {'classification_loss': 1.5858865582942963}
2025-01-12 15:31:29,774 [INFO] Step[1300/4329]: training loss : 1.4550934159755706 TRAIN  loss dict:  {'classification_loss': 1.4550934159755706}
2025-01-12 15:31:41,393 [INFO] Step[1350/4329]: training loss : 1.4598836374282838 TRAIN  loss dict:  {'classification_loss': 1.4598836374282838}
2025-01-12 15:31:53,016 [INFO] Step[1400/4329]: training loss : 1.3773014593124389 TRAIN  loss dict:  {'classification_loss': 1.3773014593124389}
2025-01-12 15:32:04,655 [INFO] Step[1450/4329]: training loss : 1.4483063566684722 TRAIN  loss dict:  {'classification_loss': 1.4483063566684722}
2025-01-12 15:32:16,307 [INFO] Step[1500/4329]: training loss : 1.4668564426898956 TRAIN  loss dict:  {'classification_loss': 1.4668564426898956}
2025-01-12 15:32:28,013 [INFO] Step[1550/4329]: training loss : 1.3847893643379212 TRAIN  loss dict:  {'classification_loss': 1.3847893643379212}
2025-01-12 15:32:39,624 [INFO] Step[1600/4329]: training loss : 1.5537121760845185 TRAIN  loss dict:  {'classification_loss': 1.5537121760845185}
2025-01-12 15:32:51,303 [INFO] Step[1650/4329]: training loss : 1.3211919784545898 TRAIN  loss dict:  {'classification_loss': 1.3211919784545898}
2025-01-12 15:33:02,987 [INFO] Step[1700/4329]: training loss : 1.4087305653095246 TRAIN  loss dict:  {'classification_loss': 1.4087305653095246}
2025-01-12 15:33:14,688 [INFO] Step[1750/4329]: training loss : 1.514649165868759 TRAIN  loss dict:  {'classification_loss': 1.514649165868759}
2025-01-12 15:33:26,338 [INFO] Step[1800/4329]: training loss : 1.5268499994277953 TRAIN  loss dict:  {'classification_loss': 1.5268499994277953}
2025-01-12 15:33:38,002 [INFO] Step[1850/4329]: training loss : 1.4869907331466674 TRAIN  loss dict:  {'classification_loss': 1.4869907331466674}
2025-01-12 15:33:49,607 [INFO] Step[1900/4329]: training loss : 1.448131490945816 TRAIN  loss dict:  {'classification_loss': 1.448131490945816}
2025-01-12 15:34:01,221 [INFO] Step[1950/4329]: training loss : 1.5287394046783447 TRAIN  loss dict:  {'classification_loss': 1.5287394046783447}
2025-01-12 15:34:12,855 [INFO] Step[2000/4329]: training loss : 1.464134703874588 TRAIN  loss dict:  {'classification_loss': 1.464134703874588}
2025-01-12 15:34:24,468 [INFO] Step[2050/4329]: training loss : 1.44985857963562 TRAIN  loss dict:  {'classification_loss': 1.44985857963562}
2025-01-12 15:34:36,074 [INFO] Step[2100/4329]: training loss : 1.4485073280334473 TRAIN  loss dict:  {'classification_loss': 1.4485073280334473}
2025-01-12 15:34:47,778 [INFO] Step[2150/4329]: training loss : 1.4607311379909516 TRAIN  loss dict:  {'classification_loss': 1.4607311379909516}
2025-01-12 15:34:59,410 [INFO] Step[2200/4329]: training loss : 1.5555589854717256 TRAIN  loss dict:  {'classification_loss': 1.5555589854717256}
2025-01-12 15:35:11,058 [INFO] Step[2250/4329]: training loss : 1.4660188698768615 TRAIN  loss dict:  {'classification_loss': 1.4660188698768615}
2025-01-12 15:35:22,684 [INFO] Step[2300/4329]: training loss : 1.5290110683441163 TRAIN  loss dict:  {'classification_loss': 1.5290110683441163}
2025-01-12 15:35:34,318 [INFO] Step[2350/4329]: training loss : 1.5011998391151429 TRAIN  loss dict:  {'classification_loss': 1.5011998391151429}
2025-01-12 15:35:45,946 [INFO] Step[2400/4329]: training loss : 1.4596282279491424 TRAIN  loss dict:  {'classification_loss': 1.4596282279491424}
2025-01-12 15:35:57,967 [INFO] Step[2450/4329]: training loss : 1.5508557319641114 TRAIN  loss dict:  {'classification_loss': 1.5508557319641114}
2025-01-12 15:36:10,309 [INFO] Step[2500/4329]: training loss : 1.481461157798767 TRAIN  loss dict:  {'classification_loss': 1.481461157798767}
2025-01-12 15:36:22,603 [INFO] Step[2550/4329]: training loss : 1.3633167707920075 TRAIN  loss dict:  {'classification_loss': 1.3633167707920075}
2025-01-12 15:36:36,271 [INFO] Step[2600/4329]: training loss : 1.5557442688941956 TRAIN  loss dict:  {'classification_loss': 1.5557442688941956}
2025-01-12 15:36:49,673 [INFO] Step[2650/4329]: training loss : 1.4894602012634277 TRAIN  loss dict:  {'classification_loss': 1.4894602012634277}
2025-01-12 15:37:01,730 [INFO] Step[2700/4329]: training loss : 1.601060495376587 TRAIN  loss dict:  {'classification_loss': 1.601060495376587}
2025-01-12 15:37:13,622 [INFO] Step[2750/4329]: training loss : 1.5472765100002288 TRAIN  loss dict:  {'classification_loss': 1.5472765100002288}
2025-01-12 15:37:25,411 [INFO] Step[2800/4329]: training loss : 1.4347631561756133 TRAIN  loss dict:  {'classification_loss': 1.4347631561756133}
2025-01-12 15:37:37,061 [INFO] Step[2850/4329]: training loss : 1.4859508442878724 TRAIN  loss dict:  {'classification_loss': 1.4859508442878724}
2025-01-12 15:37:48,716 [INFO] Step[2900/4329]: training loss : 1.5195907843112946 TRAIN  loss dict:  {'classification_loss': 1.5195907843112946}
2025-01-12 15:38:00,353 [INFO] Step[2950/4329]: training loss : 1.5903320765495301 TRAIN  loss dict:  {'classification_loss': 1.5903320765495301}
2025-01-12 15:38:11,997 [INFO] Step[3000/4329]: training loss : 1.3908283662796022 TRAIN  loss dict:  {'classification_loss': 1.3908283662796022}
2025-01-12 15:38:23,604 [INFO] Step[3050/4329]: training loss : 1.473503749370575 TRAIN  loss dict:  {'classification_loss': 1.473503749370575}
2025-01-12 15:38:35,263 [INFO] Step[3100/4329]: training loss : 1.5284990406036376 TRAIN  loss dict:  {'classification_loss': 1.5284990406036376}
2025-01-12 15:38:46,917 [INFO] Step[3150/4329]: training loss : 1.5920450496673584 TRAIN  loss dict:  {'classification_loss': 1.5920450496673584}
2025-01-12 15:38:58,571 [INFO] Step[3200/4329]: training loss : 1.5491010975837707 TRAIN  loss dict:  {'classification_loss': 1.5491010975837707}
2025-01-12 15:39:10,194 [INFO] Step[3250/4329]: training loss : 1.4967240715026855 TRAIN  loss dict:  {'classification_loss': 1.4967240715026855}
2025-01-12 15:39:21,863 [INFO] Step[3300/4329]: training loss : 1.6100250065326691 TRAIN  loss dict:  {'classification_loss': 1.6100250065326691}
2025-01-12 15:39:33,538 [INFO] Step[3350/4329]: training loss : 1.6356402277946471 TRAIN  loss dict:  {'classification_loss': 1.6356402277946471}
2025-01-12 15:39:45,131 [INFO] Step[3400/4329]: training loss : 1.4143008446693421 TRAIN  loss dict:  {'classification_loss': 1.4143008446693421}
2025-01-12 15:39:56,814 [INFO] Step[3450/4329]: training loss : 1.4412100553512572 TRAIN  loss dict:  {'classification_loss': 1.4412100553512572}
2025-01-12 15:40:08,433 [INFO] Step[3500/4329]: training loss : 1.4816456377506255 TRAIN  loss dict:  {'classification_loss': 1.4816456377506255}
2025-01-12 15:40:20,047 [INFO] Step[3550/4329]: training loss : 1.5944136583805084 TRAIN  loss dict:  {'classification_loss': 1.5944136583805084}
2025-01-12 15:40:31,654 [INFO] Step[3600/4329]: training loss : 1.499291160106659 TRAIN  loss dict:  {'classification_loss': 1.499291160106659}
2025-01-12 15:40:43,282 [INFO] Step[3650/4329]: training loss : 1.4481865966320038 TRAIN  loss dict:  {'classification_loss': 1.4481865966320038}
2025-01-12 15:40:54,935 [INFO] Step[3700/4329]: training loss : 1.4451708996295929 TRAIN  loss dict:  {'classification_loss': 1.4451708996295929}
2025-01-12 15:41:06,581 [INFO] Step[3750/4329]: training loss : 1.5854036104679108 TRAIN  loss dict:  {'classification_loss': 1.5854036104679108}
2025-01-12 15:41:18,234 [INFO] Step[3800/4329]: training loss : 1.5116928017139435 TRAIN  loss dict:  {'classification_loss': 1.5116928017139435}
2025-01-12 15:41:29,848 [INFO] Step[3850/4329]: training loss : 1.5252199852466584 TRAIN  loss dict:  {'classification_loss': 1.5252199852466584}
2025-01-12 15:41:41,529 [INFO] Step[3900/4329]: training loss : 1.5311401832103728 TRAIN  loss dict:  {'classification_loss': 1.5311401832103728}
2025-01-12 15:41:53,174 [INFO] Step[3950/4329]: training loss : 1.5044404113292693 TRAIN  loss dict:  {'classification_loss': 1.5044404113292693}
2025-01-12 15:42:04,788 [INFO] Step[4000/4329]: training loss : 1.531724853515625 TRAIN  loss dict:  {'classification_loss': 1.531724853515625}
2025-01-12 15:42:16,427 [INFO] Step[4050/4329]: training loss : 1.3872865128517151 TRAIN  loss dict:  {'classification_loss': 1.3872865128517151}
2025-01-12 15:42:28,109 [INFO] Step[4100/4329]: training loss : 1.4133311593532563 TRAIN  loss dict:  {'classification_loss': 1.4133311593532563}
2025-01-12 15:42:39,788 [INFO] Step[4150/4329]: training loss : 1.467483172416687 TRAIN  loss dict:  {'classification_loss': 1.467483172416687}
2025-01-12 15:42:51,427 [INFO] Step[4200/4329]: training loss : 1.4938367450237273 TRAIN  loss dict:  {'classification_loss': 1.4938367450237273}
2025-01-12 15:43:03,062 [INFO] Step[4250/4329]: training loss : 1.544510966539383 TRAIN  loss dict:  {'classification_loss': 1.544510966539383}
2025-01-12 15:43:14,639 [INFO] Step[4300/4329]: training loss : 1.5477723848819733 TRAIN  loss dict:  {'classification_loss': 1.5477723848819733}
2025-01-12 15:45:31,390 [INFO] Label accuracies statistics:
2025-01-12 15:45:31,390 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.6666666666666666, 3: 0.6666666666666666, 4: 0.3333333333333333, 5: 0.9166666666666666, 6: 0.5, 7: 0.3333333333333333, 8: 0.25, 9: 0.8333333333333334, 10: 1.0, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.4166666666666667, 14: 0.5, 15: 0.3333333333333333, 16: 0.25, 17: 0.4166666666666667, 18: 0.5833333333333334, 19: 0.5, 20: 0.6666666666666666, 21: 0.4166666666666667, 22: 0.6666666666666666, 23: 0.9166666666666666, 24: 0.8333333333333334, 25: 0.5, 26: 0.6666666666666666, 27: 0.6666666666666666, 28: 0.5833333333333334, 29: 1.0, 30: 0.5, 31: 0.5833333333333334, 32: 0.5, 33: 0.6666666666666666, 34: 0.6666666666666666, 35: 0.9166666666666666, 36: 0.5, 37: 0.8333333333333334, 38: 0.9166666666666666, 39: 0.9166666666666666, 40: 0.9166666666666666, 41: 0.3333333333333333, 42: 0.8333333333333334, 43: 0.8333333333333334, 44: 0.4166666666666667, 45: 0.5833333333333334, 46: 1.0, 47: 0.9166666666666666, 48: 0.6666666666666666, 49: 1.0, 50: 0.5833333333333334, 51: 0.5833333333333334, 52: 0.9166666666666666, 53: 0.4166666666666667, 54: 0.25, 55: 0.5833333333333334, 56: 0.6666666666666666, 57: 0.5833333333333334, 58: 0.25, 59: 0.6666666666666666, 60: 0.4166666666666667, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.3333333333333333, 67: 0.6666666666666666, 68: 0.4166666666666667, 69: 0.5833333333333334, 70: 0.4166666666666667, 71: 0.75, 72: 0.5833333333333334, 73: 0.6666666666666666, 74: 0.5833333333333334, 75: 0.9166666666666666, 76: 0.3333333333333333, 77: 0.5833333333333334, 78: 0.9166666666666666, 79: 0.5833333333333334, 80: 0.9166666666666666, 81: 1.0, 82: 0.75, 83: 0.5833333333333334, 84: 0.3333333333333333, 85: 0.5, 86: 0.5833333333333334, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.25, 91: 0.8333333333333334, 92: 0.9166666666666666, 93: 1.0, 94: 0.3333333333333333, 95: 0.9166666666666666, 96: 0.25, 97: 0.6666666666666666, 98: 0.8333333333333334, 99: 0.8666666666666667, 100: 0.5833333333333334, 101: 0.75, 102: 0.8333333333333334, 103: 0.5833333333333334, 104: 1.0, 105: 0.8333333333333334, 106: 0.8333333333333334, 107: 0.8333333333333334, 108: 0.8333333333333334, 109: 0.8333333333333334, 110: 0.5833333333333334, 111: 0.75, 112: 0.6666666666666666, 113: 0.16666666666666666, 114: 1.0, 115: 0.9166666666666666, 116: 0.4166666666666667, 117: 0.5, 118: 0.8333333333333334, 119: 0.6666666666666666, 120: 0.75, 121: 0.6666666666666666, 122: 0.6666666666666666, 123: 0.75, 124: 0.8333333333333334, 125: 0.75, 126: 0.5833333333333334, 127: 0.6666666666666666, 128: 0.9166666666666666, 129: 0.6666666666666666, 130: 0.75, 131: 0.9166666666666666, 132: 0.08333333333333333, 133: 1.0, 134: 0.5, 135: 0.9166666666666666, 136: 0.8333333333333334, 137: 0.6666666666666666, 138: 0.5833333333333334, 139: 0.8333333333333334, 140: 0.6666666666666666, 141: 0.9166666666666666, 142: 0.9166666666666666, 143: 0.75, 144: 0.5, 145: 0.75, 146: 0.8333333333333334, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 0.75, 153: 0.5, 154: 0.8333333333333334, 155: 0.6666666666666666, 156: 0.5, 157: 0.8333333333333334, 158: 0.3333333333333333, 159: 0.8333333333333334, 160: 0.3333333333333333, 161: 0.5833333333333334, 162: 0.8333333333333334, 163: 0.9166666666666666, 164: 0.5, 165: 0.5833333333333334, 166: 0.5833333333333334, 167: 0.4166666666666667, 168: 0.5833333333333334, 169: 0.8333333333333334, 170: 0.9166666666666666, 171: 0.4166666666666667, 172: 0.8333333333333334, 173: 0.75, 174: 1.0, 175: 0.8333333333333334, 176: 1.0, 177: 0.9166666666666666, 178: 0.9166666666666666, 179: 0.3333333333333333, 180: 0.5833333333333334, 181: 0.75, 182: 0.16666666666666666, 183: 0.5833333333333334, 184: 0.8333333333333334, 185: 1.0, 186: 0.3333333333333333, 187: 1.0, 188: 0.6666666666666666, 189: 0.6666666666666666, 190: 0.4166666666666667, 191: 0.16666666666666666, 192: 0.8333333333333334, 193: 0.8333333333333334, 194: 0.8333333333333334, 195: 0.9166666666666666, 196: 0.75, 197: 0.5833333333333334, 198: 0.6666666666666666}

2025-01-12 15:46:12,381 [INFO] [3] TRAIN  loss: 1.4861368319679282 acc: 0.8213460649930695
2025-01-12 15:46:12,381 [INFO] [3] TRAIN  loss dict: {'classification_loss': 1.4861368319679282}
2025-01-12 15:46:12,381 [INFO] [3] VALIDATION loss: 2.049631218567039 VALIDATION acc: 0.6746632996632996
2025-01-12 15:46:12,381 [INFO] [3] VALIDATION loss dict: {'classification_loss': 2.049631218567039}
2025-01-12 15:46:12,381 [INFO] 
2025-01-12 15:46:29,642 [INFO] Step[50/4329]: training loss : 1.362797577381134 TRAIN  loss dict:  {'classification_loss': 1.362797577381134}
2025-01-12 15:46:41,198 [INFO] Step[100/4329]: training loss : 1.207512741088867 TRAIN  loss dict:  {'classification_loss': 1.207512741088867}
2025-01-12 15:46:52,780 [INFO] Step[150/4329]: training loss : 1.3528474104404449 TRAIN  loss dict:  {'classification_loss': 1.3528474104404449}
2025-01-12 15:47:04,392 [INFO] Step[200/4329]: training loss : 1.2922278535366059 TRAIN  loss dict:  {'classification_loss': 1.2922278535366059}
2025-01-12 15:47:16,013 [INFO] Step[250/4329]: training loss : 1.3520769107341766 TRAIN  loss dict:  {'classification_loss': 1.3520769107341766}
2025-01-12 15:47:27,641 [INFO] Step[300/4329]: training loss : 1.4533715391159057 TRAIN  loss dict:  {'classification_loss': 1.4533715391159057}
2025-01-12 15:47:39,256 [INFO] Step[350/4329]: training loss : 1.3042986977100373 TRAIN  loss dict:  {'classification_loss': 1.3042986977100373}
2025-01-12 15:47:50,900 [INFO] Step[400/4329]: training loss : 1.4070895624160766 TRAIN  loss dict:  {'classification_loss': 1.4070895624160766}
2025-01-12 15:48:02,528 [INFO] Step[450/4329]: training loss : 1.2751393008232117 TRAIN  loss dict:  {'classification_loss': 1.2751393008232117}
2025-01-12 15:48:14,137 [INFO] Step[500/4329]: training loss : 1.2423122358322143 TRAIN  loss dict:  {'classification_loss': 1.2423122358322143}
2025-01-12 15:48:26,147 [INFO] Step[550/4329]: training loss : 1.4005518341064453 TRAIN  loss dict:  {'classification_loss': 1.4005518341064453}
2025-01-12 15:48:38,608 [INFO] Step[600/4329]: training loss : 1.3172067058086396 TRAIN  loss dict:  {'classification_loss': 1.3172067058086396}
2025-01-12 15:48:50,990 [INFO] Step[650/4329]: training loss : 1.4327704310417175 TRAIN  loss dict:  {'classification_loss': 1.4327704310417175}
2025-01-12 15:49:04,965 [INFO] Step[700/4329]: training loss : 1.3919950461387633 TRAIN  loss dict:  {'classification_loss': 1.3919950461387633}
2025-01-12 15:49:18,285 [INFO] Step[750/4329]: training loss : 1.3341882014274598 TRAIN  loss dict:  {'classification_loss': 1.3341882014274598}
2025-01-12 15:49:30,398 [INFO] Step[800/4329]: training loss : 1.336818323135376 TRAIN  loss dict:  {'classification_loss': 1.336818323135376}
2025-01-12 15:49:42,306 [INFO] Step[850/4329]: training loss : 1.32545841217041 TRAIN  loss dict:  {'classification_loss': 1.32545841217041}
2025-01-12 15:49:54,186 [INFO] Step[900/4329]: training loss : 1.4316746258735658 TRAIN  loss dict:  {'classification_loss': 1.4316746258735658}
2025-01-12 15:50:05,857 [INFO] Step[950/4329]: training loss : 1.3037040877342223 TRAIN  loss dict:  {'classification_loss': 1.3037040877342223}
2025-01-12 15:50:17,503 [INFO] Step[1000/4329]: training loss : 1.3605745029449463 TRAIN  loss dict:  {'classification_loss': 1.3605745029449463}
2025-01-12 15:50:29,110 [INFO] Step[1050/4329]: training loss : 1.3401786303520202 TRAIN  loss dict:  {'classification_loss': 1.3401786303520202}
2025-01-12 15:50:40,786 [INFO] Step[1100/4329]: training loss : 1.3166272056102752 TRAIN  loss dict:  {'classification_loss': 1.3166272056102752}
2025-01-12 15:50:52,431 [INFO] Step[1150/4329]: training loss : 1.426186476945877 TRAIN  loss dict:  {'classification_loss': 1.426186476945877}
2025-01-12 15:51:04,063 [INFO] Step[1200/4329]: training loss : 1.229601390361786 TRAIN  loss dict:  {'classification_loss': 1.229601390361786}
2025-01-12 15:51:15,697 [INFO] Step[1250/4329]: training loss : 1.3346784126758575 TRAIN  loss dict:  {'classification_loss': 1.3346784126758575}
2025-01-12 15:51:27,346 [INFO] Step[1300/4329]: training loss : 1.446193231344223 TRAIN  loss dict:  {'classification_loss': 1.446193231344223}
2025-01-12 15:51:38,999 [INFO] Step[1350/4329]: training loss : 1.4897555136680602 TRAIN  loss dict:  {'classification_loss': 1.4897555136680602}
2025-01-12 15:51:50,620 [INFO] Step[1400/4329]: training loss : 1.471919251680374 TRAIN  loss dict:  {'classification_loss': 1.471919251680374}
2025-01-12 15:52:02,257 [INFO] Step[1450/4329]: training loss : 1.4673727810382844 TRAIN  loss dict:  {'classification_loss': 1.4673727810382844}
2025-01-12 15:52:13,884 [INFO] Step[1500/4329]: training loss : 1.3188699066638947 TRAIN  loss dict:  {'classification_loss': 1.3188699066638947}
2025-01-12 15:52:25,556 [INFO] Step[1550/4329]: training loss : 1.3416690230369568 TRAIN  loss dict:  {'classification_loss': 1.3416690230369568}
2025-01-12 15:52:37,218 [INFO] Step[1600/4329]: training loss : 1.37774489402771 TRAIN  loss dict:  {'classification_loss': 1.37774489402771}
2025-01-12 15:52:48,869 [INFO] Step[1650/4329]: training loss : 1.4091400742530822 TRAIN  loss dict:  {'classification_loss': 1.4091400742530822}
2025-01-12 15:53:00,529 [INFO] Step[1700/4329]: training loss : 1.4999380552768706 TRAIN  loss dict:  {'classification_loss': 1.4999380552768706}
2025-01-12 15:53:12,157 [INFO] Step[1750/4329]: training loss : 1.3396095907688141 TRAIN  loss dict:  {'classification_loss': 1.3396095907688141}
2025-01-12 15:53:23,788 [INFO] Step[1800/4329]: training loss : 1.3044311308860779 TRAIN  loss dict:  {'classification_loss': 1.3044311308860779}
2025-01-12 15:53:35,493 [INFO] Step[1850/4329]: training loss : 1.4702178263664245 TRAIN  loss dict:  {'classification_loss': 1.4702178263664245}
2025-01-12 15:53:47,178 [INFO] Step[1900/4329]: training loss : 1.429503355026245 TRAIN  loss dict:  {'classification_loss': 1.429503355026245}
2025-01-12 15:53:58,822 [INFO] Step[1950/4329]: training loss : 1.4149465870857239 TRAIN  loss dict:  {'classification_loss': 1.4149465870857239}
2025-01-12 15:54:10,495 [INFO] Step[2000/4329]: training loss : 1.5527724289894105 TRAIN  loss dict:  {'classification_loss': 1.5527724289894105}
2025-01-12 15:54:22,097 [INFO] Step[2050/4329]: training loss : 1.380762140750885 TRAIN  loss dict:  {'classification_loss': 1.380762140750885}
2025-01-12 15:54:33,787 [INFO] Step[2100/4329]: training loss : 1.3159047150611878 TRAIN  loss dict:  {'classification_loss': 1.3159047150611878}
2025-01-12 15:54:45,428 [INFO] Step[2150/4329]: training loss : 1.4316407001018525 TRAIN  loss dict:  {'classification_loss': 1.4316407001018525}
2025-01-12 15:54:57,078 [INFO] Step[2200/4329]: training loss : 1.3571476173400878 TRAIN  loss dict:  {'classification_loss': 1.3571476173400878}
2025-01-12 15:55:08,740 [INFO] Step[2250/4329]: training loss : 1.4175351059436798 TRAIN  loss dict:  {'classification_loss': 1.4175351059436798}
2025-01-12 15:55:20,412 [INFO] Step[2300/4329]: training loss : 1.4909858465194703 TRAIN  loss dict:  {'classification_loss': 1.4909858465194703}
2025-01-12 15:55:32,032 [INFO] Step[2350/4329]: training loss : 1.3744020009040832 TRAIN  loss dict:  {'classification_loss': 1.3744020009040832}
2025-01-12 15:55:43,677 [INFO] Step[2400/4329]: training loss : 1.5040788662433624 TRAIN  loss dict:  {'classification_loss': 1.5040788662433624}
2025-01-12 15:55:55,329 [INFO] Step[2450/4329]: training loss : 1.3340300810337067 TRAIN  loss dict:  {'classification_loss': 1.3340300810337067}
2025-01-12 15:56:06,975 [INFO] Step[2500/4329]: training loss : 1.410750676393509 TRAIN  loss dict:  {'classification_loss': 1.410750676393509}
2025-01-12 15:56:18,654 [INFO] Step[2550/4329]: training loss : 1.4498613202571868 TRAIN  loss dict:  {'classification_loss': 1.4498613202571868}
2025-01-12 15:56:30,333 [INFO] Step[2600/4329]: training loss : 1.3542909824848175 TRAIN  loss dict:  {'classification_loss': 1.3542909824848175}
2025-01-12 15:56:41,981 [INFO] Step[2650/4329]: training loss : 1.5025800311565398 TRAIN  loss dict:  {'classification_loss': 1.5025800311565398}
2025-01-12 15:56:53,623 [INFO] Step[2700/4329]: training loss : 1.398903992176056 TRAIN  loss dict:  {'classification_loss': 1.398903992176056}
2025-01-12 15:57:05,252 [INFO] Step[2750/4329]: training loss : 1.4613601458072663 TRAIN  loss dict:  {'classification_loss': 1.4613601458072663}
2025-01-12 15:57:16,848 [INFO] Step[2800/4329]: training loss : 1.3750766468048097 TRAIN  loss dict:  {'classification_loss': 1.3750766468048097}
2025-01-12 15:57:28,462 [INFO] Step[2850/4329]: training loss : 1.4457044398784638 TRAIN  loss dict:  {'classification_loss': 1.4457044398784638}
2025-01-12 15:57:40,104 [INFO] Step[2900/4329]: training loss : 1.3844482576847077 TRAIN  loss dict:  {'classification_loss': 1.3844482576847077}
2025-01-12 15:57:51,721 [INFO] Step[2950/4329]: training loss : 1.504434027671814 TRAIN  loss dict:  {'classification_loss': 1.504434027671814}
2025-01-12 15:58:03,367 [INFO] Step[3000/4329]: training loss : 1.454039113521576 TRAIN  loss dict:  {'classification_loss': 1.454039113521576}
2025-01-12 15:58:15,009 [INFO] Step[3050/4329]: training loss : 1.5076678252220155 TRAIN  loss dict:  {'classification_loss': 1.5076678252220155}
2025-01-12 15:58:26,627 [INFO] Step[3100/4329]: training loss : 1.478468188047409 TRAIN  loss dict:  {'classification_loss': 1.478468188047409}
2025-01-12 15:58:38,253 [INFO] Step[3150/4329]: training loss : 1.4911223125457764 TRAIN  loss dict:  {'classification_loss': 1.4911223125457764}
2025-01-12 15:58:49,912 [INFO] Step[3200/4329]: training loss : 1.4920270895957948 TRAIN  loss dict:  {'classification_loss': 1.4920270895957948}
2025-01-12 15:59:01,572 [INFO] Step[3250/4329]: training loss : 1.445863938331604 TRAIN  loss dict:  {'classification_loss': 1.445863938331604}
2025-01-12 15:59:13,180 [INFO] Step[3300/4329]: training loss : 1.292628229856491 TRAIN  loss dict:  {'classification_loss': 1.292628229856491}
2025-01-12 15:59:24,827 [INFO] Step[3350/4329]: training loss : 1.2819719505310059 TRAIN  loss dict:  {'classification_loss': 1.2819719505310059}
2025-01-12 15:59:36,489 [INFO] Step[3400/4329]: training loss : 1.5455712842941285 TRAIN  loss dict:  {'classification_loss': 1.5455712842941285}
2025-01-12 15:59:48,150 [INFO] Step[3450/4329]: training loss : 1.3895859920978546 TRAIN  loss dict:  {'classification_loss': 1.3895859920978546}
2025-01-12 15:59:59,766 [INFO] Step[3500/4329]: training loss : 1.392138466835022 TRAIN  loss dict:  {'classification_loss': 1.392138466835022}
2025-01-12 16:00:11,395 [INFO] Step[3550/4329]: training loss : 1.3891726112365723 TRAIN  loss dict:  {'classification_loss': 1.3891726112365723}
2025-01-12 16:00:23,033 [INFO] Step[3600/4329]: training loss : 1.5020424628257751 TRAIN  loss dict:  {'classification_loss': 1.5020424628257751}
2025-01-12 16:00:34,732 [INFO] Step[3650/4329]: training loss : 1.3912622427940369 TRAIN  loss dict:  {'classification_loss': 1.3912622427940369}
2025-01-12 16:00:46,726 [INFO] Step[3700/4329]: training loss : 1.4220775437355042 TRAIN  loss dict:  {'classification_loss': 1.4220775437355042}
2025-01-12 16:00:59,039 [INFO] Step[3750/4329]: training loss : 1.3321243119239807 TRAIN  loss dict:  {'classification_loss': 1.3321243119239807}
2025-01-12 16:01:11,362 [INFO] Step[3800/4329]: training loss : 1.402677835226059 TRAIN  loss dict:  {'classification_loss': 1.402677835226059}
2025-01-12 16:01:24,495 [INFO] Step[3850/4329]: training loss : 1.4634764432907104 TRAIN  loss dict:  {'classification_loss': 1.4634764432907104}
2025-01-12 16:01:38,162 [INFO] Step[3900/4329]: training loss : 1.3975197160243988 TRAIN  loss dict:  {'classification_loss': 1.3975197160243988}
2025-01-12 16:01:50,253 [INFO] Step[3950/4329]: training loss : 1.5061597633361816 TRAIN  loss dict:  {'classification_loss': 1.5061597633361816}
2025-01-12 16:02:02,155 [INFO] Step[4000/4329]: training loss : 1.3673460614681243 TRAIN  loss dict:  {'classification_loss': 1.3673460614681243}
2025-01-12 16:02:13,993 [INFO] Step[4050/4329]: training loss : 1.4370765280723572 TRAIN  loss dict:  {'classification_loss': 1.4370765280723572}
2025-01-12 16:02:25,648 [INFO] Step[4100/4329]: training loss : 1.3747337102890014 TRAIN  loss dict:  {'classification_loss': 1.3747337102890014}
2025-01-12 16:02:37,299 [INFO] Step[4150/4329]: training loss : 1.3803277671337129 TRAIN  loss dict:  {'classification_loss': 1.3803277671337129}
2025-01-12 16:02:48,917 [INFO] Step[4200/4329]: training loss : 1.3697118318080903 TRAIN  loss dict:  {'classification_loss': 1.3697118318080903}
2025-01-12 16:03:00,532 [INFO] Step[4250/4329]: training loss : 1.3713146317005158 TRAIN  loss dict:  {'classification_loss': 1.3713146317005158}
2025-01-12 16:03:12,113 [INFO] Step[4300/4329]: training loss : 1.443857613801956 TRAIN  loss dict:  {'classification_loss': 1.443857613801956}
2025-01-12 16:05:11,962 [INFO] Label accuracies statistics:
2025-01-12 16:05:11,962 [INFO] {0: 0.4444444444444444, 1: 0.7777777777777778, 2: 0.5, 3: 0.75, 4: 0.3333333333333333, 5: 0.9166666666666666, 6: 0.5, 7: 0.4166666666666667, 8: 0.3333333333333333, 9: 0.8333333333333334, 10: 0.8333333333333334, 11: 1.0, 12: 0.4166666666666667, 13: 0.4166666666666667, 14: 0.5833333333333334, 15: 0.5555555555555556, 16: 0.3333333333333333, 17: 0.3333333333333333, 18: 0.5833333333333334, 19: 0.6666666666666666, 20: 0.4166666666666667, 21: 0.4166666666666667, 22: 0.5, 23: 0.9166666666666666, 24: 0.9166666666666666, 25: 0.5, 26: 0.8333333333333334, 27: 0.5833333333333334, 28: 0.75, 29: 0.9166666666666666, 30: 0.4166666666666667, 31: 0.5, 32: 0.5833333333333334, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.4166666666666667, 37: 1.0, 38: 1.0, 39: 0.9166666666666666, 40: 0.75, 41: 0.25, 42: 0.8333333333333334, 43: 0.6666666666666666, 44: 0.5, 45: 0.5833333333333334, 46: 1.0, 47: 0.8333333333333334, 48: 0.8333333333333334, 49: 1.0, 50: 0.5833333333333334, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.16666666666666666, 55: 0.5833333333333334, 56: 0.3333333333333333, 57: 0.5, 58: 0.4166666666666667, 59: 0.5833333333333334, 60: 0.5833333333333334, 61: 0.6666666666666666, 62: 0.75, 63: 0.4166666666666667, 64: 0.9166666666666666, 65: 1.0, 66: 0.6666666666666666, 67: 0.8333333333333334, 68: 0.5, 69: 0.5, 70: 0.25, 71: 0.5833333333333334, 72: 0.8333333333333334, 73: 0.6666666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.25, 77: 0.5833333333333334, 78: 1.0, 79: 0.5, 80: 0.9166666666666666, 81: 0.8333333333333334, 82: 0.6666666666666666, 83: 0.75, 84: 0.5, 85: 0.6666666666666666, 86: 0.4166666666666667, 87: 1.0, 88: 0.75, 89: 0.6666666666666666, 90: 0.5833333333333334, 91: 0.5833333333333334, 92: 1.0, 93: 0.9166666666666666, 94: 0.5, 95: 0.9166666666666666, 96: 0.16666666666666666, 97: 0.5, 98: 0.8333333333333334, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.6666666666666666, 103: 0.8333333333333334, 104: 0.8333333333333334, 105: 0.9166666666666666, 106: 0.8333333333333334, 107: 0.75, 108: 0.8333333333333334, 109: 0.8333333333333334, 110: 0.9166666666666666, 111: 0.9166666666666666, 112: 0.8333333333333334, 113: 0.6666666666666666, 114: 0.16666666666666666, 115: 1.0, 116: 0.5833333333333334, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.25, 121: 0.5, 122: 0.8333333333333334, 123: 1.0, 124: 1.0, 125: 0.75, 126: 0.9166666666666666, 127: 0.75, 128: 1.0, 129: 0.8333333333333334, 130: 0.9166666666666666, 131: 0.8333333333333334, 132: 0.75, 133: 1.0, 134: 0.8333333333333334, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.8333333333333334, 138: 0.8333333333333334, 139: 0.75, 140: 1.0, 141: 0.8333333333333334, 142: 0.75, 143: 1.0, 144: 0.5833333333333334, 145: 0.5833333333333334, 146: 0.6666666666666666, 147: 0.75, 148: 0.6666666666666666, 149: 1.0, 150: 0.3333333333333333, 151: 0.9166666666666666, 152: 0.8333333333333334, 153: 0.9166666666666666, 154: 0.8333333333333334, 155: 1.0, 156: 0.3333333333333333, 157: 0.75, 158: 0.5555555555555556, 159: 1.0, 160: 0.3333333333333333, 161: 0.6666666666666666, 162: 0.8333333333333334, 163: 0.8333333333333334, 164: 0.5, 165: 0.8333333333333334, 166: 0.6666666666666666, 167: 0.5, 168: 0.75, 169: 0.8333333333333334, 170: 0.9166666666666666, 171: 0.4166666666666667, 172: 1.0, 173: 1.0, 174: 1.0, 175: 0.6666666666666666, 176: 0.9166666666666666, 177: 0.75, 178: 0.8333333333333334, 179: 0.3333333333333333, 180: 0.75, 181: 0.8333333333333334, 182: 0.6666666666666666, 183: 0.75, 184: 0.8333333333333334, 185: 0.9166666666666666, 186: 0.75, 187: 1.0, 188: 0.6666666666666666, 189: 0.9166666666666666, 190: 0.5833333333333334, 191: 0.4166666666666667, 192: 0.8333333333333334, 193: 0.5833333333333334, 194: 0.9166666666666666, 195: 1.0, 196: 0.9166666666666666, 197: 0.5833333333333334, 198: 0.5833333333333334}

2025-01-12 16:05:28,312 [INFO] [4] TRAIN  loss: 1.3954068075071226 acc: 0.848144155244109
2025-01-12 16:05:28,312 [INFO] [4] TRAIN  loss dict: {'classification_loss': 1.3954068075071226}
2025-01-12 16:05:28,312 [INFO] [4] VALIDATION loss: 1.9615675730235649 VALIDATION acc: 0.7125420875420876
2025-01-12 16:05:28,312 [INFO] [4] VALIDATION loss dict: {'classification_loss': 1.9615675730235649}
2025-01-12 16:05:28,312 [INFO] 
2025-01-12 16:05:45,885 [INFO] Step[50/4329]: training loss : 1.2322914493083954 TRAIN  loss dict:  {'classification_loss': 1.2322914493083954}
2025-01-12 16:05:57,436 [INFO] Step[100/4329]: training loss : 1.2600844609737396 TRAIN  loss dict:  {'classification_loss': 1.2600844609737396}
2025-01-12 16:06:09,032 [INFO] Step[150/4329]: training loss : 1.2630127823352815 TRAIN  loss dict:  {'classification_loss': 1.2630127823352815}
2025-01-12 16:06:20,616 [INFO] Step[200/4329]: training loss : 1.3396116662025452 TRAIN  loss dict:  {'classification_loss': 1.3396116662025452}
2025-01-12 16:06:32,287 [INFO] Step[250/4329]: training loss : 1.4158267045021058 TRAIN  loss dict:  {'classification_loss': 1.4158267045021058}
2025-01-12 16:06:43,903 [INFO] Step[300/4329]: training loss : 1.2389967358112335 TRAIN  loss dict:  {'classification_loss': 1.2389967358112335}
2025-01-12 16:06:55,566 [INFO] Step[350/4329]: training loss : 1.2020118391513825 TRAIN  loss dict:  {'classification_loss': 1.2020118391513825}
2025-01-12 16:07:07,181 [INFO] Step[400/4329]: training loss : 1.1976860916614533 TRAIN  loss dict:  {'classification_loss': 1.1976860916614533}
2025-01-12 16:07:18,847 [INFO] Step[450/4329]: training loss : 1.2433125054836274 TRAIN  loss dict:  {'classification_loss': 1.2433125054836274}
2025-01-12 16:07:30,460 [INFO] Step[500/4329]: training loss : 1.327799974679947 TRAIN  loss dict:  {'classification_loss': 1.327799974679947}
2025-01-12 16:07:42,077 [INFO] Step[550/4329]: training loss : 1.2822655296325685 TRAIN  loss dict:  {'classification_loss': 1.2822655296325685}
2025-01-12 16:07:53,737 [INFO] Step[600/4329]: training loss : 1.3460229897499085 TRAIN  loss dict:  {'classification_loss': 1.3460229897499085}
2025-01-12 16:08:05,441 [INFO] Step[650/4329]: training loss : 1.3991485118865967 TRAIN  loss dict:  {'classification_loss': 1.3991485118865967}
2025-01-12 16:08:17,100 [INFO] Step[700/4329]: training loss : 1.4053834092617035 TRAIN  loss dict:  {'classification_loss': 1.4053834092617035}
2025-01-12 16:08:28,747 [INFO] Step[750/4329]: training loss : 1.407358684539795 TRAIN  loss dict:  {'classification_loss': 1.407358684539795}
2025-01-12 16:08:40,417 [INFO] Step[800/4329]: training loss : 1.3273448288440703 TRAIN  loss dict:  {'classification_loss': 1.3273448288440703}
2025-01-12 16:08:52,086 [INFO] Step[850/4329]: training loss : 1.2623280596733093 TRAIN  loss dict:  {'classification_loss': 1.2623280596733093}
2025-01-12 16:09:03,719 [INFO] Step[900/4329]: training loss : 1.2924958431720734 TRAIN  loss dict:  {'classification_loss': 1.2924958431720734}
2025-01-12 16:09:15,365 [INFO] Step[950/4329]: training loss : 1.468855426311493 TRAIN  loss dict:  {'classification_loss': 1.468855426311493}
2025-01-12 16:09:27,005 [INFO] Step[1000/4329]: training loss : 1.3780652177333832 TRAIN  loss dict:  {'classification_loss': 1.3780652177333832}
2025-01-12 16:09:38,661 [INFO] Step[1050/4329]: training loss : 1.2997794246673584 TRAIN  loss dict:  {'classification_loss': 1.2997794246673584}
2025-01-12 16:09:50,310 [INFO] Step[1100/4329]: training loss : 1.243010982275009 TRAIN  loss dict:  {'classification_loss': 1.243010982275009}
2025-01-12 16:10:01,994 [INFO] Step[1150/4329]: training loss : 1.475650943517685 TRAIN  loss dict:  {'classification_loss': 1.475650943517685}
2025-01-12 16:10:13,654 [INFO] Step[1200/4329]: training loss : 1.343149062395096 TRAIN  loss dict:  {'classification_loss': 1.343149062395096}
2025-01-12 16:10:25,293 [INFO] Step[1250/4329]: training loss : 1.2269264602661132 TRAIN  loss dict:  {'classification_loss': 1.2269264602661132}
2025-01-12 16:10:36,886 [INFO] Step[1300/4329]: training loss : 1.3701797115802765 TRAIN  loss dict:  {'classification_loss': 1.3701797115802765}
2025-01-12 16:10:48,545 [INFO] Step[1350/4329]: training loss : 1.2891004514694213 TRAIN  loss dict:  {'classification_loss': 1.2891004514694213}
2025-01-12 16:11:00,235 [INFO] Step[1400/4329]: training loss : 1.4135511410236359 TRAIN  loss dict:  {'classification_loss': 1.4135511410236359}
2025-01-12 16:11:11,882 [INFO] Step[1450/4329]: training loss : 1.3657774329185486 TRAIN  loss dict:  {'classification_loss': 1.3657774329185486}
2025-01-12 16:11:23,492 [INFO] Step[1500/4329]: training loss : 1.3966135668754578 TRAIN  loss dict:  {'classification_loss': 1.3966135668754578}
2025-01-12 16:11:35,109 [INFO] Step[1550/4329]: training loss : 1.314776338338852 TRAIN  loss dict:  {'classification_loss': 1.314776338338852}
2025-01-12 16:11:46,803 [INFO] Step[1600/4329]: training loss : 1.492272642850876 TRAIN  loss dict:  {'classification_loss': 1.492272642850876}
2025-01-12 16:11:58,509 [INFO] Step[1650/4329]: training loss : 1.306836119890213 TRAIN  loss dict:  {'classification_loss': 1.306836119890213}
2025-01-12 16:12:10,153 [INFO] Step[1700/4329]: training loss : 1.3249403965473174 TRAIN  loss dict:  {'classification_loss': 1.3249403965473174}
2025-01-12 16:12:21,814 [INFO] Step[1750/4329]: training loss : 1.3905524337291717 TRAIN  loss dict:  {'classification_loss': 1.3905524337291717}
2025-01-12 16:12:33,483 [INFO] Step[1800/4329]: training loss : 1.320263673067093 TRAIN  loss dict:  {'classification_loss': 1.320263673067093}
2025-01-12 16:12:45,116 [INFO] Step[1850/4329]: training loss : 1.3138465142250062 TRAIN  loss dict:  {'classification_loss': 1.3138465142250062}
2025-01-12 16:12:56,739 [INFO] Step[1900/4329]: training loss : 1.3153868508338928 TRAIN  loss dict:  {'classification_loss': 1.3153868508338928}
2025-01-12 16:13:08,583 [INFO] Step[1950/4329]: training loss : 1.299254411458969 TRAIN  loss dict:  {'classification_loss': 1.299254411458969}
2025-01-12 16:13:21,018 [INFO] Step[2000/4329]: training loss : 1.3081921100616456 TRAIN  loss dict:  {'classification_loss': 1.3081921100616456}
2025-01-12 16:13:33,430 [INFO] Step[2050/4329]: training loss : 1.362169851064682 TRAIN  loss dict:  {'classification_loss': 1.362169851064682}
2025-01-12 16:13:46,433 [INFO] Step[2100/4329]: training loss : 1.24862708568573 TRAIN  loss dict:  {'classification_loss': 1.24862708568573}
2025-01-12 16:13:59,990 [INFO] Step[2150/4329]: training loss : 1.3230266988277435 TRAIN  loss dict:  {'classification_loss': 1.3230266988277435}
2025-01-12 16:14:12,388 [INFO] Step[2200/4329]: training loss : 1.3113596940040588 TRAIN  loss dict:  {'classification_loss': 1.3113596940040588}
2025-01-12 16:14:24,296 [INFO] Step[2250/4329]: training loss : 1.3150006556510925 TRAIN  loss dict:  {'classification_loss': 1.3150006556510925}
2025-01-12 16:14:36,266 [INFO] Step[2300/4329]: training loss : 1.2833712887763977 TRAIN  loss dict:  {'classification_loss': 1.2833712887763977}
2025-01-12 16:14:47,920 [INFO] Step[2350/4329]: training loss : 1.3921185791492463 TRAIN  loss dict:  {'classification_loss': 1.3921185791492463}
2025-01-12 16:14:59,568 [INFO] Step[2400/4329]: training loss : 1.2517815184593202 TRAIN  loss dict:  {'classification_loss': 1.2517815184593202}
2025-01-12 16:15:11,206 [INFO] Step[2450/4329]: training loss : 1.3595954477787018 TRAIN  loss dict:  {'classification_loss': 1.3595954477787018}
2025-01-12 16:15:22,849 [INFO] Step[2500/4329]: training loss : 1.4034011721611024 TRAIN  loss dict:  {'classification_loss': 1.4034011721611024}
2025-01-12 16:15:34,502 [INFO] Step[2550/4329]: training loss : 1.292998230457306 TRAIN  loss dict:  {'classification_loss': 1.292998230457306}
2025-01-12 16:15:46,113 [INFO] Step[2600/4329]: training loss : 1.2696299767494201 TRAIN  loss dict:  {'classification_loss': 1.2696299767494201}
2025-01-12 16:15:57,793 [INFO] Step[2650/4329]: training loss : 1.3555820417404174 TRAIN  loss dict:  {'classification_loss': 1.3555820417404174}
2025-01-12 16:16:09,414 [INFO] Step[2700/4329]: training loss : 1.3210866665840149 TRAIN  loss dict:  {'classification_loss': 1.3210866665840149}
2025-01-12 16:16:21,039 [INFO] Step[2750/4329]: training loss : 1.3435034906864167 TRAIN  loss dict:  {'classification_loss': 1.3435034906864167}
2025-01-12 16:16:32,656 [INFO] Step[2800/4329]: training loss : 1.2183945512771606 TRAIN  loss dict:  {'classification_loss': 1.2183945512771606}
2025-01-12 16:16:44,258 [INFO] Step[2850/4329]: training loss : 1.3156991946697234 TRAIN  loss dict:  {'classification_loss': 1.3156991946697234}
2025-01-12 16:16:55,869 [INFO] Step[2900/4329]: training loss : 1.2961802911758422 TRAIN  loss dict:  {'classification_loss': 1.2961802911758422}
2025-01-12 16:17:07,472 [INFO] Step[2950/4329]: training loss : 1.4079713416099549 TRAIN  loss dict:  {'classification_loss': 1.4079713416099549}
2025-01-12 16:17:19,101 [INFO] Step[3000/4329]: training loss : 1.2041352915763854 TRAIN  loss dict:  {'classification_loss': 1.2041352915763854}
2025-01-12 16:17:30,737 [INFO] Step[3050/4329]: training loss : 1.329630959033966 TRAIN  loss dict:  {'classification_loss': 1.329630959033966}
2025-01-12 16:17:42,383 [INFO] Step[3100/4329]: training loss : 1.460908659696579 TRAIN  loss dict:  {'classification_loss': 1.460908659696579}
2025-01-12 16:17:53,988 [INFO] Step[3150/4329]: training loss : 1.3852559220790863 TRAIN  loss dict:  {'classification_loss': 1.3852559220790863}
2025-01-12 16:18:05,627 [INFO] Step[3200/4329]: training loss : 1.2639829087257386 TRAIN  loss dict:  {'classification_loss': 1.2639829087257386}
2025-01-12 16:18:17,258 [INFO] Step[3250/4329]: training loss : 1.3056418049335479 TRAIN  loss dict:  {'classification_loss': 1.3056418049335479}
2025-01-12 16:18:28,851 [INFO] Step[3300/4329]: training loss : 1.321984852552414 TRAIN  loss dict:  {'classification_loss': 1.321984852552414}
2025-01-12 16:18:40,486 [INFO] Step[3350/4329]: training loss : 1.338085732460022 TRAIN  loss dict:  {'classification_loss': 1.338085732460022}
2025-01-12 16:18:52,147 [INFO] Step[3400/4329]: training loss : 1.2697476899623872 TRAIN  loss dict:  {'classification_loss': 1.2697476899623872}
2025-01-12 16:19:03,804 [INFO] Step[3450/4329]: training loss : 1.3694723153114319 TRAIN  loss dict:  {'classification_loss': 1.3694723153114319}
2025-01-12 16:19:15,405 [INFO] Step[3500/4329]: training loss : 1.37421799659729 TRAIN  loss dict:  {'classification_loss': 1.37421799659729}
2025-01-12 16:19:27,055 [INFO] Step[3550/4329]: training loss : 1.4338860058784484 TRAIN  loss dict:  {'classification_loss': 1.4338860058784484}
2025-01-12 16:19:38,779 [INFO] Step[3600/4329]: training loss : 1.2698349916934968 TRAIN  loss dict:  {'classification_loss': 1.2698349916934968}
2025-01-12 16:19:50,421 [INFO] Step[3650/4329]: training loss : 1.2861922037601472 TRAIN  loss dict:  {'classification_loss': 1.2861922037601472}
2025-01-12 16:20:02,051 [INFO] Step[3700/4329]: training loss : 1.2409058439731597 TRAIN  loss dict:  {'classification_loss': 1.2409058439731597}
2025-01-12 16:20:13,696 [INFO] Step[3750/4329]: training loss : 1.2925501990318298 TRAIN  loss dict:  {'classification_loss': 1.2925501990318298}
2025-01-12 16:20:25,320 [INFO] Step[3800/4329]: training loss : 1.345015685558319 TRAIN  loss dict:  {'classification_loss': 1.345015685558319}
2025-01-12 16:20:36,957 [INFO] Step[3850/4329]: training loss : 1.441299308538437 TRAIN  loss dict:  {'classification_loss': 1.441299308538437}
2025-01-12 16:20:48,574 [INFO] Step[3900/4329]: training loss : 1.3495306122303008 TRAIN  loss dict:  {'classification_loss': 1.3495306122303008}
2025-01-12 16:21:00,229 [INFO] Step[3950/4329]: training loss : 1.4606841456890107 TRAIN  loss dict:  {'classification_loss': 1.4606841456890107}
2025-01-12 16:21:11,882 [INFO] Step[4000/4329]: training loss : 1.3668543577194214 TRAIN  loss dict:  {'classification_loss': 1.3668543577194214}
2025-01-12 16:21:23,488 [INFO] Step[4050/4329]: training loss : 1.3284802269935607 TRAIN  loss dict:  {'classification_loss': 1.3284802269935607}
2025-01-12 16:21:35,135 [INFO] Step[4100/4329]: training loss : 1.2725280654430389 TRAIN  loss dict:  {'classification_loss': 1.2725280654430389}
2025-01-12 16:21:46,803 [INFO] Step[4150/4329]: training loss : 1.329696511030197 TRAIN  loss dict:  {'classification_loss': 1.329696511030197}
2025-01-12 16:21:58,412 [INFO] Step[4200/4329]: training loss : 1.300480237007141 TRAIN  loss dict:  {'classification_loss': 1.300480237007141}
2025-01-12 16:22:10,109 [INFO] Step[4250/4329]: training loss : 1.2838974320888519 TRAIN  loss dict:  {'classification_loss': 1.2838974320888519}
2025-01-12 16:22:21,775 [INFO] Step[4300/4329]: training loss : 1.239075403213501 TRAIN  loss dict:  {'classification_loss': 1.239075403213501}
2025-01-12 16:24:21,739 [INFO] Label accuracies statistics:
2025-01-12 16:24:21,739 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.4166666666666667, 6: 0.5833333333333334, 7: 0.3333333333333333, 8: 0.4166666666666667, 9: 0.75, 10: 0.9166666666666666, 11: 0.75, 12: 0.5833333333333334, 13: 0.4166666666666667, 14: 0.5833333333333334, 15: 0.4444444444444444, 16: 0.16666666666666666, 17: 0.16666666666666666, 18: 0.4166666666666667, 19: 0.75, 20: 0.3333333333333333, 21: 0.4166666666666667, 22: 0.5833333333333334, 23: 0.9166666666666666, 24: 1.0, 25: 0.4166666666666667, 26: 0.75, 27: 0.5, 28: 0.8333333333333334, 29: 1.0, 30: 0.4166666666666667, 31: 0.5833333333333334, 32: 0.4166666666666667, 33: 0.6666666666666666, 34: 0.6666666666666666, 35: 0.75, 36: 0.25, 37: 0.8333333333333334, 38: 0.6666666666666666, 39: 0.9166666666666666, 40: 0.75, 41: 0.25, 42: 0.6666666666666666, 43: 0.9166666666666666, 44: 0.5833333333333334, 45: 0.5833333333333334, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.6666666666666666, 51: 0.8333333333333334, 52: 0.9166666666666666, 53: 0.5, 54: 0.5, 55: 0.5833333333333334, 56: 0.75, 57: 0.5833333333333334, 58: 1.0, 59: 0.16666666666666666, 60: 0.8333333333333334, 61: 0.6666666666666666, 62: 0.75, 63: 0.3333333333333333, 64: 1.0, 65: 0.9166666666666666, 66: 0.75, 67: 0.8333333333333334, 68: 1.0, 69: 0.75, 70: 0.25, 71: 0.3333333333333333, 72: 0.8333333333333334, 73: 0.75, 74: 0.6666666666666666, 75: 0.9166666666666666, 76: 0.5833333333333334, 77: 0.6666666666666666, 78: 0.9166666666666666, 79: 0.5833333333333334, 80: 0.9166666666666666, 81: 0.9166666666666666, 82: 0.6666666666666666, 83: 0.5, 84: 0.5, 85: 0.8333333333333334, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.5, 89: 0.5833333333333334, 90: 0.4166666666666667, 91: 0.9166666666666666, 92: 1.0, 93: 1.0, 94: 0.25, 95: 0.9166666666666666, 96: 0.3333333333333333, 97: 0.8333333333333334, 98: 0.8333333333333334, 99: 0.8666666666666667, 100: 0.9166666666666666, 101: 0.5, 102: 0.9166666666666666, 103: 0.75, 104: 0.8333333333333334, 105: 0.9166666666666666, 106: 0.8333333333333334, 107: 0.5833333333333334, 108: 0.6666666666666666, 109: 0.4166666666666667, 110: 0.75, 111: 0.9166666666666666, 112: 0.8333333333333334, 113: 0.3333333333333333, 114: 0.5833333333333334, 115: 0.8333333333333334, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.4166666666666667, 121: 0.6666666666666666, 122: 0.8333333333333334, 123: 0.8333333333333334, 124: 0.8333333333333334, 125: 0.8333333333333334, 126: 1.0, 127: 0.9166666666666666, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.9166666666666666, 132: 0.25, 133: 0.9166666666666666, 134: 0.75, 135: 0.9166666666666666, 136: 0.75, 137: 0.8333333333333334, 138: 0.75, 139: 0.8333333333333334, 140: 0.8333333333333334, 141: 0.9166666666666666, 142: 0.9166666666666666, 143: 1.0, 144: 0.5833333333333334, 145: 0.8333333333333334, 146: 0.9166666666666666, 147: 0.75, 148: 0.5833333333333334, 149: 0.8333333333333334, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 0.5, 153: 0.8333333333333334, 154: 0.5833333333333334, 155: 0.8333333333333334, 156: 0.6666666666666666, 157: 0.5, 158: 0.4444444444444444, 159: 0.9166666666666666, 160: 0.16666666666666666, 161: 0.8333333333333334, 162: 0.9166666666666666, 163: 0.6666666666666666, 164: 0.5833333333333334, 165: 0.75, 166: 0.6666666666666666, 167: 0.6666666666666666, 168: 0.75, 169: 0.8333333333333334, 170: 1.0, 171: 0.3333333333333333, 172: 0.9166666666666666, 173: 0.75, 174: 0.5833333333333334, 175: 0.6666666666666666, 176: 0.6666666666666666, 177: 0.75, 178: 0.9166666666666666, 179: 0.5555555555555556, 180: 0.75, 181: 0.6666666666666666, 182: 0.4166666666666667, 183: 0.9166666666666666, 184: 0.9166666666666666, 185: 1.0, 186: 0.75, 187: 0.9166666666666666, 188: 0.6666666666666666, 189: 0.9166666666666666, 190: 0.3333333333333333, 191: 0.16666666666666666, 192: 1.0, 193: 0.75, 194: 0.8333333333333334, 195: 0.5833333333333334, 196: 0.8333333333333334, 197: 0.5, 198: 0.5833333333333334}

2025-01-12 16:24:22,808 [INFO] [5] TRAIN  loss: 1.3264350162612066 acc: 0.873017095333436
2025-01-12 16:24:22,808 [INFO] [5] TRAIN  loss dict: {'classification_loss': 1.3264350162612066}
2025-01-12 16:24:22,808 [INFO] [5] VALIDATION loss: 1.923400380469934 VALIDATION acc: 0.702020202020202
2025-01-12 16:24:22,808 [INFO] [5] VALIDATION loss dict: {'classification_loss': 1.923400380469934}
2025-01-12 16:24:22,809 [INFO] 
2025-01-12 16:24:40,116 [INFO] Step[50/4329]: training loss : 1.3221277487277985 TRAIN  loss dict:  {'classification_loss': 1.3221277487277985}
2025-01-12 16:24:51,654 [INFO] Step[100/4329]: training loss : 1.2838405442237855 TRAIN  loss dict:  {'classification_loss': 1.2838405442237855}
2025-01-12 16:25:03,251 [INFO] Step[150/4329]: training loss : 1.2476551306247712 TRAIN  loss dict:  {'classification_loss': 1.2476551306247712}
2025-01-12 16:25:14,834 [INFO] Step[200/4329]: training loss : 1.4514763712882996 TRAIN  loss dict:  {'classification_loss': 1.4514763712882996}
2025-01-12 16:25:26,451 [INFO] Step[250/4329]: training loss : 1.223601359128952 TRAIN  loss dict:  {'classification_loss': 1.223601359128952}
2025-01-12 16:25:38,332 [INFO] Step[300/4329]: training loss : 1.1994484329223634 TRAIN  loss dict:  {'classification_loss': 1.1994484329223634}
2025-01-12 16:25:50,752 [INFO] Step[350/4329]: training loss : 1.2709530258178712 TRAIN  loss dict:  {'classification_loss': 1.2709530258178712}
2025-01-12 16:26:03,014 [INFO] Step[400/4329]: training loss : 1.193191068172455 TRAIN  loss dict:  {'classification_loss': 1.193191068172455}
2025-01-12 16:26:16,202 [INFO] Step[450/4329]: training loss : 1.288282482624054 TRAIN  loss dict:  {'classification_loss': 1.288282482624054}
2025-01-12 16:26:29,286 [INFO] Step[500/4329]: training loss : 1.259318014383316 TRAIN  loss dict:  {'classification_loss': 1.259318014383316}
2025-01-12 16:26:41,711 [INFO] Step[550/4329]: training loss : 1.2679414892196654 TRAIN  loss dict:  {'classification_loss': 1.2679414892196654}
2025-01-12 16:26:53,696 [INFO] Step[600/4329]: training loss : 1.2598950839042664 TRAIN  loss dict:  {'classification_loss': 1.2598950839042664}
2025-01-12 16:27:05,588 [INFO] Step[650/4329]: training loss : 1.243618403673172 TRAIN  loss dict:  {'classification_loss': 1.243618403673172}
2025-01-12 16:27:17,199 [INFO] Step[700/4329]: training loss : 1.1714493930339813 TRAIN  loss dict:  {'classification_loss': 1.1714493930339813}
2025-01-12 16:27:28,856 [INFO] Step[750/4329]: training loss : 1.2669085311889647 TRAIN  loss dict:  {'classification_loss': 1.2669085311889647}
2025-01-12 16:27:40,518 [INFO] Step[800/4329]: training loss : 1.3403648805618287 TRAIN  loss dict:  {'classification_loss': 1.3403648805618287}
2025-01-12 16:27:52,178 [INFO] Step[850/4329]: training loss : 1.2517017650604247 TRAIN  loss dict:  {'classification_loss': 1.2517017650604247}
2025-01-12 16:28:03,844 [INFO] Step[900/4329]: training loss : 1.2159977889060973 TRAIN  loss dict:  {'classification_loss': 1.2159977889060973}
2025-01-12 16:28:15,565 [INFO] Step[950/4329]: training loss : 1.1625469040870666 TRAIN  loss dict:  {'classification_loss': 1.1625469040870666}
2025-01-12 16:28:27,191 [INFO] Step[1000/4329]: training loss : 1.393570728302002 TRAIN  loss dict:  {'classification_loss': 1.393570728302002}
2025-01-12 16:28:38,827 [INFO] Step[1050/4329]: training loss : 1.2004702413082122 TRAIN  loss dict:  {'classification_loss': 1.2004702413082122}
2025-01-12 16:28:50,479 [INFO] Step[1100/4329]: training loss : 1.2647079634666443 TRAIN  loss dict:  {'classification_loss': 1.2647079634666443}
2025-01-12 16:29:02,152 [INFO] Step[1150/4329]: training loss : 1.2229648792743684 TRAIN  loss dict:  {'classification_loss': 1.2229648792743684}
2025-01-12 16:29:13,775 [INFO] Step[1200/4329]: training loss : 1.2765238523483275 TRAIN  loss dict:  {'classification_loss': 1.2765238523483275}
2025-01-12 16:29:25,430 [INFO] Step[1250/4329]: training loss : 1.2873510766029357 TRAIN  loss dict:  {'classification_loss': 1.2873510766029357}
2025-01-12 16:29:37,088 [INFO] Step[1300/4329]: training loss : 1.3032058119773864 TRAIN  loss dict:  {'classification_loss': 1.3032058119773864}
2025-01-12 16:29:48,773 [INFO] Step[1350/4329]: training loss : 1.2705532789230347 TRAIN  loss dict:  {'classification_loss': 1.2705532789230347}
2025-01-12 16:30:00,471 [INFO] Step[1400/4329]: training loss : 1.3262280571460723 TRAIN  loss dict:  {'classification_loss': 1.3262280571460723}
2025-01-12 16:30:12,104 [INFO] Step[1450/4329]: training loss : 1.2334061312675475 TRAIN  loss dict:  {'classification_loss': 1.2334061312675475}
2025-01-12 16:30:23,800 [INFO] Step[1500/4329]: training loss : 1.2587349915504455 TRAIN  loss dict:  {'classification_loss': 1.2587349915504455}
2025-01-12 16:30:35,493 [INFO] Step[1550/4329]: training loss : 1.2282362926006316 TRAIN  loss dict:  {'classification_loss': 1.2282362926006316}
2025-01-12 16:30:47,106 [INFO] Step[1600/4329]: training loss : 1.347530335187912 TRAIN  loss dict:  {'classification_loss': 1.347530335187912}
2025-01-12 16:30:58,776 [INFO] Step[1650/4329]: training loss : 1.2581849884986878 TRAIN  loss dict:  {'classification_loss': 1.2581849884986878}
2025-01-12 16:31:10,417 [INFO] Step[1700/4329]: training loss : 1.2959596467018129 TRAIN  loss dict:  {'classification_loss': 1.2959596467018129}
2025-01-12 16:31:22,037 [INFO] Step[1750/4329]: training loss : 1.2456324660778046 TRAIN  loss dict:  {'classification_loss': 1.2456324660778046}
2025-01-12 16:31:33,693 [INFO] Step[1800/4329]: training loss : 1.2376704740524291 TRAIN  loss dict:  {'classification_loss': 1.2376704740524291}
2025-01-12 16:31:45,346 [INFO] Step[1850/4329]: training loss : 1.2968750548362733 TRAIN  loss dict:  {'classification_loss': 1.2968750548362733}
2025-01-12 16:31:56,997 [INFO] Step[1900/4329]: training loss : 1.2425069224834442 TRAIN  loss dict:  {'classification_loss': 1.2425069224834442}
2025-01-12 16:32:08,652 [INFO] Step[1950/4329]: training loss : 1.3004285383224488 TRAIN  loss dict:  {'classification_loss': 1.3004285383224488}
2025-01-12 16:32:20,278 [INFO] Step[2000/4329]: training loss : 1.3249826622009278 TRAIN  loss dict:  {'classification_loss': 1.3249826622009278}
2025-01-12 16:32:31,933 [INFO] Step[2050/4329]: training loss : 1.2676047158241273 TRAIN  loss dict:  {'classification_loss': 1.2676047158241273}
2025-01-12 16:32:43,560 [INFO] Step[2100/4329]: training loss : 1.256730786561966 TRAIN  loss dict:  {'classification_loss': 1.256730786561966}
2025-01-12 16:32:55,172 [INFO] Step[2150/4329]: training loss : 1.235259394645691 TRAIN  loss dict:  {'classification_loss': 1.235259394645691}
2025-01-12 16:33:06,847 [INFO] Step[2200/4329]: training loss : 1.2989833891391753 TRAIN  loss dict:  {'classification_loss': 1.2989833891391753}
2025-01-12 16:33:18,498 [INFO] Step[2250/4329]: training loss : 1.3267853212356568 TRAIN  loss dict:  {'classification_loss': 1.3267853212356568}
2025-01-12 16:33:30,152 [INFO] Step[2300/4329]: training loss : 1.3283138489723205 TRAIN  loss dict:  {'classification_loss': 1.3283138489723205}
2025-01-12 16:33:41,800 [INFO] Step[2350/4329]: training loss : 1.4212149953842164 TRAIN  loss dict:  {'classification_loss': 1.4212149953842164}
2025-01-12 16:33:53,416 [INFO] Step[2400/4329]: training loss : 1.203267787694931 TRAIN  loss dict:  {'classification_loss': 1.203267787694931}
2025-01-12 16:34:05,055 [INFO] Step[2450/4329]: training loss : 1.2923778736591338 TRAIN  loss dict:  {'classification_loss': 1.2923778736591338}
2025-01-12 16:34:16,668 [INFO] Step[2500/4329]: training loss : 1.335140095949173 TRAIN  loss dict:  {'classification_loss': 1.335140095949173}
2025-01-12 16:34:28,364 [INFO] Step[2550/4329]: training loss : 1.3026543843746186 TRAIN  loss dict:  {'classification_loss': 1.3026543843746186}
2025-01-12 16:34:40,030 [INFO] Step[2600/4329]: training loss : 1.3067753183841706 TRAIN  loss dict:  {'classification_loss': 1.3067753183841706}
2025-01-12 16:34:51,677 [INFO] Step[2650/4329]: training loss : 1.294100272655487 TRAIN  loss dict:  {'classification_loss': 1.294100272655487}
2025-01-12 16:35:03,320 [INFO] Step[2700/4329]: training loss : 1.3223248267173766 TRAIN  loss dict:  {'classification_loss': 1.3223248267173766}
2025-01-12 16:35:14,967 [INFO] Step[2750/4329]: training loss : 1.2884007143974303 TRAIN  loss dict:  {'classification_loss': 1.2884007143974303}
2025-01-12 16:35:26,625 [INFO] Step[2800/4329]: training loss : 1.3188125705718994 TRAIN  loss dict:  {'classification_loss': 1.3188125705718994}
2025-01-12 16:35:38,307 [INFO] Step[2850/4329]: training loss : 1.2268990135192872 TRAIN  loss dict:  {'classification_loss': 1.2268990135192872}
2025-01-12 16:35:49,944 [INFO] Step[2900/4329]: training loss : 1.3252035856246949 TRAIN  loss dict:  {'classification_loss': 1.3252035856246949}
2025-01-12 16:36:01,564 [INFO] Step[2950/4329]: training loss : 1.2821738016605377 TRAIN  loss dict:  {'classification_loss': 1.2821738016605377}
2025-01-12 16:36:13,210 [INFO] Step[3000/4329]: training loss : 1.1990350735187532 TRAIN  loss dict:  {'classification_loss': 1.1990350735187532}
2025-01-12 16:36:24,861 [INFO] Step[3050/4329]: training loss : 1.2176819705963136 TRAIN  loss dict:  {'classification_loss': 1.2176819705963136}
2025-01-12 16:36:36,535 [INFO] Step[3100/4329]: training loss : 1.2525392520427703 TRAIN  loss dict:  {'classification_loss': 1.2525392520427703}
2025-01-12 16:36:48,191 [INFO] Step[3150/4329]: training loss : 1.2321276235580445 TRAIN  loss dict:  {'classification_loss': 1.2321276235580445}
2025-01-12 16:36:59,843 [INFO] Step[3200/4329]: training loss : 1.2837501287460327 TRAIN  loss dict:  {'classification_loss': 1.2837501287460327}
2025-01-12 16:37:11,506 [INFO] Step[3250/4329]: training loss : 1.4241394650936128 TRAIN  loss dict:  {'classification_loss': 1.4241394650936128}
2025-01-12 16:37:23,111 [INFO] Step[3300/4329]: training loss : 1.3102614080905914 TRAIN  loss dict:  {'classification_loss': 1.3102614080905914}
2025-01-12 16:37:34,751 [INFO] Step[3350/4329]: training loss : 1.2941971182823182 TRAIN  loss dict:  {'classification_loss': 1.2941971182823182}
2025-01-12 16:37:46,487 [INFO] Step[3400/4329]: training loss : 1.2930857491493226 TRAIN  loss dict:  {'classification_loss': 1.2930857491493226}
2025-01-12 16:37:58,662 [INFO] Step[3450/4329]: training loss : 1.3486180531978607 TRAIN  loss dict:  {'classification_loss': 1.3486180531978607}
2025-01-12 16:38:10,815 [INFO] Step[3500/4329]: training loss : 1.3477568519115448 TRAIN  loss dict:  {'classification_loss': 1.3477568519115448}
2025-01-12 16:38:23,647 [INFO] Step[3550/4329]: training loss : 1.255339080095291 TRAIN  loss dict:  {'classification_loss': 1.255339080095291}
2025-01-12 16:38:38,641 [INFO] Step[3600/4329]: training loss : 1.3681273472309112 TRAIN  loss dict:  {'classification_loss': 1.3681273472309112}
2025-01-12 16:38:51,178 [INFO] Step[3650/4329]: training loss : 1.2861673259735107 TRAIN  loss dict:  {'classification_loss': 1.2861673259735107}
2025-01-12 16:39:03,102 [INFO] Step[3700/4329]: training loss : 1.2653054022789 TRAIN  loss dict:  {'classification_loss': 1.2653054022789}
2025-01-12 16:39:14,946 [INFO] Step[3750/4329]: training loss : 1.3318802559375762 TRAIN  loss dict:  {'classification_loss': 1.3318802559375762}
2025-01-12 16:39:26,606 [INFO] Step[3800/4329]: training loss : 1.2618712151050568 TRAIN  loss dict:  {'classification_loss': 1.2618712151050568}
2025-01-12 16:39:38,267 [INFO] Step[3850/4329]: training loss : 1.2129770720005035 TRAIN  loss dict:  {'classification_loss': 1.2129770720005035}
2025-01-12 16:39:49,917 [INFO] Step[3900/4329]: training loss : 1.2268788361549376 TRAIN  loss dict:  {'classification_loss': 1.2268788361549376}
2025-01-12 16:40:01,557 [INFO] Step[3950/4329]: training loss : 1.292912813425064 TRAIN  loss dict:  {'classification_loss': 1.292912813425064}
2025-01-12 16:40:13,200 [INFO] Step[4000/4329]: training loss : 1.2434711158275604 TRAIN  loss dict:  {'classification_loss': 1.2434711158275604}
2025-01-12 16:40:24,864 [INFO] Step[4050/4329]: training loss : 1.2016096329689026 TRAIN  loss dict:  {'classification_loss': 1.2016096329689026}
2025-01-12 16:40:36,537 [INFO] Step[4100/4329]: training loss : 1.2131089627742768 TRAIN  loss dict:  {'classification_loss': 1.2131089627742768}
2025-01-12 16:40:48,107 [INFO] Step[4150/4329]: training loss : 1.2409808826446533 TRAIN  loss dict:  {'classification_loss': 1.2409808826446533}
2025-01-12 16:40:59,774 [INFO] Step[4200/4329]: training loss : 1.3852197694778443 TRAIN  loss dict:  {'classification_loss': 1.3852197694778443}
2025-01-12 16:41:11,434 [INFO] Step[4250/4329]: training loss : 1.220348165035248 TRAIN  loss dict:  {'classification_loss': 1.220348165035248}
2025-01-12 16:41:23,120 [INFO] Step[4300/4329]: training loss : 1.3510578072071076 TRAIN  loss dict:  {'classification_loss': 1.3510578072071076}
2025-01-12 16:43:22,400 [INFO] Label accuracies statistics:
2025-01-12 16:43:22,401 [INFO] {0: 0.8888888888888888, 1: 0.6666666666666666, 2: 0.5833333333333334, 3: 0.75, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5, 7: 0.4166666666666667, 8: 0.4166666666666667, 9: 0.75, 10: 0.9166666666666666, 11: 1.0, 12: 0.4166666666666667, 13: 0.3333333333333333, 14: 0.4166666666666667, 15: 0.3333333333333333, 16: 0.5, 17: 0.08333333333333333, 18: 0.5833333333333334, 19: 0.5, 20: 0.4166666666666667, 21: 0.5833333333333334, 22: 0.6666666666666666, 23: 0.9166666666666666, 24: 0.8333333333333334, 25: 0.8333333333333334, 26: 0.8333333333333334, 27: 0.4166666666666667, 28: 0.75, 29: 1.0, 30: 0.5833333333333334, 31: 0.6666666666666666, 32: 0.4166666666666667, 33: 0.75, 34: 0.6666666666666666, 35: 0.75, 36: 0.75, 37: 0.9166666666666666, 38: 0.6666666666666666, 39: 0.8333333333333334, 40: 0.8333333333333334, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.25, 45: 0.5, 46: 0.9166666666666666, 47: 0.4166666666666667, 48: 1.0, 49: 0.9166666666666666, 50: 0.75, 51: 0.75, 52: 0.9166666666666666, 53: 0.5, 54: 0.4166666666666667, 55: 0.6666666666666666, 56: 0.4166666666666667, 57: 0.6666666666666666, 58: 0.4166666666666667, 59: 0.5, 60: 0.6666666666666666, 61: 0.75, 62: 0.6666666666666666, 63: 0.4166666666666667, 64: 0.5833333333333334, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.3333333333333333, 69: 0.5833333333333334, 70: 0.16666666666666666, 71: 0.4166666666666667, 72: 0.75, 73: 0.5833333333333334, 74: 0.5833333333333334, 75: 1.0, 76: 0.5833333333333334, 77: 0.6666666666666666, 78: 0.9166666666666666, 79: 0.5833333333333334, 80: 0.9166666666666666, 81: 0.8333333333333334, 82: 0.5, 83: 0.8333333333333334, 84: 0.3333333333333333, 85: 0.5833333333333334, 86: 0.5833333333333334, 87: 0.6666666666666666, 88: 0.5, 89: 0.75, 90: 0.5833333333333334, 91: 0.75, 92: 0.9166666666666666, 93: 1.0, 94: 0.5833333333333334, 95: 0.9166666666666666, 96: 0.5, 97: 0.6666666666666666, 98: 0.8333333333333334, 99: 0.8666666666666667, 100: 0.75, 101: 0.5, 102: 0.75, 103: 0.9166666666666666, 104: 1.0, 105: 0.8333333333333334, 106: 0.9166666666666666, 107: 0.75, 108: 0.75, 109: 0.5, 110: 0.8333333333333334, 111: 0.8333333333333334, 112: 0.75, 113: 0.5, 114: 0.5833333333333334, 115: 0.8333333333333334, 116: 0.8333333333333334, 117: 0.6666666666666666, 118: 0.9166666666666666, 119: 0.8333333333333334, 120: 0.4166666666666667, 121: 1.0, 122: 0.75, 123: 0.8333333333333334, 124: 1.0, 125: 0.75, 126: 0.9166666666666666, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.5833333333333334, 131: 0.8333333333333334, 132: 0.08333333333333333, 133: 1.0, 134: 0.6666666666666666, 135: 1.0, 136: 0.9166666666666666, 137: 0.75, 138: 0.6666666666666666, 139: 0.8333333333333334, 140: 0.8333333333333334, 141: 0.8333333333333334, 142: 0.6666666666666666, 143: 0.8333333333333334, 144: 0.75, 145: 0.6666666666666666, 146: 1.0, 147: 0.75, 148: 0.5833333333333334, 149: 1.0, 150: 0.08333333333333333, 151: 0.8333333333333334, 152: 0.9166666666666666, 153: 0.5833333333333334, 154: 1.0, 155: 1.0, 156: 0.3333333333333333, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.25, 161: 0.75, 162: 0.75, 163: 0.9166666666666666, 164: 0.5, 165: 0.8333333333333334, 166: 0.5833333333333334, 167: 0.75, 168: 1.0, 169: 0.8333333333333334, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.8333333333333334, 174: 0.8333333333333334, 175: 0.8333333333333334, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.9166666666666666, 181: 0.8333333333333334, 182: 0.5833333333333334, 183: 0.6666666666666666, 184: 0.75, 185: 0.9166666666666666, 186: 0.8333333333333334, 187: 0.9166666666666666, 188: 0.6666666666666666, 189: 0.8333333333333334, 190: 0.4166666666666667, 191: 0.16666666666666666, 192: 1.0, 193: 0.9166666666666666, 194: 0.75, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.5, 198: 0.6666666666666666}

2025-01-12 16:43:23,317 [INFO] [6] TRAIN  loss: 1.2784147479567745 acc: 0.8869551825042353
2025-01-12 16:43:23,317 [INFO] [6] TRAIN  loss dict: {'classification_loss': 1.2784147479567745}
2025-01-12 16:43:23,318 [INFO] [6] VALIDATION loss: 1.9219211672592644 VALIDATION acc: 0.70496632996633
2025-01-12 16:43:23,318 [INFO] [6] VALIDATION loss dict: {'classification_loss': 1.9219211672592644}
2025-01-12 16:43:23,318 [INFO] 
2025-01-12 16:43:40,485 [INFO] Step[50/4329]: training loss : 1.2341837108135223 TRAIN  loss dict:  {'classification_loss': 1.2341837108135223}
2025-01-12 16:43:52,075 [INFO] Step[100/4329]: training loss : 1.1535743474960327 TRAIN  loss dict:  {'classification_loss': 1.1535743474960327}
2025-01-12 16:44:03,612 [INFO] Step[150/4329]: training loss : 1.2409676432609558 TRAIN  loss dict:  {'classification_loss': 1.2409676432609558}
2025-01-12 16:44:15,192 [INFO] Step[200/4329]: training loss : 1.239740216732025 TRAIN  loss dict:  {'classification_loss': 1.239740216732025}
2025-01-12 16:44:26,837 [INFO] Step[250/4329]: training loss : 1.198271176815033 TRAIN  loss dict:  {'classification_loss': 1.198271176815033}
2025-01-12 16:44:38,453 [INFO] Step[300/4329]: training loss : 1.2152783644199372 TRAIN  loss dict:  {'classification_loss': 1.2152783644199372}
2025-01-12 16:44:50,120 [INFO] Step[350/4329]: training loss : 1.1643510282039642 TRAIN  loss dict:  {'classification_loss': 1.1643510282039642}
2025-01-12 16:45:01,768 [INFO] Step[400/4329]: training loss : 1.274083743095398 TRAIN  loss dict:  {'classification_loss': 1.274083743095398}
2025-01-12 16:45:13,437 [INFO] Step[450/4329]: training loss : 1.1874891543388366 TRAIN  loss dict:  {'classification_loss': 1.1874891543388366}
2025-01-12 16:45:25,068 [INFO] Step[500/4329]: training loss : 1.2027894234657288 TRAIN  loss dict:  {'classification_loss': 1.2027894234657288}
2025-01-12 16:45:36,719 [INFO] Step[550/4329]: training loss : 1.146618927717209 TRAIN  loss dict:  {'classification_loss': 1.146618927717209}
2025-01-12 16:45:48,398 [INFO] Step[600/4329]: training loss : 1.2237068164348601 TRAIN  loss dict:  {'classification_loss': 1.2237068164348601}
2025-01-12 16:46:00,006 [INFO] Step[650/4329]: training loss : 1.218158447742462 TRAIN  loss dict:  {'classification_loss': 1.218158447742462}
2025-01-12 16:46:11,651 [INFO] Step[700/4329]: training loss : 1.1902101838588715 TRAIN  loss dict:  {'classification_loss': 1.1902101838588715}
2025-01-12 16:46:23,274 [INFO] Step[750/4329]: training loss : 1.1523563075065613 TRAIN  loss dict:  {'classification_loss': 1.1523563075065613}
2025-01-12 16:46:34,934 [INFO] Step[800/4329]: training loss : 1.1912803030014039 TRAIN  loss dict:  {'classification_loss': 1.1912803030014039}
2025-01-12 16:46:46,602 [INFO] Step[850/4329]: training loss : 1.1958650314807893 TRAIN  loss dict:  {'classification_loss': 1.1958650314807893}
2025-01-12 16:46:58,231 [INFO] Step[900/4329]: training loss : 1.1319073581695556 TRAIN  loss dict:  {'classification_loss': 1.1319073581695556}
2025-01-12 16:47:09,939 [INFO] Step[950/4329]: training loss : 1.1834163784980773 TRAIN  loss dict:  {'classification_loss': 1.1834163784980773}
2025-01-12 16:47:21,551 [INFO] Step[1000/4329]: training loss : 1.194551305770874 TRAIN  loss dict:  {'classification_loss': 1.194551305770874}
2025-01-12 16:47:33,213 [INFO] Step[1050/4329]: training loss : 1.1384464299678803 TRAIN  loss dict:  {'classification_loss': 1.1384464299678803}
2025-01-12 16:47:44,854 [INFO] Step[1100/4329]: training loss : 1.2150399327278136 TRAIN  loss dict:  {'classification_loss': 1.2150399327278136}
2025-01-12 16:47:56,509 [INFO] Step[1150/4329]: training loss : 1.1941118443012237 TRAIN  loss dict:  {'classification_loss': 1.1941118443012237}
2025-01-12 16:48:08,155 [INFO] Step[1200/4329]: training loss : 1.1110819315910339 TRAIN  loss dict:  {'classification_loss': 1.1110819315910339}
2025-01-12 16:48:19,849 [INFO] Step[1250/4329]: training loss : 1.305596479177475 TRAIN  loss dict:  {'classification_loss': 1.305596479177475}
2025-01-12 16:48:31,472 [INFO] Step[1300/4329]: training loss : 1.19524782538414 TRAIN  loss dict:  {'classification_loss': 1.19524782538414}
2025-01-12 16:48:43,174 [INFO] Step[1350/4329]: training loss : 1.1349644410610198 TRAIN  loss dict:  {'classification_loss': 1.1349644410610198}
2025-01-12 16:48:54,810 [INFO] Step[1400/4329]: training loss : 1.2800334763526917 TRAIN  loss dict:  {'classification_loss': 1.2800334763526917}
2025-01-12 16:49:06,471 [INFO] Step[1450/4329]: training loss : 1.293132907152176 TRAIN  loss dict:  {'classification_loss': 1.293132907152176}
2025-01-12 16:49:18,088 [INFO] Step[1500/4329]: training loss : 1.2002212703227997 TRAIN  loss dict:  {'classification_loss': 1.2002212703227997}
2025-01-12 16:49:29,751 [INFO] Step[1550/4329]: training loss : 1.19494797706604 TRAIN  loss dict:  {'classification_loss': 1.19494797706604}
2025-01-12 16:49:41,371 [INFO] Step[1600/4329]: training loss : 1.2585676670074464 TRAIN  loss dict:  {'classification_loss': 1.2585676670074464}
2025-01-12 16:49:53,004 [INFO] Step[1650/4329]: training loss : 1.2320133674144744 TRAIN  loss dict:  {'classification_loss': 1.2320133674144744}
2025-01-12 16:50:04,821 [INFO] Step[1700/4329]: training loss : 1.170593547821045 TRAIN  loss dict:  {'classification_loss': 1.170593547821045}
2025-01-12 16:50:17,088 [INFO] Step[1750/4329]: training loss : 1.2141308796405792 TRAIN  loss dict:  {'classification_loss': 1.2141308796405792}
2025-01-12 16:50:29,366 [INFO] Step[1800/4329]: training loss : 1.2420474708080291 TRAIN  loss dict:  {'classification_loss': 1.2420474708080291}
2025-01-12 16:50:42,214 [INFO] Step[1850/4329]: training loss : 1.3448579931259155 TRAIN  loss dict:  {'classification_loss': 1.3448579931259155}
2025-01-12 16:50:55,450 [INFO] Step[1900/4329]: training loss : 1.1279878211021424 TRAIN  loss dict:  {'classification_loss': 1.1279878211021424}
2025-01-12 16:51:08,010 [INFO] Step[1950/4329]: training loss : 1.1898365354537963 TRAIN  loss dict:  {'classification_loss': 1.1898365354537963}
2025-01-12 16:51:20,015 [INFO] Step[2000/4329]: training loss : 1.1794994008541106 TRAIN  loss dict:  {'classification_loss': 1.1794994008541106}
2025-01-12 16:51:31,927 [INFO] Step[2050/4329]: training loss : 1.2656297636032106 TRAIN  loss dict:  {'classification_loss': 1.2656297636032106}
2025-01-12 16:51:43,606 [INFO] Step[2100/4329]: training loss : 1.2700907564163209 TRAIN  loss dict:  {'classification_loss': 1.2700907564163209}
2025-01-12 16:51:55,270 [INFO] Step[2150/4329]: training loss : 1.2789346814155578 TRAIN  loss dict:  {'classification_loss': 1.2789346814155578}
2025-01-12 16:52:06,875 [INFO] Step[2200/4329]: training loss : 1.1945141673088073 TRAIN  loss dict:  {'classification_loss': 1.1945141673088073}
2025-01-12 16:52:18,560 [INFO] Step[2250/4329]: training loss : 1.2423738765716552 TRAIN  loss dict:  {'classification_loss': 1.2423738765716552}
2025-01-12 16:52:30,222 [INFO] Step[2300/4329]: training loss : 1.1681262004375457 TRAIN  loss dict:  {'classification_loss': 1.1681262004375457}
2025-01-12 16:52:41,875 [INFO] Step[2350/4329]: training loss : 1.2268241500854493 TRAIN  loss dict:  {'classification_loss': 1.2268241500854493}
2025-01-12 16:52:53,488 [INFO] Step[2400/4329]: training loss : 1.26527774810791 TRAIN  loss dict:  {'classification_loss': 1.26527774810791}
2025-01-12 16:53:05,144 [INFO] Step[2450/4329]: training loss : 1.2284095406532287 TRAIN  loss dict:  {'classification_loss': 1.2284095406532287}
2025-01-12 16:53:16,781 [INFO] Step[2500/4329]: training loss : 1.2412867450714111 TRAIN  loss dict:  {'classification_loss': 1.2412867450714111}
2025-01-12 16:53:28,433 [INFO] Step[2550/4329]: training loss : 1.3606895077228547 TRAIN  loss dict:  {'classification_loss': 1.3606895077228547}
2025-01-12 16:53:40,068 [INFO] Step[2600/4329]: training loss : 1.2859637820720673 TRAIN  loss dict:  {'classification_loss': 1.2859637820720673}
2025-01-12 16:53:51,741 [INFO] Step[2650/4329]: training loss : 1.2450214838981628 TRAIN  loss dict:  {'classification_loss': 1.2450214838981628}
2025-01-12 16:54:03,382 [INFO] Step[2700/4329]: training loss : 1.1697623682022096 TRAIN  loss dict:  {'classification_loss': 1.1697623682022096}
2025-01-12 16:54:14,994 [INFO] Step[2750/4329]: training loss : 1.1485604894161225 TRAIN  loss dict:  {'classification_loss': 1.1485604894161225}
2025-01-12 16:54:26,621 [INFO] Step[2800/4329]: training loss : 1.1940089523792268 TRAIN  loss dict:  {'classification_loss': 1.1940089523792268}
2025-01-12 16:54:38,254 [INFO] Step[2850/4329]: training loss : 1.2386159002780914 TRAIN  loss dict:  {'classification_loss': 1.2386159002780914}
2025-01-12 16:54:49,896 [INFO] Step[2900/4329]: training loss : 1.2995476877689363 TRAIN  loss dict:  {'classification_loss': 1.2995476877689363}
2025-01-12 16:55:01,561 [INFO] Step[2950/4329]: training loss : 1.4174998140335082 TRAIN  loss dict:  {'classification_loss': 1.4174998140335082}
2025-01-12 16:55:13,209 [INFO] Step[3000/4329]: training loss : 1.1836852037906647 TRAIN  loss dict:  {'classification_loss': 1.1836852037906647}
2025-01-12 16:55:24,812 [INFO] Step[3050/4329]: training loss : 1.2974152386188507 TRAIN  loss dict:  {'classification_loss': 1.2974152386188507}
2025-01-12 16:55:36,451 [INFO] Step[3100/4329]: training loss : 1.2433453130722045 TRAIN  loss dict:  {'classification_loss': 1.2433453130722045}
2025-01-12 16:55:48,112 [INFO] Step[3150/4329]: training loss : 1.240552099943161 TRAIN  loss dict:  {'classification_loss': 1.240552099943161}
2025-01-12 16:55:59,757 [INFO] Step[3200/4329]: training loss : 1.208228613138199 TRAIN  loss dict:  {'classification_loss': 1.208228613138199}
2025-01-12 16:56:11,378 [INFO] Step[3250/4329]: training loss : 1.3133603835105896 TRAIN  loss dict:  {'classification_loss': 1.3133603835105896}
2025-01-12 16:56:23,021 [INFO] Step[3300/4329]: training loss : 1.2776355731487274 TRAIN  loss dict:  {'classification_loss': 1.2776355731487274}
2025-01-12 16:56:34,683 [INFO] Step[3350/4329]: training loss : 1.3282260036468505 TRAIN  loss dict:  {'classification_loss': 1.3282260036468505}
2025-01-12 16:56:46,330 [INFO] Step[3400/4329]: training loss : 1.28243128657341 TRAIN  loss dict:  {'classification_loss': 1.28243128657341}
2025-01-12 16:56:58,007 [INFO] Step[3450/4329]: training loss : 1.1854929208755494 TRAIN  loss dict:  {'classification_loss': 1.1854929208755494}
2025-01-12 16:57:09,589 [INFO] Step[3500/4329]: training loss : 1.2671089661121369 TRAIN  loss dict:  {'classification_loss': 1.2671089661121369}
2025-01-12 16:57:21,284 [INFO] Step[3550/4329]: training loss : 1.3039192128181458 TRAIN  loss dict:  {'classification_loss': 1.3039192128181458}
2025-01-12 16:57:32,896 [INFO] Step[3600/4329]: training loss : 1.2949916338920593 TRAIN  loss dict:  {'classification_loss': 1.2949916338920593}
2025-01-12 16:57:44,568 [INFO] Step[3650/4329]: training loss : 1.2529038524627685 TRAIN  loss dict:  {'classification_loss': 1.2529038524627685}
2025-01-12 16:57:56,211 [INFO] Step[3700/4329]: training loss : 1.3520903861522675 TRAIN  loss dict:  {'classification_loss': 1.3520903861522675}
2025-01-12 16:58:07,857 [INFO] Step[3750/4329]: training loss : 1.2109356868267058 TRAIN  loss dict:  {'classification_loss': 1.2109356868267058}
2025-01-12 16:58:19,484 [INFO] Step[3800/4329]: training loss : 1.2812011432647705 TRAIN  loss dict:  {'classification_loss': 1.2812011432647705}
2025-01-12 16:58:31,165 [INFO] Step[3850/4329]: training loss : 1.2347752583026885 TRAIN  loss dict:  {'classification_loss': 1.2347752583026885}
2025-01-12 16:58:42,808 [INFO] Step[3900/4329]: training loss : 1.2875008153915406 TRAIN  loss dict:  {'classification_loss': 1.2875008153915406}
2025-01-12 16:58:54,473 [INFO] Step[3950/4329]: training loss : 1.2399215471744538 TRAIN  loss dict:  {'classification_loss': 1.2399215471744538}
2025-01-12 16:59:06,132 [INFO] Step[4000/4329]: training loss : 1.1905769681930543 TRAIN  loss dict:  {'classification_loss': 1.1905769681930543}
2025-01-12 16:59:17,829 [INFO] Step[4050/4329]: training loss : 1.3947550117969514 TRAIN  loss dict:  {'classification_loss': 1.3947550117969514}
2025-01-12 16:59:29,480 [INFO] Step[4100/4329]: training loss : 1.439900325536728 TRAIN  loss dict:  {'classification_loss': 1.439900325536728}
2025-01-12 16:59:41,136 [INFO] Step[4150/4329]: training loss : 1.264821046590805 TRAIN  loss dict:  {'classification_loss': 1.264821046590805}
2025-01-12 16:59:52,760 [INFO] Step[4200/4329]: training loss : 1.2137056398391723 TRAIN  loss dict:  {'classification_loss': 1.2137056398391723}
2025-01-12 17:00:04,443 [INFO] Step[4250/4329]: training loss : 1.2831093156337738 TRAIN  loss dict:  {'classification_loss': 1.2831093156337738}
2025-01-12 17:00:16,057 [INFO] Step[4300/4329]: training loss : 1.1254776418209076 TRAIN  loss dict:  {'classification_loss': 1.1254776418209076}
2025-01-12 17:02:14,916 [INFO] Label accuracies statistics:
2025-01-12 17:02:14,916 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.9166666666666666, 6: 0.5833333333333334, 7: 0.5, 8: 0.6666666666666666, 9: 0.75, 10: 1.0, 11: 0.6666666666666666, 12: 0.4166666666666667, 13: 0.25, 14: 0.6666666666666666, 15: 0.6666666666666666, 16: 0.4166666666666667, 17: 0.25, 18: 0.5833333333333334, 19: 0.5833333333333334, 20: 0.6666666666666666, 21: 0.6666666666666666, 22: 0.5833333333333334, 23: 0.9166666666666666, 24: 1.0, 25: 0.6666666666666666, 26: 0.75, 27: 0.4166666666666667, 28: 0.75, 29: 1.0, 30: 0.4166666666666667, 31: 0.6666666666666666, 32: 0.75, 33: 0.8333333333333334, 34: 0.75, 35: 0.8333333333333334, 36: 0.5833333333333334, 37: 0.9166666666666666, 38: 0.5833333333333334, 39: 0.9166666666666666, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.9166666666666666, 44: 0.5, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 0.8333333333333334, 49: 0.9166666666666666, 50: 0.5833333333333334, 51: 0.6666666666666666, 52: 0.9166666666666666, 53: 0.4166666666666667, 54: 0.4166666666666667, 55: 0.6666666666666666, 56: 0.75, 57: 0.5833333333333334, 58: 0.5, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.6666666666666666, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 0.9166666666666666, 66: 0.5, 67: 0.9166666666666666, 68: 0.75, 69: 0.6666666666666666, 70: 0.16666666666666666, 71: 0.5833333333333334, 72: 0.5833333333333334, 73: 1.0, 74: 0.75, 75: 0.9166666666666666, 76: 0.6666666666666666, 77: 0.5833333333333334, 78: 0.9166666666666666, 79: 0.75, 80: 0.9166666666666666, 81: 1.0, 82: 0.6666666666666666, 83: 0.5833333333333334, 84: 0.4166666666666667, 85: 0.75, 86: 0.5833333333333334, 87: 0.8333333333333334, 88: 0.8333333333333334, 89: 0.5, 90: 0.8333333333333334, 91: 0.6666666666666666, 92: 1.0, 93: 0.9166666666666666, 94: 0.5, 95: 0.9166666666666666, 96: 0.4166666666666667, 97: 0.75, 98: 0.6666666666666666, 99: 0.8666666666666667, 100: 0.8333333333333334, 101: 1.0, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 0.8333333333333334, 107: 0.3333333333333333, 108: 0.8333333333333334, 109: 0.6666666666666666, 110: 0.9166666666666666, 111: 1.0, 112: 0.6666666666666666, 113: 0.4166666666666667, 114: 0.5833333333333334, 115: 0.8333333333333334, 116: 0.75, 117: 1.0, 118: 0.9166666666666666, 119: 0.75, 120: 0.5833333333333334, 121: 0.5833333333333334, 122: 0.75, 123: 1.0, 124: 0.6666666666666666, 125: 0.75, 126: 1.0, 127: 0.9166666666666666, 128: 1.0, 129: 0.8333333333333334, 130: 0.8333333333333334, 131: 0.8333333333333334, 132: 0.8333333333333334, 133: 1.0, 134: 0.4166666666666667, 135: 1.0, 136: 1.0, 137: 0.6666666666666666, 138: 0.6666666666666666, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.9166666666666666, 144: 0.6666666666666666, 145: 0.75, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 0.9166666666666666, 150: 0.4166666666666667, 151: 1.0, 152: 0.75, 153: 0.9166666666666666, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.6666666666666666, 158: 0.7777777777777778, 159: 0.9166666666666666, 160: 0.3333333333333333, 161: 0.9166666666666666, 162: 0.9166666666666666, 163: 0.9166666666666666, 164: 1.0, 165: 1.0, 166: 0.75, 167: 0.8333333333333334, 168: 0.8333333333333334, 169: 0.8333333333333334, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.8333333333333334, 175: 0.75, 176: 0.8333333333333334, 177: 0.5833333333333334, 178: 0.8333333333333334, 179: 0.0, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.6666666666666666, 183: 0.8333333333333334, 184: 0.5, 185: 1.0, 186: 0.5833333333333334, 187: 1.0, 188: 0.75, 189: 0.9166666666666666, 190: 0.5, 191: 0.4166666666666667, 192: 0.9166666666666666, 193: 0.8333333333333334, 194: 0.8333333333333334, 195: 1.0, 196: 0.9166666666666666, 197: 0.6666666666666666, 198: 0.75}

2025-01-12 17:02:16,763 [INFO] [7] TRAIN  loss: 1.2340518649771628 acc: 0.9006622516556292
2025-01-12 17:02:16,763 [INFO] [7] TRAIN  loss dict: {'classification_loss': 1.2340518649771628}
2025-01-12 17:02:16,763 [INFO] [7] VALIDATION loss: 1.8197729214273317 VALIDATION acc: 0.7491582491582491
2025-01-12 17:02:16,763 [INFO] [7] VALIDATION loss dict: {'classification_loss': 1.8197729214273317}
2025-01-12 17:02:16,763 [INFO] 
2025-01-12 17:02:33,518 [INFO] Step[50/4329]: training loss : 1.1487622666358948 TRAIN  loss dict:  {'classification_loss': 1.1487622666358948}
2025-01-12 17:02:45,780 [INFO] Step[100/4329]: training loss : 1.2255483531951905 TRAIN  loss dict:  {'classification_loss': 1.2255483531951905}
2025-01-12 17:02:58,081 [INFO] Step[150/4329]: training loss : 1.1476103127002717 TRAIN  loss dict:  {'classification_loss': 1.1476103127002717}
2025-01-12 17:03:11,376 [INFO] Step[200/4329]: training loss : 1.1964081919193268 TRAIN  loss dict:  {'classification_loss': 1.1964081919193268}
2025-01-12 17:03:24,770 [INFO] Step[250/4329]: training loss : 1.0956480288505555 TRAIN  loss dict:  {'classification_loss': 1.0956480288505555}
2025-01-12 17:03:38,514 [INFO] Step[300/4329]: training loss : 1.1440276277065278 TRAIN  loss dict:  {'classification_loss': 1.1440276277065278}
2025-01-12 17:03:50,504 [INFO] Step[350/4329]: training loss : 1.192282156944275 TRAIN  loss dict:  {'classification_loss': 1.192282156944275}
2025-01-12 17:04:02,310 [INFO] Step[400/4329]: training loss : 1.1449574744701385 TRAIN  loss dict:  {'classification_loss': 1.1449574744701385}
2025-01-12 17:04:14,010 [INFO] Step[450/4329]: training loss : 1.2237467455863953 TRAIN  loss dict:  {'classification_loss': 1.2237467455863953}
2025-01-12 17:04:25,656 [INFO] Step[500/4329]: training loss : 1.165680136680603 TRAIN  loss dict:  {'classification_loss': 1.165680136680603}
2025-01-12 17:04:37,324 [INFO] Step[550/4329]: training loss : 1.1783761942386628 TRAIN  loss dict:  {'classification_loss': 1.1783761942386628}
2025-01-12 17:04:48,998 [INFO] Step[600/4329]: training loss : 1.1543613588809967 TRAIN  loss dict:  {'classification_loss': 1.1543613588809967}
2025-01-12 17:05:00,632 [INFO] Step[650/4329]: training loss : 1.1467565178871155 TRAIN  loss dict:  {'classification_loss': 1.1467565178871155}
2025-01-12 17:05:12,270 [INFO] Step[700/4329]: training loss : 1.1526625835895539 TRAIN  loss dict:  {'classification_loss': 1.1526625835895539}
2025-01-12 17:05:23,970 [INFO] Step[750/4329]: training loss : 1.2125515449047088 TRAIN  loss dict:  {'classification_loss': 1.2125515449047088}
2025-01-12 17:05:35,602 [INFO] Step[800/4329]: training loss : 1.220459784269333 TRAIN  loss dict:  {'classification_loss': 1.220459784269333}
2025-01-12 17:05:47,222 [INFO] Step[850/4329]: training loss : 1.2390389776229858 TRAIN  loss dict:  {'classification_loss': 1.2390389776229858}
2025-01-12 17:05:58,864 [INFO] Step[900/4329]: training loss : 1.165059300661087 TRAIN  loss dict:  {'classification_loss': 1.165059300661087}
2025-01-12 17:06:10,523 [INFO] Step[950/4329]: training loss : 1.185214834213257 TRAIN  loss dict:  {'classification_loss': 1.185214834213257}
2025-01-12 17:06:22,135 [INFO] Step[1000/4329]: training loss : 1.2495706474781036 TRAIN  loss dict:  {'classification_loss': 1.2495706474781036}
2025-01-12 17:06:33,841 [INFO] Step[1050/4329]: training loss : 1.1957616627216339 TRAIN  loss dict:  {'classification_loss': 1.1957616627216339}
2025-01-12 17:06:45,493 [INFO] Step[1100/4329]: training loss : 1.1842095053195953 TRAIN  loss dict:  {'classification_loss': 1.1842095053195953}
2025-01-12 17:06:57,151 [INFO] Step[1150/4329]: training loss : 1.1494099473953248 TRAIN  loss dict:  {'classification_loss': 1.1494099473953248}
2025-01-12 17:07:08,812 [INFO] Step[1200/4329]: training loss : 1.264186395406723 TRAIN  loss dict:  {'classification_loss': 1.264186395406723}
2025-01-12 17:07:20,447 [INFO] Step[1250/4329]: training loss : 1.1724814093112945 TRAIN  loss dict:  {'classification_loss': 1.1724814093112945}
2025-01-12 17:07:32,094 [INFO] Step[1300/4329]: training loss : 1.1767020440101623 TRAIN  loss dict:  {'classification_loss': 1.1767020440101623}
2025-01-12 17:07:43,720 [INFO] Step[1350/4329]: training loss : 1.1448401629924774 TRAIN  loss dict:  {'classification_loss': 1.1448401629924774}
2025-01-12 17:07:55,353 [INFO] Step[1400/4329]: training loss : 1.2212476098537446 TRAIN  loss dict:  {'classification_loss': 1.2212476098537446}
2025-01-12 17:08:06,944 [INFO] Step[1450/4329]: training loss : 1.2575344717502595 TRAIN  loss dict:  {'classification_loss': 1.2575344717502595}
2025-01-12 17:08:18,600 [INFO] Step[1500/4329]: training loss : 1.3115492355823517 TRAIN  loss dict:  {'classification_loss': 1.3115492355823517}
2025-01-12 17:08:30,251 [INFO] Step[1550/4329]: training loss : 1.2113726580142974 TRAIN  loss dict:  {'classification_loss': 1.2113726580142974}
2025-01-12 17:08:41,836 [INFO] Step[1600/4329]: training loss : 1.1686781573295593 TRAIN  loss dict:  {'classification_loss': 1.1686781573295593}
2025-01-12 17:08:53,445 [INFO] Step[1650/4329]: training loss : 1.1274380934238435 TRAIN  loss dict:  {'classification_loss': 1.1274380934238435}
2025-01-12 17:09:05,076 [INFO] Step[1700/4329]: training loss : 1.2691929733753204 TRAIN  loss dict:  {'classification_loss': 1.2691929733753204}
2025-01-12 17:09:16,751 [INFO] Step[1750/4329]: training loss : 1.1811283004283906 TRAIN  loss dict:  {'classification_loss': 1.1811283004283906}
2025-01-12 17:09:28,407 [INFO] Step[1800/4329]: training loss : 1.2183083426952361 TRAIN  loss dict:  {'classification_loss': 1.2183083426952361}
2025-01-12 17:09:40,054 [INFO] Step[1850/4329]: training loss : 1.1572175705432892 TRAIN  loss dict:  {'classification_loss': 1.1572175705432892}
2025-01-12 17:09:51,710 [INFO] Step[1900/4329]: training loss : 1.1584223914146423 TRAIN  loss dict:  {'classification_loss': 1.1584223914146423}
2025-01-12 17:10:03,364 [INFO] Step[1950/4329]: training loss : 1.1718604350090027 TRAIN  loss dict:  {'classification_loss': 1.1718604350090027}
2025-01-12 17:10:14,980 [INFO] Step[2000/4329]: training loss : 1.2363723456859588 TRAIN  loss dict:  {'classification_loss': 1.2363723456859588}
2025-01-12 17:10:26,666 [INFO] Step[2050/4329]: training loss : 1.1612698125839234 TRAIN  loss dict:  {'classification_loss': 1.1612698125839234}
2025-01-12 17:10:38,263 [INFO] Step[2100/4329]: training loss : 1.205486489534378 TRAIN  loss dict:  {'classification_loss': 1.205486489534378}
2025-01-12 17:10:49,874 [INFO] Step[2150/4329]: training loss : 1.1907369363307954 TRAIN  loss dict:  {'classification_loss': 1.1907369363307954}
2025-01-12 17:11:01,518 [INFO] Step[2200/4329]: training loss : 1.1943523168563843 TRAIN  loss dict:  {'classification_loss': 1.1943523168563843}
2025-01-12 17:11:13,136 [INFO] Step[2250/4329]: training loss : 1.1362625908851625 TRAIN  loss dict:  {'classification_loss': 1.1362625908851625}
2025-01-12 17:11:24,773 [INFO] Step[2300/4329]: training loss : 1.3069385552406312 TRAIN  loss dict:  {'classification_loss': 1.3069385552406312}
2025-01-12 17:11:36,381 [INFO] Step[2350/4329]: training loss : 1.172436809539795 TRAIN  loss dict:  {'classification_loss': 1.172436809539795}
2025-01-12 17:11:48,028 [INFO] Step[2400/4329]: training loss : 1.3087834441661834 TRAIN  loss dict:  {'classification_loss': 1.3087834441661834}
2025-01-12 17:11:59,657 [INFO] Step[2450/4329]: training loss : 1.1723273062705994 TRAIN  loss dict:  {'classification_loss': 1.1723273062705994}
2025-01-12 17:12:11,284 [INFO] Step[2500/4329]: training loss : 1.1886523187160491 TRAIN  loss dict:  {'classification_loss': 1.1886523187160491}
2025-01-12 17:12:22,939 [INFO] Step[2550/4329]: training loss : 1.185868457555771 TRAIN  loss dict:  {'classification_loss': 1.185868457555771}
2025-01-12 17:12:34,604 [INFO] Step[2600/4329]: training loss : 1.147837414741516 TRAIN  loss dict:  {'classification_loss': 1.147837414741516}
2025-01-12 17:12:46,285 [INFO] Step[2650/4329]: training loss : 1.2842009162902832 TRAIN  loss dict:  {'classification_loss': 1.2842009162902832}
2025-01-12 17:12:57,928 [INFO] Step[2700/4329]: training loss : 1.1964783012866973 TRAIN  loss dict:  {'classification_loss': 1.1964783012866973}
2025-01-12 17:13:09,576 [INFO] Step[2750/4329]: training loss : 1.198933629989624 TRAIN  loss dict:  {'classification_loss': 1.198933629989624}
2025-01-12 17:13:21,240 [INFO] Step[2800/4329]: training loss : 1.2438696479797364 TRAIN  loss dict:  {'classification_loss': 1.2438696479797364}
2025-01-12 17:13:32,861 [INFO] Step[2850/4329]: training loss : 1.2452719926834106 TRAIN  loss dict:  {'classification_loss': 1.2452719926834106}
2025-01-12 17:13:44,487 [INFO] Step[2900/4329]: training loss : 1.1607813823223114 TRAIN  loss dict:  {'classification_loss': 1.1607813823223114}
2025-01-12 17:13:56,143 [INFO] Step[2950/4329]: training loss : 1.2613532972335815 TRAIN  loss dict:  {'classification_loss': 1.2613532972335815}
2025-01-12 17:14:07,737 [INFO] Step[3000/4329]: training loss : 1.2271323204040527 TRAIN  loss dict:  {'classification_loss': 1.2271323204040527}
2025-01-12 17:14:19,413 [INFO] Step[3050/4329]: training loss : 1.1304311275482177 TRAIN  loss dict:  {'classification_loss': 1.1304311275482177}
2025-01-12 17:14:31,044 [INFO] Step[3100/4329]: training loss : 1.2236582827568054 TRAIN  loss dict:  {'classification_loss': 1.2236582827568054}
2025-01-12 17:14:42,755 [INFO] Step[3150/4329]: training loss : 1.2243131983280182 TRAIN  loss dict:  {'classification_loss': 1.2243131983280182}
2025-01-12 17:14:54,860 [INFO] Step[3200/4329]: training loss : 1.1936444389820098 TRAIN  loss dict:  {'classification_loss': 1.1936444389820098}
2025-01-12 17:15:07,066 [INFO] Step[3250/4329]: training loss : 1.1751077461242676 TRAIN  loss dict:  {'classification_loss': 1.1751077461242676}
2025-01-12 17:15:19,636 [INFO] Step[3300/4329]: training loss : 1.174187432527542 TRAIN  loss dict:  {'classification_loss': 1.174187432527542}
2025-01-12 17:15:32,841 [INFO] Step[3350/4329]: training loss : 1.2125317013263703 TRAIN  loss dict:  {'classification_loss': 1.2125317013263703}
2025-01-12 17:15:46,046 [INFO] Step[3400/4329]: training loss : 1.1754890644550324 TRAIN  loss dict:  {'classification_loss': 1.1754890644550324}
2025-01-12 17:15:57,972 [INFO] Step[3450/4329]: training loss : 1.1505564498901366 TRAIN  loss dict:  {'classification_loss': 1.1505564498901366}
2025-01-12 17:16:09,683 [INFO] Step[3500/4329]: training loss : 1.2347072243690491 TRAIN  loss dict:  {'classification_loss': 1.2347072243690491}
2025-01-12 17:16:21,349 [INFO] Step[3550/4329]: training loss : 1.1352227413654328 TRAIN  loss dict:  {'classification_loss': 1.1352227413654328}
2025-01-12 17:16:33,268 [INFO] Step[3600/4329]: training loss : 1.2828947865962983 TRAIN  loss dict:  {'classification_loss': 1.2828947865962983}
2025-01-12 17:16:44,912 [INFO] Step[3650/4329]: training loss : 1.202175908088684 TRAIN  loss dict:  {'classification_loss': 1.202175908088684}
2025-01-12 17:16:56,579 [INFO] Step[3700/4329]: training loss : 1.2007102525234223 TRAIN  loss dict:  {'classification_loss': 1.2007102525234223}
2025-01-12 17:17:08,215 [INFO] Step[3750/4329]: training loss : 1.272164648771286 TRAIN  loss dict:  {'classification_loss': 1.272164648771286}
2025-01-12 17:17:19,834 [INFO] Step[3800/4329]: training loss : 1.1061379897594452 TRAIN  loss dict:  {'classification_loss': 1.1061379897594452}
2025-01-12 17:17:31,485 [INFO] Step[3850/4329]: training loss : 1.205357574224472 TRAIN  loss dict:  {'classification_loss': 1.205357574224472}
2025-01-12 17:17:43,111 [INFO] Step[3900/4329]: training loss : 1.2775270819664002 TRAIN  loss dict:  {'classification_loss': 1.2775270819664002}
2025-01-12 17:17:54,733 [INFO] Step[3950/4329]: training loss : 1.1898724937438965 TRAIN  loss dict:  {'classification_loss': 1.1898724937438965}
2025-01-12 17:18:06,372 [INFO] Step[4000/4329]: training loss : 1.1481320583820342 TRAIN  loss dict:  {'classification_loss': 1.1481320583820342}
2025-01-12 17:18:17,996 [INFO] Step[4050/4329]: training loss : 1.2507753729820252 TRAIN  loss dict:  {'classification_loss': 1.2507753729820252}
2025-01-12 17:18:29,576 [INFO] Step[4100/4329]: training loss : 1.1986135566234588 TRAIN  loss dict:  {'classification_loss': 1.1986135566234588}
2025-01-12 17:18:41,204 [INFO] Step[4150/4329]: training loss : 1.2189394295215608 TRAIN  loss dict:  {'classification_loss': 1.2189394295215608}
2025-01-12 17:18:52,829 [INFO] Step[4200/4329]: training loss : 1.1200292015075684 TRAIN  loss dict:  {'classification_loss': 1.1200292015075684}
2025-01-12 17:19:04,444 [INFO] Step[4250/4329]: training loss : 1.1442479121685027 TRAIN  loss dict:  {'classification_loss': 1.1442479121685027}
2025-01-12 17:19:16,100 [INFO] Step[4300/4329]: training loss : 1.3012062048912048 TRAIN  loss dict:  {'classification_loss': 1.3012062048912048}
2025-01-12 17:21:14,875 [INFO] Label accuracies statistics:
2025-01-12 17:21:14,875 [INFO] {0: 0.6666666666666666, 1: 0.7777777777777778, 2: 0.6666666666666666, 3: 0.75, 4: 0.4166666666666667, 5: 0.6666666666666666, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.8333333333333334, 10: 0.9166666666666666, 11: 0.75, 12: 0.5833333333333334, 13: 0.75, 14: 0.4166666666666667, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.5833333333333334, 18: 0.5833333333333334, 19: 0.6666666666666666, 20: 0.5, 21: 0.5833333333333334, 22: 0.6666666666666666, 23: 0.9166666666666666, 24: 1.0, 25: 0.5, 26: 0.9166666666666666, 27: 0.6666666666666666, 28: 0.8333333333333334, 29: 1.0, 30: 0.4166666666666667, 31: 0.5833333333333334, 32: 0.6666666666666666, 33: 0.75, 34: 0.8333333333333334, 35: 0.75, 36: 0.5, 37: 0.8333333333333334, 38: 0.9166666666666666, 39: 0.9166666666666666, 40: 0.75, 41: 0.25, 42: 0.8333333333333334, 43: 0.8333333333333334, 44: 0.5833333333333334, 45: 0.4166666666666667, 46: 1.0, 47: 0.75, 48: 0.8333333333333334, 49: 1.0, 50: 0.5833333333333334, 51: 0.75, 52: 0.9166666666666666, 53: 0.5, 54: 0.3333333333333333, 55: 0.5, 56: 0.75, 57: 0.6666666666666666, 58: 0.16666666666666666, 59: 1.0, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.4166666666666667, 64: 0.75, 65: 1.0, 66: 0.5833333333333334, 67: 0.5833333333333334, 68: 0.25, 69: 0.5833333333333334, 70: 0.16666666666666666, 71: 0.6666666666666666, 72: 0.9166666666666666, 73: 0.75, 74: 0.4166666666666667, 75: 1.0, 76: 0.5, 77: 0.5833333333333334, 78: 0.9166666666666666, 79: 0.5833333333333334, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5833333333333334, 84: 0.4166666666666667, 85: 0.5, 86: 0.5, 87: 0.8333333333333334, 88: 0.6666666666666666, 89: 0.6666666666666666, 90: 0.9166666666666666, 91: 0.9166666666666666, 92: 1.0, 93: 0.8333333333333334, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.75, 98: 0.8333333333333334, 99: 0.8666666666666667, 100: 0.5, 101: 0.6666666666666666, 102: 0.9166666666666666, 103: 0.75, 104: 1.0, 105: 0.9166666666666666, 106: 0.9166666666666666, 107: 0.08333333333333333, 108: 1.0, 109: 0.8333333333333334, 110: 0.8333333333333334, 111: 0.75, 112: 0.8333333333333334, 113: 0.6666666666666666, 114: 0.3333333333333333, 115: 0.8333333333333334, 116: 0.5, 117: 0.3333333333333333, 118: 0.9166666666666666, 119: 0.75, 120: 0.9166666666666666, 121: 0.8333333333333334, 122: 0.9166666666666666, 123: 0.8333333333333334, 124: 0.8333333333333334, 125: 0.6666666666666666, 126: 0.8333333333333334, 127: 0.8333333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.4166666666666667, 131: 0.9166666666666666, 132: 0.5833333333333334, 133: 1.0, 134: 0.6666666666666666, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.75, 138: 0.8333333333333334, 139: 0.75, 140: 0.8333333333333334, 141: 0.9166666666666666, 142: 0.5, 143: 0.8333333333333334, 144: 0.5, 145: 0.9166666666666666, 146: 0.9166666666666666, 147: 0.6666666666666666, 148: 0.5833333333333334, 149: 0.9166666666666666, 150: 0.4166666666666667, 151: 0.9166666666666666, 152: 0.9166666666666666, 153: 1.0, 154: 1.0, 155: 0.9166666666666666, 156: 0.5, 157: 0.9166666666666666, 158: 0.6666666666666666, 159: 0.9166666666666666, 160: 0.4166666666666667, 161: 0.6666666666666666, 162: 0.6666666666666666, 163: 0.8333333333333334, 164: 0.75, 165: 0.5, 166: 0.5833333333333334, 167: 0.8333333333333334, 168: 0.3333333333333333, 169: 0.8333333333333334, 170: 0.9166666666666666, 171: 0.4166666666666667, 172: 1.0, 173: 0.6666666666666666, 174: 0.9166666666666666, 175: 0.5, 176: 1.0, 177: 0.6666666666666666, 178: 1.0, 179: 0.2222222222222222, 180: 0.9166666666666666, 181: 0.75, 182: 0.5833333333333334, 183: 0.8333333333333334, 184: 0.5833333333333334, 185: 1.0, 186: 0.9166666666666666, 187: 0.9166666666666666, 188: 0.25, 189: 0.8333333333333334, 190: 0.4166666666666667, 191: 0.4166666666666667, 192: 1.0, 193: 0.8333333333333334, 194: 0.9166666666666666, 195: 0.75, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.3333333333333333}

2025-01-12 17:21:14,877 [INFO] [8] TRAIN  loss: 1.1968729700880256 acc: 0.9178345910981056
2025-01-12 17:21:14,877 [INFO] [8] TRAIN  loss dict: {'classification_loss': 1.1968729700880256}
2025-01-12 17:21:14,877 [INFO] [8] VALIDATION loss: 1.8652376500946102 VALIDATION acc: 0.7188552188552189
2025-01-12 17:21:14,877 [INFO] [8] VALIDATION loss dict: {'classification_loss': 1.8652376500946102}
2025-01-12 17:21:14,877 [INFO] 
2025-01-12 17:21:32,788 [INFO] Step[50/4329]: training loss : 1.2040934193134307 TRAIN  loss dict:  {'classification_loss': 1.2040934193134307}
2025-01-12 17:21:44,412 [INFO] Step[100/4329]: training loss : 1.2101230645179748 TRAIN  loss dict:  {'classification_loss': 1.2101230645179748}
2025-01-12 17:21:55,981 [INFO] Step[150/4329]: training loss : 1.1871163547039032 TRAIN  loss dict:  {'classification_loss': 1.1871163547039032}
2025-01-12 17:22:07,599 [INFO] Step[200/4329]: training loss : 1.2483935785293578 TRAIN  loss dict:  {'classification_loss': 1.2483935785293578}
2025-01-12 17:22:19,228 [INFO] Step[250/4329]: training loss : 1.2083933913707734 TRAIN  loss dict:  {'classification_loss': 1.2083933913707734}
2025-01-12 17:22:30,851 [INFO] Step[300/4329]: training loss : 1.1456314826011658 TRAIN  loss dict:  {'classification_loss': 1.1456314826011658}
2025-01-12 17:22:42,512 [INFO] Step[350/4329]: training loss : 1.0584323513507843 TRAIN  loss dict:  {'classification_loss': 1.0584323513507843}
2025-01-12 17:22:54,148 [INFO] Step[400/4329]: training loss : 1.1984793472290038 TRAIN  loss dict:  {'classification_loss': 1.1984793472290038}
2025-01-12 17:23:05,753 [INFO] Step[450/4329]: training loss : 1.102627694606781 TRAIN  loss dict:  {'classification_loss': 1.102627694606781}
2025-01-12 17:23:17,375 [INFO] Step[500/4329]: training loss : 1.1246090865135192 TRAIN  loss dict:  {'classification_loss': 1.1246090865135192}
2025-01-12 17:23:29,035 [INFO] Step[550/4329]: training loss : 1.1459301590919495 TRAIN  loss dict:  {'classification_loss': 1.1459301590919495}
2025-01-12 17:23:40,634 [INFO] Step[600/4329]: training loss : 1.1579804968833924 TRAIN  loss dict:  {'classification_loss': 1.1579804968833924}
2025-01-12 17:23:52,238 [INFO] Step[650/4329]: training loss : 1.1485935819149018 TRAIN  loss dict:  {'classification_loss': 1.1485935819149018}
2025-01-12 17:24:03,859 [INFO] Step[700/4329]: training loss : 1.1995889556407928 TRAIN  loss dict:  {'classification_loss': 1.1995889556407928}
2025-01-12 17:24:15,524 [INFO] Step[750/4329]: training loss : 1.1061440765857697 TRAIN  loss dict:  {'classification_loss': 1.1061440765857697}
2025-01-12 17:24:27,136 [INFO] Step[800/4329]: training loss : 1.2077293956279755 TRAIN  loss dict:  {'classification_loss': 1.2077293956279755}
2025-01-12 17:24:38,750 [INFO] Step[850/4329]: training loss : 1.1122666347026824 TRAIN  loss dict:  {'classification_loss': 1.1122666347026824}
2025-01-12 17:24:50,352 [INFO] Step[900/4329]: training loss : 1.17024506688118 TRAIN  loss dict:  {'classification_loss': 1.17024506688118}
2025-01-12 17:25:02,001 [INFO] Step[950/4329]: training loss : 1.2117388772964477 TRAIN  loss dict:  {'classification_loss': 1.2117388772964477}
2025-01-12 17:25:13,618 [INFO] Step[1000/4329]: training loss : 1.1785512852668762 TRAIN  loss dict:  {'classification_loss': 1.1785512852668762}
2025-01-12 17:25:25,232 [INFO] Step[1050/4329]: training loss : 1.123396873474121 TRAIN  loss dict:  {'classification_loss': 1.123396873474121}
2025-01-12 17:25:36,873 [INFO] Step[1100/4329]: training loss : 1.2295011699199676 TRAIN  loss dict:  {'classification_loss': 1.2295011699199676}
2025-01-12 17:25:48,520 [INFO] Step[1150/4329]: training loss : 1.2003364491462707 TRAIN  loss dict:  {'classification_loss': 1.2003364491462707}
2025-01-12 17:26:00,095 [INFO] Step[1200/4329]: training loss : 1.1169702053070067 TRAIN  loss dict:  {'classification_loss': 1.1169702053070067}
2025-01-12 17:26:11,727 [INFO] Step[1250/4329]: training loss : 1.1862040984630584 TRAIN  loss dict:  {'classification_loss': 1.1862040984630584}
2025-01-12 17:26:23,347 [INFO] Step[1300/4329]: training loss : 1.1922805082798005 TRAIN  loss dict:  {'classification_loss': 1.1922805082798005}
2025-01-12 17:26:34,977 [INFO] Step[1350/4329]: training loss : 1.1082622361183168 TRAIN  loss dict:  {'classification_loss': 1.1082622361183168}
2025-01-12 17:26:46,585 [INFO] Step[1400/4329]: training loss : 1.2073806321620941 TRAIN  loss dict:  {'classification_loss': 1.2073806321620941}
2025-01-12 17:26:58,212 [INFO] Step[1450/4329]: training loss : 1.1828797090053558 TRAIN  loss dict:  {'classification_loss': 1.1828797090053558}
2025-01-12 17:27:09,789 [INFO] Step[1500/4329]: training loss : 1.1734337615966797 TRAIN  loss dict:  {'classification_loss': 1.1734337615966797}
2025-01-12 17:27:21,460 [INFO] Step[1550/4329]: training loss : 1.17329643368721 TRAIN  loss dict:  {'classification_loss': 1.17329643368721}
2025-01-12 17:27:33,607 [INFO] Step[1600/4329]: training loss : 1.2231286561489105 TRAIN  loss dict:  {'classification_loss': 1.2231286561489105}
2025-01-12 17:27:45,855 [INFO] Step[1650/4329]: training loss : 1.2320948100090028 TRAIN  loss dict:  {'classification_loss': 1.2320948100090028}
2025-01-12 17:27:58,458 [INFO] Step[1700/4329]: training loss : 1.2292320597171784 TRAIN  loss dict:  {'classification_loss': 1.2292320597171784}
2025-01-12 17:28:12,101 [INFO] Step[1750/4329]: training loss : 1.0640918171405793 TRAIN  loss dict:  {'classification_loss': 1.0640918171405793}
2025-01-12 17:28:26,070 [INFO] Step[1800/4329]: training loss : 1.1468227732181548 TRAIN  loss dict:  {'classification_loss': 1.1468227732181548}
2025-01-12 17:28:38,027 [INFO] Step[1850/4329]: training loss : 1.1338355326652527 TRAIN  loss dict:  {'classification_loss': 1.1338355326652527}
2025-01-12 17:28:49,951 [INFO] Step[1900/4329]: training loss : 1.1802450931072235 TRAIN  loss dict:  {'classification_loss': 1.1802450931072235}
2025-01-12 17:29:01,658 [INFO] Step[1950/4329]: training loss : 1.161523529291153 TRAIN  loss dict:  {'classification_loss': 1.161523529291153}
2025-01-12 17:29:13,314 [INFO] Step[2000/4329]: training loss : 1.2607500779628753 TRAIN  loss dict:  {'classification_loss': 1.2607500779628753}
2025-01-12 17:29:24,931 [INFO] Step[2050/4329]: training loss : 1.1856353628635405 TRAIN  loss dict:  {'classification_loss': 1.1856353628635405}
2025-01-12 17:29:36,537 [INFO] Step[2100/4329]: training loss : 1.1594253814220428 TRAIN  loss dict:  {'classification_loss': 1.1594253814220428}
2025-01-12 17:29:48,154 [INFO] Step[2150/4329]: training loss : 1.2091945922374725 TRAIN  loss dict:  {'classification_loss': 1.2091945922374725}
2025-01-12 17:29:59,773 [INFO] Step[2200/4329]: training loss : 1.1171335399150848 TRAIN  loss dict:  {'classification_loss': 1.1171335399150848}
2025-01-12 17:30:11,456 [INFO] Step[2250/4329]: training loss : 1.137676191329956 TRAIN  loss dict:  {'classification_loss': 1.137676191329956}
2025-01-12 17:30:23,055 [INFO] Step[2300/4329]: training loss : 1.18014723777771 TRAIN  loss dict:  {'classification_loss': 1.18014723777771}
2025-01-12 17:30:34,686 [INFO] Step[2350/4329]: training loss : 1.146321873664856 TRAIN  loss dict:  {'classification_loss': 1.146321873664856}
2025-01-12 17:30:46,352 [INFO] Step[2400/4329]: training loss : 1.2363230335712432 TRAIN  loss dict:  {'classification_loss': 1.2363230335712432}
2025-01-12 17:30:57,985 [INFO] Step[2450/4329]: training loss : 1.1847863733768462 TRAIN  loss dict:  {'classification_loss': 1.1847863733768462}
2025-01-12 17:31:09,590 [INFO] Step[2500/4329]: training loss : 1.160777976512909 TRAIN  loss dict:  {'classification_loss': 1.160777976512909}
2025-01-12 17:31:21,197 [INFO] Step[2550/4329]: training loss : 1.1436659431457519 TRAIN  loss dict:  {'classification_loss': 1.1436659431457519}
2025-01-12 17:31:32,824 [INFO] Step[2600/4329]: training loss : 1.2107027637958527 TRAIN  loss dict:  {'classification_loss': 1.2107027637958527}
2025-01-12 17:31:44,452 [INFO] Step[2650/4329]: training loss : 1.097673588991165 TRAIN  loss dict:  {'classification_loss': 1.097673588991165}
2025-01-12 17:31:56,058 [INFO] Step[2700/4329]: training loss : 1.1410298991203307 TRAIN  loss dict:  {'classification_loss': 1.1410298991203307}
2025-01-12 17:32:07,675 [INFO] Step[2750/4329]: training loss : 1.2362920427322388 TRAIN  loss dict:  {'classification_loss': 1.2362920427322388}
2025-01-12 17:32:19,317 [INFO] Step[2800/4329]: training loss : 1.1637538397312164 TRAIN  loss dict:  {'classification_loss': 1.1637538397312164}
2025-01-12 17:32:30,979 [INFO] Step[2850/4329]: training loss : 1.1038069450855255 TRAIN  loss dict:  {'classification_loss': 1.1038069450855255}
2025-01-12 17:32:42,573 [INFO] Step[2900/4329]: training loss : 1.2786408019065858 TRAIN  loss dict:  {'classification_loss': 1.2786408019065858}
2025-01-12 17:32:54,216 [INFO] Step[2950/4329]: training loss : 1.1947922921180725 TRAIN  loss dict:  {'classification_loss': 1.1947922921180725}
2025-01-12 17:33:05,867 [INFO] Step[3000/4329]: training loss : 1.1607085716724397 TRAIN  loss dict:  {'classification_loss': 1.1607085716724397}
2025-01-12 17:33:17,459 [INFO] Step[3050/4329]: training loss : 1.1862749063968658 TRAIN  loss dict:  {'classification_loss': 1.1862749063968658}
2025-01-12 17:33:29,044 [INFO] Step[3100/4329]: training loss : 1.1139315021038056 TRAIN  loss dict:  {'classification_loss': 1.1139315021038056}
2025-01-12 17:33:40,664 [INFO] Step[3150/4329]: training loss : 1.1103469657897949 TRAIN  loss dict:  {'classification_loss': 1.1103469657897949}
2025-01-12 17:33:52,281 [INFO] Step[3200/4329]: training loss : 1.1714208126068115 TRAIN  loss dict:  {'classification_loss': 1.1714208126068115}
2025-01-12 17:34:03,933 [INFO] Step[3250/4329]: training loss : 1.2615194749832153 TRAIN  loss dict:  {'classification_loss': 1.2615194749832153}
2025-01-12 17:34:15,580 [INFO] Step[3300/4329]: training loss : 1.2741217339038848 TRAIN  loss dict:  {'classification_loss': 1.2741217339038848}
2025-01-12 17:34:27,157 [INFO] Step[3350/4329]: training loss : 1.2104195308685304 TRAIN  loss dict:  {'classification_loss': 1.2104195308685304}
2025-01-12 17:34:38,795 [INFO] Step[3400/4329]: training loss : 1.1937964510917665 TRAIN  loss dict:  {'classification_loss': 1.1937964510917665}
2025-01-12 17:34:50,434 [INFO] Step[3450/4329]: training loss : 1.1910817182064057 TRAIN  loss dict:  {'classification_loss': 1.1910817182064057}
2025-01-12 17:35:02,049 [INFO] Step[3500/4329]: training loss : 1.1355112385749817 TRAIN  loss dict:  {'classification_loss': 1.1355112385749817}
2025-01-12 17:35:13,700 [INFO] Step[3550/4329]: training loss : 1.226692770719528 TRAIN  loss dict:  {'classification_loss': 1.226692770719528}
2025-01-12 17:35:25,295 [INFO] Step[3600/4329]: training loss : 1.128309552669525 TRAIN  loss dict:  {'classification_loss': 1.128309552669525}
2025-01-12 17:35:36,883 [INFO] Step[3650/4329]: training loss : 1.200696725845337 TRAIN  loss dict:  {'classification_loss': 1.200696725845337}
2025-01-12 17:35:48,450 [INFO] Step[3700/4329]: training loss : 1.170999277830124 TRAIN  loss dict:  {'classification_loss': 1.170999277830124}
2025-01-12 17:36:00,094 [INFO] Step[3750/4329]: training loss : 1.1589718568325043 TRAIN  loss dict:  {'classification_loss': 1.1589718568325043}
2025-01-12 17:36:11,715 [INFO] Step[3800/4329]: training loss : 1.1705047130584716 TRAIN  loss dict:  {'classification_loss': 1.1705047130584716}
2025-01-12 17:36:23,362 [INFO] Step[3850/4329]: training loss : 1.2602659285068512 TRAIN  loss dict:  {'classification_loss': 1.2602659285068512}
2025-01-12 17:36:34,974 [INFO] Step[3900/4329]: training loss : 1.1853218162059784 TRAIN  loss dict:  {'classification_loss': 1.1853218162059784}
2025-01-12 17:36:46,637 [INFO] Step[3950/4329]: training loss : 1.206320366859436 TRAIN  loss dict:  {'classification_loss': 1.206320366859436}
2025-01-12 17:36:58,311 [INFO] Step[4000/4329]: training loss : 1.1518890488147735 TRAIN  loss dict:  {'classification_loss': 1.1518890488147735}
2025-01-12 17:37:09,903 [INFO] Step[4050/4329]: training loss : 1.2330174112319947 TRAIN  loss dict:  {'classification_loss': 1.2330174112319947}
2025-01-12 17:37:21,563 [INFO] Step[4100/4329]: training loss : 1.1991887140274047 TRAIN  loss dict:  {'classification_loss': 1.1991887140274047}
2025-01-12 17:37:33,167 [INFO] Step[4150/4329]: training loss : 1.157904771566391 TRAIN  loss dict:  {'classification_loss': 1.157904771566391}
2025-01-12 17:37:44,762 [INFO] Step[4200/4329]: training loss : 1.3577242517471313 TRAIN  loss dict:  {'classification_loss': 1.3577242517471313}
2025-01-12 17:37:56,433 [INFO] Step[4250/4329]: training loss : 1.2107531034946442 TRAIN  loss dict:  {'classification_loss': 1.2107531034946442}
2025-01-12 17:38:08,024 [INFO] Step[4300/4329]: training loss : 1.1819113326072692 TRAIN  loss dict:  {'classification_loss': 1.1819113326072692}
2025-01-12 17:40:04,289 [INFO] Label accuracies statistics:
2025-01-12 17:40:04,290 [INFO] {0: 0.3333333333333333, 1: 0.8888888888888888, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.6666666666666666, 6: 0.5833333333333334, 7: 0.4166666666666667, 8: 0.3333333333333333, 9: 0.9166666666666666, 10: 1.0, 11: 0.75, 12: 0.3333333333333333, 13: 0.3333333333333333, 14: 0.6666666666666666, 15: 0.4444444444444444, 16: 0.5833333333333334, 17: 0.5833333333333334, 18: 0.5, 19: 0.75, 20: 0.5833333333333334, 21: 0.75, 22: 0.75, 23: 0.9166666666666666, 24: 1.0, 25: 0.6666666666666666, 26: 0.75, 27: 0.5833333333333334, 28: 0.75, 29: 1.0, 30: 0.5833333333333334, 31: 0.6666666666666666, 32: 0.6666666666666666, 33: 0.75, 34: 0.5833333333333334, 35: 0.8333333333333334, 36: 0.4166666666666667, 37: 0.8333333333333334, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.3333333333333333, 42: 0.8333333333333334, 43: 0.9166666666666666, 44: 0.6666666666666666, 45: 0.5833333333333334, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 0.9166666666666666, 50: 0.75, 51: 1.0, 52: 0.9166666666666666, 53: 0.3333333333333333, 54: 0.5, 55: 0.5833333333333334, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.5, 59: 0.4166666666666667, 60: 0.6666666666666666, 61: 0.6666666666666666, 62: 0.75, 63: 0.4166666666666667, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.8333333333333334, 68: 0.5, 69: 0.3333333333333333, 70: 0.3333333333333333, 71: 0.5, 72: 0.8333333333333334, 73: 0.75, 74: 0.6666666666666666, 75: 1.0, 76: 0.4166666666666667, 77: 0.5833333333333334, 78: 0.9166666666666666, 79: 0.75, 80: 0.9166666666666666, 81: 1.0, 82: 0.6666666666666666, 83: 0.3333333333333333, 84: 0.4166666666666667, 85: 0.6666666666666666, 86: 0.5, 87: 0.8333333333333334, 88: 0.6666666666666666, 89: 0.5833333333333334, 90: 0.75, 91: 0.8333333333333334, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 1.0, 96: 0.4166666666666667, 97: 0.75, 98: 0.75, 99: 0.7333333333333333, 100: 0.6666666666666666, 101: 0.75, 102: 0.8333333333333334, 103: 0.8333333333333334, 104: 1.0, 105: 0.9166666666666666, 106: 0.8333333333333334, 107: 0.4166666666666667, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.8333333333333334, 111: 0.8333333333333334, 112: 0.6666666666666666, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.6666666666666666, 117: 0.6666666666666666, 118: 0.8333333333333334, 119: 0.9166666666666666, 120: 0.8333333333333334, 121: 0.6666666666666666, 122: 0.8333333333333334, 123: 0.75, 124: 1.0, 125: 0.6666666666666666, 126: 0.75, 127: 0.5833333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 1.0, 131: 0.6666666666666666, 132: 0.8333333333333334, 133: 0.9166666666666666, 134: 0.5833333333333334, 135: 0.9166666666666666, 136: 0.8333333333333334, 137: 0.6666666666666666, 138: 0.8333333333333334, 139: 0.8333333333333334, 140: 0.9166666666666666, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.75, 148: 0.6666666666666666, 149: 1.0, 150: 0.4166666666666667, 151: 0.75, 152: 0.75, 153: 0.6666666666666666, 154: 1.0, 155: 1.0, 156: 0.5833333333333334, 157: 0.8333333333333334, 158: 0.5555555555555556, 159: 0.9166666666666666, 160: 0.25, 161: 0.5833333333333334, 162: 0.8333333333333334, 163: 0.6666666666666666, 164: 0.8333333333333334, 165: 0.75, 166: 0.5833333333333334, 167: 0.75, 168: 0.9166666666666666, 169: 0.8333333333333334, 170: 0.9166666666666666, 171: 0.6666666666666666, 172: 1.0, 173: 0.8333333333333334, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 0.8333333333333334, 177: 0.75, 178: 0.9166666666666666, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.3333333333333333, 183: 0.8333333333333334, 184: 0.4166666666666667, 185: 0.8333333333333334, 186: 0.6666666666666666, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.5833333333333334, 192: 0.9166666666666666, 193: 0.75, 194: 0.8333333333333334, 195: 0.5833333333333334, 196: 0.9166666666666666, 197: 0.6666666666666666, 198: 0.5833333333333334}

2025-01-12 17:40:04,295 [INFO] [9] TRAIN  loss: 1.1793956083853765 acc: 0.9203757893115663
2025-01-12 17:40:04,295 [INFO] [9] TRAIN  loss dict: {'classification_loss': 1.1793956083853765}
2025-01-12 17:40:04,295 [INFO] [9] VALIDATION loss: 1.8561215457892177 VALIDATION acc: 0.7276936026936027
2025-01-12 17:40:04,295 [INFO] [9] VALIDATION loss dict: {'classification_loss': 1.8561215457892177}
2025-01-12 17:40:04,296 [INFO] 
2025-01-12 17:40:25,153 [INFO] Step[50/4329]: training loss : 1.2041230154037477 TRAIN  loss dict:  {'classification_loss': 1.2041230154037477}
2025-01-12 17:40:38,179 [INFO] Step[100/4329]: training loss : 1.0923361194133758 TRAIN  loss dict:  {'classification_loss': 1.0923361194133758}
2025-01-12 17:40:51,719 [INFO] Step[150/4329]: training loss : 1.0997242975234984 TRAIN  loss dict:  {'classification_loss': 1.0997242975234984}
2025-01-12 17:41:04,023 [INFO] Step[200/4329]: training loss : 1.0697695410251618 TRAIN  loss dict:  {'classification_loss': 1.0697695410251618}
2025-01-12 17:41:15,914 [INFO] Step[250/4329]: training loss : 1.138043509721756 TRAIN  loss dict:  {'classification_loss': 1.138043509721756}
2025-01-12 17:41:27,781 [INFO] Step[300/4329]: training loss : 1.1564797842502594 TRAIN  loss dict:  {'classification_loss': 1.1564797842502594}
2025-01-12 17:41:39,407 [INFO] Step[350/4329]: training loss : 1.171873894929886 TRAIN  loss dict:  {'classification_loss': 1.171873894929886}
2025-01-12 17:41:51,030 [INFO] Step[400/4329]: training loss : 1.1676158344745635 TRAIN  loss dict:  {'classification_loss': 1.1676158344745635}
2025-01-12 17:42:02,655 [INFO] Step[450/4329]: training loss : 1.1404890942573547 TRAIN  loss dict:  {'classification_loss': 1.1404890942573547}
2025-01-12 17:42:14,269 [INFO] Step[500/4329]: training loss : 1.2140110146999359 TRAIN  loss dict:  {'classification_loss': 1.2140110146999359}
2025-01-12 17:42:25,899 [INFO] Step[550/4329]: training loss : 1.2336006319522859 TRAIN  loss dict:  {'classification_loss': 1.2336006319522859}
2025-01-12 17:42:37,540 [INFO] Step[600/4329]: training loss : 1.1471322762966156 TRAIN  loss dict:  {'classification_loss': 1.1471322762966156}
2025-01-12 17:42:49,161 [INFO] Step[650/4329]: training loss : 1.1716014385223388 TRAIN  loss dict:  {'classification_loss': 1.1716014385223388}
2025-01-12 17:43:00,788 [INFO] Step[700/4329]: training loss : 1.1751139855384827 TRAIN  loss dict:  {'classification_loss': 1.1751139855384827}
2025-01-12 17:43:12,421 [INFO] Step[750/4329]: training loss : 1.0847070622444153 TRAIN  loss dict:  {'classification_loss': 1.0847070622444153}
2025-01-12 17:43:24,045 [INFO] Step[800/4329]: training loss : 1.1988244068622589 TRAIN  loss dict:  {'classification_loss': 1.1988244068622589}
2025-01-12 17:43:35,693 [INFO] Step[850/4329]: training loss : 1.1478366804122926 TRAIN  loss dict:  {'classification_loss': 1.1478366804122926}
2025-01-12 17:43:47,344 [INFO] Step[900/4329]: training loss : 1.1326223623752594 TRAIN  loss dict:  {'classification_loss': 1.1326223623752594}
2025-01-12 17:43:58,943 [INFO] Step[950/4329]: training loss : 1.1882863473892211 TRAIN  loss dict:  {'classification_loss': 1.1882863473892211}
2025-01-12 17:44:10,578 [INFO] Step[1000/4329]: training loss : 1.1554756331443787 TRAIN  loss dict:  {'classification_loss': 1.1554756331443787}
2025-01-12 17:44:22,226 [INFO] Step[1050/4329]: training loss : 1.1677013421058655 TRAIN  loss dict:  {'classification_loss': 1.1677013421058655}
2025-01-12 17:44:33,872 [INFO] Step[1100/4329]: training loss : 1.1311243093013763 TRAIN  loss dict:  {'classification_loss': 1.1311243093013763}
2025-01-12 17:44:45,532 [INFO] Step[1150/4329]: training loss : 1.10363227725029 TRAIN  loss dict:  {'classification_loss': 1.10363227725029}
2025-01-12 17:44:57,123 [INFO] Step[1200/4329]: training loss : 1.0997609782218933 TRAIN  loss dict:  {'classification_loss': 1.0997609782218933}
2025-01-12 17:45:08,767 [INFO] Step[1250/4329]: training loss : 1.0994142603874206 TRAIN  loss dict:  {'classification_loss': 1.0994142603874206}
2025-01-12 17:45:20,389 [INFO] Step[1300/4329]: training loss : 1.172664338350296 TRAIN  loss dict:  {'classification_loss': 1.172664338350296}
2025-01-12 17:45:32,018 [INFO] Step[1350/4329]: training loss : 1.117253555059433 TRAIN  loss dict:  {'classification_loss': 1.117253555059433}
2025-01-12 17:45:43,633 [INFO] Step[1400/4329]: training loss : 1.1817669355869294 TRAIN  loss dict:  {'classification_loss': 1.1817669355869294}
2025-01-12 17:45:55,256 [INFO] Step[1450/4329]: training loss : 1.1865064215660095 TRAIN  loss dict:  {'classification_loss': 1.1865064215660095}
2025-01-12 17:46:06,881 [INFO] Step[1500/4329]: training loss : 1.1605532610416411 TRAIN  loss dict:  {'classification_loss': 1.1605532610416411}
2025-01-12 17:46:18,480 [INFO] Step[1550/4329]: training loss : 1.126296602487564 TRAIN  loss dict:  {'classification_loss': 1.126296602487564}
2025-01-12 17:46:30,092 [INFO] Step[1600/4329]: training loss : 1.173768516778946 TRAIN  loss dict:  {'classification_loss': 1.173768516778946}
2025-01-12 17:46:41,684 [INFO] Step[1650/4329]: training loss : 1.134378912448883 TRAIN  loss dict:  {'classification_loss': 1.134378912448883}
2025-01-12 17:46:53,268 [INFO] Step[1700/4329]: training loss : 1.1960474038124085 TRAIN  loss dict:  {'classification_loss': 1.1960474038124085}
2025-01-12 17:47:04,927 [INFO] Step[1750/4329]: training loss : 1.2041037106513977 TRAIN  loss dict:  {'classification_loss': 1.2041037106513977}
2025-01-12 17:47:16,578 [INFO] Step[1800/4329]: training loss : 1.1451474034786224 TRAIN  loss dict:  {'classification_loss': 1.1451474034786224}
2025-01-12 17:47:28,223 [INFO] Step[1850/4329]: training loss : 1.1996842110157013 TRAIN  loss dict:  {'classification_loss': 1.1996842110157013}
2025-01-12 17:47:39,821 [INFO] Step[1900/4329]: training loss : 1.2229244685173035 TRAIN  loss dict:  {'classification_loss': 1.2229244685173035}
2025-01-12 17:47:51,391 [INFO] Step[1950/4329]: training loss : 1.0801398372650146 TRAIN  loss dict:  {'classification_loss': 1.0801398372650146}
2025-01-12 17:48:03,001 [INFO] Step[2000/4329]: training loss : 1.1480231177806854 TRAIN  loss dict:  {'classification_loss': 1.1480231177806854}
2025-01-12 17:48:14,637 [INFO] Step[2050/4329]: training loss : 1.1481903052330018 TRAIN  loss dict:  {'classification_loss': 1.1481903052330018}
2025-01-12 17:48:26,304 [INFO] Step[2100/4329]: training loss : 1.164656810760498 TRAIN  loss dict:  {'classification_loss': 1.164656810760498}
2025-01-12 17:48:37,964 [INFO] Step[2150/4329]: training loss : 1.1839938294887542 TRAIN  loss dict:  {'classification_loss': 1.1839938294887542}
2025-01-12 17:48:49,543 [INFO] Step[2200/4329]: training loss : 1.1052644300460814 TRAIN  loss dict:  {'classification_loss': 1.1052644300460814}
2025-01-12 17:49:01,173 [INFO] Step[2250/4329]: training loss : 1.172796596288681 TRAIN  loss dict:  {'classification_loss': 1.172796596288681}
2025-01-12 17:49:12,747 [INFO] Step[2300/4329]: training loss : 1.173210997581482 TRAIN  loss dict:  {'classification_loss': 1.173210997581482}
2025-01-12 17:49:24,368 [INFO] Step[2350/4329]: training loss : 1.1771415972709656 TRAIN  loss dict:  {'classification_loss': 1.1771415972709656}
2025-01-12 17:49:35,964 [INFO] Step[2400/4329]: training loss : 1.1197872686386108 TRAIN  loss dict:  {'classification_loss': 1.1197872686386108}
2025-01-12 17:49:47,586 [INFO] Step[2450/4329]: training loss : 1.2139653289318084 TRAIN  loss dict:  {'classification_loss': 1.2139653289318084}
2025-01-12 17:49:59,178 [INFO] Step[2500/4329]: training loss : 1.2278971779346466 TRAIN  loss dict:  {'classification_loss': 1.2278971779346466}
2025-01-12 17:50:10,786 [INFO] Step[2550/4329]: training loss : 1.1609814071655273 TRAIN  loss dict:  {'classification_loss': 1.1609814071655273}
2025-01-12 17:50:22,400 [INFO] Step[2600/4329]: training loss : 1.1494311821460723 TRAIN  loss dict:  {'classification_loss': 1.1494311821460723}
2025-01-12 17:50:34,026 [INFO] Step[2650/4329]: training loss : 1.1742971312999726 TRAIN  loss dict:  {'classification_loss': 1.1742971312999726}
2025-01-12 17:50:45,609 [INFO] Step[2700/4329]: training loss : 1.2892462289333344 TRAIN  loss dict:  {'classification_loss': 1.2892462289333344}
2025-01-12 17:50:57,240 [INFO] Step[2750/4329]: training loss : 1.1216649305820465 TRAIN  loss dict:  {'classification_loss': 1.1216649305820465}
2025-01-12 17:51:08,839 [INFO] Step[2800/4329]: training loss : 1.217862411737442 TRAIN  loss dict:  {'classification_loss': 1.217862411737442}
2025-01-12 17:51:20,496 [INFO] Step[2850/4329]: training loss : 1.1358829641342163 TRAIN  loss dict:  {'classification_loss': 1.1358829641342163}
2025-01-12 17:51:32,074 [INFO] Step[2900/4329]: training loss : 1.0971769309043884 TRAIN  loss dict:  {'classification_loss': 1.0971769309043884}
2025-01-12 17:51:43,684 [INFO] Step[2950/4329]: training loss : 1.1000541257858276 TRAIN  loss dict:  {'classification_loss': 1.1000541257858276}
2025-01-12 17:51:55,351 [INFO] Step[3000/4329]: training loss : 1.1695901226997376 TRAIN  loss dict:  {'classification_loss': 1.1695901226997376}
2025-01-12 17:52:07,004 [INFO] Step[3050/4329]: training loss : 1.2057693266868592 TRAIN  loss dict:  {'classification_loss': 1.2057693266868592}
2025-01-12 17:52:18,906 [INFO] Step[3100/4329]: training loss : 1.1632343530654907 TRAIN  loss dict:  {'classification_loss': 1.1632343530654907}
2025-01-12 17:52:31,268 [INFO] Step[3150/4329]: training loss : 1.0975120759010315 TRAIN  loss dict:  {'classification_loss': 1.0975120759010315}
2025-01-12 17:52:43,623 [INFO] Step[3200/4329]: training loss : 1.1775633001327515 TRAIN  loss dict:  {'classification_loss': 1.1775633001327515}
2025-01-12 17:52:57,120 [INFO] Step[3250/4329]: training loss : 1.2240528392791747 TRAIN  loss dict:  {'classification_loss': 1.2240528392791747}
2025-01-12 17:53:10,942 [INFO] Step[3300/4329]: training loss : 1.1816918885707854 TRAIN  loss dict:  {'classification_loss': 1.1816918885707854}
2025-01-12 17:53:22,975 [INFO] Step[3350/4329]: training loss : 1.0860293304920197 TRAIN  loss dict:  {'classification_loss': 1.0860293304920197}
2025-01-12 17:53:34,932 [INFO] Step[3400/4329]: training loss : 1.2229041349887848 TRAIN  loss dict:  {'classification_loss': 1.2229041349887848}
2025-01-12 17:53:46,749 [INFO] Step[3450/4329]: training loss : 1.0590734338760377 TRAIN  loss dict:  {'classification_loss': 1.0590734338760377}
2025-01-12 17:53:58,395 [INFO] Step[3500/4329]: training loss : 1.1871046710014344 TRAIN  loss dict:  {'classification_loss': 1.1871046710014344}
2025-01-12 17:54:10,005 [INFO] Step[3550/4329]: training loss : 1.0789259386062622 TRAIN  loss dict:  {'classification_loss': 1.0789259386062622}
2025-01-12 17:54:21,627 [INFO] Step[3600/4329]: training loss : 1.1451340162754058 TRAIN  loss dict:  {'classification_loss': 1.1451340162754058}
2025-01-12 17:54:33,269 [INFO] Step[3650/4329]: training loss : 1.0963842356204987 TRAIN  loss dict:  {'classification_loss': 1.0963842356204987}
2025-01-12 17:54:44,889 [INFO] Step[3700/4329]: training loss : 1.177316209077835 TRAIN  loss dict:  {'classification_loss': 1.177316209077835}
2025-01-12 17:54:56,482 [INFO] Step[3750/4329]: training loss : 1.1312938380241393 TRAIN  loss dict:  {'classification_loss': 1.1312938380241393}
2025-01-12 17:55:08,153 [INFO] Step[3800/4329]: training loss : 1.1996592903137206 TRAIN  loss dict:  {'classification_loss': 1.1996592903137206}
2025-01-12 17:55:19,766 [INFO] Step[3850/4329]: training loss : 1.2319133949279786 TRAIN  loss dict:  {'classification_loss': 1.2319133949279786}
2025-01-12 17:55:31,395 [INFO] Step[3900/4329]: training loss : 1.1306311893463135 TRAIN  loss dict:  {'classification_loss': 1.1306311893463135}
2025-01-12 17:55:43,033 [INFO] Step[3950/4329]: training loss : 1.0942219388484955 TRAIN  loss dict:  {'classification_loss': 1.0942219388484955}
2025-01-12 17:55:54,648 [INFO] Step[4000/4329]: training loss : 1.1310695362091066 TRAIN  loss dict:  {'classification_loss': 1.1310695362091066}
2025-01-12 17:56:06,328 [INFO] Step[4050/4329]: training loss : 1.166789481639862 TRAIN  loss dict:  {'classification_loss': 1.166789481639862}
2025-01-12 17:56:17,905 [INFO] Step[4100/4329]: training loss : 1.0863140225410461 TRAIN  loss dict:  {'classification_loss': 1.0863140225410461}
2025-01-12 17:56:29,591 [INFO] Step[4150/4329]: training loss : 1.1796970915794374 TRAIN  loss dict:  {'classification_loss': 1.1796970915794374}
2025-01-12 17:56:41,212 [INFO] Step[4200/4329]: training loss : 1.1276710176467895 TRAIN  loss dict:  {'classification_loss': 1.1276710176467895}
2025-01-12 17:56:52,875 [INFO] Step[4250/4329]: training loss : 1.1501327419281007 TRAIN  loss dict:  {'classification_loss': 1.1501327419281007}
2025-01-12 17:57:04,521 [INFO] Step[4300/4329]: training loss : 1.1852410292625428 TRAIN  loss dict:  {'classification_loss': 1.1852410292625428}
2025-01-12 17:59:03,383 [INFO] Label accuracies statistics:
2025-01-12 17:59:03,383 [INFO] {0: 0.6666666666666666, 1: 0.7777777777777778, 2: 0.5833333333333334, 3: 0.8333333333333334, 4: 0.25, 5: 0.8333333333333334, 6: 0.5, 7: 0.5833333333333334, 8: 0.3333333333333333, 9: 0.75, 10: 0.9166666666666666, 11: 0.75, 12: 0.25, 13: 0.4166666666666667, 14: 0.75, 15: 0.6666666666666666, 16: 0.5833333333333334, 17: 0.4166666666666667, 18: 0.5833333333333334, 19: 0.5833333333333334, 20: 0.4166666666666667, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.9166666666666666, 24: 1.0, 25: 0.6666666666666666, 26: 0.9166666666666666, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.6666666666666666, 32: 0.75, 33: 0.8333333333333334, 34: 0.8333333333333334, 35: 0.8333333333333334, 36: 0.5833333333333334, 37: 0.8333333333333334, 38: 0.8333333333333334, 39: 1.0, 40: 0.9166666666666666, 41: 0.3333333333333333, 42: 0.75, 43: 0.9166666666666666, 44: 0.4166666666666667, 45: 0.5833333333333334, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.4166666666666667, 55: 0.5833333333333334, 56: 0.5833333333333334, 57: 0.75, 58: 0.4166666666666667, 59: 0.5833333333333334, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.3333333333333333, 64: 0.9166666666666666, 65: 1.0, 66: 0.6666666666666666, 67: 0.6666666666666666, 68: 0.8333333333333334, 69: 0.5833333333333334, 70: 0.5, 71: 0.4166666666666667, 72: 0.8333333333333334, 73: 0.8333333333333334, 74: 0.6666666666666666, 75: 1.0, 76: 0.5, 77: 0.6666666666666666, 78: 0.9166666666666666, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.5833333333333334, 83: 0.5833333333333334, 84: 0.4166666666666667, 85: 0.75, 86: 0.5, 87: 0.9166666666666666, 88: 0.75, 89: 0.5, 90: 0.8333333333333334, 91: 0.8333333333333334, 92: 1.0, 93: 1.0, 94: 0.4166666666666667, 95: 1.0, 96: 0.25, 97: 0.75, 98: 0.8333333333333334, 99: 0.8666666666666667, 100: 0.75, 101: 0.6666666666666666, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 0.9166666666666666, 105: 0.9166666666666666, 106: 1.0, 107: 0.6666666666666666, 108: 0.9166666666666666, 109: 0.5, 110: 0.8333333333333334, 111: 0.8333333333333334, 112: 0.75, 113: 0.5833333333333334, 114: 0.5, 115: 0.75, 116: 0.75, 117: 0.9166666666666666, 118: 0.9166666666666666, 119: 0.75, 120: 0.75, 121: 0.8333333333333334, 122: 0.75, 123: 0.9166666666666666, 124: 0.9166666666666666, 125: 0.9166666666666666, 126: 1.0, 127: 0.8333333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 1.0, 131: 0.8333333333333334, 132: 0.4166666666666667, 133: 1.0, 134: 0.9166666666666666, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.6666666666666666, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 0.9166666666666666, 141: 0.9166666666666666, 142: 0.5, 143: 0.8333333333333334, 144: 0.5833333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 0.8333333333333334, 150: 0.3333333333333333, 151: 0.9166666666666666, 152: 0.8333333333333334, 153: 0.75, 154: 0.8333333333333334, 155: 0.9166666666666666, 156: 0.6666666666666666, 157: 0.8333333333333334, 158: 0.6666666666666666, 159: 0.9166666666666666, 160: 0.3333333333333333, 161: 0.6666666666666666, 162: 0.8333333333333334, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.6666666666666666, 167: 0.8333333333333334, 168: 0.8333333333333334, 169: 0.8333333333333334, 170: 0.9166666666666666, 171: 0.75, 172: 1.0, 173: 0.8333333333333334, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 0.8333333333333334, 177: 0.75, 178: 0.8333333333333334, 179: 0.0, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.25, 183: 0.5, 184: 0.5833333333333334, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.8333333333333334, 189: 1.0, 190: 0.5, 191: 0.5, 192: 0.9166666666666666, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 1.0, 196: 0.9166666666666666, 197: 0.75, 198: 0.6666666666666666}

2025-01-12 17:59:05,263 [INFO] [10] TRAIN  loss: 1.1553807579003297 acc: 0.9290774680425073
2025-01-12 17:59:05,263 [INFO] [10] TRAIN  loss dict: {'classification_loss': 1.1553807579003297}
2025-01-12 17:59:05,263 [INFO] [10] VALIDATION loss: 1.7782302374641101 VALIDATION acc: 0.7542087542087542
2025-01-12 17:59:05,264 [INFO] [10] VALIDATION loss dict: {'classification_loss': 1.7782302374641101}
2025-01-12 17:59:05,264 [INFO] 
2025-01-12 17:59:22,950 [INFO] Step[50/4329]: training loss : 1.0813577926158906 TRAIN  loss dict:  {'classification_loss': 1.0813577926158906}
2025-01-12 17:59:34,558 [INFO] Step[100/4329]: training loss : 1.1262770748138429 TRAIN  loss dict:  {'classification_loss': 1.1262770748138429}
2025-01-12 17:59:46,160 [INFO] Step[150/4329]: training loss : 1.111512176990509 TRAIN  loss dict:  {'classification_loss': 1.111512176990509}
2025-01-12 17:59:57,795 [INFO] Step[200/4329]: training loss : 1.0499665975570678 TRAIN  loss dict:  {'classification_loss': 1.0499665975570678}
2025-01-12 18:00:09,410 [INFO] Step[250/4329]: training loss : 1.0879452431201935 TRAIN  loss dict:  {'classification_loss': 1.0879452431201935}
2025-01-12 18:00:21,025 [INFO] Step[300/4329]: training loss : 1.076705094575882 TRAIN  loss dict:  {'classification_loss': 1.076705094575882}
2025-01-12 18:00:32,684 [INFO] Step[350/4329]: training loss : 1.099752368927002 TRAIN  loss dict:  {'classification_loss': 1.099752368927002}
2025-01-12 18:00:44,299 [INFO] Step[400/4329]: training loss : 1.0931011831760407 TRAIN  loss dict:  {'classification_loss': 1.0931011831760407}
2025-01-12 18:00:55,930 [INFO] Step[450/4329]: training loss : 1.137211847305298 TRAIN  loss dict:  {'classification_loss': 1.137211847305298}
2025-01-12 18:01:07,531 [INFO] Step[500/4329]: training loss : 1.096720452308655 TRAIN  loss dict:  {'classification_loss': 1.096720452308655}
2025-01-12 18:01:19,179 [INFO] Step[550/4329]: training loss : 1.087620840072632 TRAIN  loss dict:  {'classification_loss': 1.087620840072632}
2025-01-12 18:01:30,771 [INFO] Step[600/4329]: training loss : 1.121777755022049 TRAIN  loss dict:  {'classification_loss': 1.121777755022049}
2025-01-12 18:01:42,377 [INFO] Step[650/4329]: training loss : 1.0435475504398346 TRAIN  loss dict:  {'classification_loss': 1.0435475504398346}
2025-01-12 18:01:53,982 [INFO] Step[700/4329]: training loss : 1.1360667181015014 TRAIN  loss dict:  {'classification_loss': 1.1360667181015014}
2025-01-12 18:02:05,653 [INFO] Step[750/4329]: training loss : 1.1067999756336213 TRAIN  loss dict:  {'classification_loss': 1.1067999756336213}
2025-01-12 18:02:17,269 [INFO] Step[800/4329]: training loss : 1.054562064409256 TRAIN  loss dict:  {'classification_loss': 1.054562064409256}
2025-01-12 18:02:28,856 [INFO] Step[850/4329]: training loss : 1.0587560939788818 TRAIN  loss dict:  {'classification_loss': 1.0587560939788818}
2025-01-12 18:02:40,513 [INFO] Step[900/4329]: training loss : 1.0502788984775544 TRAIN  loss dict:  {'classification_loss': 1.0502788984775544}
2025-01-12 18:02:52,182 [INFO] Step[950/4329]: training loss : 1.0532785737514496 TRAIN  loss dict:  {'classification_loss': 1.0532785737514496}
2025-01-12 18:03:03,766 [INFO] Step[1000/4329]: training loss : 1.0329326474666596 TRAIN  loss dict:  {'classification_loss': 1.0329326474666596}
2025-01-12 18:03:15,393 [INFO] Step[1050/4329]: training loss : 1.1456605064868928 TRAIN  loss dict:  {'classification_loss': 1.1456605064868928}
2025-01-12 18:03:27,009 [INFO] Step[1100/4329]: training loss : 1.072049584388733 TRAIN  loss dict:  {'classification_loss': 1.072049584388733}
2025-01-12 18:03:38,628 [INFO] Step[1150/4329]: training loss : 1.1126934051513673 TRAIN  loss dict:  {'classification_loss': 1.1126934051513673}
2025-01-12 18:03:50,279 [INFO] Step[1200/4329]: training loss : 1.0423036217689514 TRAIN  loss dict:  {'classification_loss': 1.0423036217689514}
2025-01-12 18:04:01,891 [INFO] Step[1250/4329]: training loss : 1.1018996465206146 TRAIN  loss dict:  {'classification_loss': 1.1018996465206146}
2025-01-12 18:04:13,501 [INFO] Step[1300/4329]: training loss : 1.0709362363815307 TRAIN  loss dict:  {'classification_loss': 1.0709362363815307}
2025-01-12 18:04:25,150 [INFO] Step[1350/4329]: training loss : 1.0130189406871795 TRAIN  loss dict:  {'classification_loss': 1.0130189406871795}
2025-01-12 18:04:36,864 [INFO] Step[1400/4329]: training loss : 1.1126184606552123 TRAIN  loss dict:  {'classification_loss': 1.1126184606552123}
2025-01-12 18:04:49,055 [INFO] Step[1450/4329]: training loss : 1.055360916852951 TRAIN  loss dict:  {'classification_loss': 1.055360916852951}
2025-01-12 18:05:01,308 [INFO] Step[1500/4329]: training loss : 1.149210010766983 TRAIN  loss dict:  {'classification_loss': 1.149210010766983}
2025-01-12 18:05:14,187 [INFO] Step[1550/4329]: training loss : 1.0963693153858185 TRAIN  loss dict:  {'classification_loss': 1.0963693153858185}
2025-01-12 18:05:27,550 [INFO] Step[1600/4329]: training loss : 1.1238775086402892 TRAIN  loss dict:  {'classification_loss': 1.1238775086402892}
2025-01-12 18:05:40,734 [INFO] Step[1650/4329]: training loss : 1.089754639863968 TRAIN  loss dict:  {'classification_loss': 1.089754639863968}
2025-01-12 18:05:52,682 [INFO] Step[1700/4329]: training loss : 1.0878666925430298 TRAIN  loss dict:  {'classification_loss': 1.0878666925430298}
2025-01-12 18:06:04,571 [INFO] Step[1750/4329]: training loss : 1.1330410814285279 TRAIN  loss dict:  {'classification_loss': 1.1330410814285279}
2025-01-12 18:06:16,193 [INFO] Step[1800/4329]: training loss : 1.0547177064418793 TRAIN  loss dict:  {'classification_loss': 1.0547177064418793}
2025-01-12 18:06:27,843 [INFO] Step[1850/4329]: training loss : 1.224298415184021 TRAIN  loss dict:  {'classification_loss': 1.224298415184021}
2025-01-12 18:06:39,483 [INFO] Step[1900/4329]: training loss : 1.0283611702919007 TRAIN  loss dict:  {'classification_loss': 1.0283611702919007}
2025-01-12 18:06:51,120 [INFO] Step[1950/4329]: training loss : 1.118363347053528 TRAIN  loss dict:  {'classification_loss': 1.118363347053528}
2025-01-12 18:07:02,738 [INFO] Step[2000/4329]: training loss : 1.113215104341507 TRAIN  loss dict:  {'classification_loss': 1.113215104341507}
2025-01-12 18:07:14,336 [INFO] Step[2050/4329]: training loss : 1.1177343142032623 TRAIN  loss dict:  {'classification_loss': 1.1177343142032623}
2025-01-12 18:07:25,954 [INFO] Step[2100/4329]: training loss : 1.0643892681598663 TRAIN  loss dict:  {'classification_loss': 1.0643892681598663}
2025-01-12 18:07:37,561 [INFO] Step[2150/4329]: training loss : 1.1110696375370026 TRAIN  loss dict:  {'classification_loss': 1.1110696375370026}
2025-01-12 18:07:49,194 [INFO] Step[2200/4329]: training loss : 1.0460014355182647 TRAIN  loss dict:  {'classification_loss': 1.0460014355182647}
2025-01-12 18:08:00,809 [INFO] Step[2250/4329]: training loss : 1.051530293226242 TRAIN  loss dict:  {'classification_loss': 1.051530293226242}
2025-01-12 18:08:12,435 [INFO] Step[2300/4329]: training loss : 1.1078716003894806 TRAIN  loss dict:  {'classification_loss': 1.1078716003894806}
2025-01-12 18:08:24,086 [INFO] Step[2350/4329]: training loss : 1.1063446617126464 TRAIN  loss dict:  {'classification_loss': 1.1063446617126464}
2025-01-12 18:08:35,725 [INFO] Step[2400/4329]: training loss : 1.0913496339321136 TRAIN  loss dict:  {'classification_loss': 1.0913496339321136}
2025-01-12 18:08:47,358 [INFO] Step[2450/4329]: training loss : 1.0775921905040742 TRAIN  loss dict:  {'classification_loss': 1.0775921905040742}
2025-01-12 18:08:58,945 [INFO] Step[2500/4329]: training loss : 1.118043224811554 TRAIN  loss dict:  {'classification_loss': 1.118043224811554}
2025-01-12 18:09:10,565 [INFO] Step[2550/4329]: training loss : 1.0856719994544983 TRAIN  loss dict:  {'classification_loss': 1.0856719994544983}
2025-01-12 18:09:22,192 [INFO] Step[2600/4329]: training loss : 1.1006995034217835 TRAIN  loss dict:  {'classification_loss': 1.1006995034217835}
2025-01-12 18:09:33,850 [INFO] Step[2650/4329]: training loss : 1.0316536664962768 TRAIN  loss dict:  {'classification_loss': 1.0316536664962768}
2025-01-12 18:09:45,483 [INFO] Step[2700/4329]: training loss : 1.084836665391922 TRAIN  loss dict:  {'classification_loss': 1.084836665391922}
2025-01-12 18:09:57,106 [INFO] Step[2750/4329]: training loss : 1.070511120557785 TRAIN  loss dict:  {'classification_loss': 1.070511120557785}
2025-01-12 18:10:08,739 [INFO] Step[2800/4329]: training loss : 1.1000762856006623 TRAIN  loss dict:  {'classification_loss': 1.1000762856006623}
2025-01-12 18:10:20,427 [INFO] Step[2850/4329]: training loss : 1.0325981521606444 TRAIN  loss dict:  {'classification_loss': 1.0325981521606444}
2025-01-12 18:10:31,994 [INFO] Step[2900/4329]: training loss : 1.1016960191726684 TRAIN  loss dict:  {'classification_loss': 1.1016960191726684}
2025-01-12 18:10:43,588 [INFO] Step[2950/4329]: training loss : 1.0298872208595276 TRAIN  loss dict:  {'classification_loss': 1.0298872208595276}
2025-01-12 18:10:55,200 [INFO] Step[3000/4329]: training loss : 1.0354204094409942 TRAIN  loss dict:  {'classification_loss': 1.0354204094409942}
2025-01-12 18:11:06,823 [INFO] Step[3050/4329]: training loss : 1.1301563251018525 TRAIN  loss dict:  {'classification_loss': 1.1301563251018525}
2025-01-12 18:11:18,420 [INFO] Step[3100/4329]: training loss : 1.0634853768348693 TRAIN  loss dict:  {'classification_loss': 1.0634853768348693}
2025-01-12 18:11:30,040 [INFO] Step[3150/4329]: training loss : 1.1113971018791198 TRAIN  loss dict:  {'classification_loss': 1.1113971018791198}
2025-01-12 18:11:41,621 [INFO] Step[3200/4329]: training loss : 1.0915016329288483 TRAIN  loss dict:  {'classification_loss': 1.0915016329288483}
2025-01-12 18:11:53,244 [INFO] Step[3250/4329]: training loss : 1.0885605037212371 TRAIN  loss dict:  {'classification_loss': 1.0885605037212371}
2025-01-12 18:12:04,855 [INFO] Step[3300/4329]: training loss : 1.0806953728199005 TRAIN  loss dict:  {'classification_loss': 1.0806953728199005}
2025-01-12 18:12:16,476 [INFO] Step[3350/4329]: training loss : 1.073003225326538 TRAIN  loss dict:  {'classification_loss': 1.073003225326538}
2025-01-12 18:12:28,115 [INFO] Step[3400/4329]: training loss : 1.1195836079120636 TRAIN  loss dict:  {'classification_loss': 1.1195836079120636}
2025-01-12 18:12:39,748 [INFO] Step[3450/4329]: training loss : 1.1049540257453918 TRAIN  loss dict:  {'classification_loss': 1.1049540257453918}
2025-01-12 18:12:51,312 [INFO] Step[3500/4329]: training loss : 1.0612986624240874 TRAIN  loss dict:  {'classification_loss': 1.0612986624240874}
2025-01-12 18:13:02,905 [INFO] Step[3550/4329]: training loss : 1.121400728225708 TRAIN  loss dict:  {'classification_loss': 1.121400728225708}
2025-01-12 18:13:14,549 [INFO] Step[3600/4329]: training loss : 1.2702489817142486 TRAIN  loss dict:  {'classification_loss': 1.2702489817142486}
2025-01-12 18:13:26,196 [INFO] Step[3650/4329]: training loss : 1.0717360806465148 TRAIN  loss dict:  {'classification_loss': 1.0717360806465148}
2025-01-12 18:13:37,804 [INFO] Step[3700/4329]: training loss : 1.081188280582428 TRAIN  loss dict:  {'classification_loss': 1.081188280582428}
2025-01-12 18:13:49,469 [INFO] Step[3750/4329]: training loss : 1.1494843089580535 TRAIN  loss dict:  {'classification_loss': 1.1494843089580535}
2025-01-12 18:14:01,131 [INFO] Step[3800/4329]: training loss : 1.0863412868976594 TRAIN  loss dict:  {'classification_loss': 1.0863412868976594}
2025-01-12 18:14:12,718 [INFO] Step[3850/4329]: training loss : 1.0962248945236206 TRAIN  loss dict:  {'classification_loss': 1.0962248945236206}
2025-01-12 18:14:24,332 [INFO] Step[3900/4329]: training loss : 1.0759394204616546 TRAIN  loss dict:  {'classification_loss': 1.0759394204616546}
2025-01-12 18:14:35,945 [INFO] Step[3950/4329]: training loss : 1.1135000061988831 TRAIN  loss dict:  {'classification_loss': 1.1135000061988831}
2025-01-12 18:14:47,549 [INFO] Step[4000/4329]: training loss : 1.0609324228763581 TRAIN  loss dict:  {'classification_loss': 1.0609324228763581}
2025-01-12 18:14:59,141 [INFO] Step[4050/4329]: training loss : 1.0657194316387177 TRAIN  loss dict:  {'classification_loss': 1.0657194316387177}
2025-01-12 18:15:10,716 [INFO] Step[4100/4329]: training loss : 1.061351945400238 TRAIN  loss dict:  {'classification_loss': 1.061351945400238}
2025-01-12 18:15:22,378 [INFO] Step[4150/4329]: training loss : 1.1288887989521026 TRAIN  loss dict:  {'classification_loss': 1.1288887989521026}
2025-01-12 18:15:33,993 [INFO] Step[4200/4329]: training loss : 1.0945565223693847 TRAIN  loss dict:  {'classification_loss': 1.0945565223693847}
2025-01-12 18:15:45,632 [INFO] Step[4250/4329]: training loss : 1.0775043320655824 TRAIN  loss dict:  {'classification_loss': 1.0775043320655824}
2025-01-12 18:15:57,226 [INFO] Step[4300/4329]: training loss : 1.0628702592849733 TRAIN  loss dict:  {'classification_loss': 1.0628702592849733}
2025-01-12 18:18:15,083 [INFO] Label accuracies statistics:
2025-01-12 18:18:15,083 [INFO] {0: 0.8888888888888888, 1: 0.7777777777777778, 2: 0.6666666666666666, 3: 0.75, 4: 0.25, 5: 0.8333333333333334, 6: 0.6666666666666666, 7: 0.5, 8: 0.16666666666666666, 9: 0.75, 10: 0.9166666666666666, 11: 0.8333333333333334, 12: 0.5, 13: 0.5833333333333334, 14: 0.5833333333333334, 15: 0.4444444444444444, 16: 0.5833333333333334, 17: 0.6666666666666666, 18: 0.6666666666666666, 19: 0.75, 20: 0.5, 21: 0.5833333333333334, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.9166666666666666, 27: 0.5833333333333334, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.6666666666666666, 32: 0.6666666666666666, 33: 0.8333333333333334, 34: 0.8333333333333334, 35: 0.8333333333333334, 36: 0.5, 37: 0.9166666666666666, 38: 0.9166666666666666, 39: 1.0, 40: 0.75, 41: 0.4166666666666667, 42: 0.75, 43: 0.8333333333333334, 44: 0.3333333333333333, 45: 0.6666666666666666, 46: 0.9166666666666666, 47: 1.0, 48: 0.9166666666666666, 49: 0.9166666666666666, 50: 0.75, 51: 0.6666666666666666, 52: 1.0, 53: 0.6666666666666666, 54: 0.4166666666666667, 55: 0.6666666666666666, 56: 0.75, 57: 0.6666666666666666, 58: 0.3333333333333333, 59: 0.6666666666666666, 60: 0.5833333333333334, 61: 0.9166666666666666, 62: 0.75, 63: 0.5833333333333334, 64: 0.9166666666666666, 65: 0.9166666666666666, 66: 0.5833333333333334, 67: 0.75, 68: 0.8333333333333334, 69: 0.6666666666666666, 70: 0.16666666666666666, 71: 0.5833333333333334, 72: 0.8333333333333334, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.3333333333333333, 77: 0.5833333333333334, 78: 0.9166666666666666, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.6666666666666666, 85: 0.6666666666666666, 86: 0.5833333333333334, 87: 1.0, 88: 0.4166666666666667, 89: 0.5833333333333334, 90: 0.5833333333333334, 91: 0.8333333333333334, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.4166666666666667, 97: 0.5833333333333334, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.9166666666666666, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 0.8333333333333334, 106: 0.9166666666666666, 107: 0.75, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 0.8333333333333334, 111: 1.0, 112: 0.75, 113: 0.4166666666666667, 114: 0.75, 115: 0.9166666666666666, 116: 0.9166666666666666, 117: 0.75, 118: 1.0, 119: 0.8333333333333334, 120: 0.8333333333333334, 121: 0.75, 122: 0.8333333333333334, 123: 0.75, 124: 0.9166666666666666, 125: 0.9166666666666666, 126: 0.9166666666666666, 127: 0.6666666666666666, 128: 1.0, 129: 1.0, 130: 0.9166666666666666, 131: 1.0, 132: 0.16666666666666666, 133: 0.9166666666666666, 134: 0.9166666666666666, 135: 1.0, 136: 0.9166666666666666, 137: 0.75, 138: 0.75, 139: 0.9166666666666666, 140: 0.9166666666666666, 141: 1.0, 142: 0.75, 143: 0.9166666666666666, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.6666666666666666, 151: 1.0, 152: 0.75, 153: 0.75, 154: 0.9166666666666666, 155: 1.0, 156: 0.3333333333333333, 157: 0.75, 158: 0.6666666666666666, 159: 0.9166666666666666, 160: 0.4166666666666667, 161: 0.75, 162: 1.0, 163: 0.9166666666666666, 164: 0.8333333333333334, 165: 0.8333333333333334, 166: 0.75, 167: 0.75, 168: 0.8333333333333334, 169: 0.8333333333333334, 170: 1.0, 171: 0.8333333333333334, 172: 1.0, 173: 0.5833333333333334, 174: 0.8333333333333334, 175: 0.8333333333333334, 176: 0.9166666666666666, 177: 0.9166666666666666, 178: 0.9166666666666666, 179: 0.4444444444444444, 180: 0.8333333333333334, 181: 0.75, 182: 0.25, 183: 0.6666666666666666, 184: 0.75, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.5, 189: 0.8333333333333334, 190: 0.5833333333333334, 191: 0.3333333333333333, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.8333333333333334}

2025-01-12 18:18:54,478 [INFO] [11] TRAIN  loss: 1.0904922053840922 acc: 0.9510241798860312
2025-01-12 18:18:54,479 [INFO] [11] TRAIN  loss dict: {'classification_loss': 1.0904922053840922}
2025-01-12 18:18:54,479 [INFO] [11] VALIDATION loss: 1.7309067980057062 VALIDATION acc: 0.7689393939393939
2025-01-12 18:18:54,479 [INFO] [11] VALIDATION loss dict: {'classification_loss': 1.7309067980057062}
2025-01-12 18:18:54,479 [INFO] 
2025-01-12 18:19:11,081 [INFO] Step[50/4329]: training loss : 1.0841878569126129 TRAIN  loss dict:  {'classification_loss': 1.0841878569126129}
2025-01-12 18:19:22,673 [INFO] Step[100/4329]: training loss : 1.0267709350585938 TRAIN  loss dict:  {'classification_loss': 1.0267709350585938}
2025-01-12 18:19:34,299 [INFO] Step[150/4329]: training loss : 1.03139404296875 TRAIN  loss dict:  {'classification_loss': 1.03139404296875}
2025-01-12 18:19:45,902 [INFO] Step[200/4329]: training loss : 1.064816539287567 TRAIN  loss dict:  {'classification_loss': 1.064816539287567}
2025-01-12 18:19:57,586 [INFO] Step[250/4329]: training loss : 1.076215078830719 TRAIN  loss dict:  {'classification_loss': 1.076215078830719}
2025-01-12 18:20:09,197 [INFO] Step[300/4329]: training loss : 1.0434819293022155 TRAIN  loss dict:  {'classification_loss': 1.0434819293022155}
2025-01-12 18:20:20,848 [INFO] Step[350/4329]: training loss : 1.04379612326622 TRAIN  loss dict:  {'classification_loss': 1.04379612326622}
2025-01-12 18:20:32,502 [INFO] Step[400/4329]: training loss : 1.1238044929504394 TRAIN  loss dict:  {'classification_loss': 1.1238044929504394}
2025-01-12 18:20:44,176 [INFO] Step[450/4329]: training loss : 1.0525938582420349 TRAIN  loss dict:  {'classification_loss': 1.0525938582420349}
2025-01-12 18:20:55,787 [INFO] Step[500/4329]: training loss : 1.026555210351944 TRAIN  loss dict:  {'classification_loss': 1.026555210351944}
2025-01-12 18:21:07,477 [INFO] Step[550/4329]: training loss : 1.0196350944042205 TRAIN  loss dict:  {'classification_loss': 1.0196350944042205}
2025-01-12 18:21:19,105 [INFO] Step[600/4329]: training loss : 1.0450614941120149 TRAIN  loss dict:  {'classification_loss': 1.0450614941120149}
2025-01-12 18:21:30,754 [INFO] Step[650/4329]: training loss : 1.0568852281570436 TRAIN  loss dict:  {'classification_loss': 1.0568852281570436}
2025-01-12 18:21:42,470 [INFO] Step[700/4329]: training loss : 1.0092244577407836 TRAIN  loss dict:  {'classification_loss': 1.0092244577407836}
2025-01-12 18:21:54,106 [INFO] Step[750/4329]: training loss : 1.0309916985034944 TRAIN  loss dict:  {'classification_loss': 1.0309916985034944}
2025-01-12 18:22:05,742 [INFO] Step[800/4329]: training loss : 1.0272016763687133 TRAIN  loss dict:  {'classification_loss': 1.0272016763687133}
2025-01-12 18:22:17,420 [INFO] Step[850/4329]: training loss : 1.0874897062778472 TRAIN  loss dict:  {'classification_loss': 1.0874897062778472}
2025-01-12 18:22:29,034 [INFO] Step[900/4329]: training loss : 1.0517172384262086 TRAIN  loss dict:  {'classification_loss': 1.0517172384262086}
2025-01-12 18:22:40,687 [INFO] Step[950/4329]: training loss : 1.0514101874828339 TRAIN  loss dict:  {'classification_loss': 1.0514101874828339}
2025-01-12 18:22:52,339 [INFO] Step[1000/4329]: training loss : 1.0593875908851624 TRAIN  loss dict:  {'classification_loss': 1.0593875908851624}
2025-01-12 18:23:04,007 [INFO] Step[1050/4329]: training loss : 1.031940566301346 TRAIN  loss dict:  {'classification_loss': 1.031940566301346}
2025-01-12 18:23:15,699 [INFO] Step[1100/4329]: training loss : 1.0707898366451263 TRAIN  loss dict:  {'classification_loss': 1.0707898366451263}
2025-01-12 18:23:27,359 [INFO] Step[1150/4329]: training loss : 1.1033023762702943 TRAIN  loss dict:  {'classification_loss': 1.1033023762702943}
2025-01-12 18:23:39,033 [INFO] Step[1200/4329]: training loss : 1.0652238321304321 TRAIN  loss dict:  {'classification_loss': 1.0652238321304321}
2025-01-12 18:23:50,733 [INFO] Step[1250/4329]: training loss : 1.01760089635849 TRAIN  loss dict:  {'classification_loss': 1.01760089635849}
2025-01-12 18:24:02,387 [INFO] Step[1300/4329]: training loss : 1.0147258067131042 TRAIN  loss dict:  {'classification_loss': 1.0147258067131042}
2025-01-12 18:24:14,050 [INFO] Step[1350/4329]: training loss : 1.0056034564971923 TRAIN  loss dict:  {'classification_loss': 1.0056034564971923}
2025-01-12 18:24:25,706 [INFO] Step[1400/4329]: training loss : 1.0866993761062622 TRAIN  loss dict:  {'classification_loss': 1.0866993761062622}
2025-01-12 18:24:37,348 [INFO] Step[1450/4329]: training loss : 1.0688761639595032 TRAIN  loss dict:  {'classification_loss': 1.0688761639595032}
2025-01-12 18:24:49,008 [INFO] Step[1500/4329]: training loss : 1.0358693480491639 TRAIN  loss dict:  {'classification_loss': 1.0358693480491639}
2025-01-12 18:25:00,671 [INFO] Step[1550/4329]: training loss : 1.0937853062152862 TRAIN  loss dict:  {'classification_loss': 1.0937853062152862}
2025-01-12 18:25:12,390 [INFO] Step[1600/4329]: training loss : 1.069323617219925 TRAIN  loss dict:  {'classification_loss': 1.069323617219925}
2025-01-12 18:25:24,055 [INFO] Step[1650/4329]: training loss : 1.107159972190857 TRAIN  loss dict:  {'classification_loss': 1.107159972190857}
2025-01-12 18:25:35,726 [INFO] Step[1700/4329]: training loss : 1.1059904706478119 TRAIN  loss dict:  {'classification_loss': 1.1059904706478119}
2025-01-12 18:25:47,381 [INFO] Step[1750/4329]: training loss : 1.0998000240325927 TRAIN  loss dict:  {'classification_loss': 1.0998000240325927}
2025-01-12 18:25:59,028 [INFO] Step[1800/4329]: training loss : 1.0558240342140197 TRAIN  loss dict:  {'classification_loss': 1.0558240342140197}
2025-01-12 18:26:10,672 [INFO] Step[1850/4329]: training loss : 1.0271368253231048 TRAIN  loss dict:  {'classification_loss': 1.0271368253231048}
2025-01-12 18:26:22,330 [INFO] Step[1900/4329]: training loss : 1.1051929807662964 TRAIN  loss dict:  {'classification_loss': 1.1051929807662964}
2025-01-12 18:26:33,993 [INFO] Step[1950/4329]: training loss : 1.0985968899726868 TRAIN  loss dict:  {'classification_loss': 1.0985968899726868}
2025-01-12 18:26:45,657 [INFO] Step[2000/4329]: training loss : 1.05082888007164 TRAIN  loss dict:  {'classification_loss': 1.05082888007164}
2025-01-12 18:26:57,325 [INFO] Step[2050/4329]: training loss : 1.0496794509887695 TRAIN  loss dict:  {'classification_loss': 1.0496794509887695}
2025-01-12 18:27:08,968 [INFO] Step[2100/4329]: training loss : 1.0608260571956634 TRAIN  loss dict:  {'classification_loss': 1.0608260571956634}
2025-01-12 18:27:20,581 [INFO] Step[2150/4329]: training loss : 1.0626311922073364 TRAIN  loss dict:  {'classification_loss': 1.0626311922073364}
2025-01-12 18:27:32,251 [INFO] Step[2200/4329]: training loss : 1.072355626821518 TRAIN  loss dict:  {'classification_loss': 1.072355626821518}
2025-01-12 18:27:43,911 [INFO] Step[2250/4329]: training loss : 1.074306334257126 TRAIN  loss dict:  {'classification_loss': 1.074306334257126}
2025-01-12 18:27:55,578 [INFO] Step[2300/4329]: training loss : 1.0764886939525604 TRAIN  loss dict:  {'classification_loss': 1.0764886939525604}
2025-01-12 18:28:07,217 [INFO] Step[2350/4329]: training loss : 1.0016616153717042 TRAIN  loss dict:  {'classification_loss': 1.0016616153717042}
2025-01-12 18:28:18,868 [INFO] Step[2400/4329]: training loss : 1.0643483471870423 TRAIN  loss dict:  {'classification_loss': 1.0643483471870423}
2025-01-12 18:28:30,519 [INFO] Step[2450/4329]: training loss : 1.0250267827510833 TRAIN  loss dict:  {'classification_loss': 1.0250267827510833}
2025-01-12 18:28:42,152 [INFO] Step[2500/4329]: training loss : 1.0647870886325836 TRAIN  loss dict:  {'classification_loss': 1.0647870886325836}
2025-01-12 18:28:53,806 [INFO] Step[2550/4329]: training loss : 1.1112475967407227 TRAIN  loss dict:  {'classification_loss': 1.1112475967407227}
2025-01-12 18:29:05,436 [INFO] Step[2600/4329]: training loss : 1.0668102753162385 TRAIN  loss dict:  {'classification_loss': 1.0668102753162385}
2025-01-12 18:29:17,138 [INFO] Step[2650/4329]: training loss : 1.0706623601913452 TRAIN  loss dict:  {'classification_loss': 1.0706623601913452}
2025-01-12 18:29:28,761 [INFO] Step[2700/4329]: training loss : 1.099703528881073 TRAIN  loss dict:  {'classification_loss': 1.099703528881073}
2025-01-12 18:29:41,003 [INFO] Step[2750/4329]: training loss : 1.071758235692978 TRAIN  loss dict:  {'classification_loss': 1.071758235692978}
2025-01-12 18:29:53,207 [INFO] Step[2800/4329]: training loss : 1.0560200440883636 TRAIN  loss dict:  {'classification_loss': 1.0560200440883636}
2025-01-12 18:30:05,899 [INFO] Step[2850/4329]: training loss : 1.0847475159168243 TRAIN  loss dict:  {'classification_loss': 1.0847475159168243}
2025-01-12 18:30:19,305 [INFO] Step[2900/4329]: training loss : 1.0686316549777986 TRAIN  loss dict:  {'classification_loss': 1.0686316549777986}
2025-01-12 18:30:32,331 [INFO] Step[2950/4329]: training loss : 1.018210461139679 TRAIN  loss dict:  {'classification_loss': 1.018210461139679}
2025-01-12 18:30:44,223 [INFO] Step[3000/4329]: training loss : 1.04729105591774 TRAIN  loss dict:  {'classification_loss': 1.04729105591774}
2025-01-12 18:30:56,077 [INFO] Step[3050/4329]: training loss : 1.0425841093063355 TRAIN  loss dict:  {'classification_loss': 1.0425841093063355}
2025-01-12 18:31:07,751 [INFO] Step[3100/4329]: training loss : 1.1010751807689667 TRAIN  loss dict:  {'classification_loss': 1.1010751807689667}
2025-01-12 18:31:19,337 [INFO] Step[3150/4329]: training loss : 1.0411522829532622 TRAIN  loss dict:  {'classification_loss': 1.0411522829532622}
2025-01-12 18:31:30,898 [INFO] Step[3200/4329]: training loss : 1.1321680104732514 TRAIN  loss dict:  {'classification_loss': 1.1321680104732514}
2025-01-12 18:31:42,564 [INFO] Step[3250/4329]: training loss : 1.097241141796112 TRAIN  loss dict:  {'classification_loss': 1.097241141796112}
2025-01-12 18:31:54,156 [INFO] Step[3300/4329]: training loss : 1.1154543340206147 TRAIN  loss dict:  {'classification_loss': 1.1154543340206147}
2025-01-12 18:32:05,761 [INFO] Step[3350/4329]: training loss : 1.0642452347278595 TRAIN  loss dict:  {'classification_loss': 1.0642452347278595}
2025-01-12 18:32:17,370 [INFO] Step[3400/4329]: training loss : 1.003561350107193 TRAIN  loss dict:  {'classification_loss': 1.003561350107193}
2025-01-12 18:32:28,970 [INFO] Step[3450/4329]: training loss : 1.0362453436851502 TRAIN  loss dict:  {'classification_loss': 1.0362453436851502}
2025-01-12 18:32:40,592 [INFO] Step[3500/4329]: training loss : 1.1310827016830445 TRAIN  loss dict:  {'classification_loss': 1.1310827016830445}
2025-01-12 18:32:52,207 [INFO] Step[3550/4329]: training loss : 1.0534916830062866 TRAIN  loss dict:  {'classification_loss': 1.0534916830062866}
2025-01-12 18:33:03,805 [INFO] Step[3600/4329]: training loss : 1.0514289498329163 TRAIN  loss dict:  {'classification_loss': 1.0514289498329163}
2025-01-12 18:33:15,405 [INFO] Step[3650/4329]: training loss : 1.055330753326416 TRAIN  loss dict:  {'classification_loss': 1.055330753326416}
2025-01-12 18:33:27,016 [INFO] Step[3700/4329]: training loss : 1.1001229906082153 TRAIN  loss dict:  {'classification_loss': 1.1001229906082153}
2025-01-12 18:33:38,623 [INFO] Step[3750/4329]: training loss : 1.0928944301605226 TRAIN  loss dict:  {'classification_loss': 1.0928944301605226}
2025-01-12 18:33:50,281 [INFO] Step[3800/4329]: training loss : 1.061597365140915 TRAIN  loss dict:  {'classification_loss': 1.061597365140915}
2025-01-12 18:34:01,883 [INFO] Step[3850/4329]: training loss : 1.0622698199748992 TRAIN  loss dict:  {'classification_loss': 1.0622698199748992}
2025-01-12 18:34:13,487 [INFO] Step[3900/4329]: training loss : 1.0782961082458495 TRAIN  loss dict:  {'classification_loss': 1.0782961082458495}
2025-01-12 18:34:25,125 [INFO] Step[3950/4329]: training loss : 1.0930964207649232 TRAIN  loss dict:  {'classification_loss': 1.0930964207649232}
2025-01-12 18:34:36,778 [INFO] Step[4000/4329]: training loss : 1.0912252926826478 TRAIN  loss dict:  {'classification_loss': 1.0912252926826478}
2025-01-12 18:34:48,407 [INFO] Step[4050/4329]: training loss : 1.1100627923011779 TRAIN  loss dict:  {'classification_loss': 1.1100627923011779}
2025-01-12 18:34:59,994 [INFO] Step[4100/4329]: training loss : 1.0266132164001465 TRAIN  loss dict:  {'classification_loss': 1.0266132164001465}
2025-01-12 18:35:11,647 [INFO] Step[4150/4329]: training loss : 1.03988379240036 TRAIN  loss dict:  {'classification_loss': 1.03988379240036}
2025-01-12 18:35:23,268 [INFO] Step[4200/4329]: training loss : 1.0517557537555695 TRAIN  loss dict:  {'classification_loss': 1.0517557537555695}
2025-01-12 18:35:34,856 [INFO] Step[4250/4329]: training loss : 1.0892822456359863 TRAIN  loss dict:  {'classification_loss': 1.0892822456359863}
2025-01-12 18:35:46,473 [INFO] Step[4300/4329]: training loss : 1.0308958721160888 TRAIN  loss dict:  {'classification_loss': 1.0308958721160888}
2025-01-12 18:37:45,765 [INFO] Label accuracies statistics:
2025-01-12 18:37:45,765 [INFO] {0: 0.5555555555555556, 1: 0.8888888888888888, 2: 0.5833333333333334, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.6666666666666666, 7: 0.5, 8: 0.4166666666666667, 9: 0.8333333333333334, 10: 1.0, 11: 0.6666666666666666, 12: 0.4166666666666667, 13: 0.4166666666666667, 14: 0.6666666666666666, 15: 0.5555555555555556, 16: 0.3333333333333333, 17: 0.5833333333333334, 18: 0.6666666666666666, 19: 0.6666666666666666, 20: 0.5, 21: 0.6666666666666666, 22: 0.75, 23: 0.9166666666666666, 24: 0.9166666666666666, 25: 0.5833333333333334, 26: 0.75, 27: 0.5833333333333334, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.75, 32: 0.6666666666666666, 33: 0.8333333333333334, 34: 0.75, 35: 1.0, 36: 0.5833333333333334, 37: 0.9166666666666666, 38: 0.8333333333333334, 39: 1.0, 40: 0.75, 41: 0.3333333333333333, 42: 0.8333333333333334, 43: 0.9166666666666666, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 0.8333333333333334, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.4166666666666667, 54: 0.4166666666666667, 55: 0.75, 56: 0.5833333333333334, 57: 0.75, 58: 0.5, 59: 0.75, 60: 0.6666666666666666, 61: 0.9166666666666666, 62: 0.75, 63: 0.4166666666666667, 64: 1.0, 65: 0.9166666666666666, 66: 0.6666666666666666, 67: 0.9166666666666666, 68: 0.3333333333333333, 69: 0.5833333333333334, 70: 0.5, 71: 0.4166666666666667, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 0.9166666666666666, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5833333333333334, 84: 0.5833333333333334, 85: 0.6666666666666666, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.6666666666666666, 89: 0.5, 90: 0.6666666666666666, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.9166666666666666, 106: 0.9166666666666666, 107: 0.25, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.75, 111: 1.0, 112: 0.9166666666666666, 113: 0.5, 114: 0.3333333333333333, 115: 1.0, 116: 0.5833333333333334, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.6666666666666666, 121: 0.75, 122: 0.9166666666666666, 123: 1.0, 124: 0.8333333333333334, 125: 0.9166666666666666, 126: 0.9166666666666666, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.9166666666666666, 132: 0.6666666666666666, 133: 1.0, 134: 0.8333333333333334, 135: 0.9166666666666666, 136: 0.8333333333333334, 137: 0.9166666666666666, 138: 1.0, 139: 0.75, 140: 0.8333333333333334, 141: 0.9166666666666666, 142: 0.75, 143: 1.0, 144: 0.5833333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.75, 148: 1.0, 149: 0.9166666666666666, 150: 0.5, 151: 0.8333333333333334, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 1.0, 156: 0.8333333333333334, 157: 0.5833333333333334, 158: 0.7777777777777778, 159: 0.9166666666666666, 160: 0.3333333333333333, 161: 0.75, 162: 0.9166666666666666, 163: 0.9166666666666666, 164: 0.75, 165: 1.0, 166: 0.6666666666666666, 167: 0.8333333333333334, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.4166666666666667, 172: 1.0, 173: 0.75, 174: 1.0, 175: 0.8333333333333334, 176: 0.9166666666666666, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.75, 183: 0.8333333333333334, 184: 0.75, 185: 1.0, 186: 0.75, 187: 0.9166666666666666, 188: 0.5833333333333334, 189: 0.6666666666666666, 190: 0.5833333333333334, 191: 0.4166666666666667, 192: 1.0, 193: 0.8333333333333334, 194: 0.9166666666666666, 195: 0.8333333333333334, 196: 0.8333333333333334, 197: 0.9166666666666666, 198: 0.5833333333333334}

2025-01-12 18:37:46,706 [INFO] [12] TRAIN  loss: 1.0633863491283935 acc: 0.9588017865393501
2025-01-12 18:37:46,706 [INFO] [12] TRAIN  loss dict: {'classification_loss': 1.0633863491283935}
2025-01-12 18:37:46,706 [INFO] [12] VALIDATION loss: 1.7212258669162037 VALIDATION acc: 0.7685185185185185
2025-01-12 18:37:46,706 [INFO] [12] VALIDATION loss dict: {'classification_loss': 1.7212258669162037}
2025-01-12 18:37:46,706 [INFO] 
2025-01-12 18:38:04,205 [INFO] Step[50/4329]: training loss : 1.0768020677566528 TRAIN  loss dict:  {'classification_loss': 1.0768020677566528}
2025-01-12 18:38:15,780 [INFO] Step[100/4329]: training loss : 1.029835433959961 TRAIN  loss dict:  {'classification_loss': 1.029835433959961}
2025-01-12 18:38:27,395 [INFO] Step[150/4329]: training loss : 1.0582489132881165 TRAIN  loss dict:  {'classification_loss': 1.0582489132881165}
2025-01-12 18:38:38,971 [INFO] Step[200/4329]: training loss : 1.0223352646827697 TRAIN  loss dict:  {'classification_loss': 1.0223352646827697}
2025-01-12 18:38:50,648 [INFO] Step[250/4329]: training loss : 1.0422245156764984 TRAIN  loss dict:  {'classification_loss': 1.0422245156764984}
2025-01-12 18:39:02,267 [INFO] Step[300/4329]: training loss : 1.0390262973308564 TRAIN  loss dict:  {'classification_loss': 1.0390262973308564}
2025-01-12 18:39:13,889 [INFO] Step[350/4329]: training loss : 1.088431088924408 TRAIN  loss dict:  {'classification_loss': 1.088431088924408}
2025-01-12 18:39:25,539 [INFO] Step[400/4329]: training loss : 0.9722587430477142 TRAIN  loss dict:  {'classification_loss': 0.9722587430477142}
2025-01-12 18:39:37,149 [INFO] Step[450/4329]: training loss : 1.0145273685455323 TRAIN  loss dict:  {'classification_loss': 1.0145273685455323}
2025-01-12 18:39:48,746 [INFO] Step[500/4329]: training loss : 1.049749457836151 TRAIN  loss dict:  {'classification_loss': 1.049749457836151}
2025-01-12 18:40:00,390 [INFO] Step[550/4329]: training loss : 1.0595708465576172 TRAIN  loss dict:  {'classification_loss': 1.0595708465576172}
2025-01-12 18:40:12,016 [INFO] Step[600/4329]: training loss : 1.0430793833732606 TRAIN  loss dict:  {'classification_loss': 1.0430793833732606}
2025-01-12 18:40:23,616 [INFO] Step[650/4329]: training loss : 1.0218431663513183 TRAIN  loss dict:  {'classification_loss': 1.0218431663513183}
2025-01-12 18:40:35,256 [INFO] Step[700/4329]: training loss : 1.0468902850151063 TRAIN  loss dict:  {'classification_loss': 1.0468902850151063}
2025-01-12 18:40:46,850 [INFO] Step[750/4329]: training loss : 1.038221263885498 TRAIN  loss dict:  {'classification_loss': 1.038221263885498}
2025-01-12 18:40:58,472 [INFO] Step[800/4329]: training loss : 1.066064372062683 TRAIN  loss dict:  {'classification_loss': 1.066064372062683}
2025-01-12 18:41:10,089 [INFO] Step[850/4329]: training loss : 1.049822324514389 TRAIN  loss dict:  {'classification_loss': 1.049822324514389}
2025-01-12 18:41:21,691 [INFO] Step[900/4329]: training loss : 1.046393839120865 TRAIN  loss dict:  {'classification_loss': 1.046393839120865}
2025-01-12 18:41:33,345 [INFO] Step[950/4329]: training loss : 1.0952277994155883 TRAIN  loss dict:  {'classification_loss': 1.0952277994155883}
2025-01-12 18:41:44,972 [INFO] Step[1000/4329]: training loss : 1.0258887791633606 TRAIN  loss dict:  {'classification_loss': 1.0258887791633606}
2025-01-12 18:41:56,749 [INFO] Step[1050/4329]: training loss : 1.0492064845561981 TRAIN  loss dict:  {'classification_loss': 1.0492064845561981}
2025-01-12 18:42:09,047 [INFO] Step[1100/4329]: training loss : 0.9921410000324249 TRAIN  loss dict:  {'classification_loss': 0.9921410000324249}
2025-01-12 18:42:21,281 [INFO] Step[1150/4329]: training loss : 1.0564771008491516 TRAIN  loss dict:  {'classification_loss': 1.0564771008491516}
2025-01-12 18:42:34,207 [INFO] Step[1200/4329]: training loss : 1.0320684814453125 TRAIN  loss dict:  {'classification_loss': 1.0320684814453125}
2025-01-12 18:42:47,741 [INFO] Step[1250/4329]: training loss : 1.0467584240436554 TRAIN  loss dict:  {'classification_loss': 1.0467584240436554}
2025-01-12 18:43:00,305 [INFO] Step[1300/4329]: training loss : 1.0048308718204497 TRAIN  loss dict:  {'classification_loss': 1.0048308718204497}
2025-01-12 18:43:12,193 [INFO] Step[1350/4329]: training loss : 1.0473824620246888 TRAIN  loss dict:  {'classification_loss': 1.0473824620246888}
2025-01-12 18:43:24,073 [INFO] Step[1400/4329]: training loss : 1.058815256357193 TRAIN  loss dict:  {'classification_loss': 1.058815256357193}
2025-01-12 18:43:35,680 [INFO] Step[1450/4329]: training loss : 1.0313477158546447 TRAIN  loss dict:  {'classification_loss': 1.0313477158546447}
2025-01-12 18:43:47,270 [INFO] Step[1500/4329]: training loss : 1.0845482921600342 TRAIN  loss dict:  {'classification_loss': 1.0845482921600342}
2025-01-12 18:43:58,878 [INFO] Step[1550/4329]: training loss : 1.0835458755493164 TRAIN  loss dict:  {'classification_loss': 1.0835458755493164}
2025-01-12 18:44:10,476 [INFO] Step[1600/4329]: training loss : 0.9919189214706421 TRAIN  loss dict:  {'classification_loss': 0.9919189214706421}
2025-01-12 18:44:22,097 [INFO] Step[1650/4329]: training loss : 1.0517095744609832 TRAIN  loss dict:  {'classification_loss': 1.0517095744609832}
2025-01-12 18:44:33,713 [INFO] Step[1700/4329]: training loss : 1.0833125007152558 TRAIN  loss dict:  {'classification_loss': 1.0833125007152558}
2025-01-12 18:44:45,304 [INFO] Step[1750/4329]: training loss : 1.0464979672431947 TRAIN  loss dict:  {'classification_loss': 1.0464979672431947}
2025-01-12 18:44:56,918 [INFO] Step[1800/4329]: training loss : 1.0392371761798858 TRAIN  loss dict:  {'classification_loss': 1.0392371761798858}
2025-01-12 18:45:08,516 [INFO] Step[1850/4329]: training loss : 1.0400552916526795 TRAIN  loss dict:  {'classification_loss': 1.0400552916526795}
2025-01-12 18:45:20,131 [INFO] Step[1900/4329]: training loss : 1.045517921447754 TRAIN  loss dict:  {'classification_loss': 1.045517921447754}
2025-01-12 18:45:31,744 [INFO] Step[1950/4329]: training loss : 1.033795462846756 TRAIN  loss dict:  {'classification_loss': 1.033795462846756}
2025-01-12 18:45:43,337 [INFO] Step[2000/4329]: training loss : 1.0257510840892792 TRAIN  loss dict:  {'classification_loss': 1.0257510840892792}
2025-01-12 18:45:54,936 [INFO] Step[2050/4329]: training loss : 1.0766542696952819 TRAIN  loss dict:  {'classification_loss': 1.0766542696952819}
2025-01-12 18:46:06,564 [INFO] Step[2100/4329]: training loss : 1.0652276706695556 TRAIN  loss dict:  {'classification_loss': 1.0652276706695556}
2025-01-12 18:46:18,169 [INFO] Step[2150/4329]: training loss : 1.008544511795044 TRAIN  loss dict:  {'classification_loss': 1.008544511795044}
2025-01-12 18:46:29,767 [INFO] Step[2200/4329]: training loss : 1.0812674713134767 TRAIN  loss dict:  {'classification_loss': 1.0812674713134767}
2025-01-12 18:46:41,336 [INFO] Step[2250/4329]: training loss : 1.0418538749217987 TRAIN  loss dict:  {'classification_loss': 1.0418538749217987}
2025-01-12 18:46:52,980 [INFO] Step[2300/4329]: training loss : 1.0760864877700806 TRAIN  loss dict:  {'classification_loss': 1.0760864877700806}
2025-01-12 18:47:04,616 [INFO] Step[2350/4329]: training loss : 1.0487869381904602 TRAIN  loss dict:  {'classification_loss': 1.0487869381904602}
2025-01-12 18:47:16,254 [INFO] Step[2400/4329]: training loss : 1.037847558259964 TRAIN  loss dict:  {'classification_loss': 1.037847558259964}
2025-01-12 18:47:27,860 [INFO] Step[2450/4329]: training loss : 1.0159541416168212 TRAIN  loss dict:  {'classification_loss': 1.0159541416168212}
2025-01-12 18:47:39,451 [INFO] Step[2500/4329]: training loss : 1.0361066496372222 TRAIN  loss dict:  {'classification_loss': 1.0361066496372222}
2025-01-12 18:47:51,101 [INFO] Step[2550/4329]: training loss : 1.0099112260341645 TRAIN  loss dict:  {'classification_loss': 1.0099112260341645}
2025-01-12 18:48:02,704 [INFO] Step[2600/4329]: training loss : 1.0790967524051667 TRAIN  loss dict:  {'classification_loss': 1.0790967524051667}
2025-01-12 18:48:14,355 [INFO] Step[2650/4329]: training loss : 1.0856214928627015 TRAIN  loss dict:  {'classification_loss': 1.0856214928627015}
2025-01-12 18:48:25,930 [INFO] Step[2700/4329]: training loss : 0.9951080918312073 TRAIN  loss dict:  {'classification_loss': 0.9951080918312073}
2025-01-12 18:48:37,517 [INFO] Step[2750/4329]: training loss : 1.0170169043540955 TRAIN  loss dict:  {'classification_loss': 1.0170169043540955}
2025-01-12 18:48:49,124 [INFO] Step[2800/4329]: training loss : 1.0471985054016113 TRAIN  loss dict:  {'classification_loss': 1.0471985054016113}
2025-01-12 18:49:00,813 [INFO] Step[2850/4329]: training loss : 1.05113578915596 TRAIN  loss dict:  {'classification_loss': 1.05113578915596}
2025-01-12 18:49:12,414 [INFO] Step[2900/4329]: training loss : 1.0262807643413543 TRAIN  loss dict:  {'classification_loss': 1.0262807643413543}
2025-01-12 18:49:24,014 [INFO] Step[2950/4329]: training loss : 1.0324577224254607 TRAIN  loss dict:  {'classification_loss': 1.0324577224254607}
2025-01-12 18:49:35,626 [INFO] Step[3000/4329]: training loss : 1.0896972978115083 TRAIN  loss dict:  {'classification_loss': 1.0896972978115083}
2025-01-12 18:49:47,234 [INFO] Step[3050/4329]: training loss : 1.0944262397289277 TRAIN  loss dict:  {'classification_loss': 1.0944262397289277}
2025-01-12 18:49:58,855 [INFO] Step[3100/4329]: training loss : 1.0569106602668763 TRAIN  loss dict:  {'classification_loss': 1.0569106602668763}
2025-01-12 18:50:10,497 [INFO] Step[3150/4329]: training loss : 1.0054029655456542 TRAIN  loss dict:  {'classification_loss': 1.0054029655456542}
2025-01-12 18:50:22,069 [INFO] Step[3200/4329]: training loss : 1.04998610496521 TRAIN  loss dict:  {'classification_loss': 1.04998610496521}
2025-01-12 18:50:33,682 [INFO] Step[3250/4329]: training loss : 0.9684864902496337 TRAIN  loss dict:  {'classification_loss': 0.9684864902496337}
2025-01-12 18:50:45,293 [INFO] Step[3300/4329]: training loss : 1.0345888543128967 TRAIN  loss dict:  {'classification_loss': 1.0345888543128967}
2025-01-12 18:50:56,933 [INFO] Step[3350/4329]: training loss : 1.0643494236469269 TRAIN  loss dict:  {'classification_loss': 1.0643494236469269}
2025-01-12 18:51:08,535 [INFO] Step[3400/4329]: training loss : 1.068754243850708 TRAIN  loss dict:  {'classification_loss': 1.068754243850708}
2025-01-12 18:51:20,159 [INFO] Step[3450/4329]: training loss : 1.0302738857269287 TRAIN  loss dict:  {'classification_loss': 1.0302738857269287}
2025-01-12 18:51:31,767 [INFO] Step[3500/4329]: training loss : 1.0295343816280365 TRAIN  loss dict:  {'classification_loss': 1.0295343816280365}
2025-01-12 18:51:43,363 [INFO] Step[3550/4329]: training loss : 1.0662782287597656 TRAIN  loss dict:  {'classification_loss': 1.0662782287597656}
2025-01-12 18:51:54,993 [INFO] Step[3600/4329]: training loss : 1.0697831416130066 TRAIN  loss dict:  {'classification_loss': 1.0697831416130066}
2025-01-12 18:52:06,604 [INFO] Step[3650/4329]: training loss : 1.0457223427295685 TRAIN  loss dict:  {'classification_loss': 1.0457223427295685}
2025-01-12 18:52:18,196 [INFO] Step[3700/4329]: training loss : 1.0013144767284394 TRAIN  loss dict:  {'classification_loss': 1.0013144767284394}
2025-01-12 18:52:29,816 [INFO] Step[3750/4329]: training loss : 1.0772380065917968 TRAIN  loss dict:  {'classification_loss': 1.0772380065917968}
2025-01-12 18:52:41,392 [INFO] Step[3800/4329]: training loss : 1.0828271389007569 TRAIN  loss dict:  {'classification_loss': 1.0828271389007569}
2025-01-12 18:52:53,037 [INFO] Step[3850/4329]: training loss : 0.9850550222396851 TRAIN  loss dict:  {'classification_loss': 0.9850550222396851}
2025-01-12 18:53:04,678 [INFO] Step[3900/4329]: training loss : 1.0496924102306366 TRAIN  loss dict:  {'classification_loss': 1.0496924102306366}
2025-01-12 18:53:16,352 [INFO] Step[3950/4329]: training loss : 1.0219811379909516 TRAIN  loss dict:  {'classification_loss': 1.0219811379909516}
2025-01-12 18:53:27,930 [INFO] Step[4000/4329]: training loss : 1.0633345115184785 TRAIN  loss dict:  {'classification_loss': 1.0633345115184785}
2025-01-12 18:53:39,553 [INFO] Step[4050/4329]: training loss : 1.0328993332386016 TRAIN  loss dict:  {'classification_loss': 1.0328993332386016}
2025-01-12 18:53:51,132 [INFO] Step[4100/4329]: training loss : 1.027450032234192 TRAIN  loss dict:  {'classification_loss': 1.027450032234192}
2025-01-12 18:54:02,726 [INFO] Step[4150/4329]: training loss : 1.0445532488822937 TRAIN  loss dict:  {'classification_loss': 1.0445532488822937}
2025-01-12 18:54:14,578 [INFO] Step[4200/4329]: training loss : 1.0323241543769837 TRAIN  loss dict:  {'classification_loss': 1.0323241543769837}
2025-01-12 18:54:26,876 [INFO] Step[4250/4329]: training loss : 1.0689415788650514 TRAIN  loss dict:  {'classification_loss': 1.0689415788650514}
2025-01-12 18:54:39,128 [INFO] Step[4300/4329]: training loss : 1.005809997320175 TRAIN  loss dict:  {'classification_loss': 1.005809997320175}
2025-01-12 18:56:54,486 [INFO] Label accuracies statistics:
2025-01-12 18:56:54,487 [INFO] {0: 0.5555555555555556, 1: 1.0, 2: 0.5833333333333334, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.5, 7: 0.5833333333333334, 8: 0.6666666666666666, 9: 0.8333333333333334, 10: 1.0, 11: 0.75, 12: 0.4166666666666667, 13: 0.5, 14: 0.5833333333333334, 15: 0.7777777777777778, 16: 0.6666666666666666, 17: 0.4166666666666667, 18: 0.4166666666666667, 19: 0.5, 20: 0.5, 21: 0.6666666666666666, 22: 0.75, 23: 0.8333333333333334, 24: 1.0, 25: 0.6666666666666666, 26: 0.75, 27: 0.4166666666666667, 28: 0.8333333333333334, 29: 1.0, 30: 0.6666666666666666, 31: 0.8333333333333334, 32: 0.75, 33: 0.8333333333333334, 34: 0.9166666666666666, 35: 0.9166666666666666, 36: 0.6666666666666666, 37: 0.9166666666666666, 38: 0.8333333333333334, 39: 1.0, 40: 0.75, 41: 0.4166666666666667, 42: 0.75, 43: 0.9166666666666666, 44: 0.5, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 0.75, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.4166666666666667, 54: 0.4166666666666667, 55: 0.6666666666666666, 56: 0.75, 57: 0.75, 58: 0.75, 59: 0.5833333333333334, 60: 0.75, 61: 0.9166666666666666, 62: 0.75, 63: 0.4166666666666667, 64: 1.0, 65: 1.0, 66: 0.5833333333333334, 67: 0.8333333333333334, 68: 0.75, 69: 0.5, 70: 0.3333333333333333, 71: 0.5, 72: 1.0, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.5833333333333334, 77: 0.6666666666666666, 78: 0.8333333333333334, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.6666666666666666, 83: 0.6666666666666666, 84: 0.5, 85: 0.6666666666666666, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.5833333333333334, 89: 0.6666666666666666, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 0.9166666666666666, 96: 0.5, 97: 0.6666666666666666, 98: 0.75, 99: 0.9333333333333333, 100: 0.8333333333333334, 101: 0.8333333333333334, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 0.9166666666666666, 106: 0.9166666666666666, 107: 0.6666666666666666, 108: 0.8333333333333334, 109: 0.9166666666666666, 110: 0.9166666666666666, 111: 1.0, 112: 0.75, 113: 0.3333333333333333, 114: 0.75, 115: 0.75, 116: 0.5833333333333334, 117: 0.75, 118: 0.9166666666666666, 119: 0.75, 120: 0.6666666666666666, 121: 0.8333333333333334, 122: 0.8333333333333334, 123: 0.8333333333333334, 124: 0.9166666666666666, 125: 0.8333333333333334, 126: 0.9166666666666666, 127: 0.75, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.9166666666666666, 132: 0.8333333333333334, 133: 1.0, 134: 0.6666666666666666, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.8333333333333334, 138: 0.8333333333333334, 139: 0.8333333333333334, 140: 0.8333333333333334, 141: 0.9166666666666666, 142: 0.6666666666666666, 143: 0.9166666666666666, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.75, 148: 0.75, 149: 0.9166666666666666, 150: 0.3333333333333333, 151: 0.75, 152: 1.0, 153: 0.5833333333333334, 154: 0.8333333333333334, 155: 1.0, 156: 0.9166666666666666, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.5, 161: 0.9166666666666666, 162: 0.8333333333333334, 163: 0.75, 164: 0.6666666666666666, 165: 0.75, 166: 0.6666666666666666, 167: 0.75, 168: 0.9166666666666666, 169: 0.9166666666666666, 170: 1.0, 171: 0.3333333333333333, 172: 1.0, 173: 0.5833333333333334, 174: 0.8333333333333334, 175: 0.9166666666666666, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.5833333333333334, 183: 0.8333333333333334, 184: 0.6666666666666666, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.6666666666666666, 189: 0.9166666666666666, 190: 0.6666666666666666, 191: 0.5, 192: 1.0, 193: 0.9166666666666666, 194: 0.8333333333333334, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.8333333333333334}

2025-01-12 18:56:56,294 [INFO] [13] TRAIN  loss: 1.0438415321529422 acc: 0.9663483751732636
2025-01-12 18:56:56,294 [INFO] [13] TRAIN  loss dict: {'classification_loss': 1.0438415321529422}
2025-01-12 18:56:56,295 [INFO] [13] VALIDATION loss: 1.6966936997692994 VALIDATION acc: 0.7723063973063973
2025-01-12 18:56:56,295 [INFO] [13] VALIDATION loss dict: {'classification_loss': 1.6966936997692994}
2025-01-12 18:56:56,295 [INFO] 
2025-01-12 18:57:13,492 [INFO] Step[50/4329]: training loss : 1.0351142477989197 TRAIN  loss dict:  {'classification_loss': 1.0351142477989197}
2025-01-12 18:57:25,057 [INFO] Step[100/4329]: training loss : 0.9727646708488464 TRAIN  loss dict:  {'classification_loss': 0.9727646708488464}
2025-01-12 18:57:36,691 [INFO] Step[150/4329]: training loss : 1.0421057188510894 TRAIN  loss dict:  {'classification_loss': 1.0421057188510894}
2025-01-12 18:57:48,268 [INFO] Step[200/4329]: training loss : 1.002923047542572 TRAIN  loss dict:  {'classification_loss': 1.002923047542572}
2025-01-12 18:57:59,886 [INFO] Step[250/4329]: training loss : 1.020059244632721 TRAIN  loss dict:  {'classification_loss': 1.020059244632721}
2025-01-12 18:58:11,538 [INFO] Step[300/4329]: training loss : 1.100382205247879 TRAIN  loss dict:  {'classification_loss': 1.100382205247879}
2025-01-12 18:58:23,166 [INFO] Step[350/4329]: training loss : 1.026256411075592 TRAIN  loss dict:  {'classification_loss': 1.026256411075592}
2025-01-12 18:58:34,781 [INFO] Step[400/4329]: training loss : 0.9906942987442017 TRAIN  loss dict:  {'classification_loss': 0.9906942987442017}
2025-01-12 18:58:46,438 [INFO] Step[450/4329]: training loss : 1.0974074602127075 TRAIN  loss dict:  {'classification_loss': 1.0974074602127075}
2025-01-12 18:58:58,071 [INFO] Step[500/4329]: training loss : 1.0914539420604705 TRAIN  loss dict:  {'classification_loss': 1.0914539420604705}
2025-01-12 18:59:09,708 [INFO] Step[550/4329]: training loss : 1.0043866968154906 TRAIN  loss dict:  {'classification_loss': 1.0043866968154906}
2025-01-12 18:59:21,293 [INFO] Step[600/4329]: training loss : 1.0524342370033264 TRAIN  loss dict:  {'classification_loss': 1.0524342370033264}
2025-01-12 18:59:32,957 [INFO] Step[650/4329]: training loss : 0.9962719118595124 TRAIN  loss dict:  {'classification_loss': 0.9962719118595124}
2025-01-12 18:59:44,619 [INFO] Step[700/4329]: training loss : 1.0401059544086457 TRAIN  loss dict:  {'classification_loss': 1.0401059544086457}
2025-01-12 18:59:56,261 [INFO] Step[750/4329]: training loss : 1.0585007560253143 TRAIN  loss dict:  {'classification_loss': 1.0585007560253143}
2025-01-12 19:00:07,882 [INFO] Step[800/4329]: training loss : 1.0624064409732819 TRAIN  loss dict:  {'classification_loss': 1.0624064409732819}
2025-01-12 19:00:19,475 [INFO] Step[850/4329]: training loss : 0.9915710008144378 TRAIN  loss dict:  {'classification_loss': 0.9915710008144378}
2025-01-12 19:00:31,084 [INFO] Step[900/4329]: training loss : 1.0716385424137116 TRAIN  loss dict:  {'classification_loss': 1.0716385424137116}
2025-01-12 19:00:42,741 [INFO] Step[950/4329]: training loss : 1.0609604334831237 TRAIN  loss dict:  {'classification_loss': 1.0609604334831237}
2025-01-12 19:00:54,407 [INFO] Step[1000/4329]: training loss : 1.0084691059589386 TRAIN  loss dict:  {'classification_loss': 1.0084691059589386}
2025-01-12 19:01:06,059 [INFO] Step[1050/4329]: training loss : 1.0341957223415374 TRAIN  loss dict:  {'classification_loss': 1.0341957223415374}
2025-01-12 19:01:17,675 [INFO] Step[1100/4329]: training loss : 1.0621515488624573 TRAIN  loss dict:  {'classification_loss': 1.0621515488624573}
2025-01-12 19:01:29,302 [INFO] Step[1150/4329]: training loss : 1.0165970063209533 TRAIN  loss dict:  {'classification_loss': 1.0165970063209533}
2025-01-12 19:01:40,967 [INFO] Step[1200/4329]: training loss : 1.0565441739559174 TRAIN  loss dict:  {'classification_loss': 1.0565441739559174}
2025-01-12 19:01:52,571 [INFO] Step[1250/4329]: training loss : 1.0579270434379577 TRAIN  loss dict:  {'classification_loss': 1.0579270434379577}
2025-01-12 19:02:04,184 [INFO] Step[1300/4329]: training loss : 1.0365347695350646 TRAIN  loss dict:  {'classification_loss': 1.0365347695350646}
2025-01-12 19:02:15,825 [INFO] Step[1350/4329]: training loss : 1.0071936988830565 TRAIN  loss dict:  {'classification_loss': 1.0071936988830565}
2025-01-12 19:02:27,427 [INFO] Step[1400/4329]: training loss : 1.031679344177246 TRAIN  loss dict:  {'classification_loss': 1.031679344177246}
2025-01-12 19:02:39,037 [INFO] Step[1450/4329]: training loss : 0.9828667545318603 TRAIN  loss dict:  {'classification_loss': 0.9828667545318603}
2025-01-12 19:02:50,621 [INFO] Step[1500/4329]: training loss : 1.0387233889102936 TRAIN  loss dict:  {'classification_loss': 1.0387233889102936}
2025-01-12 19:03:02,255 [INFO] Step[1550/4329]: training loss : 1.035162353515625 TRAIN  loss dict:  {'classification_loss': 1.035162353515625}
2025-01-12 19:03:13,883 [INFO] Step[1600/4329]: training loss : 1.039802566766739 TRAIN  loss dict:  {'classification_loss': 1.039802566766739}
2025-01-12 19:03:25,510 [INFO] Step[1650/4329]: training loss : 1.0886711871623993 TRAIN  loss dict:  {'classification_loss': 1.0886711871623993}
2025-01-12 19:03:37,161 [INFO] Step[1700/4329]: training loss : 1.0308102226257325 TRAIN  loss dict:  {'classification_loss': 1.0308102226257325}
2025-01-12 19:03:48,798 [INFO] Step[1750/4329]: training loss : 1.027885320186615 TRAIN  loss dict:  {'classification_loss': 1.027885320186615}
2025-01-12 19:04:00,445 [INFO] Step[1800/4329]: training loss : 1.0388902735710144 TRAIN  loss dict:  {'classification_loss': 1.0388902735710144}
2025-01-12 19:04:12,034 [INFO] Step[1850/4329]: training loss : 0.991235054731369 TRAIN  loss dict:  {'classification_loss': 0.991235054731369}
2025-01-12 19:04:23,636 [INFO] Step[1900/4329]: training loss : 1.0271466267108917 TRAIN  loss dict:  {'classification_loss': 1.0271466267108917}
2025-01-12 19:04:35,261 [INFO] Step[1950/4329]: training loss : 1.087977306842804 TRAIN  loss dict:  {'classification_loss': 1.087977306842804}
2025-01-12 19:04:46,858 [INFO] Step[2000/4329]: training loss : 1.0866312456130982 TRAIN  loss dict:  {'classification_loss': 1.0866312456130982}
2025-01-12 19:04:58,479 [INFO] Step[2050/4329]: training loss : 1.0544104743003846 TRAIN  loss dict:  {'classification_loss': 1.0544104743003846}
2025-01-12 19:05:10,165 [INFO] Step[2100/4329]: training loss : 1.0182051575183868 TRAIN  loss dict:  {'classification_loss': 1.0182051575183868}
2025-01-12 19:05:21,737 [INFO] Step[2150/4329]: training loss : 1.0906657326221465 TRAIN  loss dict:  {'classification_loss': 1.0906657326221465}
2025-01-12 19:05:33,370 [INFO] Step[2200/4329]: training loss : 1.0442397594451904 TRAIN  loss dict:  {'classification_loss': 1.0442397594451904}
2025-01-12 19:05:44,988 [INFO] Step[2250/4329]: training loss : 1.05335404753685 TRAIN  loss dict:  {'classification_loss': 1.05335404753685}
2025-01-12 19:05:56,608 [INFO] Step[2300/4329]: training loss : 1.0793240761756897 TRAIN  loss dict:  {'classification_loss': 1.0793240761756897}
2025-01-12 19:06:08,214 [INFO] Step[2350/4329]: training loss : 1.006535634994507 TRAIN  loss dict:  {'classification_loss': 1.006535634994507}
2025-01-12 19:06:19,807 [INFO] Step[2400/4329]: training loss : 1.0534225499629974 TRAIN  loss dict:  {'classification_loss': 1.0534225499629974}
2025-01-12 19:06:31,431 [INFO] Step[2450/4329]: training loss : 1.0337268924713134 TRAIN  loss dict:  {'classification_loss': 1.0337268924713134}
2025-01-12 19:06:43,395 [INFO] Step[2500/4329]: training loss : 1.040156546831131 TRAIN  loss dict:  {'classification_loss': 1.040156546831131}
2025-01-12 19:06:55,676 [INFO] Step[2550/4329]: training loss : 1.059995195865631 TRAIN  loss dict:  {'classification_loss': 1.059995195865631}
2025-01-12 19:07:08,014 [INFO] Step[2600/4329]: training loss : 1.0484410583972932 TRAIN  loss dict:  {'classification_loss': 1.0484410583972932}
2025-01-12 19:07:21,533 [INFO] Step[2650/4329]: training loss : 1.148799765110016 TRAIN  loss dict:  {'classification_loss': 1.148799765110016}
2025-01-12 19:07:36,037 [INFO] Step[2700/4329]: training loss : 1.010607076883316 TRAIN  loss dict:  {'classification_loss': 1.010607076883316}
2025-01-12 19:07:48,082 [INFO] Step[2750/4329]: training loss : 1.061529358625412 TRAIN  loss dict:  {'classification_loss': 1.061529358625412}
2025-01-12 19:07:59,926 [INFO] Step[2800/4329]: training loss : 1.0792579710483552 TRAIN  loss dict:  {'classification_loss': 1.0792579710483552}
2025-01-12 19:08:11,691 [INFO] Step[2850/4329]: training loss : 1.0427271366119384 TRAIN  loss dict:  {'classification_loss': 1.0427271366119384}
2025-01-12 19:08:23,319 [INFO] Step[2900/4329]: training loss : 1.020493550300598 TRAIN  loss dict:  {'classification_loss': 1.020493550300598}
2025-01-12 19:08:34,940 [INFO] Step[2950/4329]: training loss : 1.0158953714370726 TRAIN  loss dict:  {'classification_loss': 1.0158953714370726}
2025-01-12 19:08:46,511 [INFO] Step[3000/4329]: training loss : 1.054732848405838 TRAIN  loss dict:  {'classification_loss': 1.054732848405838}
2025-01-12 19:08:58,140 [INFO] Step[3050/4329]: training loss : 1.0449285316467285 TRAIN  loss dict:  {'classification_loss': 1.0449285316467285}
2025-01-12 19:09:09,759 [INFO] Step[3100/4329]: training loss : 1.009599198102951 TRAIN  loss dict:  {'classification_loss': 1.009599198102951}
2025-01-12 19:09:21,399 [INFO] Step[3150/4329]: training loss : 1.0423088383674621 TRAIN  loss dict:  {'classification_loss': 1.0423088383674621}
2025-01-12 19:09:33,050 [INFO] Step[3200/4329]: training loss : 1.011144460439682 TRAIN  loss dict:  {'classification_loss': 1.011144460439682}
2025-01-12 19:09:44,641 [INFO] Step[3250/4329]: training loss : 1.02510999917984 TRAIN  loss dict:  {'classification_loss': 1.02510999917984}
2025-01-12 19:09:56,259 [INFO] Step[3300/4329]: training loss : 1.0335963654518128 TRAIN  loss dict:  {'classification_loss': 1.0335963654518128}
2025-01-12 19:10:07,889 [INFO] Step[3350/4329]: training loss : 1.048221331834793 TRAIN  loss dict:  {'classification_loss': 1.048221331834793}
2025-01-12 19:10:19,490 [INFO] Step[3400/4329]: training loss : 0.987816596031189 TRAIN  loss dict:  {'classification_loss': 0.987816596031189}
2025-01-12 19:10:31,078 [INFO] Step[3450/4329]: training loss : 1.1147680401802063 TRAIN  loss dict:  {'classification_loss': 1.1147680401802063}
2025-01-12 19:10:42,709 [INFO] Step[3500/4329]: training loss : 1.033110350370407 TRAIN  loss dict:  {'classification_loss': 1.033110350370407}
2025-01-12 19:10:54,351 [INFO] Step[3550/4329]: training loss : 0.9933492565155029 TRAIN  loss dict:  {'classification_loss': 0.9933492565155029}
2025-01-12 19:11:05,947 [INFO] Step[3600/4329]: training loss : 1.081850528717041 TRAIN  loss dict:  {'classification_loss': 1.081850528717041}
2025-01-12 19:11:17,547 [INFO] Step[3650/4329]: training loss : 1.1425331962108611 TRAIN  loss dict:  {'classification_loss': 1.1425331962108611}
2025-01-12 19:11:29,192 [INFO] Step[3700/4329]: training loss : 1.036341953277588 TRAIN  loss dict:  {'classification_loss': 1.036341953277588}
2025-01-12 19:11:40,814 [INFO] Step[3750/4329]: training loss : 1.0818034744262695 TRAIN  loss dict:  {'classification_loss': 1.0818034744262695}
2025-01-12 19:11:52,424 [INFO] Step[3800/4329]: training loss : 1.067588678598404 TRAIN  loss dict:  {'classification_loss': 1.067588678598404}
2025-01-12 19:12:04,090 [INFO] Step[3850/4329]: training loss : 1.0490068972110749 TRAIN  loss dict:  {'classification_loss': 1.0490068972110749}
2025-01-12 19:12:15,697 [INFO] Step[3900/4329]: training loss : 1.0992371201515199 TRAIN  loss dict:  {'classification_loss': 1.0992371201515199}
2025-01-12 19:12:27,337 [INFO] Step[3950/4329]: training loss : 1.0849511325359344 TRAIN  loss dict:  {'classification_loss': 1.0849511325359344}
2025-01-12 19:12:38,935 [INFO] Step[4000/4329]: training loss : 1.0366422867774963 TRAIN  loss dict:  {'classification_loss': 1.0366422867774963}
2025-01-12 19:12:50,579 [INFO] Step[4050/4329]: training loss : 1.0522564589977264 TRAIN  loss dict:  {'classification_loss': 1.0522564589977264}
2025-01-12 19:13:02,206 [INFO] Step[4100/4329]: training loss : 1.0290848445892333 TRAIN  loss dict:  {'classification_loss': 1.0290848445892333}
2025-01-12 19:13:13,840 [INFO] Step[4150/4329]: training loss : 1.0152140283584594 TRAIN  loss dict:  {'classification_loss': 1.0152140283584594}
2025-01-12 19:13:25,445 [INFO] Step[4200/4329]: training loss : 1.0147721314430236 TRAIN  loss dict:  {'classification_loss': 1.0147721314430236}
2025-01-12 19:13:37,115 [INFO] Step[4250/4329]: training loss : 1.0343052327632904 TRAIN  loss dict:  {'classification_loss': 1.0343052327632904}
2025-01-12 19:13:48,722 [INFO] Step[4300/4329]: training loss : 1.0779001128673553 TRAIN  loss dict:  {'classification_loss': 1.0779001128673553}
2025-01-12 19:15:49,036 [INFO] Label accuracies statistics:
2025-01-12 19:15:49,036 [INFO] {0: 0.5555555555555556, 1: 0.8888888888888888, 2: 0.5833333333333334, 3: 0.8333333333333334, 4: 0.3333333333333333, 5: 0.75, 6: 0.75, 7: 0.4166666666666667, 8: 0.5, 9: 0.75, 10: 0.9166666666666666, 11: 0.9166666666666666, 12: 0.5, 13: 0.4166666666666667, 14: 0.5833333333333334, 15: 0.6666666666666666, 16: 0.5, 17: 0.4166666666666667, 18: 0.5833333333333334, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.5833333333333334, 23: 0.8333333333333334, 24: 1.0, 25: 0.75, 26: 0.9166666666666666, 27: 0.6666666666666666, 28: 0.8333333333333334, 29: 1.0, 30: 0.75, 31: 0.6666666666666666, 32: 0.75, 33: 0.8333333333333334, 34: 0.75, 35: 0.6666666666666666, 36: 0.6666666666666666, 37: 1.0, 38: 0.75, 39: 0.9166666666666666, 40: 0.9166666666666666, 41: 0.5, 42: 0.75, 43: 1.0, 44: 0.5, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 0.8333333333333334, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.5833333333333334, 54: 0.4166666666666667, 55: 0.5833333333333334, 56: 0.8333333333333334, 57: 0.75, 58: 0.5, 59: 0.9166666666666666, 60: 0.5, 61: 0.9166666666666666, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.5833333333333334, 67: 0.75, 68: 0.5833333333333334, 69: 0.6666666666666666, 70: 0.16666666666666666, 71: 0.4166666666666667, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 0.9166666666666666, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.8333333333333334, 83: 0.3333333333333333, 84: 0.5, 85: 0.6666666666666666, 86: 0.5, 87: 0.9166666666666666, 88: 0.75, 89: 0.6666666666666666, 90: 0.5833333333333334, 91: 0.9166666666666666, 92: 1.0, 93: 1.0, 94: 0.5, 95: 0.75, 96: 0.5, 97: 0.5833333333333334, 98: 0.8333333333333334, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.6666666666666666, 113: 0.4166666666666667, 114: 0.5833333333333334, 115: 0.75, 116: 0.5833333333333334, 117: 0.8333333333333334, 118: 0.8333333333333334, 119: 0.8333333333333334, 120: 0.8333333333333334, 121: 0.75, 122: 0.75, 123: 0.75, 124: 0.9166666666666666, 125: 1.0, 126: 0.8333333333333334, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.8333333333333334, 132: 0.75, 133: 1.0, 134: 0.9166666666666666, 135: 0.8333333333333334, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.8333333333333334, 140: 0.6666666666666666, 141: 1.0, 142: 0.6666666666666666, 143: 0.9166666666666666, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 0.9166666666666666, 147: 0.9166666666666666, 148: 1.0, 149: 0.9166666666666666, 150: 0.4166666666666667, 151: 0.9166666666666666, 152: 0.75, 153: 0.8333333333333334, 154: 1.0, 155: 0.8333333333333334, 156: 0.8333333333333334, 157: 0.6666666666666666, 158: 0.5555555555555556, 159: 1.0, 160: 0.4166666666666667, 161: 0.8333333333333334, 162: 0.9166666666666666, 163: 0.8333333333333334, 164: 0.8333333333333334, 165: 0.8333333333333334, 166: 0.5, 167: 0.75, 168: 0.9166666666666666, 169: 0.9166666666666666, 170: 0.8333333333333334, 171: 0.4166666666666667, 172: 1.0, 173: 0.6666666666666666, 174: 0.75, 175: 0.8333333333333334, 176: 0.9166666666666666, 177: 0.9166666666666666, 178: 0.9166666666666666, 179: 0.2222222222222222, 180: 0.75, 181: 0.8333333333333334, 182: 0.4166666666666667, 183: 0.6666666666666666, 184: 0.75, 185: 1.0, 186: 0.5833333333333334, 187: 0.9166666666666666, 188: 0.5833333333333334, 189: 1.0, 190: 0.6666666666666666, 191: 0.5, 192: 1.0, 193: 0.9166666666666666, 194: 0.8333333333333334, 195: 0.8333333333333334, 196: 0.8333333333333334, 197: 0.75, 198: 0.6666666666666666}

2025-01-12 19:15:49,039 [INFO] [14] TRAIN  loss: 1.043515661829034 acc: 0.9633451409209919
2025-01-12 19:15:49,039 [INFO] [14] TRAIN  loss dict: {'classification_loss': 1.043515661829034}
2025-01-12 19:15:49,039 [INFO] [14] VALIDATION loss: 1.7462099196784424 VALIDATION acc: 0.7647306397306397
2025-01-12 19:15:49,039 [INFO] [14] VALIDATION loss dict: {'classification_loss': 1.7462099196784424}
2025-01-12 19:15:49,039 [INFO] 
2025-01-12 19:16:05,807 [INFO] Step[50/4329]: training loss : 0.9663087546825408 TRAIN  loss dict:  {'classification_loss': 0.9663087546825408}
2025-01-12 19:16:17,403 [INFO] Step[100/4329]: training loss : 1.0145734584331512 TRAIN  loss dict:  {'classification_loss': 1.0145734584331512}
2025-01-12 19:16:28,971 [INFO] Step[150/4329]: training loss : 1.0658653485774994 TRAIN  loss dict:  {'classification_loss': 1.0658653485774994}
2025-01-12 19:16:40,577 [INFO] Step[200/4329]: training loss : 1.0232057678699493 TRAIN  loss dict:  {'classification_loss': 1.0232057678699493}
2025-01-12 19:16:52,227 [INFO] Step[250/4329]: training loss : 0.9788494718074798 TRAIN  loss dict:  {'classification_loss': 0.9788494718074798}
2025-01-12 19:17:03,868 [INFO] Step[300/4329]: training loss : 1.0092119669914246 TRAIN  loss dict:  {'classification_loss': 1.0092119669914246}
2025-01-12 19:17:15,523 [INFO] Step[350/4329]: training loss : 0.9729004156589508 TRAIN  loss dict:  {'classification_loss': 0.9729004156589508}
2025-01-12 19:17:27,122 [INFO] Step[400/4329]: training loss : 0.9766086614131928 TRAIN  loss dict:  {'classification_loss': 0.9766086614131928}
2025-01-12 19:17:38,741 [INFO] Step[450/4329]: training loss : 1.0456607699394227 TRAIN  loss dict:  {'classification_loss': 1.0456607699394227}
2025-01-12 19:17:50,376 [INFO] Step[500/4329]: training loss : 1.0269662141799927 TRAIN  loss dict:  {'classification_loss': 1.0269662141799927}
2025-01-12 19:18:02,018 [INFO] Step[550/4329]: training loss : 0.9753717494010925 TRAIN  loss dict:  {'classification_loss': 0.9753717494010925}
2025-01-12 19:18:13,628 [INFO] Step[600/4329]: training loss : 1.0481056666374207 TRAIN  loss dict:  {'classification_loss': 1.0481056666374207}
2025-01-12 19:18:25,224 [INFO] Step[650/4329]: training loss : 1.062415999174118 TRAIN  loss dict:  {'classification_loss': 1.062415999174118}
2025-01-12 19:18:36,889 [INFO] Step[700/4329]: training loss : 1.0115522682666778 TRAIN  loss dict:  {'classification_loss': 1.0115522682666778}
2025-01-12 19:18:48,509 [INFO] Step[750/4329]: training loss : 1.0489944803714752 TRAIN  loss dict:  {'classification_loss': 1.0489944803714752}
2025-01-12 19:19:00,264 [INFO] Step[800/4329]: training loss : 1.0237191033363342 TRAIN  loss dict:  {'classification_loss': 1.0237191033363342}
2025-01-12 19:19:12,585 [INFO] Step[850/4329]: training loss : 1.0080260026454926 TRAIN  loss dict:  {'classification_loss': 1.0080260026454926}
2025-01-12 19:19:24,788 [INFO] Step[900/4329]: training loss : 1.0116321957111358 TRAIN  loss dict:  {'classification_loss': 1.0116321957111358}
2025-01-12 19:19:37,530 [INFO] Step[950/4329]: training loss : 1.0110532236099243 TRAIN  loss dict:  {'classification_loss': 1.0110532236099243}
2025-01-12 19:19:50,904 [INFO] Step[1000/4329]: training loss : 1.0045840382575988 TRAIN  loss dict:  {'classification_loss': 1.0045840382575988}
2025-01-12 19:20:03,603 [INFO] Step[1050/4329]: training loss : 1.0096428668498993 TRAIN  loss dict:  {'classification_loss': 1.0096428668498993}
2025-01-12 19:20:15,543 [INFO] Step[1100/4329]: training loss : 0.9960238182544708 TRAIN  loss dict:  {'classification_loss': 0.9960238182544708}
2025-01-12 19:20:27,479 [INFO] Step[1150/4329]: training loss : 1.019866464138031 TRAIN  loss dict:  {'classification_loss': 1.019866464138031}
2025-01-12 19:20:39,108 [INFO] Step[1200/4329]: training loss : 1.0034541189670563 TRAIN  loss dict:  {'classification_loss': 1.0034541189670563}
2025-01-12 19:20:50,743 [INFO] Step[1250/4329]: training loss : 1.0205496990680694 TRAIN  loss dict:  {'classification_loss': 1.0205496990680694}
2025-01-12 19:21:02,347 [INFO] Step[1300/4329]: training loss : 1.0593473064899444 TRAIN  loss dict:  {'classification_loss': 1.0593473064899444}
2025-01-12 19:21:14,026 [INFO] Step[1350/4329]: training loss : 1.0772010946273805 TRAIN  loss dict:  {'classification_loss': 1.0772010946273805}
2025-01-12 19:21:25,673 [INFO] Step[1400/4329]: training loss : 1.0738627576828004 TRAIN  loss dict:  {'classification_loss': 1.0738627576828004}
2025-01-12 19:21:37,263 [INFO] Step[1450/4329]: training loss : 0.9955245399475098 TRAIN  loss dict:  {'classification_loss': 0.9955245399475098}
2025-01-12 19:21:48,876 [INFO] Step[1500/4329]: training loss : 1.0405018198490144 TRAIN  loss dict:  {'classification_loss': 1.0405018198490144}
2025-01-12 19:22:00,529 [INFO] Step[1550/4329]: training loss : 1.022489367723465 TRAIN  loss dict:  {'classification_loss': 1.022489367723465}
2025-01-12 19:22:12,123 [INFO] Step[1600/4329]: training loss : 1.0192197799682616 TRAIN  loss dict:  {'classification_loss': 1.0192197799682616}
2025-01-12 19:22:23,727 [INFO] Step[1650/4329]: training loss : 1.074870456457138 TRAIN  loss dict:  {'classification_loss': 1.074870456457138}
2025-01-12 19:22:35,325 [INFO] Step[1700/4329]: training loss : 1.0468107438087464 TRAIN  loss dict:  {'classification_loss': 1.0468107438087464}
2025-01-12 19:22:46,909 [INFO] Step[1750/4329]: training loss : 1.0100397503376006 TRAIN  loss dict:  {'classification_loss': 1.0100397503376006}
2025-01-12 19:22:58,500 [INFO] Step[1800/4329]: training loss : 1.0566998374462129 TRAIN  loss dict:  {'classification_loss': 1.0566998374462129}
2025-01-12 19:23:10,137 [INFO] Step[1850/4329]: training loss : 1.019924350976944 TRAIN  loss dict:  {'classification_loss': 1.019924350976944}
2025-01-12 19:23:21,719 [INFO] Step[1900/4329]: training loss : 1.0201801097393035 TRAIN  loss dict:  {'classification_loss': 1.0201801097393035}
2025-01-12 19:23:33,337 [INFO] Step[1950/4329]: training loss : 0.9524323463439941 TRAIN  loss dict:  {'classification_loss': 0.9524323463439941}
2025-01-12 19:23:44,969 [INFO] Step[2000/4329]: training loss : 1.0178031027317047 TRAIN  loss dict:  {'classification_loss': 1.0178031027317047}
2025-01-12 19:23:56,590 [INFO] Step[2050/4329]: training loss : 1.0364710700511932 TRAIN  loss dict:  {'classification_loss': 1.0364710700511932}
2025-01-12 19:24:08,210 [INFO] Step[2100/4329]: training loss : 1.0179571533203124 TRAIN  loss dict:  {'classification_loss': 1.0179571533203124}
2025-01-12 19:24:19,852 [INFO] Step[2150/4329]: training loss : 1.0285331523418426 TRAIN  loss dict:  {'classification_loss': 1.0285331523418426}
2025-01-12 19:24:31,499 [INFO] Step[2200/4329]: training loss : 1.1251675629615783 TRAIN  loss dict:  {'classification_loss': 1.1251675629615783}
2025-01-12 19:24:43,114 [INFO] Step[2250/4329]: training loss : 1.0067687153816223 TRAIN  loss dict:  {'classification_loss': 1.0067687153816223}
2025-01-12 19:24:54,747 [INFO] Step[2300/4329]: training loss : 1.001182050704956 TRAIN  loss dict:  {'classification_loss': 1.001182050704956}
2025-01-12 19:25:06,350 [INFO] Step[2350/4329]: training loss : 1.0045488333702088 TRAIN  loss dict:  {'classification_loss': 1.0045488333702088}
2025-01-12 19:25:17,965 [INFO] Step[2400/4329]: training loss : 0.9918278288841248 TRAIN  loss dict:  {'classification_loss': 0.9918278288841248}
2025-01-12 19:25:29,542 [INFO] Step[2450/4329]: training loss : 1.0836497092247008 TRAIN  loss dict:  {'classification_loss': 1.0836497092247008}
2025-01-12 19:25:41,118 [INFO] Step[2500/4329]: training loss : 0.9734508407115936 TRAIN  loss dict:  {'classification_loss': 0.9734508407115936}
2025-01-12 19:25:52,745 [INFO] Step[2550/4329]: training loss : 1.0253806948661803 TRAIN  loss dict:  {'classification_loss': 1.0253806948661803}
2025-01-12 19:26:04,357 [INFO] Step[2600/4329]: training loss : 1.0194043982028962 TRAIN  loss dict:  {'classification_loss': 1.0194043982028962}
2025-01-12 19:26:15,969 [INFO] Step[2650/4329]: training loss : 1.100433589220047 TRAIN  loss dict:  {'classification_loss': 1.100433589220047}
2025-01-12 19:26:27,621 [INFO] Step[2700/4329]: training loss : 1.0029063999652863 TRAIN  loss dict:  {'classification_loss': 1.0029063999652863}
2025-01-12 19:26:39,250 [INFO] Step[2750/4329]: training loss : 0.9968762683868408 TRAIN  loss dict:  {'classification_loss': 0.9968762683868408}
2025-01-12 19:26:50,881 [INFO] Step[2800/4329]: training loss : 1.0809787499904633 TRAIN  loss dict:  {'classification_loss': 1.0809787499904633}
2025-01-12 19:27:02,494 [INFO] Step[2850/4329]: training loss : 1.0066278338432313 TRAIN  loss dict:  {'classification_loss': 1.0066278338432313}
2025-01-12 19:27:14,100 [INFO] Step[2900/4329]: training loss : 1.039671220779419 TRAIN  loss dict:  {'classification_loss': 1.039671220779419}
2025-01-12 19:27:25,678 [INFO] Step[2950/4329]: training loss : 1.0246140396595 TRAIN  loss dict:  {'classification_loss': 1.0246140396595}
2025-01-12 19:27:37,275 [INFO] Step[3000/4329]: training loss : 1.072863336801529 TRAIN  loss dict:  {'classification_loss': 1.072863336801529}
2025-01-12 19:27:48,915 [INFO] Step[3050/4329]: training loss : 1.0352744090557098 TRAIN  loss dict:  {'classification_loss': 1.0352744090557098}
2025-01-12 19:28:00,549 [INFO] Step[3100/4329]: training loss : 0.9973883187770843 TRAIN  loss dict:  {'classification_loss': 0.9973883187770843}
2025-01-12 19:28:12,162 [INFO] Step[3150/4329]: training loss : 0.9910724556446076 TRAIN  loss dict:  {'classification_loss': 0.9910724556446076}
2025-01-12 19:28:23,757 [INFO] Step[3200/4329]: training loss : 1.0307770490646362 TRAIN  loss dict:  {'classification_loss': 1.0307770490646362}
2025-01-12 19:28:35,355 [INFO] Step[3250/4329]: training loss : 1.0712773025035858 TRAIN  loss dict:  {'classification_loss': 1.0712773025035858}
2025-01-12 19:28:46,954 [INFO] Step[3300/4329]: training loss : 1.0459635770320892 TRAIN  loss dict:  {'classification_loss': 1.0459635770320892}
2025-01-12 19:28:58,581 [INFO] Step[3350/4329]: training loss : 1.0395322680473327 TRAIN  loss dict:  {'classification_loss': 1.0395322680473327}
2025-01-12 19:29:10,240 [INFO] Step[3400/4329]: training loss : 1.0349270391464234 TRAIN  loss dict:  {'classification_loss': 1.0349270391464234}
2025-01-12 19:29:21,891 [INFO] Step[3450/4329]: training loss : 1.0211976385116577 TRAIN  loss dict:  {'classification_loss': 1.0211976385116577}
2025-01-12 19:29:33,497 [INFO] Step[3500/4329]: training loss : 1.0154023218154906 TRAIN  loss dict:  {'classification_loss': 1.0154023218154906}
2025-01-12 19:29:45,119 [INFO] Step[3550/4329]: training loss : 1.0130646014213562 TRAIN  loss dict:  {'classification_loss': 1.0130646014213562}
2025-01-12 19:29:56,713 [INFO] Step[3600/4329]: training loss : 1.0489024066925048 TRAIN  loss dict:  {'classification_loss': 1.0489024066925048}
2025-01-12 19:30:08,293 [INFO] Step[3650/4329]: training loss : 1.004448162317276 TRAIN  loss dict:  {'classification_loss': 1.004448162317276}
2025-01-12 19:30:19,901 [INFO] Step[3700/4329]: training loss : 1.014837999343872 TRAIN  loss dict:  {'classification_loss': 1.014837999343872}
2025-01-12 19:30:31,517 [INFO] Step[3750/4329]: training loss : 1.0235136139392853 TRAIN  loss dict:  {'classification_loss': 1.0235136139392853}
2025-01-12 19:30:43,157 [INFO] Step[3800/4329]: training loss : 1.0203579998016357 TRAIN  loss dict:  {'classification_loss': 1.0203579998016357}
2025-01-12 19:30:54,865 [INFO] Step[3850/4329]: training loss : 1.059316076040268 TRAIN  loss dict:  {'classification_loss': 1.059316076040268}
2025-01-12 19:31:06,451 [INFO] Step[3900/4329]: training loss : 1.0173365366458893 TRAIN  loss dict:  {'classification_loss': 1.0173365366458893}
2025-01-12 19:31:18,232 [INFO] Step[3950/4329]: training loss : 1.045560871362686 TRAIN  loss dict:  {'classification_loss': 1.045560871362686}
2025-01-12 19:31:30,486 [INFO] Step[4000/4329]: training loss : 1.0402221083641052 TRAIN  loss dict:  {'classification_loss': 1.0402221083641052}
2025-01-12 19:31:42,647 [INFO] Step[4050/4329]: training loss : 1.043406423330307 TRAIN  loss dict:  {'classification_loss': 1.043406423330307}
2025-01-12 19:31:55,633 [INFO] Step[4100/4329]: training loss : 1.0568254482746124 TRAIN  loss dict:  {'classification_loss': 1.0568254482746124}
2025-01-12 19:32:09,978 [INFO] Step[4150/4329]: training loss : 0.9948284482955932 TRAIN  loss dict:  {'classification_loss': 0.9948284482955932}
2025-01-12 19:32:22,433 [INFO] Step[4200/4329]: training loss : 1.028051689863205 TRAIN  loss dict:  {'classification_loss': 1.028051689863205}
2025-01-12 19:32:34,316 [INFO] Step[4250/4329]: training loss : 1.0269175386428833 TRAIN  loss dict:  {'classification_loss': 1.0269175386428833}
2025-01-12 19:32:46,225 [INFO] Step[4300/4329]: training loss : 1.0046203529834747 TRAIN  loss dict:  {'classification_loss': 1.0046203529834747}
2025-01-12 19:34:45,684 [INFO] Label accuracies statistics:
2025-01-12 19:34:45,684 [INFO] {0: 0.7777777777777778, 1: 0.7777777777777778, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.3333333333333333, 5: 0.6666666666666666, 6: 0.5, 7: 0.5, 8: 0.4166666666666667, 9: 0.8333333333333334, 10: 1.0, 11: 1.0, 12: 0.5833333333333334, 13: 0.3333333333333333, 14: 0.5, 15: 0.5555555555555556, 16: 0.3333333333333333, 17: 0.6666666666666666, 18: 0.5833333333333334, 19: 0.6666666666666666, 20: 0.75, 21: 0.6666666666666666, 22: 0.5833333333333334, 23: 1.0, 24: 0.9166666666666666, 25: 0.9166666666666666, 26: 0.6666666666666666, 27: 0.5833333333333334, 28: 0.8333333333333334, 29: 1.0, 30: 0.6666666666666666, 31: 0.8333333333333334, 32: 0.5833333333333334, 33: 0.8333333333333334, 34: 0.75, 35: 0.8333333333333334, 36: 0.75, 37: 0.8333333333333334, 38: 0.8333333333333334, 39: 1.0, 40: 0.9166666666666666, 41: 0.5, 42: 0.8333333333333334, 43: 0.8333333333333334, 44: 0.5833333333333334, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.4166666666666667, 54: 0.5, 55: 0.5833333333333334, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.6666666666666666, 59: 0.8333333333333334, 60: 0.6666666666666666, 61: 0.9166666666666666, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.8333333333333334, 68: 0.9166666666666666, 69: 0.5833333333333334, 70: 0.5, 71: 0.3333333333333333, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.5833333333333334, 75: 1.0, 76: 0.5833333333333334, 77: 0.5833333333333334, 78: 1.0, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.6666666666666666, 83: 0.5, 84: 0.4166666666666667, 85: 0.5, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.5833333333333334, 89: 0.5, 90: 0.6666666666666666, 91: 0.9166666666666666, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 0.75, 96: 0.3333333333333333, 97: 0.6666666666666666, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.75, 102: 1.0, 103: 0.75, 104: 0.9166666666666666, 105: 1.0, 106: 0.9166666666666666, 107: 0.5, 108: 0.9166666666666666, 109: 0.4166666666666667, 110: 0.8333333333333334, 111: 1.0, 112: 0.8333333333333334, 113: 0.4166666666666667, 114: 0.5833333333333334, 115: 1.0, 116: 0.8333333333333334, 117: 0.5833333333333334, 118: 0.9166666666666666, 119: 0.75, 120: 0.75, 121: 0.75, 122: 0.9166666666666666, 123: 1.0, 124: 0.9166666666666666, 125: 0.9166666666666666, 126: 0.75, 127: 0.9166666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.6666666666666666, 131: 0.8333333333333334, 132: 0.3333333333333333, 133: 1.0, 134: 0.5, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.75, 138: 0.8333333333333334, 139: 0.75, 140: 0.8333333333333334, 141: 0.8333333333333334, 142: 0.8333333333333334, 143: 1.0, 144: 0.9166666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.6666666666666666, 149: 1.0, 150: 0.3333333333333333, 151: 0.8333333333333334, 152: 0.8333333333333334, 153: 1.0, 154: 1.0, 155: 0.8333333333333334, 156: 0.75, 157: 0.9166666666666666, 158: 0.6666666666666666, 159: 0.9166666666666666, 160: 0.08333333333333333, 161: 0.5833333333333334, 162: 0.6666666666666666, 163: 1.0, 164: 0.75, 165: 0.9166666666666666, 166: 0.6666666666666666, 167: 0.75, 168: 0.6666666666666666, 169: 0.8333333333333334, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.9166666666666666, 174: 0.8333333333333334, 175: 0.8333333333333334, 176: 0.8333333333333334, 177: 0.8333333333333334, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.4166666666666667, 183: 0.6666666666666666, 184: 0.6666666666666666, 185: 0.9166666666666666, 186: 0.8333333333333334, 187: 0.9166666666666666, 188: 0.6666666666666666, 189: 0.9166666666666666, 190: 0.6666666666666666, 191: 0.6666666666666666, 192: 0.9166666666666666, 193: 0.8333333333333334, 194: 0.9166666666666666, 195: 0.8333333333333334, 196: 0.75, 197: 0.5833333333333334, 198: 0.8333333333333334}

2025-01-12 19:34:45,687 [INFO] [15] TRAIN  loss: 1.0260580650348536 acc: 0.9696596334514093
2025-01-12 19:34:45,687 [INFO] [15] TRAIN  loss dict: {'classification_loss': 1.0260580650348536}
2025-01-12 19:34:45,687 [INFO] [15] VALIDATION loss: 1.7954540482223635 VALIDATION acc: 0.7605218855218855
2025-01-12 19:34:45,687 [INFO] [15] VALIDATION loss dict: {'classification_loss': 1.7954540482223635}
2025-01-12 19:34:45,687 [INFO] 
2025-01-12 19:35:02,677 [INFO] Step[50/4329]: training loss : 1.0653222393989563 TRAIN  loss dict:  {'classification_loss': 1.0653222393989563}
2025-01-12 19:35:14,246 [INFO] Step[100/4329]: training loss : 0.972669917345047 TRAIN  loss dict:  {'classification_loss': 0.972669917345047}
2025-01-12 19:35:25,842 [INFO] Step[150/4329]: training loss : 1.0295035552978515 TRAIN  loss dict:  {'classification_loss': 1.0295035552978515}
2025-01-12 19:35:37,447 [INFO] Step[200/4329]: training loss : 1.0159125876426698 TRAIN  loss dict:  {'classification_loss': 1.0159125876426698}
2025-01-12 19:35:49,043 [INFO] Step[250/4329]: training loss : 1.00977632522583 TRAIN  loss dict:  {'classification_loss': 1.00977632522583}
2025-01-12 19:36:00,676 [INFO] Step[300/4329]: training loss : 1.0078999412059784 TRAIN  loss dict:  {'classification_loss': 1.0078999412059784}
2025-01-12 19:36:12,365 [INFO] Step[350/4329]: training loss : 1.034654711484909 TRAIN  loss dict:  {'classification_loss': 1.034654711484909}
2025-01-12 19:36:23,978 [INFO] Step[400/4329]: training loss : 1.0303699707984924 TRAIN  loss dict:  {'classification_loss': 1.0303699707984924}
2025-01-12 19:36:35,612 [INFO] Step[450/4329]: training loss : 0.9957795929908753 TRAIN  loss dict:  {'classification_loss': 0.9957795929908753}
2025-01-12 19:36:47,283 [INFO] Step[500/4329]: training loss : 1.0190880024433135 TRAIN  loss dict:  {'classification_loss': 1.0190880024433135}
2025-01-12 19:36:58,895 [INFO] Step[550/4329]: training loss : 1.0137321090698241 TRAIN  loss dict:  {'classification_loss': 1.0137321090698241}
2025-01-12 19:37:10,506 [INFO] Step[600/4329]: training loss : 0.9802208435535431 TRAIN  loss dict:  {'classification_loss': 0.9802208435535431}
2025-01-12 19:37:22,190 [INFO] Step[650/4329]: training loss : 0.9688517987728119 TRAIN  loss dict:  {'classification_loss': 0.9688517987728119}
2025-01-12 19:37:33,805 [INFO] Step[700/4329]: training loss : 0.9897403144836425 TRAIN  loss dict:  {'classification_loss': 0.9897403144836425}
2025-01-12 19:37:45,481 [INFO] Step[750/4329]: training loss : 1.0054706263542175 TRAIN  loss dict:  {'classification_loss': 1.0054706263542175}
2025-01-12 19:37:57,104 [INFO] Step[800/4329]: training loss : 0.9998417985439301 TRAIN  loss dict:  {'classification_loss': 0.9998417985439301}
2025-01-12 19:38:08,731 [INFO] Step[850/4329]: training loss : 1.0126696085929872 TRAIN  loss dict:  {'classification_loss': 1.0126696085929872}
2025-01-12 19:38:20,358 [INFO] Step[900/4329]: training loss : 1.0131279528141022 TRAIN  loss dict:  {'classification_loss': 1.0131279528141022}
2025-01-12 19:38:32,004 [INFO] Step[950/4329]: training loss : 1.0154430627822877 TRAIN  loss dict:  {'classification_loss': 1.0154430627822877}
2025-01-12 19:38:43,647 [INFO] Step[1000/4329]: training loss : 1.0469279861450196 TRAIN  loss dict:  {'classification_loss': 1.0469279861450196}
2025-01-12 19:38:55,252 [INFO] Step[1050/4329]: training loss : 1.0022215092182158 TRAIN  loss dict:  {'classification_loss': 1.0022215092182158}
2025-01-12 19:39:06,889 [INFO] Step[1100/4329]: training loss : 1.0950424456596375 TRAIN  loss dict:  {'classification_loss': 1.0950424456596375}
2025-01-12 19:39:18,511 [INFO] Step[1150/4329]: training loss : 0.9949000287055969 TRAIN  loss dict:  {'classification_loss': 0.9949000287055969}
2025-01-12 19:39:30,119 [INFO] Step[1200/4329]: training loss : 1.0431427681446075 TRAIN  loss dict:  {'classification_loss': 1.0431427681446075}
2025-01-12 19:39:41,745 [INFO] Step[1250/4329]: training loss : 1.1076573193073274 TRAIN  loss dict:  {'classification_loss': 1.1076573193073274}
2025-01-12 19:39:53,404 [INFO] Step[1300/4329]: training loss : 1.0260956633090972 TRAIN  loss dict:  {'classification_loss': 1.0260956633090972}
2025-01-12 19:40:05,014 [INFO] Step[1350/4329]: training loss : 1.0045425593852997 TRAIN  loss dict:  {'classification_loss': 1.0045425593852997}
2025-01-12 19:40:16,659 [INFO] Step[1400/4329]: training loss : 1.0326729679107667 TRAIN  loss dict:  {'classification_loss': 1.0326729679107667}
2025-01-12 19:40:28,236 [INFO] Step[1450/4329]: training loss : 1.0417754924297333 TRAIN  loss dict:  {'classification_loss': 1.0417754924297333}
2025-01-12 19:40:39,832 [INFO] Step[1500/4329]: training loss : 1.010124534368515 TRAIN  loss dict:  {'classification_loss': 1.010124534368515}
2025-01-12 19:40:51,427 [INFO] Step[1550/4329]: training loss : 1.0181773948669433 TRAIN  loss dict:  {'classification_loss': 1.0181773948669433}
2025-01-12 19:41:03,011 [INFO] Step[1600/4329]: training loss : 1.0082964181900025 TRAIN  loss dict:  {'classification_loss': 1.0082964181900025}
2025-01-12 19:41:14,605 [INFO] Step[1650/4329]: training loss : 0.9878460347652436 TRAIN  loss dict:  {'classification_loss': 0.9878460347652436}
2025-01-12 19:41:26,270 [INFO] Step[1700/4329]: training loss : 1.0165422320365907 TRAIN  loss dict:  {'classification_loss': 1.0165422320365907}
2025-01-12 19:41:37,885 [INFO] Step[1750/4329]: training loss : 1.0108896911144256 TRAIN  loss dict:  {'classification_loss': 1.0108896911144256}
2025-01-12 19:41:49,467 [INFO] Step[1800/4329]: training loss : 0.9943282842636109 TRAIN  loss dict:  {'classification_loss': 0.9943282842636109}
2025-01-12 19:42:01,081 [INFO] Step[1850/4329]: training loss : 1.0348925483226776 TRAIN  loss dict:  {'classification_loss': 1.0348925483226776}
2025-01-12 19:42:12,711 [INFO] Step[1900/4329]: training loss : 1.0334539544582366 TRAIN  loss dict:  {'classification_loss': 1.0334539544582366}
2025-01-12 19:42:24,344 [INFO] Step[1950/4329]: training loss : 1.0300029146671295 TRAIN  loss dict:  {'classification_loss': 1.0300029146671295}
2025-01-12 19:42:35,982 [INFO] Step[2000/4329]: training loss : 1.0243390810489654 TRAIN  loss dict:  {'classification_loss': 1.0243390810489654}
2025-01-12 19:42:47,637 [INFO] Step[2050/4329]: training loss : 1.0296471107006073 TRAIN  loss dict:  {'classification_loss': 1.0296471107006073}
2025-01-12 19:42:59,227 [INFO] Step[2100/4329]: training loss : 1.0411044120788575 TRAIN  loss dict:  {'classification_loss': 1.0411044120788575}
2025-01-12 19:43:10,859 [INFO] Step[2150/4329]: training loss : 1.031758235692978 TRAIN  loss dict:  {'classification_loss': 1.031758235692978}
2025-01-12 19:43:22,467 [INFO] Step[2200/4329]: training loss : 0.9919469487667084 TRAIN  loss dict:  {'classification_loss': 0.9919469487667084}
2025-01-12 19:43:34,083 [INFO] Step[2250/4329]: training loss : 0.9868570709228516 TRAIN  loss dict:  {'classification_loss': 0.9868570709228516}
2025-01-12 19:43:45,908 [INFO] Step[2300/4329]: training loss : 1.0159956955909728 TRAIN  loss dict:  {'classification_loss': 1.0159956955909728}
2025-01-12 19:43:58,336 [INFO] Step[2350/4329]: training loss : 1.0397560036182403 TRAIN  loss dict:  {'classification_loss': 1.0397560036182403}
2025-01-12 19:44:10,574 [INFO] Step[2400/4329]: training loss : 0.9942048573493958 TRAIN  loss dict:  {'classification_loss': 0.9942048573493958}
2025-01-12 19:44:23,912 [INFO] Step[2450/4329]: training loss : 1.0358427631855012 TRAIN  loss dict:  {'classification_loss': 1.0358427631855012}
2025-01-12 19:44:37,309 [INFO] Step[2500/4329]: training loss : 0.9798460960388183 TRAIN  loss dict:  {'classification_loss': 0.9798460960388183}
2025-01-12 19:44:50,507 [INFO] Step[2550/4329]: training loss : 1.037164113521576 TRAIN  loss dict:  {'classification_loss': 1.037164113521576}
2025-01-12 19:45:02,329 [INFO] Step[2600/4329]: training loss : 0.9875607514381408 TRAIN  loss dict:  {'classification_loss': 0.9875607514381408}
2025-01-12 19:45:14,082 [INFO] Step[2650/4329]: training loss : 0.9994586813449859 TRAIN  loss dict:  {'classification_loss': 0.9994586813449859}
2025-01-12 19:45:25,681 [INFO] Step[2700/4329]: training loss : 0.997337920665741 TRAIN  loss dict:  {'classification_loss': 0.997337920665741}
2025-01-12 19:45:37,270 [INFO] Step[2750/4329]: training loss : 0.9988430452346801 TRAIN  loss dict:  {'classification_loss': 0.9988430452346801}
2025-01-12 19:45:48,902 [INFO] Step[2800/4329]: training loss : 1.004426726102829 TRAIN  loss dict:  {'classification_loss': 1.004426726102829}
2025-01-12 19:46:00,554 [INFO] Step[2850/4329]: training loss : 0.9924274206161499 TRAIN  loss dict:  {'classification_loss': 0.9924274206161499}
2025-01-12 19:46:12,151 [INFO] Step[2900/4329]: training loss : 1.034052654504776 TRAIN  loss dict:  {'classification_loss': 1.034052654504776}
2025-01-12 19:46:23,791 [INFO] Step[2950/4329]: training loss : 1.0132058238983155 TRAIN  loss dict:  {'classification_loss': 1.0132058238983155}
2025-01-12 19:46:35,395 [INFO] Step[3000/4329]: training loss : 0.9936783933639526 TRAIN  loss dict:  {'classification_loss': 0.9936783933639526}
2025-01-12 19:46:47,036 [INFO] Step[3050/4329]: training loss : 1.0006347763538361 TRAIN  loss dict:  {'classification_loss': 1.0006347763538361}
2025-01-12 19:46:58,636 [INFO] Step[3100/4329]: training loss : 1.0234653270244598 TRAIN  loss dict:  {'classification_loss': 1.0234653270244598}
2025-01-12 19:47:10,252 [INFO] Step[3150/4329]: training loss : 0.999316372871399 TRAIN  loss dict:  {'classification_loss': 0.999316372871399}
2025-01-12 19:47:21,869 [INFO] Step[3200/4329]: training loss : 1.000416042804718 TRAIN  loss dict:  {'classification_loss': 1.000416042804718}
2025-01-12 19:47:33,499 [INFO] Step[3250/4329]: training loss : 0.9862697768211365 TRAIN  loss dict:  {'classification_loss': 0.9862697768211365}
2025-01-12 19:47:45,122 [INFO] Step[3300/4329]: training loss : 0.9979112255573273 TRAIN  loss dict:  {'classification_loss': 0.9979112255573273}
2025-01-12 19:47:56,764 [INFO] Step[3350/4329]: training loss : 1.0534170973300934 TRAIN  loss dict:  {'classification_loss': 1.0534170973300934}
2025-01-12 19:48:08,372 [INFO] Step[3400/4329]: training loss : 0.9691082954406738 TRAIN  loss dict:  {'classification_loss': 0.9691082954406738}
2025-01-12 19:48:19,988 [INFO] Step[3450/4329]: training loss : 1.0344020104408265 TRAIN  loss dict:  {'classification_loss': 1.0344020104408265}
2025-01-12 19:48:31,584 [INFO] Step[3500/4329]: training loss : 1.0461264860630035 TRAIN  loss dict:  {'classification_loss': 1.0461264860630035}
2025-01-12 19:48:43,183 [INFO] Step[3550/4329]: training loss : 1.0294121086597443 TRAIN  loss dict:  {'classification_loss': 1.0294121086597443}
2025-01-12 19:48:54,808 [INFO] Step[3600/4329]: training loss : 1.0481026911735534 TRAIN  loss dict:  {'classification_loss': 1.0481026911735534}
2025-01-12 19:49:06,444 [INFO] Step[3650/4329]: training loss : 1.0013245046138763 TRAIN  loss dict:  {'classification_loss': 1.0013245046138763}
2025-01-12 19:49:18,048 [INFO] Step[3700/4329]: training loss : 1.0169883847236634 TRAIN  loss dict:  {'classification_loss': 1.0169883847236634}
2025-01-12 19:49:29,698 [INFO] Step[3750/4329]: training loss : 1.025140519142151 TRAIN  loss dict:  {'classification_loss': 1.025140519142151}
2025-01-12 19:49:41,296 [INFO] Step[3800/4329]: training loss : 1.0276081895828246 TRAIN  loss dict:  {'classification_loss': 1.0276081895828246}
2025-01-12 19:49:52,950 [INFO] Step[3850/4329]: training loss : 0.9825723803043366 TRAIN  loss dict:  {'classification_loss': 0.9825723803043366}
2025-01-12 19:50:04,558 [INFO] Step[3900/4329]: training loss : 0.9732800948619843 TRAIN  loss dict:  {'classification_loss': 0.9732800948619843}
2025-01-12 19:50:16,158 [INFO] Step[3950/4329]: training loss : 0.9755442535877228 TRAIN  loss dict:  {'classification_loss': 0.9755442535877228}
2025-01-12 19:50:27,709 [INFO] Step[4000/4329]: training loss : 0.9892757022380829 TRAIN  loss dict:  {'classification_loss': 0.9892757022380829}
2025-01-12 19:50:39,303 [INFO] Step[4050/4329]: training loss : 1.0149717116355896 TRAIN  loss dict:  {'classification_loss': 1.0149717116355896}
2025-01-12 19:50:50,925 [INFO] Step[4100/4329]: training loss : 1.0090829133987427 TRAIN  loss dict:  {'classification_loss': 1.0090829133987427}
2025-01-12 19:51:02,532 [INFO] Step[4150/4329]: training loss : 0.9992291724681854 TRAIN  loss dict:  {'classification_loss': 0.9992291724681854}
2025-01-12 19:51:14,164 [INFO] Step[4200/4329]: training loss : 0.9895773267745972 TRAIN  loss dict:  {'classification_loss': 0.9895773267745972}
2025-01-12 19:51:25,762 [INFO] Step[4250/4329]: training loss : 1.0234704160690307 TRAIN  loss dict:  {'classification_loss': 1.0234704160690307}
2025-01-12 19:51:37,439 [INFO] Step[4300/4329]: training loss : 1.0356339061260222 TRAIN  loss dict:  {'classification_loss': 1.0356339061260222}
2025-01-12 19:53:34,545 [INFO] Label accuracies statistics:
2025-01-12 19:53:34,545 [INFO] {0: 0.4444444444444444, 1: 0.8888888888888888, 2: 0.5833333333333334, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5833333333333334, 7: 0.4166666666666667, 8: 0.6666666666666666, 9: 0.75, 10: 1.0, 11: 0.8333333333333334, 12: 0.4166666666666667, 13: 0.4166666666666667, 14: 0.6666666666666666, 15: 0.6666666666666666, 16: 0.5833333333333334, 17: 0.4166666666666667, 18: 0.5833333333333334, 19: 0.6666666666666666, 20: 0.5833333333333334, 21: 0.75, 22: 0.75, 23: 0.8333333333333334, 24: 0.75, 25: 0.5833333333333334, 26: 0.8333333333333334, 27: 0.5833333333333334, 28: 0.8333333333333334, 29: 1.0, 30: 0.6666666666666666, 31: 0.8333333333333334, 32: 0.6666666666666666, 33: 0.8333333333333334, 34: 0.8333333333333334, 35: 0.75, 36: 0.6666666666666666, 37: 0.8333333333333334, 38: 0.8333333333333334, 39: 1.0, 40: 1.0, 41: 0.4166666666666667, 42: 0.9166666666666666, 43: 0.8333333333333334, 44: 0.5833333333333334, 45: 0.5833333333333334, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.3333333333333333, 55: 0.6666666666666666, 56: 0.75, 57: 0.5833333333333334, 58: 0.3333333333333333, 59: 0.8333333333333334, 60: 0.8333333333333334, 61: 1.0, 62: 0.75, 63: 0.4166666666666667, 64: 0.9166666666666666, 65: 1.0, 66: 0.6666666666666666, 67: 0.8333333333333334, 68: 0.8333333333333334, 69: 0.75, 70: 0.3333333333333333, 71: 0.5, 72: 0.6666666666666666, 73: 0.75, 74: 0.5833333333333334, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.3333333333333333, 84: 0.4166666666666667, 85: 0.8333333333333334, 86: 0.5833333333333334, 87: 0.8333333333333334, 88: 0.9166666666666666, 89: 0.5833333333333334, 90: 0.25, 91: 1.0, 92: 1.0, 93: 0.9166666666666666, 94: 0.6666666666666666, 95: 0.9166666666666666, 96: 0.4166666666666667, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.8333333333333334, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.8333333333333334, 106: 0.9166666666666666, 107: 0.75, 108: 0.8333333333333334, 109: 0.8333333333333334, 110: 0.9166666666666666, 111: 0.9166666666666666, 112: 1.0, 113: 0.3333333333333333, 114: 0.75, 115: 1.0, 116: 0.5833333333333334, 117: 0.6666666666666666, 118: 1.0, 119: 0.6666666666666666, 120: 1.0, 121: 0.75, 122: 0.8333333333333334, 123: 0.8333333333333334, 124: 0.9166666666666666, 125: 0.9166666666666666, 126: 0.8333333333333334, 127: 0.75, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.9166666666666666, 132: 0.5833333333333334, 133: 0.9166666666666666, 134: 0.75, 135: 0.8333333333333334, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.75, 140: 0.9166666666666666, 141: 0.9166666666666666, 142: 0.9166666666666666, 143: 1.0, 144: 0.5833333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.9166666666666666, 148: 0.6666666666666666, 149: 1.0, 150: 0.5, 151: 0.8333333333333334, 152: 0.9166666666666666, 153: 0.9166666666666666, 154: 1.0, 155: 0.9166666666666666, 156: 0.5833333333333334, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.08333333333333333, 161: 0.4166666666666667, 162: 0.8333333333333334, 163: 0.8333333333333334, 164: 0.8333333333333334, 165: 0.9166666666666666, 166: 0.6666666666666666, 167: 0.5833333333333334, 168: 0.6666666666666666, 169: 0.9166666666666666, 170: 1.0, 171: 0.5833333333333334, 172: 1.0, 173: 0.9166666666666666, 174: 0.9166666666666666, 175: 0.75, 176: 0.8333333333333334, 177: 0.75, 178: 1.0, 179: 0.2222222222222222, 180: 0.75, 181: 0.75, 182: 0.5833333333333334, 183: 0.75, 184: 0.5833333333333334, 185: 1.0, 186: 0.8333333333333334, 187: 0.9166666666666666, 188: 0.75, 189: 0.9166666666666666, 190: 0.5833333333333334, 191: 0.16666666666666666, 192: 1.0, 193: 0.8333333333333334, 194: 1.0, 195: 0.8333333333333334, 196: 0.8333333333333334, 197: 0.8333333333333334, 198: 0.8333333333333334}

2025-01-12 19:53:34,547 [INFO] [16] TRAIN  loss: 1.01424788736146 acc: 0.974356999845988
2025-01-12 19:53:34,547 [INFO] [16] TRAIN  loss dict: {'classification_loss': 1.01424788736146}
2025-01-12 19:53:34,547 [INFO] [16] VALIDATION loss: 1.7363757973518035 VALIDATION acc: 0.765993265993266
2025-01-12 19:53:34,547 [INFO] [16] VALIDATION loss dict: {'classification_loss': 1.7363757973518035}
2025-01-12 19:53:34,548 [INFO] 
2025-01-12 19:53:52,719 [INFO] Step[50/4329]: training loss : 0.9839973402023315 TRAIN  loss dict:  {'classification_loss': 0.9839973402023315}
2025-01-12 19:54:04,282 [INFO] Step[100/4329]: training loss : 0.9787913846969605 TRAIN  loss dict:  {'classification_loss': 0.9787913846969605}
2025-01-12 19:54:15,915 [INFO] Step[150/4329]: training loss : 0.9769819974899292 TRAIN  loss dict:  {'classification_loss': 0.9769819974899292}
2025-01-12 19:54:27,527 [INFO] Step[200/4329]: training loss : 1.01124902844429 TRAIN  loss dict:  {'classification_loss': 1.01124902844429}
2025-01-12 19:54:39,180 [INFO] Step[250/4329]: training loss : 0.9919835889339447 TRAIN  loss dict:  {'classification_loss': 0.9919835889339447}
2025-01-12 19:54:50,835 [INFO] Step[300/4329]: training loss : 1.002148984670639 TRAIN  loss dict:  {'classification_loss': 1.002148984670639}
2025-01-12 19:55:02,495 [INFO] Step[350/4329]: training loss : 0.9778607571125031 TRAIN  loss dict:  {'classification_loss': 0.9778607571125031}
2025-01-12 19:55:14,134 [INFO] Step[400/4329]: training loss : 1.0262150657176972 TRAIN  loss dict:  {'classification_loss': 1.0262150657176972}
2025-01-12 19:55:25,789 [INFO] Step[450/4329]: training loss : 1.0050744485855103 TRAIN  loss dict:  {'classification_loss': 1.0050744485855103}
2025-01-12 19:55:37,409 [INFO] Step[500/4329]: training loss : 1.0355315101146698 TRAIN  loss dict:  {'classification_loss': 1.0355315101146698}
2025-01-12 19:55:49,081 [INFO] Step[550/4329]: training loss : 1.0029073870182037 TRAIN  loss dict:  {'classification_loss': 1.0029073870182037}
2025-01-12 19:56:00,757 [INFO] Step[600/4329]: training loss : 0.9979238557815552 TRAIN  loss dict:  {'classification_loss': 0.9979238557815552}
2025-01-12 19:56:12,829 [INFO] Step[650/4329]: training loss : 1.0063591384887696 TRAIN  loss dict:  {'classification_loss': 1.0063591384887696}
2025-01-12 19:56:25,072 [INFO] Step[700/4329]: training loss : 0.989892737865448 TRAIN  loss dict:  {'classification_loss': 0.989892737865448}
2025-01-12 19:56:37,640 [INFO] Step[750/4329]: training loss : 1.0086831951141357 TRAIN  loss dict:  {'classification_loss': 1.0086831951141357}
2025-01-12 19:56:50,992 [INFO] Step[800/4329]: training loss : 0.9875408375263214 TRAIN  loss dict:  {'classification_loss': 0.9875408375263214}
2025-01-12 19:57:05,293 [INFO] Step[850/4329]: training loss : 0.9684908735752106 TRAIN  loss dict:  {'classification_loss': 0.9684908735752106}
2025-01-12 19:57:17,222 [INFO] Step[900/4329]: training loss : 1.075265290737152 TRAIN  loss dict:  {'classification_loss': 1.075265290737152}
2025-01-12 19:57:29,119 [INFO] Step[950/4329]: training loss : 1.0093155777454377 TRAIN  loss dict:  {'classification_loss': 1.0093155777454377}
2025-01-12 19:57:40,767 [INFO] Step[1000/4329]: training loss : 0.987633730173111 TRAIN  loss dict:  {'classification_loss': 0.987633730173111}
2025-01-12 19:57:52,428 [INFO] Step[1050/4329]: training loss : 1.052291601896286 TRAIN  loss dict:  {'classification_loss': 1.052291601896286}
2025-01-12 19:58:04,022 [INFO] Step[1100/4329]: training loss : 0.9754162669181824 TRAIN  loss dict:  {'classification_loss': 0.9754162669181824}
2025-01-12 19:58:15,597 [INFO] Step[1150/4329]: training loss : 1.0454547023773193 TRAIN  loss dict:  {'classification_loss': 1.0454547023773193}
2025-01-12 19:58:27,201 [INFO] Step[1200/4329]: training loss : 1.0062130272388459 TRAIN  loss dict:  {'classification_loss': 1.0062130272388459}
2025-01-12 19:58:38,827 [INFO] Step[1250/4329]: training loss : 1.0144698166847228 TRAIN  loss dict:  {'classification_loss': 1.0144698166847228}
2025-01-12 19:58:50,448 [INFO] Step[1300/4329]: training loss : 1.0018562817573546 TRAIN  loss dict:  {'classification_loss': 1.0018562817573546}
2025-01-12 19:59:02,045 [INFO] Step[1350/4329]: training loss : 1.002637892961502 TRAIN  loss dict:  {'classification_loss': 1.002637892961502}
2025-01-12 19:59:13,697 [INFO] Step[1400/4329]: training loss : 0.9924041414260865 TRAIN  loss dict:  {'classification_loss': 0.9924041414260865}
2025-01-12 19:59:25,297 [INFO] Step[1450/4329]: training loss : 1.0176133573055268 TRAIN  loss dict:  {'classification_loss': 1.0176133573055268}
2025-01-12 19:59:36,958 [INFO] Step[1500/4329]: training loss : 0.982621169090271 TRAIN  loss dict:  {'classification_loss': 0.982621169090271}
2025-01-12 19:59:48,572 [INFO] Step[1550/4329]: training loss : 0.9851095306873322 TRAIN  loss dict:  {'classification_loss': 0.9851095306873322}
2025-01-12 20:00:00,183 [INFO] Step[1600/4329]: training loss : 1.006316876411438 TRAIN  loss dict:  {'classification_loss': 1.006316876411438}
2025-01-12 20:00:11,775 [INFO] Step[1650/4329]: training loss : 0.9929187035560608 TRAIN  loss dict:  {'classification_loss': 0.9929187035560608}
2025-01-12 20:00:23,390 [INFO] Step[1700/4329]: training loss : 1.0593046510219575 TRAIN  loss dict:  {'classification_loss': 1.0593046510219575}
2025-01-12 20:00:35,021 [INFO] Step[1750/4329]: training loss : 0.9969423115253448 TRAIN  loss dict:  {'classification_loss': 0.9969423115253448}
2025-01-12 20:00:46,632 [INFO] Step[1800/4329]: training loss : 1.007677389383316 TRAIN  loss dict:  {'classification_loss': 1.007677389383316}
2025-01-12 20:00:58,252 [INFO] Step[1850/4329]: training loss : 1.016388601064682 TRAIN  loss dict:  {'classification_loss': 1.016388601064682}
2025-01-12 20:01:09,859 [INFO] Step[1900/4329]: training loss : 1.0362292993068696 TRAIN  loss dict:  {'classification_loss': 1.0362292993068696}
2025-01-12 20:01:21,498 [INFO] Step[1950/4329]: training loss : 1.0219574129581452 TRAIN  loss dict:  {'classification_loss': 1.0219574129581452}
2025-01-12 20:01:33,103 [INFO] Step[2000/4329]: training loss : 0.9807468688488007 TRAIN  loss dict:  {'classification_loss': 0.9807468688488007}
2025-01-12 20:01:44,724 [INFO] Step[2050/4329]: training loss : 0.9887736463546752 TRAIN  loss dict:  {'classification_loss': 0.9887736463546752}
2025-01-12 20:01:56,316 [INFO] Step[2100/4329]: training loss : 1.0127258396148682 TRAIN  loss dict:  {'classification_loss': 1.0127258396148682}
2025-01-12 20:02:07,966 [INFO] Step[2150/4329]: training loss : 0.9839896595478058 TRAIN  loss dict:  {'classification_loss': 0.9839896595478058}
2025-01-12 20:02:19,572 [INFO] Step[2200/4329]: training loss : 0.9954016351699829 TRAIN  loss dict:  {'classification_loss': 0.9954016351699829}
2025-01-12 20:02:31,179 [INFO] Step[2250/4329]: training loss : 0.9881638872623444 TRAIN  loss dict:  {'classification_loss': 0.9881638872623444}
2025-01-12 20:02:42,813 [INFO] Step[2300/4329]: training loss : 1.0188584899902344 TRAIN  loss dict:  {'classification_loss': 1.0188584899902344}
2025-01-12 20:02:54,434 [INFO] Step[2350/4329]: training loss : 1.0113603842258454 TRAIN  loss dict:  {'classification_loss': 1.0113603842258454}
2025-01-12 20:03:06,060 [INFO] Step[2400/4329]: training loss : 1.018117879629135 TRAIN  loss dict:  {'classification_loss': 1.018117879629135}
2025-01-12 20:03:17,684 [INFO] Step[2450/4329]: training loss : 0.9737479960918427 TRAIN  loss dict:  {'classification_loss': 0.9737479960918427}
2025-01-12 20:03:29,286 [INFO] Step[2500/4329]: training loss : 1.0046511793136597 TRAIN  loss dict:  {'classification_loss': 1.0046511793136597}
2025-01-12 20:03:40,892 [INFO] Step[2550/4329]: training loss : 0.9858757257461548 TRAIN  loss dict:  {'classification_loss': 0.9858757257461548}
2025-01-12 20:03:52,508 [INFO] Step[2600/4329]: training loss : 1.0341899442672728 TRAIN  loss dict:  {'classification_loss': 1.0341899442672728}
2025-01-12 20:04:04,151 [INFO] Step[2650/4329]: training loss : 1.0038434946537018 TRAIN  loss dict:  {'classification_loss': 1.0038434946537018}
2025-01-12 20:04:15,748 [INFO] Step[2700/4329]: training loss : 1.061187617778778 TRAIN  loss dict:  {'classification_loss': 1.061187617778778}
2025-01-12 20:04:27,381 [INFO] Step[2750/4329]: training loss : 0.9974840903282165 TRAIN  loss dict:  {'classification_loss': 0.9974840903282165}
2025-01-12 20:04:38,979 [INFO] Step[2800/4329]: training loss : 1.0106584441661834 TRAIN  loss dict:  {'classification_loss': 1.0106584441661834}
2025-01-12 20:04:50,660 [INFO] Step[2850/4329]: training loss : 0.987041175365448 TRAIN  loss dict:  {'classification_loss': 0.987041175365448}
2025-01-12 20:05:02,284 [INFO] Step[2900/4329]: training loss : 1.03491797208786 TRAIN  loss dict:  {'classification_loss': 1.03491797208786}
2025-01-12 20:05:13,937 [INFO] Step[2950/4329]: training loss : 1.026091094017029 TRAIN  loss dict:  {'classification_loss': 1.026091094017029}
2025-01-12 20:05:25,595 [INFO] Step[3000/4329]: training loss : 1.0806161558628082 TRAIN  loss dict:  {'classification_loss': 1.0806161558628082}
2025-01-12 20:05:37,228 [INFO] Step[3050/4329]: training loss : 0.9995524764060975 TRAIN  loss dict:  {'classification_loss': 0.9995524764060975}
2025-01-12 20:05:48,828 [INFO] Step[3100/4329]: training loss : 0.9899241209030152 TRAIN  loss dict:  {'classification_loss': 0.9899241209030152}
2025-01-12 20:06:00,490 [INFO] Step[3150/4329]: training loss : 0.9545698547363282 TRAIN  loss dict:  {'classification_loss': 0.9545698547363282}
2025-01-12 20:06:12,100 [INFO] Step[3200/4329]: training loss : 1.0003824877738952 TRAIN  loss dict:  {'classification_loss': 1.0003824877738952}
2025-01-12 20:06:23,755 [INFO] Step[3250/4329]: training loss : 1.0063685834407807 TRAIN  loss dict:  {'classification_loss': 1.0063685834407807}
2025-01-12 20:06:35,359 [INFO] Step[3300/4329]: training loss : 1.0804877042770387 TRAIN  loss dict:  {'classification_loss': 1.0804877042770387}
2025-01-12 20:06:46,948 [INFO] Step[3350/4329]: training loss : 0.9918242514133453 TRAIN  loss dict:  {'classification_loss': 0.9918242514133453}
2025-01-12 20:06:58,580 [INFO] Step[3400/4329]: training loss : 1.0676331102848053 TRAIN  loss dict:  {'classification_loss': 1.0676331102848053}
2025-01-12 20:07:10,210 [INFO] Step[3450/4329]: training loss : 0.9766071963310242 TRAIN  loss dict:  {'classification_loss': 0.9766071963310242}
2025-01-12 20:07:21,795 [INFO] Step[3500/4329]: training loss : 0.9857116115093231 TRAIN  loss dict:  {'classification_loss': 0.9857116115093231}
2025-01-12 20:07:33,417 [INFO] Step[3550/4329]: training loss : 1.0605907154083252 TRAIN  loss dict:  {'classification_loss': 1.0605907154083252}
2025-01-12 20:07:45,060 [INFO] Step[3600/4329]: training loss : 1.002478196620941 TRAIN  loss dict:  {'classification_loss': 1.002478196620941}
2025-01-12 20:07:56,673 [INFO] Step[3650/4329]: training loss : 1.024381207227707 TRAIN  loss dict:  {'classification_loss': 1.024381207227707}
2025-01-12 20:08:08,265 [INFO] Step[3700/4329]: training loss : 0.9790504193305969 TRAIN  loss dict:  {'classification_loss': 0.9790504193305969}
2025-01-12 20:08:20,023 [INFO] Step[3750/4329]: training loss : 0.9904498279094696 TRAIN  loss dict:  {'classification_loss': 0.9904498279094696}
2025-01-12 20:08:32,374 [INFO] Step[3800/4329]: training loss : 1.0355502009391784 TRAIN  loss dict:  {'classification_loss': 1.0355502009391784}
2025-01-12 20:08:44,781 [INFO] Step[3850/4329]: training loss : 1.017056485414505 TRAIN  loss dict:  {'classification_loss': 1.017056485414505}
2025-01-12 20:08:57,714 [INFO] Step[3900/4329]: training loss : 1.0448169553279876 TRAIN  loss dict:  {'classification_loss': 1.0448169553279876}
2025-01-12 20:09:15,057 [INFO] Step[3950/4329]: training loss : 1.05074724316597 TRAIN  loss dict:  {'classification_loss': 1.05074724316597}
2025-01-12 20:09:27,239 [INFO] Step[4000/4329]: training loss : 0.9937326884269715 TRAIN  loss dict:  {'classification_loss': 0.9937326884269715}
2025-01-12 20:09:39,143 [INFO] Step[4050/4329]: training loss : 0.9760879278182983 TRAIN  loss dict:  {'classification_loss': 0.9760879278182983}
2025-01-12 20:09:51,008 [INFO] Step[4100/4329]: training loss : 1.0845233726501464 TRAIN  loss dict:  {'classification_loss': 1.0845233726501464}
2025-01-12 20:10:02,675 [INFO] Step[4150/4329]: training loss : 1.0146968674659729 TRAIN  loss dict:  {'classification_loss': 1.0146968674659729}
2025-01-12 20:10:14,252 [INFO] Step[4200/4329]: training loss : 1.0073910605907441 TRAIN  loss dict:  {'classification_loss': 1.0073910605907441}
2025-01-12 20:10:25,903 [INFO] Step[4250/4329]: training loss : 0.9941927146911621 TRAIN  loss dict:  {'classification_loss': 0.9941927146911621}
2025-01-12 20:10:37,549 [INFO] Step[4300/4329]: training loss : 0.9633020448684693 TRAIN  loss dict:  {'classification_loss': 0.9633020448684693}
2025-01-12 20:12:36,391 [INFO] Label accuracies statistics:
2025-01-12 20:12:36,392 [INFO] {0: 0.6666666666666666, 1: 0.7777777777777778, 2: 0.5833333333333334, 3: 0.8333333333333334, 4: 0.3333333333333333, 5: 0.75, 6: 0.5833333333333334, 7: 0.4166666666666667, 8: 0.3333333333333333, 9: 0.75, 10: 0.8333333333333334, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.5833333333333334, 14: 0.75, 15: 0.4444444444444444, 16: 0.6666666666666666, 17: 0.4166666666666667, 18: 0.5, 19: 0.5, 20: 0.75, 21: 0.5833333333333334, 22: 0.75, 23: 0.9166666666666666, 24: 1.0, 25: 0.75, 26: 0.9166666666666666, 27: 0.5833333333333334, 28: 0.8333333333333334, 29: 1.0, 30: 0.6666666666666666, 31: 0.5833333333333334, 32: 0.75, 33: 0.8333333333333334, 34: 0.9166666666666666, 35: 1.0, 36: 0.6666666666666666, 37: 1.0, 38: 0.9166666666666666, 39: 1.0, 40: 0.9166666666666666, 41: 0.3333333333333333, 42: 0.8333333333333334, 43: 0.75, 44: 0.5833333333333334, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.75, 51: 0.8333333333333334, 52: 1.0, 53: 0.25, 54: 0.5, 55: 0.6666666666666666, 56: 0.5833333333333334, 57: 0.6666666666666666, 58: 0.6666666666666666, 59: 0.5833333333333334, 60: 0.6666666666666666, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.9166666666666666, 65: 1.0, 66: 0.6666666666666666, 67: 0.5833333333333334, 68: 0.6666666666666666, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.8333333333333334, 73: 0.75, 74: 0.75, 75: 0.9166666666666666, 76: 0.6666666666666666, 77: 0.6666666666666666, 78: 0.9166666666666666, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.4166666666666667, 85: 0.8333333333333334, 86: 0.5, 87: 1.0, 88: 0.8333333333333334, 89: 0.5833333333333334, 90: 0.4166666666666667, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 0.9166666666666666, 96: 0.3333333333333333, 97: 0.8333333333333334, 98: 0.8333333333333334, 99: 0.9333333333333333, 100: 0.8333333333333334, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 1.0, 108: 0.8333333333333334, 109: 0.6666666666666666, 110: 0.8333333333333334, 111: 0.9166666666666666, 112: 0.9166666666666666, 113: 0.4166666666666667, 114: 0.6666666666666666, 115: 0.8333333333333334, 116: 0.75, 117: 0.5833333333333334, 118: 1.0, 119: 0.8333333333333334, 120: 0.6666666666666666, 121: 0.9166666666666666, 122: 0.75, 123: 1.0, 124: 0.9166666666666666, 125: 1.0, 126: 0.8333333333333334, 127: 0.75, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.8333333333333334, 132: 0.5, 133: 1.0, 134: 0.6666666666666666, 135: 0.9166666666666666, 136: 1.0, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.75, 140: 0.8333333333333334, 141: 1.0, 142: 0.9166666666666666, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 0.9166666666666666, 153: 0.6666666666666666, 154: 1.0, 155: 0.9166666666666666, 156: 0.5833333333333334, 157: 0.8333333333333334, 158: 0.5555555555555556, 159: 1.0, 160: 0.25, 161: 0.5833333333333334, 162: 0.9166666666666666, 163: 0.8333333333333334, 164: 0.75, 165: 0.75, 166: 0.6666666666666666, 167: 0.8333333333333334, 168: 1.0, 169: 0.9166666666666666, 170: 0.9166666666666666, 171: 0.5833333333333334, 172: 1.0, 173: 0.75, 174: 1.0, 175: 0.9166666666666666, 176: 0.8333333333333334, 177: 0.6666666666666666, 178: 0.9166666666666666, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.75, 182: 0.75, 183: 0.5833333333333334, 184: 0.8333333333333334, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.75, 189: 0.8333333333333334, 190: 0.3333333333333333, 191: 0.5833333333333334, 192: 1.0, 193: 0.8333333333333334, 194: 0.8333333333333334, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.6666666666666666}

2025-01-12 20:12:37,320 [INFO] [17] TRAIN  loss: 1.0083877785179955 acc: 0.974356999845988
2025-01-12 20:12:37,320 [INFO] [17] TRAIN  loss dict: {'classification_loss': 1.0083877785179955}
2025-01-12 20:12:37,321 [INFO] [17] VALIDATION loss: 1.7149717350951348 VALIDATION acc: 0.7731481481481481
2025-01-12 20:12:37,321 [INFO] [17] VALIDATION loss dict: {'classification_loss': 1.7149717350951348}
2025-01-12 20:12:37,321 [INFO] 
2025-01-12 20:12:55,061 [INFO] Step[50/4329]: training loss : 1.003037223815918 TRAIN  loss dict:  {'classification_loss': 1.003037223815918}
2025-01-12 20:13:06,617 [INFO] Step[100/4329]: training loss : 0.9851169800758361 TRAIN  loss dict:  {'classification_loss': 0.9851169800758361}
2025-01-12 20:13:18,212 [INFO] Step[150/4329]: training loss : 0.9930522060394287 TRAIN  loss dict:  {'classification_loss': 0.9930522060394287}
2025-01-12 20:13:29,820 [INFO] Step[200/4329]: training loss : 0.9515683114528656 TRAIN  loss dict:  {'classification_loss': 0.9515683114528656}
2025-01-12 20:13:41,448 [INFO] Step[250/4329]: training loss : 0.9917443430423737 TRAIN  loss dict:  {'classification_loss': 0.9917443430423737}
2025-01-12 20:13:53,061 [INFO] Step[300/4329]: training loss : 1.063366482257843 TRAIN  loss dict:  {'classification_loss': 1.063366482257843}
2025-01-12 20:14:04,692 [INFO] Step[350/4329]: training loss : 0.9812313544750214 TRAIN  loss dict:  {'classification_loss': 0.9812313544750214}
2025-01-12 20:14:16,326 [INFO] Step[400/4329]: training loss : 0.9586107683181763 TRAIN  loss dict:  {'classification_loss': 0.9586107683181763}
2025-01-12 20:14:27,990 [INFO] Step[450/4329]: training loss : 0.9933213210105896 TRAIN  loss dict:  {'classification_loss': 0.9933213210105896}
2025-01-12 20:14:39,610 [INFO] Step[500/4329]: training loss : 1.034859846830368 TRAIN  loss dict:  {'classification_loss': 1.034859846830368}
2025-01-12 20:14:51,273 [INFO] Step[550/4329]: training loss : 0.9985862767696381 TRAIN  loss dict:  {'classification_loss': 0.9985862767696381}
2025-01-12 20:15:02,908 [INFO] Step[600/4329]: training loss : 0.9805755746364594 TRAIN  loss dict:  {'classification_loss': 0.9805755746364594}
2025-01-12 20:15:14,534 [INFO] Step[650/4329]: training loss : 0.9888472628593444 TRAIN  loss dict:  {'classification_loss': 0.9888472628593444}
2025-01-12 20:15:26,157 [INFO] Step[700/4329]: training loss : 0.9963001036643981 TRAIN  loss dict:  {'classification_loss': 0.9963001036643981}
2025-01-12 20:15:37,847 [INFO] Step[750/4329]: training loss : 1.0386711883544921 TRAIN  loss dict:  {'classification_loss': 1.0386711883544921}
2025-01-12 20:15:49,449 [INFO] Step[800/4329]: training loss : 0.9689792454242706 TRAIN  loss dict:  {'classification_loss': 0.9689792454242706}
2025-01-12 20:16:01,121 [INFO] Step[850/4329]: training loss : 1.0177280914783478 TRAIN  loss dict:  {'classification_loss': 1.0177280914783478}
2025-01-12 20:16:12,781 [INFO] Step[900/4329]: training loss : 1.003244823217392 TRAIN  loss dict:  {'classification_loss': 1.003244823217392}
2025-01-12 20:16:24,402 [INFO] Step[950/4329]: training loss : 1.0307570254802705 TRAIN  loss dict:  {'classification_loss': 1.0307570254802705}
2025-01-12 20:16:36,021 [INFO] Step[1000/4329]: training loss : 1.0338722610473632 TRAIN  loss dict:  {'classification_loss': 1.0338722610473632}
2025-01-12 20:16:47,688 [INFO] Step[1050/4329]: training loss : 0.9938248085975647 TRAIN  loss dict:  {'classification_loss': 0.9938248085975647}
2025-01-12 20:16:59,339 [INFO] Step[1100/4329]: training loss : 1.0221004319190978 TRAIN  loss dict:  {'classification_loss': 1.0221004319190978}
2025-01-12 20:17:10,943 [INFO] Step[1150/4329]: training loss : 0.9850267517566681 TRAIN  loss dict:  {'classification_loss': 0.9850267517566681}
2025-01-12 20:17:22,557 [INFO] Step[1200/4329]: training loss : 1.0006719398498536 TRAIN  loss dict:  {'classification_loss': 1.0006719398498536}
2025-01-12 20:17:34,160 [INFO] Step[1250/4329]: training loss : 0.9817594802379608 TRAIN  loss dict:  {'classification_loss': 0.9817594802379608}
2025-01-12 20:17:45,809 [INFO] Step[1300/4329]: training loss : 0.976283746957779 TRAIN  loss dict:  {'classification_loss': 0.976283746957779}
2025-01-12 20:17:57,455 [INFO] Step[1350/4329]: training loss : 1.0025606536865235 TRAIN  loss dict:  {'classification_loss': 1.0025606536865235}
2025-01-12 20:18:09,023 [INFO] Step[1400/4329]: training loss : 0.998101351261139 TRAIN  loss dict:  {'classification_loss': 0.998101351261139}
2025-01-12 20:18:20,650 [INFO] Step[1450/4329]: training loss : 1.0185631358623504 TRAIN  loss dict:  {'classification_loss': 1.0185631358623504}
2025-01-12 20:18:32,281 [INFO] Step[1500/4329]: training loss : 0.9997773873806 TRAIN  loss dict:  {'classification_loss': 0.9997773873806}
2025-01-12 20:18:43,928 [INFO] Step[1550/4329]: training loss : 1.0012554442882537 TRAIN  loss dict:  {'classification_loss': 1.0012554442882537}
2025-01-12 20:18:55,592 [INFO] Step[1600/4329]: training loss : 1.0231024503707886 TRAIN  loss dict:  {'classification_loss': 1.0231024503707886}
2025-01-12 20:19:07,224 [INFO] Step[1650/4329]: training loss : 0.9898311626911164 TRAIN  loss dict:  {'classification_loss': 0.9898311626911164}
2025-01-12 20:19:18,865 [INFO] Step[1700/4329]: training loss : 0.9814188086986542 TRAIN  loss dict:  {'classification_loss': 0.9814188086986542}
2025-01-12 20:19:30,518 [INFO] Step[1750/4329]: training loss : 0.9846476316452026 TRAIN  loss dict:  {'classification_loss': 0.9846476316452026}
2025-01-12 20:19:42,123 [INFO] Step[1800/4329]: training loss : 0.9700213849544526 TRAIN  loss dict:  {'classification_loss': 0.9700213849544526}
2025-01-12 20:19:53,754 [INFO] Step[1850/4329]: training loss : 1.0152383053302765 TRAIN  loss dict:  {'classification_loss': 1.0152383053302765}
2025-01-12 20:20:05,366 [INFO] Step[1900/4329]: training loss : 0.9987592732906342 TRAIN  loss dict:  {'classification_loss': 0.9987592732906342}
2025-01-12 20:20:17,002 [INFO] Step[1950/4329]: training loss : 1.018825936317444 TRAIN  loss dict:  {'classification_loss': 1.018825936317444}
2025-01-12 20:20:28,571 [INFO] Step[2000/4329]: training loss : 1.0148513412475586 TRAIN  loss dict:  {'classification_loss': 1.0148513412475586}
2025-01-12 20:20:40,262 [INFO] Step[2050/4329]: training loss : 0.9725141406059266 TRAIN  loss dict:  {'classification_loss': 0.9725141406059266}
2025-01-12 20:20:52,323 [INFO] Step[2100/4329]: training loss : 1.0205449640750885 TRAIN  loss dict:  {'classification_loss': 1.0205449640750885}
2025-01-12 20:21:04,534 [INFO] Step[2150/4329]: training loss : 0.99761390209198 TRAIN  loss dict:  {'classification_loss': 0.99761390209198}
2025-01-12 20:21:17,079 [INFO] Step[2200/4329]: training loss : 0.9978218364715576 TRAIN  loss dict:  {'classification_loss': 0.9978218364715576}
2025-01-12 20:21:30,210 [INFO] Step[2250/4329]: training loss : 0.9506247246265411 TRAIN  loss dict:  {'classification_loss': 0.9506247246265411}
2025-01-12 20:21:44,380 [INFO] Step[2300/4329]: training loss : 1.0511887323856355 TRAIN  loss dict:  {'classification_loss': 1.0511887323856355}
2025-01-12 20:21:56,357 [INFO] Step[2350/4329]: training loss : 0.9871189177036286 TRAIN  loss dict:  {'classification_loss': 0.9871189177036286}
2025-01-12 20:22:08,215 [INFO] Step[2400/4329]: training loss : 0.9593796277046204 TRAIN  loss dict:  {'classification_loss': 0.9593796277046204}
2025-01-12 20:22:19,938 [INFO] Step[2450/4329]: training loss : 1.020939130783081 TRAIN  loss dict:  {'classification_loss': 1.020939130783081}
2025-01-12 20:22:31,566 [INFO] Step[2500/4329]: training loss : 1.0313095831871033 TRAIN  loss dict:  {'classification_loss': 1.0313095831871033}
2025-01-12 20:22:43,196 [INFO] Step[2550/4329]: training loss : 0.9885863375663757 TRAIN  loss dict:  {'classification_loss': 0.9885863375663757}
2025-01-12 20:22:54,814 [INFO] Step[2600/4329]: training loss : 0.9578373456001281 TRAIN  loss dict:  {'classification_loss': 0.9578373456001281}
2025-01-12 20:23:06,466 [INFO] Step[2650/4329]: training loss : 1.0775225603580474 TRAIN  loss dict:  {'classification_loss': 1.0775225603580474}
2025-01-12 20:23:18,098 [INFO] Step[2700/4329]: training loss : 1.011875877380371 TRAIN  loss dict:  {'classification_loss': 1.011875877380371}
2025-01-12 20:23:29,771 [INFO] Step[2750/4329]: training loss : 0.9529102087020874 TRAIN  loss dict:  {'classification_loss': 0.9529102087020874}
2025-01-12 20:23:41,353 [INFO] Step[2800/4329]: training loss : 1.0196632397174836 TRAIN  loss dict:  {'classification_loss': 1.0196632397174836}
2025-01-12 20:23:52,986 [INFO] Step[2850/4329]: training loss : 1.043914988040924 TRAIN  loss dict:  {'classification_loss': 1.043914988040924}
2025-01-12 20:24:04,636 [INFO] Step[2900/4329]: training loss : 0.9895310497283936 TRAIN  loss dict:  {'classification_loss': 0.9895310497283936}
2025-01-12 20:24:16,270 [INFO] Step[2950/4329]: training loss : 1.0082438433170318 TRAIN  loss dict:  {'classification_loss': 1.0082438433170318}
2025-01-12 20:24:27,911 [INFO] Step[3000/4329]: training loss : 0.9925109219551086 TRAIN  loss dict:  {'classification_loss': 0.9925109219551086}
2025-01-12 20:24:39,544 [INFO] Step[3050/4329]: training loss : 0.9918565106391907 TRAIN  loss dict:  {'classification_loss': 0.9918565106391907}
2025-01-12 20:24:51,181 [INFO] Step[3100/4329]: training loss : 0.9712895548343659 TRAIN  loss dict:  {'classification_loss': 0.9712895548343659}
2025-01-12 20:25:02,765 [INFO] Step[3150/4329]: training loss : 0.9950606369972229 TRAIN  loss dict:  {'classification_loss': 0.9950606369972229}
2025-01-12 20:25:14,409 [INFO] Step[3200/4329]: training loss : 1.0468888628482818 TRAIN  loss dict:  {'classification_loss': 1.0468888628482818}
2025-01-12 20:25:26,036 [INFO] Step[3250/4329]: training loss : 1.0227847731113433 TRAIN  loss dict:  {'classification_loss': 1.0227847731113433}
2025-01-12 20:25:37,656 [INFO] Step[3300/4329]: training loss : 0.9626499509811401 TRAIN  loss dict:  {'classification_loss': 0.9626499509811401}
2025-01-12 20:25:49,276 [INFO] Step[3350/4329]: training loss : 0.9805004358291626 TRAIN  loss dict:  {'classification_loss': 0.9805004358291626}
2025-01-12 20:26:00,925 [INFO] Step[3400/4329]: training loss : 1.0292597544193267 TRAIN  loss dict:  {'classification_loss': 1.0292597544193267}
2025-01-12 20:26:12,571 [INFO] Step[3450/4329]: training loss : 1.0642114901542663 TRAIN  loss dict:  {'classification_loss': 1.0642114901542663}
2025-01-12 20:26:24,172 [INFO] Step[3500/4329]: training loss : 1.0034789955615997 TRAIN  loss dict:  {'classification_loss': 1.0034789955615997}
2025-01-12 20:26:35,806 [INFO] Step[3550/4329]: training loss : 1.0126696968078612 TRAIN  loss dict:  {'classification_loss': 1.0126696968078612}
2025-01-12 20:26:47,449 [INFO] Step[3600/4329]: training loss : 1.0283153200149535 TRAIN  loss dict:  {'classification_loss': 1.0283153200149535}
2025-01-12 20:26:59,095 [INFO] Step[3650/4329]: training loss : 1.0187473428249358 TRAIN  loss dict:  {'classification_loss': 1.0187473428249358}
2025-01-12 20:27:10,713 [INFO] Step[3700/4329]: training loss : 1.0033835363388062 TRAIN  loss dict:  {'classification_loss': 1.0033835363388062}
2025-01-12 20:27:22,387 [INFO] Step[3750/4329]: training loss : 1.0467384779453277 TRAIN  loss dict:  {'classification_loss': 1.0467384779453277}
2025-01-12 20:27:34,035 [INFO] Step[3800/4329]: training loss : 1.0508102440834046 TRAIN  loss dict:  {'classification_loss': 1.0508102440834046}
2025-01-12 20:27:45,706 [INFO] Step[3850/4329]: training loss : 1.05692835688591 TRAIN  loss dict:  {'classification_loss': 1.05692835688591}
2025-01-12 20:27:57,366 [INFO] Step[3900/4329]: training loss : 0.9763562321662903 TRAIN  loss dict:  {'classification_loss': 0.9763562321662903}
2025-01-12 20:28:08,984 [INFO] Step[3950/4329]: training loss : 0.9843226182460785 TRAIN  loss dict:  {'classification_loss': 0.9843226182460785}
2025-01-12 20:28:20,648 [INFO] Step[4000/4329]: training loss : 1.02085062623024 TRAIN  loss dict:  {'classification_loss': 1.02085062623024}
2025-01-12 20:28:32,276 [INFO] Step[4050/4329]: training loss : 1.0310383498668672 TRAIN  loss dict:  {'classification_loss': 1.0310383498668672}
2025-01-12 20:28:43,904 [INFO] Step[4100/4329]: training loss : 0.9913819217681885 TRAIN  loss dict:  {'classification_loss': 0.9913819217681885}
2025-01-12 20:28:55,555 [INFO] Step[4150/4329]: training loss : 0.953647712469101 TRAIN  loss dict:  {'classification_loss': 0.953647712469101}
2025-01-12 20:29:07,199 [INFO] Step[4200/4329]: training loss : 0.9763496124744415 TRAIN  loss dict:  {'classification_loss': 0.9763496124744415}
2025-01-12 20:29:18,815 [INFO] Step[4250/4329]: training loss : 0.9994671678543091 TRAIN  loss dict:  {'classification_loss': 0.9994671678543091}
2025-01-12 20:29:30,476 [INFO] Step[4300/4329]: training loss : 1.024880781173706 TRAIN  loss dict:  {'classification_loss': 1.024880781173706}
2025-01-12 20:31:29,856 [INFO] Label accuracies statistics:
2025-01-12 20:31:29,856 [INFO] {0: 0.4444444444444444, 1: 0.8888888888888888, 2: 0.5833333333333334, 3: 0.75, 4: 0.6666666666666666, 5: 0.9166666666666666, 6: 0.5833333333333334, 7: 0.4166666666666667, 8: 0.5, 9: 0.75, 10: 1.0, 11: 0.9166666666666666, 12: 0.5, 13: 0.4166666666666667, 14: 0.75, 15: 0.5555555555555556, 16: 0.5, 17: 0.6666666666666666, 18: 0.5833333333333334, 19: 0.6666666666666666, 20: 0.5, 21: 0.6666666666666666, 22: 0.75, 23: 1.0, 24: 0.9166666666666666, 25: 0.5833333333333334, 26: 0.5833333333333334, 27: 0.5833333333333334, 28: 0.8333333333333334, 29: 1.0, 30: 0.5, 31: 0.6666666666666666, 32: 0.6666666666666666, 33: 0.8333333333333334, 34: 0.8333333333333334, 35: 0.8333333333333334, 36: 0.5833333333333334, 37: 1.0, 38: 0.8333333333333334, 39: 1.0, 40: 0.8333333333333334, 41: 0.5, 42: 0.75, 43: 0.8333333333333334, 44: 0.4166666666666667, 45: 0.5833333333333334, 46: 1.0, 47: 1.0, 48: 0.8333333333333334, 49: 0.9166666666666666, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.6666666666666666, 56: 0.8333333333333334, 57: 0.6666666666666666, 58: 0.4166666666666667, 59: 0.8333333333333334, 60: 0.5833333333333334, 61: 1.0, 62: 0.75, 63: 0.5, 64: 0.9166666666666666, 65: 1.0, 66: 0.6666666666666666, 67: 0.75, 68: 1.0, 69: 0.75, 70: 0.4166666666666667, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.6666666666666666, 75: 1.0, 76: 0.5833333333333334, 77: 0.6666666666666666, 78: 1.0, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.6666666666666666, 83: 0.5833333333333334, 84: 0.4166666666666667, 85: 0.9166666666666666, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.5, 89: 0.5, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.6666666666666666, 97: 0.5, 98: 0.75, 99: 0.9333333333333333, 100: 0.8333333333333334, 101: 0.9166666666666666, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 0.9166666666666666, 105: 1.0, 106: 0.9166666666666666, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.75, 110: 0.9166666666666666, 111: 1.0, 112: 0.8333333333333334, 113: 0.5, 114: 0.5833333333333334, 115: 0.9166666666666666, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.8333333333333334, 120: 0.8333333333333334, 121: 0.75, 122: 0.9166666666666666, 123: 0.9166666666666666, 124: 0.9166666666666666, 125: 1.0, 126: 0.9166666666666666, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.8333333333333334, 131: 0.9166666666666666, 132: 0.4166666666666667, 133: 1.0, 134: 0.75, 135: 0.8333333333333334, 136: 0.9166666666666666, 137: 0.8333333333333334, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 0.8333333333333334, 141: 0.9166666666666666, 142: 0.5833333333333334, 143: 0.9166666666666666, 144: 0.8333333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.3333333333333333, 151: 0.9166666666666666, 152: 0.8333333333333334, 153: 0.6666666666666666, 154: 1.0, 155: 0.8333333333333334, 156: 0.8333333333333334, 157: 0.75, 158: 0.7777777777777778, 159: 0.9166666666666666, 160: 0.3333333333333333, 161: 0.8333333333333334, 162: 0.9166666666666666, 163: 1.0, 164: 0.75, 165: 0.9166666666666666, 166: 0.75, 167: 0.75, 168: 0.9166666666666666, 169: 0.9166666666666666, 170: 1.0, 171: 0.5833333333333334, 172: 1.0, 173: 0.75, 174: 0.8333333333333334, 175: 0.9166666666666666, 176: 0.8333333333333334, 177: 0.9166666666666666, 178: 0.9166666666666666, 179: 0.2222222222222222, 180: 0.75, 181: 0.8333333333333334, 182: 0.6666666666666666, 183: 0.75, 184: 0.8333333333333334, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.6666666666666666, 189: 1.0, 190: 0.5, 191: 0.4166666666666667, 192: 1.0, 193: 0.8333333333333334, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.9166666666666666, 198: 0.6666666666666666}

2025-01-12 20:31:31,732 [INFO] [18] TRAIN  loss: 1.0028903821264246 acc: 0.9753580779300786
2025-01-12 20:31:31,732 [INFO] [18] TRAIN  loss dict: {'classification_loss': 1.0028903821264246}
2025-01-12 20:31:31,733 [INFO] [18] VALIDATION loss: 1.6676321293820033 VALIDATION acc: 0.7840909090909091
2025-01-12 20:31:31,733 [INFO] [18] VALIDATION loss dict: {'classification_loss': 1.6676321293820033}
2025-01-12 20:31:31,733 [INFO] 
2025-01-12 20:31:49,149 [INFO] Step[50/4329]: training loss : 0.9737872231006622 TRAIN  loss dict:  {'classification_loss': 0.9737872231006622}
2025-01-12 20:32:00,711 [INFO] Step[100/4329]: training loss : 0.9616419756412506 TRAIN  loss dict:  {'classification_loss': 0.9616419756412506}
2025-01-12 20:32:12,295 [INFO] Step[150/4329]: training loss : 0.9861957168579102 TRAIN  loss dict:  {'classification_loss': 0.9861957168579102}
2025-01-12 20:32:23,926 [INFO] Step[200/4329]: training loss : 0.9722693359851837 TRAIN  loss dict:  {'classification_loss': 0.9722693359851837}
2025-01-12 20:32:35,537 [INFO] Step[250/4329]: training loss : 0.9642857539653779 TRAIN  loss dict:  {'classification_loss': 0.9642857539653779}
2025-01-12 20:32:47,170 [INFO] Step[300/4329]: training loss : 1.0101319539546967 TRAIN  loss dict:  {'classification_loss': 1.0101319539546967}
2025-01-12 20:32:58,794 [INFO] Step[350/4329]: training loss : 0.9972932350635528 TRAIN  loss dict:  {'classification_loss': 0.9972932350635528}
2025-01-12 20:33:10,497 [INFO] Step[400/4329]: training loss : 1.0234779250621795 TRAIN  loss dict:  {'classification_loss': 1.0234779250621795}
2025-01-12 20:33:22,604 [INFO] Step[450/4329]: training loss : 0.9787743699550628 TRAIN  loss dict:  {'classification_loss': 0.9787743699550628}
2025-01-12 20:33:34,267 [INFO] Step[500/4329]: training loss : 0.9801477265357971 TRAIN  loss dict:  {'classification_loss': 0.9801477265357971}
2025-01-12 20:33:46,268 [INFO] Step[550/4329]: training loss : 0.9909236407279969 TRAIN  loss dict:  {'classification_loss': 0.9909236407279969}
2025-01-12 20:33:58,487 [INFO] Step[600/4329]: training loss : 0.9917153966426849 TRAIN  loss dict:  {'classification_loss': 0.9917153966426849}
2025-01-12 20:34:10,874 [INFO] Step[650/4329]: training loss : 1.012745624780655 TRAIN  loss dict:  {'classification_loss': 1.012745624780655}
2025-01-12 20:34:24,036 [INFO] Step[700/4329]: training loss : 1.0109322249889374 TRAIN  loss dict:  {'classification_loss': 1.0109322249889374}
2025-01-12 20:34:37,293 [INFO] Step[750/4329]: training loss : 1.0286199283599853 TRAIN  loss dict:  {'classification_loss': 1.0286199283599853}
2025-01-12 20:34:49,295 [INFO] Step[800/4329]: training loss : 0.9949795210361481 TRAIN  loss dict:  {'classification_loss': 0.9949795210361481}
2025-01-12 20:35:01,063 [INFO] Step[850/4329]: training loss : 0.986623147726059 TRAIN  loss dict:  {'classification_loss': 0.986623147726059}
2025-01-12 20:35:12,899 [INFO] Step[900/4329]: training loss : 1.0048089241981506 TRAIN  loss dict:  {'classification_loss': 1.0048089241981506}
2025-01-12 20:35:24,592 [INFO] Step[950/4329]: training loss : 1.0128984320163728 TRAIN  loss dict:  {'classification_loss': 1.0128984320163728}
2025-01-12 20:35:36,248 [INFO] Step[1000/4329]: training loss : 0.9825280845165253 TRAIN  loss dict:  {'classification_loss': 0.9825280845165253}
2025-01-12 20:35:47,877 [INFO] Step[1050/4329]: training loss : 1.0089687609672546 TRAIN  loss dict:  {'classification_loss': 1.0089687609672546}
2025-01-12 20:35:59,465 [INFO] Step[1100/4329]: training loss : 0.9549785494804383 TRAIN  loss dict:  {'classification_loss': 0.9549785494804383}
2025-01-12 20:36:11,113 [INFO] Step[1150/4329]: training loss : 0.9805435919761658 TRAIN  loss dict:  {'classification_loss': 0.9805435919761658}
2025-01-12 20:36:22,720 [INFO] Step[1200/4329]: training loss : 0.9526488876342774 TRAIN  loss dict:  {'classification_loss': 0.9526488876342774}
2025-01-12 20:36:34,382 [INFO] Step[1250/4329]: training loss : 1.0056920158863067 TRAIN  loss dict:  {'classification_loss': 1.0056920158863067}
2025-01-12 20:36:45,969 [INFO] Step[1300/4329]: training loss : 1.0202849435806274 TRAIN  loss dict:  {'classification_loss': 1.0202849435806274}
2025-01-12 20:36:57,578 [INFO] Step[1350/4329]: training loss : 1.023739743232727 TRAIN  loss dict:  {'classification_loss': 1.023739743232727}
2025-01-12 20:37:09,216 [INFO] Step[1400/4329]: training loss : 0.9941551804542541 TRAIN  loss dict:  {'classification_loss': 0.9941551804542541}
2025-01-12 20:37:20,896 [INFO] Step[1450/4329]: training loss : 0.9694452464580536 TRAIN  loss dict:  {'classification_loss': 0.9694452464580536}
2025-01-12 20:37:32,519 [INFO] Step[1500/4329]: training loss : 0.9950522935390472 TRAIN  loss dict:  {'classification_loss': 0.9950522935390472}
2025-01-12 20:37:44,154 [INFO] Step[1550/4329]: training loss : 1.0461529099941254 TRAIN  loss dict:  {'classification_loss': 1.0461529099941254}
2025-01-12 20:37:55,795 [INFO] Step[1600/4329]: training loss : 1.004660691022873 TRAIN  loss dict:  {'classification_loss': 1.004660691022873}
2025-01-12 20:38:07,473 [INFO] Step[1650/4329]: training loss : 1.0031144964694976 TRAIN  loss dict:  {'classification_loss': 1.0031144964694976}
2025-01-12 20:38:19,114 [INFO] Step[1700/4329]: training loss : 0.9830845034122467 TRAIN  loss dict:  {'classification_loss': 0.9830845034122467}
2025-01-12 20:38:30,706 [INFO] Step[1750/4329]: training loss : 1.0065450406074523 TRAIN  loss dict:  {'classification_loss': 1.0065450406074523}
2025-01-12 20:38:42,309 [INFO] Step[1800/4329]: training loss : 1.0253118336200715 TRAIN  loss dict:  {'classification_loss': 1.0253118336200715}
2025-01-12 20:38:53,889 [INFO] Step[1850/4329]: training loss : 0.9987164771556855 TRAIN  loss dict:  {'classification_loss': 0.9987164771556855}
2025-01-12 20:39:05,440 [INFO] Step[1900/4329]: training loss : 0.9695776247978211 TRAIN  loss dict:  {'classification_loss': 0.9695776247978211}
2025-01-12 20:39:17,108 [INFO] Step[1950/4329]: training loss : 0.9923987007141113 TRAIN  loss dict:  {'classification_loss': 0.9923987007141113}
2025-01-12 20:39:28,746 [INFO] Step[2000/4329]: training loss : 0.9837602257728577 TRAIN  loss dict:  {'classification_loss': 0.9837602257728577}
2025-01-12 20:39:40,343 [INFO] Step[2050/4329]: training loss : 1.0393189895153045 TRAIN  loss dict:  {'classification_loss': 1.0393189895153045}
2025-01-12 20:39:51,937 [INFO] Step[2100/4329]: training loss : 1.0394527661800383 TRAIN  loss dict:  {'classification_loss': 1.0394527661800383}
2025-01-12 20:40:03,572 [INFO] Step[2150/4329]: training loss : 1.0135512948036194 TRAIN  loss dict:  {'classification_loss': 1.0135512948036194}
2025-01-12 20:40:15,169 [INFO] Step[2200/4329]: training loss : 0.9709791254997253 TRAIN  loss dict:  {'classification_loss': 0.9709791254997253}
2025-01-12 20:40:26,776 [INFO] Step[2250/4329]: training loss : 1.0317943251132966 TRAIN  loss dict:  {'classification_loss': 1.0317943251132966}
2025-01-12 20:40:38,399 [INFO] Step[2300/4329]: training loss : 1.0221561729907989 TRAIN  loss dict:  {'classification_loss': 1.0221561729907989}
2025-01-12 20:40:50,054 [INFO] Step[2350/4329]: training loss : 0.9956725442409515 TRAIN  loss dict:  {'classification_loss': 0.9956725442409515}
2025-01-12 20:41:01,680 [INFO] Step[2400/4329]: training loss : 0.9764210462570191 TRAIN  loss dict:  {'classification_loss': 0.9764210462570191}
2025-01-12 20:41:13,325 [INFO] Step[2450/4329]: training loss : 1.007365870475769 TRAIN  loss dict:  {'classification_loss': 1.007365870475769}
2025-01-12 20:41:24,952 [INFO] Step[2500/4329]: training loss : 1.040735193490982 TRAIN  loss dict:  {'classification_loss': 1.040735193490982}
2025-01-12 20:41:36,588 [INFO] Step[2550/4329]: training loss : 0.9496686339378357 TRAIN  loss dict:  {'classification_loss': 0.9496686339378357}
2025-01-12 20:41:48,202 [INFO] Step[2600/4329]: training loss : 0.9998600018024445 TRAIN  loss dict:  {'classification_loss': 0.9998600018024445}
2025-01-12 20:41:59,809 [INFO] Step[2650/4329]: training loss : 0.9942272639274597 TRAIN  loss dict:  {'classification_loss': 0.9942272639274597}
2025-01-12 20:42:11,406 [INFO] Step[2700/4329]: training loss : 1.0479055404663087 TRAIN  loss dict:  {'classification_loss': 1.0479055404663087}
2025-01-12 20:42:23,032 [INFO] Step[2750/4329]: training loss : 0.9885827136039734 TRAIN  loss dict:  {'classification_loss': 0.9885827136039734}
2025-01-12 20:42:34,668 [INFO] Step[2800/4329]: training loss : 0.9771851754188537 TRAIN  loss dict:  {'classification_loss': 0.9771851754188537}
2025-01-12 20:42:46,286 [INFO] Step[2850/4329]: training loss : 1.0235231256484985 TRAIN  loss dict:  {'classification_loss': 1.0235231256484985}
2025-01-12 20:42:57,914 [INFO] Step[2900/4329]: training loss : 1.048847234249115 TRAIN  loss dict:  {'classification_loss': 1.048847234249115}
2025-01-12 20:43:09,564 [INFO] Step[2950/4329]: training loss : 0.942536084651947 TRAIN  loss dict:  {'classification_loss': 0.942536084651947}
2025-01-12 20:43:21,164 [INFO] Step[3000/4329]: training loss : 1.0149306535720826 TRAIN  loss dict:  {'classification_loss': 1.0149306535720826}
2025-01-12 20:43:32,795 [INFO] Step[3050/4329]: training loss : 1.0413675391674042 TRAIN  loss dict:  {'classification_loss': 1.0413675391674042}
2025-01-12 20:43:44,395 [INFO] Step[3100/4329]: training loss : 0.979513304233551 TRAIN  loss dict:  {'classification_loss': 0.979513304233551}
2025-01-12 20:43:56,031 [INFO] Step[3150/4329]: training loss : 1.0098746132850647 TRAIN  loss dict:  {'classification_loss': 1.0098746132850647}
2025-01-12 20:44:07,701 [INFO] Step[3200/4329]: training loss : 1.0325407028198241 TRAIN  loss dict:  {'classification_loss': 1.0325407028198241}
2025-01-12 20:44:19,317 [INFO] Step[3250/4329]: training loss : 1.0293339109420776 TRAIN  loss dict:  {'classification_loss': 1.0293339109420776}
2025-01-12 20:44:31,010 [INFO] Step[3300/4329]: training loss : 0.9956759965419769 TRAIN  loss dict:  {'classification_loss': 0.9956759965419769}
2025-01-12 20:44:42,637 [INFO] Step[3350/4329]: training loss : 1.0482806301116943 TRAIN  loss dict:  {'classification_loss': 1.0482806301116943}
2025-01-12 20:44:54,242 [INFO] Step[3400/4329]: training loss : 1.0147199010849 TRAIN  loss dict:  {'classification_loss': 1.0147199010849}
2025-01-12 20:45:05,930 [INFO] Step[3450/4329]: training loss : 1.0482086777687072 TRAIN  loss dict:  {'classification_loss': 1.0482086777687072}
2025-01-12 20:45:17,559 [INFO] Step[3500/4329]: training loss : 0.9602978909015656 TRAIN  loss dict:  {'classification_loss': 0.9602978909015656}
2025-01-12 20:45:29,211 [INFO] Step[3550/4329]: training loss : 0.9938226675987244 TRAIN  loss dict:  {'classification_loss': 0.9938226675987244}
2025-01-12 20:45:40,845 [INFO] Step[3600/4329]: training loss : 1.0256267118453979 TRAIN  loss dict:  {'classification_loss': 1.0256267118453979}
2025-01-12 20:45:52,470 [INFO] Step[3650/4329]: training loss : 0.9788000440597534 TRAIN  loss dict:  {'classification_loss': 0.9788000440597534}
2025-01-12 20:46:04,212 [INFO] Step[3700/4329]: training loss : 1.0744762992858887 TRAIN  loss dict:  {'classification_loss': 1.0744762992858887}
2025-01-12 20:46:16,483 [INFO] Step[3750/4329]: training loss : 1.0528954565525055 TRAIN  loss dict:  {'classification_loss': 1.0528954565525055}
2025-01-12 20:46:28,713 [INFO] Step[3800/4329]: training loss : 0.980900593996048 TRAIN  loss dict:  {'classification_loss': 0.980900593996048}
2025-01-12 20:46:41,337 [INFO] Step[3850/4329]: training loss : 1.0003160262107849 TRAIN  loss dict:  {'classification_loss': 1.0003160262107849}
2025-01-12 20:46:56,997 [INFO] Step[3900/4329]: training loss : 0.9688982713222504 TRAIN  loss dict:  {'classification_loss': 0.9688982713222504}
2025-01-12 20:47:09,468 [INFO] Step[3950/4329]: training loss : 1.023447997570038 TRAIN  loss dict:  {'classification_loss': 1.023447997570038}
2025-01-12 20:47:21,398 [INFO] Step[4000/4329]: training loss : 0.9915101039409637 TRAIN  loss dict:  {'classification_loss': 0.9915101039409637}
2025-01-12 20:47:33,250 [INFO] Step[4050/4329]: training loss : 0.974941861629486 TRAIN  loss dict:  {'classification_loss': 0.974941861629486}
2025-01-12 20:47:44,874 [INFO] Step[4100/4329]: training loss : 1.0006821954250336 TRAIN  loss dict:  {'classification_loss': 1.0006821954250336}
2025-01-12 20:47:56,467 [INFO] Step[4150/4329]: training loss : 1.0175525319576264 TRAIN  loss dict:  {'classification_loss': 1.0175525319576264}
2025-01-12 20:48:08,108 [INFO] Step[4200/4329]: training loss : 1.0499935412406922 TRAIN  loss dict:  {'classification_loss': 1.0499935412406922}
2025-01-12 20:48:19,737 [INFO] Step[4250/4329]: training loss : 1.0248732960224152 TRAIN  loss dict:  {'classification_loss': 1.0248732960224152}
2025-01-12 20:48:31,339 [INFO] Step[4300/4329]: training loss : 1.0093812501430512 TRAIN  loss dict:  {'classification_loss': 1.0093812501430512}
2025-01-12 20:50:29,205 [INFO] Label accuracies statistics:
2025-01-12 20:50:29,205 [INFO] {0: 0.6666666666666666, 1: 0.8888888888888888, 2: 0.5833333333333334, 3: 0.8333333333333334, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.5833333333333334, 8: 0.5, 9: 0.9166666666666666, 10: 0.9166666666666666, 11: 0.75, 12: 0.5833333333333334, 13: 0.5, 14: 0.3333333333333333, 15: 0.4444444444444444, 16: 0.4166666666666667, 17: 0.5833333333333334, 18: 0.6666666666666666, 19: 0.75, 20: 0.5833333333333334, 21: 0.5833333333333334, 22: 0.75, 23: 1.0, 24: 0.8333333333333334, 25: 0.75, 26: 0.8333333333333334, 27: 0.6666666666666666, 28: 0.75, 29: 0.9166666666666666, 30: 0.5, 31: 0.75, 32: 0.6666666666666666, 33: 0.8333333333333334, 34: 0.9166666666666666, 35: 0.9166666666666666, 36: 0.4166666666666667, 37: 0.9166666666666666, 38: 1.0, 39: 1.0, 40: 0.8333333333333334, 41: 0.5, 42: 0.75, 43: 0.8333333333333334, 44: 0.5833333333333334, 45: 0.5, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.6666666666666666, 51: 0.8333333333333334, 52: 1.0, 53: 0.5, 54: 0.5833333333333334, 55: 0.6666666666666666, 56: 0.75, 57: 0.5833333333333334, 58: 0.6666666666666666, 59: 0.4166666666666667, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.5833333333333334, 64: 0.9166666666666666, 65: 1.0, 66: 0.5, 67: 0.5833333333333334, 68: 0.9166666666666666, 69: 0.6666666666666666, 70: 0.4166666666666667, 71: 0.4166666666666667, 72: 0.8333333333333334, 73: 0.8333333333333334, 74: 0.5833333333333334, 75: 1.0, 76: 0.5833333333333334, 77: 0.5833333333333334, 78: 1.0, 79: 0.5833333333333334, 80: 1.0, 81: 1.0, 82: 0.6666666666666666, 83: 0.6666666666666666, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.9166666666666666, 88: 0.4166666666666667, 89: 0.5, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 1.0, 96: 0.4166666666666667, 97: 0.5833333333333334, 98: 0.75, 99: 0.8666666666666667, 100: 0.8333333333333334, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5833333333333334, 108: 0.8333333333333334, 109: 0.8333333333333334, 110: 0.8333333333333334, 111: 1.0, 112: 0.8333333333333334, 113: 0.4166666666666667, 114: 0.5833333333333334, 115: 1.0, 116: 0.75, 117: 0.6666666666666666, 118: 1.0, 119: 0.6666666666666666, 120: 0.6666666666666666, 121: 0.75, 122: 0.9166666666666666, 123: 0.8333333333333334, 124: 0.9166666666666666, 125: 0.8333333333333334, 126: 0.8333333333333334, 127: 0.75, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 1.0, 132: 0.6666666666666666, 133: 1.0, 134: 0.6666666666666666, 135: 0.75, 136: 0.9166666666666666, 137: 1.0, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 0.6666666666666666, 141: 1.0, 142: 0.5833333333333334, 143: 1.0, 144: 0.5833333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 0.9166666666666666, 153: 0.9166666666666666, 154: 1.0, 155: 0.9166666666666666, 156: 0.9166666666666666, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.3333333333333333, 161: 0.8333333333333334, 162: 0.8333333333333334, 163: 1.0, 164: 0.75, 165: 0.5833333333333334, 166: 0.5833333333333334, 167: 0.9166666666666666, 168: 0.75, 169: 0.8333333333333334, 170: 1.0, 171: 0.75, 172: 1.0, 173: 0.6666666666666666, 174: 0.8333333333333334, 175: 0.9166666666666666, 176: 0.8333333333333334, 177: 0.5833333333333334, 178: 0.9166666666666666, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.5, 183: 0.8333333333333334, 184: 0.9166666666666666, 185: 0.9166666666666666, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.9166666666666666, 190: 0.5, 191: 0.4166666666666667, 192: 1.0, 193: 0.9166666666666666, 194: 0.8333333333333334, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.75}

2025-01-12 20:50:29,207 [INFO] [19] TRAIN  loss: 1.0027057136638964 acc: 0.9742799938395195
2025-01-12 20:50:29,207 [INFO] [19] TRAIN  loss dict: {'classification_loss': 1.0027057136638964}
2025-01-12 20:50:29,207 [INFO] [19] VALIDATION loss: 1.708049236975535 VALIDATION acc: 0.7697811447811448
2025-01-12 20:50:29,208 [INFO] [19] VALIDATION loss dict: {'classification_loss': 1.708049236975535}
2025-01-12 20:50:29,208 [INFO] 
2025-01-12 20:50:46,000 [INFO] Step[50/4329]: training loss : 0.9757696270942688 TRAIN  loss dict:  {'classification_loss': 0.9757696270942688}
2025-01-12 20:50:57,577 [INFO] Step[100/4329]: training loss : 0.9768195557594299 TRAIN  loss dict:  {'classification_loss': 0.9768195557594299}
2025-01-12 20:51:09,190 [INFO] Step[150/4329]: training loss : 0.9882465839385987 TRAIN  loss dict:  {'classification_loss': 0.9882465839385987}
2025-01-12 20:51:20,815 [INFO] Step[200/4329]: training loss : 0.9738389348983765 TRAIN  loss dict:  {'classification_loss': 0.9738389348983765}
2025-01-12 20:51:32,424 [INFO] Step[250/4329]: training loss : 1.012621772289276 TRAIN  loss dict:  {'classification_loss': 1.012621772289276}
2025-01-12 20:51:44,069 [INFO] Step[300/4329]: training loss : 0.9725164353847504 TRAIN  loss dict:  {'classification_loss': 0.9725164353847504}
2025-01-12 20:51:55,713 [INFO] Step[350/4329]: training loss : 0.9783612394332886 TRAIN  loss dict:  {'classification_loss': 0.9783612394332886}
2025-01-12 20:52:07,311 [INFO] Step[400/4329]: training loss : 0.9509467494487762 TRAIN  loss dict:  {'classification_loss': 0.9509467494487762}
2025-01-12 20:52:18,964 [INFO] Step[450/4329]: training loss : 0.9985983717441559 TRAIN  loss dict:  {'classification_loss': 0.9985983717441559}
2025-01-12 20:52:30,583 [INFO] Step[500/4329]: training loss : 0.9616493272781372 TRAIN  loss dict:  {'classification_loss': 0.9616493272781372}
2025-01-12 20:52:42,238 [INFO] Step[550/4329]: training loss : 0.9925786542892456 TRAIN  loss dict:  {'classification_loss': 0.9925786542892456}
2025-01-12 20:52:53,867 [INFO] Step[600/4329]: training loss : 1.0052160954475402 TRAIN  loss dict:  {'classification_loss': 1.0052160954475402}
2025-01-12 20:53:05,514 [INFO] Step[650/4329]: training loss : 0.9826604735851288 TRAIN  loss dict:  {'classification_loss': 0.9826604735851288}
2025-01-12 20:53:17,151 [INFO] Step[700/4329]: training loss : 0.9839367282390594 TRAIN  loss dict:  {'classification_loss': 0.9839367282390594}
2025-01-12 20:53:28,746 [INFO] Step[750/4329]: training loss : 0.9861412692070007 TRAIN  loss dict:  {'classification_loss': 0.9861412692070007}
2025-01-12 20:53:40,333 [INFO] Step[800/4329]: training loss : 0.9819588744640351 TRAIN  loss dict:  {'classification_loss': 0.9819588744640351}
2025-01-12 20:53:51,966 [INFO] Step[850/4329]: training loss : 0.9754815208911896 TRAIN  loss dict:  {'classification_loss': 0.9754815208911896}
2025-01-12 20:54:03,572 [INFO] Step[900/4329]: training loss : 0.9760111248493195 TRAIN  loss dict:  {'classification_loss': 0.9760111248493195}
2025-01-12 20:54:15,180 [INFO] Step[950/4329]: training loss : 1.0012443768978119 TRAIN  loss dict:  {'classification_loss': 1.0012443768978119}
2025-01-12 20:54:26,816 [INFO] Step[1000/4329]: training loss : 1.0220947718620301 TRAIN  loss dict:  {'classification_loss': 1.0220947718620301}
2025-01-12 20:54:38,445 [INFO] Step[1050/4329]: training loss : 0.9993780434131623 TRAIN  loss dict:  {'classification_loss': 0.9993780434131623}
2025-01-12 20:54:50,113 [INFO] Step[1100/4329]: training loss : 1.0120784640312195 TRAIN  loss dict:  {'classification_loss': 1.0120784640312195}
2025-01-12 20:55:01,769 [INFO] Step[1150/4329]: training loss : 0.9808943748474122 TRAIN  loss dict:  {'classification_loss': 0.9808943748474122}
2025-01-12 20:55:13,382 [INFO] Step[1200/4329]: training loss : 0.9740563833713531 TRAIN  loss dict:  {'classification_loss': 0.9740563833713531}
2025-01-12 20:55:25,018 [INFO] Step[1250/4329]: training loss : 1.0067152452468873 TRAIN  loss dict:  {'classification_loss': 1.0067152452468873}
2025-01-12 20:55:36,637 [INFO] Step[1300/4329]: training loss : 0.9852022194862365 TRAIN  loss dict:  {'classification_loss': 0.9852022194862365}
2025-01-12 20:55:48,253 [INFO] Step[1350/4329]: training loss : 0.9645223689079284 TRAIN  loss dict:  {'classification_loss': 0.9645223689079284}
2025-01-12 20:55:59,899 [INFO] Step[1400/4329]: training loss : 0.9470730650424958 TRAIN  loss dict:  {'classification_loss': 0.9470730650424958}
2025-01-12 20:56:11,510 [INFO] Step[1450/4329]: training loss : 0.9794293940067291 TRAIN  loss dict:  {'classification_loss': 0.9794293940067291}
2025-01-12 20:56:23,127 [INFO] Step[1500/4329]: training loss : 0.9439174056053161 TRAIN  loss dict:  {'classification_loss': 0.9439174056053161}
2025-01-12 20:56:34,748 [INFO] Step[1550/4329]: training loss : 0.9690315079689026 TRAIN  loss dict:  {'classification_loss': 0.9690315079689026}
2025-01-12 20:56:46,368 [INFO] Step[1600/4329]: training loss : 0.9938651549816132 TRAIN  loss dict:  {'classification_loss': 0.9938651549816132}
2025-01-12 20:56:58,013 [INFO] Step[1650/4329]: training loss : 0.9646499812602997 TRAIN  loss dict:  {'classification_loss': 0.9646499812602997}
2025-01-12 20:57:09,617 [INFO] Step[1700/4329]: training loss : 0.9497784852981568 TRAIN  loss dict:  {'classification_loss': 0.9497784852981568}
2025-01-12 20:57:21,243 [INFO] Step[1750/4329]: training loss : 1.0283757209777833 TRAIN  loss dict:  {'classification_loss': 1.0283757209777833}
2025-01-12 20:57:32,876 [INFO] Step[1800/4329]: training loss : 0.9702843487262726 TRAIN  loss dict:  {'classification_loss': 0.9702843487262726}
2025-01-12 20:57:44,541 [INFO] Step[1850/4329]: training loss : 0.9558592033386231 TRAIN  loss dict:  {'classification_loss': 0.9558592033386231}
2025-01-12 20:57:56,155 [INFO] Step[1900/4329]: training loss : 0.9781594550609589 TRAIN  loss dict:  {'classification_loss': 0.9781594550609589}
2025-01-12 20:58:07,798 [INFO] Step[1950/4329]: training loss : 0.9965546226501465 TRAIN  loss dict:  {'classification_loss': 0.9965546226501465}
2025-01-12 20:58:19,395 [INFO] Step[2000/4329]: training loss : 0.9923524796962738 TRAIN  loss dict:  {'classification_loss': 0.9923524796962738}
2025-01-12 20:58:31,235 [INFO] Step[2050/4329]: training loss : 0.969306218624115 TRAIN  loss dict:  {'classification_loss': 0.969306218624115}
2025-01-12 20:58:43,515 [INFO] Step[2100/4329]: training loss : 0.9874265134334564 TRAIN  loss dict:  {'classification_loss': 0.9874265134334564}
2025-01-12 20:58:55,728 [INFO] Step[2150/4329]: training loss : 0.9827371776103974 TRAIN  loss dict:  {'classification_loss': 0.9827371776103974}
2025-01-12 20:59:09,287 [INFO] Step[2200/4329]: training loss : 0.9970559203624725 TRAIN  loss dict:  {'classification_loss': 0.9970559203624725}
2025-01-12 20:59:22,375 [INFO] Step[2250/4329]: training loss : 0.978243225812912 TRAIN  loss dict:  {'classification_loss': 0.978243225812912}
2025-01-12 20:59:34,559 [INFO] Step[2300/4329]: training loss : 0.948263736963272 TRAIN  loss dict:  {'classification_loss': 0.948263736963272}
2025-01-12 20:59:46,402 [INFO] Step[2350/4329]: training loss : 0.9456696307659149 TRAIN  loss dict:  {'classification_loss': 0.9456696307659149}
2025-01-12 20:59:58,128 [INFO] Step[2400/4329]: training loss : 0.9737229669094085 TRAIN  loss dict:  {'classification_loss': 0.9737229669094085}
2025-01-12 21:00:09,772 [INFO] Step[2450/4329]: training loss : 0.9933277189731597 TRAIN  loss dict:  {'classification_loss': 0.9933277189731597}
2025-01-12 21:00:21,420 [INFO] Step[2500/4329]: training loss : 0.9928142547607421 TRAIN  loss dict:  {'classification_loss': 0.9928142547607421}
2025-01-12 21:00:33,062 [INFO] Step[2550/4329]: training loss : 0.9743839514255523 TRAIN  loss dict:  {'classification_loss': 0.9743839514255523}
2025-01-12 21:00:44,651 [INFO] Step[2600/4329]: training loss : 1.0117888629436493 TRAIN  loss dict:  {'classification_loss': 1.0117888629436493}
2025-01-12 21:00:56,274 [INFO] Step[2650/4329]: training loss : 0.9890188872814178 TRAIN  loss dict:  {'classification_loss': 0.9890188872814178}
2025-01-12 21:01:07,842 [INFO] Step[2700/4329]: training loss : 0.9875214850902557 TRAIN  loss dict:  {'classification_loss': 0.9875214850902557}
2025-01-12 21:01:19,471 [INFO] Step[2750/4329]: training loss : 1.0037705087661744 TRAIN  loss dict:  {'classification_loss': 1.0037705087661744}
2025-01-12 21:01:31,128 [INFO] Step[2800/4329]: training loss : 0.9603840804100037 TRAIN  loss dict:  {'classification_loss': 0.9603840804100037}
2025-01-12 21:01:42,759 [INFO] Step[2850/4329]: training loss : 1.0214063119888306 TRAIN  loss dict:  {'classification_loss': 1.0214063119888306}
2025-01-12 21:01:54,387 [INFO] Step[2900/4329]: training loss : 0.9697693240642548 TRAIN  loss dict:  {'classification_loss': 0.9697693240642548}
2025-01-12 21:02:06,008 [INFO] Step[2950/4329]: training loss : 0.980594630241394 TRAIN  loss dict:  {'classification_loss': 0.980594630241394}
2025-01-12 21:02:17,613 [INFO] Step[3000/4329]: training loss : 1.0077390730381013 TRAIN  loss dict:  {'classification_loss': 1.0077390730381013}
2025-01-12 21:02:29,237 [INFO] Step[3050/4329]: training loss : 1.0223450458049774 TRAIN  loss dict:  {'classification_loss': 1.0223450458049774}
2025-01-12 21:02:40,845 [INFO] Step[3100/4329]: training loss : 1.012652895450592 TRAIN  loss dict:  {'classification_loss': 1.012652895450592}
2025-01-12 21:02:52,421 [INFO] Step[3150/4329]: training loss : 0.999487156867981 TRAIN  loss dict:  {'classification_loss': 0.999487156867981}
2025-01-12 21:03:04,019 [INFO] Step[3200/4329]: training loss : 1.0154440355300904 TRAIN  loss dict:  {'classification_loss': 1.0154440355300904}
2025-01-12 21:03:15,638 [INFO] Step[3250/4329]: training loss : 1.0359482955932617 TRAIN  loss dict:  {'classification_loss': 1.0359482955932617}
2025-01-12 21:03:27,238 [INFO] Step[3300/4329]: training loss : 0.9543294024467468 TRAIN  loss dict:  {'classification_loss': 0.9543294024467468}
2025-01-12 21:03:38,828 [INFO] Step[3350/4329]: training loss : 1.0076756262779236 TRAIN  loss dict:  {'classification_loss': 1.0076756262779236}
2025-01-12 21:03:50,434 [INFO] Step[3400/4329]: training loss : 1.0153647840023041 TRAIN  loss dict:  {'classification_loss': 1.0153647840023041}
2025-01-12 21:04:02,027 [INFO] Step[3450/4329]: training loss : 1.0130199897289276 TRAIN  loss dict:  {'classification_loss': 1.0130199897289276}
2025-01-12 21:04:13,657 [INFO] Step[3500/4329]: training loss : 1.0051263511180877 TRAIN  loss dict:  {'classification_loss': 1.0051263511180877}
2025-01-12 21:04:25,249 [INFO] Step[3550/4329]: training loss : 0.9507962584495544 TRAIN  loss dict:  {'classification_loss': 0.9507962584495544}
2025-01-12 21:04:36,861 [INFO] Step[3600/4329]: training loss : 0.9661434185504914 TRAIN  loss dict:  {'classification_loss': 0.9661434185504914}
2025-01-12 21:04:48,460 [INFO] Step[3650/4329]: training loss : 0.9734962964057923 TRAIN  loss dict:  {'classification_loss': 0.9734962964057923}
2025-01-12 21:05:00,041 [INFO] Step[3700/4329]: training loss : 0.977346488237381 TRAIN  loss dict:  {'classification_loss': 0.977346488237381}
2025-01-12 21:05:11,629 [INFO] Step[3750/4329]: training loss : 1.0249317336082457 TRAIN  loss dict:  {'classification_loss': 1.0249317336082457}
2025-01-12 21:05:23,234 [INFO] Step[3800/4329]: training loss : 1.00905592918396 TRAIN  loss dict:  {'classification_loss': 1.00905592918396}
2025-01-12 21:05:34,849 [INFO] Step[3850/4329]: training loss : 0.9593177330493927 TRAIN  loss dict:  {'classification_loss': 0.9593177330493927}
2025-01-12 21:05:46,448 [INFO] Step[3900/4329]: training loss : 1.0116419649124146 TRAIN  loss dict:  {'classification_loss': 1.0116419649124146}
2025-01-12 21:05:58,031 [INFO] Step[3950/4329]: training loss : 0.9878631663322449 TRAIN  loss dict:  {'classification_loss': 0.9878631663322449}
2025-01-12 21:06:09,619 [INFO] Step[4000/4329]: training loss : 0.9892646431922912 TRAIN  loss dict:  {'classification_loss': 0.9892646431922912}
2025-01-12 21:06:21,214 [INFO] Step[4050/4329]: training loss : 0.964417849779129 TRAIN  loss dict:  {'classification_loss': 0.964417849779129}
2025-01-12 21:06:32,791 [INFO] Step[4100/4329]: training loss : 0.9444627785682678 TRAIN  loss dict:  {'classification_loss': 0.9444627785682678}
2025-01-12 21:06:44,404 [INFO] Step[4150/4329]: training loss : 0.9949327290058136 TRAIN  loss dict:  {'classification_loss': 0.9949327290058136}
2025-01-12 21:06:55,939 [INFO] Step[4200/4329]: training loss : 0.9817165946960449 TRAIN  loss dict:  {'classification_loss': 0.9817165946960449}
2025-01-12 21:07:07,556 [INFO] Step[4250/4329]: training loss : 0.9680345833301545 TRAIN  loss dict:  {'classification_loss': 0.9680345833301545}
2025-01-12 21:07:19,176 [INFO] Step[4300/4329]: training loss : 1.0157942008972167 TRAIN  loss dict:  {'classification_loss': 1.0157942008972167}
2025-01-12 21:09:17,911 [INFO] Label accuracies statistics:
2025-01-12 21:09:17,912 [INFO] {0: 0.5555555555555556, 1: 0.7777777777777778, 2: 0.5833333333333334, 3: 0.8333333333333334, 4: 0.4166666666666667, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.5, 8: 0.5, 9: 0.6666666666666666, 10: 1.0, 11: 1.0, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5833333333333334, 17: 0.25, 18: 0.6666666666666666, 19: 0.5833333333333334, 20: 0.4166666666666667, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.8333333333333334, 24: 0.9166666666666666, 25: 0.8333333333333334, 26: 0.9166666666666666, 27: 0.5, 28: 0.8333333333333334, 29: 1.0, 30: 0.5, 31: 0.6666666666666666, 32: 0.6666666666666666, 33: 0.8333333333333334, 34: 1.0, 35: 0.8333333333333334, 36: 0.4166666666666667, 37: 1.0, 38: 0.8333333333333334, 39: 1.0, 40: 0.9166666666666666, 41: 0.3333333333333333, 42: 0.9166666666666666, 43: 0.8333333333333334, 44: 0.3333333333333333, 45: 0.5833333333333334, 46: 1.0, 47: 0.9166666666666666, 48: 0.9166666666666666, 49: 0.9166666666666666, 50: 0.6666666666666666, 51: 0.6666666666666666, 52: 1.0, 53: 0.5833333333333334, 54: 0.5, 55: 0.5833333333333334, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.6666666666666666, 59: 0.5833333333333334, 60: 0.6666666666666666, 61: 0.8333333333333334, 62: 0.8333333333333334, 63: 0.4166666666666667, 64: 1.0, 65: 1.0, 66: 0.5833333333333334, 67: 0.8333333333333334, 68: 0.9166666666666666, 69: 0.5833333333333334, 70: 0.4166666666666667, 71: 0.4166666666666667, 72: 0.6666666666666666, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.5833333333333334, 77: 0.6666666666666666, 78: 0.9166666666666666, 79: 0.5, 80: 0.9166666666666666, 81: 1.0, 82: 0.8333333333333334, 83: 0.5, 84: 0.4166666666666667, 85: 0.6666666666666666, 86: 0.5833333333333334, 87: 0.8333333333333334, 88: 0.75, 89: 0.4166666666666667, 90: 0.25, 91: 0.8333333333333334, 92: 1.0, 93: 1.0, 94: 0.5, 95: 0.9166666666666666, 96: 0.5833333333333334, 97: 0.5, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.9166666666666666, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.9166666666666666, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.8333333333333334, 111: 1.0, 112: 0.75, 113: 0.75, 114: 0.3333333333333333, 115: 0.9166666666666666, 116: 0.6666666666666666, 117: 0.75, 118: 0.9166666666666666, 119: 0.6666666666666666, 120: 0.6666666666666666, 121: 0.6666666666666666, 122: 0.8333333333333334, 123: 0.75, 124: 0.8333333333333334, 125: 0.75, 126: 0.9166666666666666, 127: 0.75, 128: 1.0, 129: 0.8333333333333334, 130: 0.75, 131: 0.75, 132: 0.75, 133: 1.0, 134: 0.5833333333333334, 135: 1.0, 136: 0.9166666666666666, 137: 0.8333333333333334, 138: 0.8333333333333334, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.9166666666666666, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 0.6666666666666666, 153: 0.9166666666666666, 154: 1.0, 155: 0.9166666666666666, 156: 0.4166666666666667, 157: 0.5833333333333334, 158: 0.4444444444444444, 159: 0.9166666666666666, 160: 0.25, 161: 0.8333333333333334, 162: 0.75, 163: 0.9166666666666666, 164: 0.75, 165: 0.8333333333333334, 166: 0.5, 167: 0.5833333333333334, 168: 0.8333333333333334, 169: 0.9166666666666666, 170: 0.9166666666666666, 171: 0.4166666666666667, 172: 1.0, 173: 0.8333333333333334, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 0.75, 177: 0.6666666666666666, 178: 0.8333333333333334, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.3333333333333333, 183: 0.8333333333333334, 184: 0.75, 185: 1.0, 186: 0.5833333333333334, 187: 0.9166666666666666, 188: 0.5, 189: 1.0, 190: 0.5833333333333334, 191: 0.3333333333333333, 192: 0.9166666666666666, 193: 0.8333333333333334, 194: 0.9166666666666666, 195: 0.6666666666666666, 196: 0.8333333333333334, 197: 0.75, 198: 0.5833333333333334}

2025-01-12 21:09:17,917 [INFO] [20] TRAIN  loss: 0.98590088760806 acc: 0.9789003542276298
2025-01-12 21:09:17,917 [INFO] [20] TRAIN  loss dict: {'classification_loss': 0.98590088760806}
2025-01-12 21:09:17,917 [INFO] [20] VALIDATION loss: 1.8023394909169939 VALIDATION acc: 0.7457912457912458
2025-01-12 21:09:17,917 [INFO] [20] VALIDATION loss dict: {'classification_loss': 1.8023394909169939}
2025-01-12 21:09:17,918 [INFO] 
2025-01-12 21:09:35,184 [INFO] Step[50/4329]: training loss : 1.0007490861415862 TRAIN  loss dict:  {'classification_loss': 1.0007490861415862}
2025-01-12 21:09:46,791 [INFO] Step[100/4329]: training loss : 1.0311221992969513 TRAIN  loss dict:  {'classification_loss': 1.0311221992969513}
2025-01-12 21:09:58,405 [INFO] Step[150/4329]: training loss : 0.9557185494899749 TRAIN  loss dict:  {'classification_loss': 0.9557185494899749}
2025-01-12 21:10:10,040 [INFO] Step[200/4329]: training loss : 0.9540362763404846 TRAIN  loss dict:  {'classification_loss': 0.9540362763404846}
2025-01-12 21:10:21,722 [INFO] Step[250/4329]: training loss : 0.9653711569309235 TRAIN  loss dict:  {'classification_loss': 0.9653711569309235}
2025-01-12 21:10:33,415 [INFO] Step[300/4329]: training loss : 0.950957932472229 TRAIN  loss dict:  {'classification_loss': 0.950957932472229}
2025-01-12 21:10:45,378 [INFO] Step[350/4329]: training loss : 0.9670439743995667 TRAIN  loss dict:  {'classification_loss': 0.9670439743995667}
2025-01-12 21:10:57,720 [INFO] Step[400/4329]: training loss : 0.9742556631565094 TRAIN  loss dict:  {'classification_loss': 0.9742556631565094}
2025-01-12 21:11:10,158 [INFO] Step[450/4329]: training loss : 0.9337398862838745 TRAIN  loss dict:  {'classification_loss': 0.9337398862838745}
2025-01-12 21:11:23,737 [INFO] Step[500/4329]: training loss : 0.964271399974823 TRAIN  loss dict:  {'classification_loss': 0.964271399974823}
2025-01-12 21:11:36,840 [INFO] Step[550/4329]: training loss : 0.9743827629089356 TRAIN  loss dict:  {'classification_loss': 0.9743827629089356}
2025-01-12 21:11:49,073 [INFO] Step[600/4329]: training loss : 0.9726777219772339 TRAIN  loss dict:  {'classification_loss': 0.9726777219772339}
2025-01-12 21:12:01,055 [INFO] Step[650/4329]: training loss : 0.955441609621048 TRAIN  loss dict:  {'classification_loss': 0.955441609621048}
2025-01-12 21:12:12,930 [INFO] Step[700/4329]: training loss : 0.9295470798015595 TRAIN  loss dict:  {'classification_loss': 0.9295470798015595}
2025-01-12 21:12:24,559 [INFO] Step[750/4329]: training loss : 0.9781810009479522 TRAIN  loss dict:  {'classification_loss': 0.9781810009479522}
2025-01-12 21:12:36,182 [INFO] Step[800/4329]: training loss : 0.961760630607605 TRAIN  loss dict:  {'classification_loss': 0.961760630607605}
2025-01-12 21:12:47,787 [INFO] Step[850/4329]: training loss : 0.9730769276618958 TRAIN  loss dict:  {'classification_loss': 0.9730769276618958}
2025-01-12 21:12:59,434 [INFO] Step[900/4329]: training loss : 1.026771764755249 TRAIN  loss dict:  {'classification_loss': 1.026771764755249}
2025-01-12 21:13:11,044 [INFO] Step[950/4329]: training loss : 1.0141398978233338 TRAIN  loss dict:  {'classification_loss': 1.0141398978233338}
2025-01-12 21:13:22,709 [INFO] Step[1000/4329]: training loss : 0.9597778069972992 TRAIN  loss dict:  {'classification_loss': 0.9597778069972992}
2025-01-12 21:13:34,335 [INFO] Step[1050/4329]: training loss : 0.93185112118721 TRAIN  loss dict:  {'classification_loss': 0.93185112118721}
2025-01-12 21:13:45,967 [INFO] Step[1100/4329]: training loss : 0.9650831294059753 TRAIN  loss dict:  {'classification_loss': 0.9650831294059753}
2025-01-12 21:13:57,577 [INFO] Step[1150/4329]: training loss : 0.99458327293396 TRAIN  loss dict:  {'classification_loss': 0.99458327293396}
2025-01-12 21:14:09,203 [INFO] Step[1200/4329]: training loss : 0.9384744393825531 TRAIN  loss dict:  {'classification_loss': 0.9384744393825531}
2025-01-12 21:14:20,860 [INFO] Step[1250/4329]: training loss : 0.9438697755336761 TRAIN  loss dict:  {'classification_loss': 0.9438697755336761}
2025-01-12 21:14:32,522 [INFO] Step[1300/4329]: training loss : 0.9515895760059356 TRAIN  loss dict:  {'classification_loss': 0.9515895760059356}
2025-01-12 21:14:44,128 [INFO] Step[1350/4329]: training loss : 0.9777088046073914 TRAIN  loss dict:  {'classification_loss': 0.9777088046073914}
2025-01-12 21:14:55,710 [INFO] Step[1400/4329]: training loss : 0.9411068058013916 TRAIN  loss dict:  {'classification_loss': 0.9411068058013916}
2025-01-12 21:15:07,329 [INFO] Step[1450/4329]: training loss : 0.9718216288089753 TRAIN  loss dict:  {'classification_loss': 0.9718216288089753}
2025-01-12 21:15:18,919 [INFO] Step[1500/4329]: training loss : 0.9847741889953613 TRAIN  loss dict:  {'classification_loss': 0.9847741889953613}
2025-01-12 21:15:30,562 [INFO] Step[1550/4329]: training loss : 0.9457656359672546 TRAIN  loss dict:  {'classification_loss': 0.9457656359672546}
2025-01-12 21:15:42,161 [INFO] Step[1600/4329]: training loss : 0.9577743434906005 TRAIN  loss dict:  {'classification_loss': 0.9577743434906005}
2025-01-12 21:15:53,764 [INFO] Step[1650/4329]: training loss : 0.9532883262634277 TRAIN  loss dict:  {'classification_loss': 0.9532883262634277}
2025-01-12 21:16:05,384 [INFO] Step[1700/4329]: training loss : 0.9660432386398315 TRAIN  loss dict:  {'classification_loss': 0.9660432386398315}
2025-01-12 21:16:16,993 [INFO] Step[1750/4329]: training loss : 0.9874011969566345 TRAIN  loss dict:  {'classification_loss': 0.9874011969566345}
2025-01-12 21:16:28,569 [INFO] Step[1800/4329]: training loss : 0.9399345469474792 TRAIN  loss dict:  {'classification_loss': 0.9399345469474792}
2025-01-12 21:16:40,210 [INFO] Step[1850/4329]: training loss : 0.9602679681777954 TRAIN  loss dict:  {'classification_loss': 0.9602679681777954}
2025-01-12 21:16:51,820 [INFO] Step[1900/4329]: training loss : 0.9457096815109253 TRAIN  loss dict:  {'classification_loss': 0.9457096815109253}
2025-01-12 21:17:03,483 [INFO] Step[1950/4329]: training loss : 0.9910971224308014 TRAIN  loss dict:  {'classification_loss': 0.9910971224308014}
2025-01-12 21:17:15,108 [INFO] Step[2000/4329]: training loss : 0.9676213788986207 TRAIN  loss dict:  {'classification_loss': 0.9676213788986207}
2025-01-12 21:17:26,728 [INFO] Step[2050/4329]: training loss : 0.9496305418014527 TRAIN  loss dict:  {'classification_loss': 0.9496305418014527}
2025-01-12 21:17:38,339 [INFO] Step[2100/4329]: training loss : 0.9711394381523132 TRAIN  loss dict:  {'classification_loss': 0.9711394381523132}
2025-01-12 21:17:49,980 [INFO] Step[2150/4329]: training loss : 0.9475173270702362 TRAIN  loss dict:  {'classification_loss': 0.9475173270702362}
2025-01-12 21:18:01,599 [INFO] Step[2200/4329]: training loss : 0.9926936995983123 TRAIN  loss dict:  {'classification_loss': 0.9926936995983123}
2025-01-12 21:18:13,228 [INFO] Step[2250/4329]: training loss : 0.9453483700752259 TRAIN  loss dict:  {'classification_loss': 0.9453483700752259}
2025-01-12 21:18:24,828 [INFO] Step[2300/4329]: training loss : 0.9480325746536254 TRAIN  loss dict:  {'classification_loss': 0.9480325746536254}
2025-01-12 21:18:36,444 [INFO] Step[2350/4329]: training loss : 0.9619920194149018 TRAIN  loss dict:  {'classification_loss': 0.9619920194149018}
2025-01-12 21:18:48,047 [INFO] Step[2400/4329]: training loss : 0.9789218604564667 TRAIN  loss dict:  {'classification_loss': 0.9789218604564667}
2025-01-12 21:18:59,653 [INFO] Step[2450/4329]: training loss : 1.0136790943145753 TRAIN  loss dict:  {'classification_loss': 1.0136790943145753}
2025-01-12 21:19:11,254 [INFO] Step[2500/4329]: training loss : 0.9546736562252045 TRAIN  loss dict:  {'classification_loss': 0.9546736562252045}
2025-01-12 21:19:22,859 [INFO] Step[2550/4329]: training loss : 0.9657736325263977 TRAIN  loss dict:  {'classification_loss': 0.9657736325263977}
2025-01-12 21:19:34,507 [INFO] Step[2600/4329]: training loss : 0.9401329112052917 TRAIN  loss dict:  {'classification_loss': 0.9401329112052917}
2025-01-12 21:19:46,177 [INFO] Step[2650/4329]: training loss : 0.9519386970996857 TRAIN  loss dict:  {'classification_loss': 0.9519386970996857}
2025-01-12 21:19:57,788 [INFO] Step[2700/4329]: training loss : 0.9452499771118164 TRAIN  loss dict:  {'classification_loss': 0.9452499771118164}
2025-01-12 21:20:09,374 [INFO] Step[2750/4329]: training loss : 0.9623991775512696 TRAIN  loss dict:  {'classification_loss': 0.9623991775512696}
2025-01-12 21:20:20,985 [INFO] Step[2800/4329]: training loss : 1.0013634288311004 TRAIN  loss dict:  {'classification_loss': 1.0013634288311004}
2025-01-12 21:20:32,642 [INFO] Step[2850/4329]: training loss : 0.9675982332229615 TRAIN  loss dict:  {'classification_loss': 0.9675982332229615}
2025-01-12 21:20:44,239 [INFO] Step[2900/4329]: training loss : 1.0313946676254273 TRAIN  loss dict:  {'classification_loss': 1.0313946676254273}
2025-01-12 21:20:55,836 [INFO] Step[2950/4329]: training loss : 0.9635340893268585 TRAIN  loss dict:  {'classification_loss': 0.9635340893268585}
2025-01-12 21:21:07,473 [INFO] Step[3000/4329]: training loss : 0.9511973655223847 TRAIN  loss dict:  {'classification_loss': 0.9511973655223847}
2025-01-12 21:21:19,089 [INFO] Step[3050/4329]: training loss : 0.9515628826618194 TRAIN  loss dict:  {'classification_loss': 0.9515628826618194}
2025-01-12 21:21:30,698 [INFO] Step[3100/4329]: training loss : 0.9652492415904999 TRAIN  loss dict:  {'classification_loss': 0.9652492415904999}
2025-01-12 21:21:42,341 [INFO] Step[3150/4329]: training loss : 0.9620819139480591 TRAIN  loss dict:  {'classification_loss': 0.9620819139480591}
2025-01-12 21:21:53,973 [INFO] Step[3200/4329]: training loss : 0.9517648148536683 TRAIN  loss dict:  {'classification_loss': 0.9517648148536683}
2025-01-12 21:22:05,584 [INFO] Step[3250/4329]: training loss : 0.9669105303287506 TRAIN  loss dict:  {'classification_loss': 0.9669105303287506}
2025-01-12 21:22:17,198 [INFO] Step[3300/4329]: training loss : 0.9498176991939544 TRAIN  loss dict:  {'classification_loss': 0.9498176991939544}
2025-01-12 21:22:28,819 [INFO] Step[3350/4329]: training loss : 0.9631939816474915 TRAIN  loss dict:  {'classification_loss': 0.9631939816474915}
2025-01-12 21:22:40,454 [INFO] Step[3400/4329]: training loss : 0.9717115604877472 TRAIN  loss dict:  {'classification_loss': 0.9717115604877472}
2025-01-12 21:22:52,111 [INFO] Step[3450/4329]: training loss : 0.9938460469245911 TRAIN  loss dict:  {'classification_loss': 0.9938460469245911}
2025-01-12 21:23:04,122 [INFO] Step[3500/4329]: training loss : 0.9594440031051635 TRAIN  loss dict:  {'classification_loss': 0.9594440031051635}
2025-01-12 21:23:16,393 [INFO] Step[3550/4329]: training loss : 0.9511593246459961 TRAIN  loss dict:  {'classification_loss': 0.9511593246459961}
2025-01-12 21:23:28,784 [INFO] Step[3600/4329]: training loss : 0.9791146516799927 TRAIN  loss dict:  {'classification_loss': 0.9791146516799927}
2025-01-12 21:23:42,333 [INFO] Step[3650/4329]: training loss : 0.9355343711376191 TRAIN  loss dict:  {'classification_loss': 0.9355343711376191}
2025-01-12 21:23:57,985 [INFO] Step[3700/4329]: training loss : 0.9618719923496246 TRAIN  loss dict:  {'classification_loss': 0.9618719923496246}
2025-01-12 21:24:09,990 [INFO] Step[3750/4329]: training loss : 0.965221666097641 TRAIN  loss dict:  {'classification_loss': 0.965221666097641}
2025-01-12 21:24:21,868 [INFO] Step[3800/4329]: training loss : 0.9225856411457062 TRAIN  loss dict:  {'classification_loss': 0.9225856411457062}
2025-01-12 21:24:33,497 [INFO] Step[3850/4329]: training loss : 0.9506953477859497 TRAIN  loss dict:  {'classification_loss': 0.9506953477859497}
2025-01-12 21:24:45,127 [INFO] Step[3900/4329]: training loss : 0.94980313539505 TRAIN  loss dict:  {'classification_loss': 0.94980313539505}
2025-01-12 21:24:56,723 [INFO] Step[3950/4329]: training loss : 0.9886239469051361 TRAIN  loss dict:  {'classification_loss': 0.9886239469051361}
2025-01-12 21:25:08,309 [INFO] Step[4000/4329]: training loss : 0.9533548069000244 TRAIN  loss dict:  {'classification_loss': 0.9533548069000244}
2025-01-12 21:25:19,971 [INFO] Step[4050/4329]: training loss : 0.9494417500495911 TRAIN  loss dict:  {'classification_loss': 0.9494417500495911}
2025-01-12 21:25:31,590 [INFO] Step[4100/4329]: training loss : 0.9460099291801453 TRAIN  loss dict:  {'classification_loss': 0.9460099291801453}
2025-01-12 21:25:43,235 [INFO] Step[4150/4329]: training loss : 0.9456244552135468 TRAIN  loss dict:  {'classification_loss': 0.9456244552135468}
2025-01-12 21:25:54,897 [INFO] Step[4200/4329]: training loss : 0.9361051452159882 TRAIN  loss dict:  {'classification_loss': 0.9361051452159882}
2025-01-12 21:26:06,523 [INFO] Step[4250/4329]: training loss : 0.9985641276836396 TRAIN  loss dict:  {'classification_loss': 0.9985641276836396}
2025-01-12 21:26:18,146 [INFO] Step[4300/4329]: training loss : 0.943562638759613 TRAIN  loss dict:  {'classification_loss': 0.943562638759613}
2025-01-12 21:28:16,770 [INFO] Label accuracies statistics:
2025-01-12 21:28:16,770 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5833333333333334, 3: 0.75, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.3333333333333333, 8: 0.5, 9: 0.75, 10: 1.0, 11: 1.0, 12: 0.4166666666666667, 13: 0.5, 14: 0.5833333333333334, 15: 0.6666666666666666, 16: 0.5833333333333334, 17: 0.6666666666666666, 18: 0.5833333333333334, 19: 0.5833333333333334, 20: 0.6666666666666666, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 1.0, 24: 1.0, 25: 0.9166666666666666, 26: 0.8333333333333334, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5833333333333334, 31: 0.6666666666666666, 32: 0.6666666666666666, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 0.8333333333333334, 36: 0.6666666666666666, 37: 1.0, 38: 0.9166666666666666, 39: 0.9166666666666666, 40: 0.9166666666666666, 41: 0.5, 42: 0.8333333333333334, 43: 0.75, 44: 0.5833333333333334, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5833333333333334, 55: 0.6666666666666666, 56: 0.6666666666666666, 57: 0.75, 58: 0.5833333333333334, 59: 0.8333333333333334, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.9166666666666666, 66: 0.6666666666666666, 67: 1.0, 68: 0.75, 69: 0.5833333333333334, 70: 0.25, 71: 0.5, 72: 0.8333333333333334, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.5833333333333334, 77: 0.5833333333333334, 78: 1.0, 79: 0.5833333333333334, 80: 1.0, 81: 1.0, 82: 0.6666666666666666, 83: 0.4166666666666667, 84: 0.5, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.5, 89: 0.5, 90: 0.3333333333333333, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 0.8333333333333334, 96: 0.4166666666666667, 97: 0.8333333333333334, 98: 0.8333333333333334, 99: 0.9333333333333333, 100: 0.9166666666666666, 101: 0.75, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.8333333333333334, 108: 0.9166666666666666, 109: 0.75, 110: 0.8333333333333334, 111: 1.0, 112: 0.9166666666666666, 113: 0.75, 114: 0.3333333333333333, 115: 0.8333333333333334, 116: 0.8333333333333334, 117: 0.75, 118: 0.9166666666666666, 119: 0.8333333333333334, 120: 0.8333333333333334, 121: 0.75, 122: 0.8333333333333334, 123: 0.9166666666666666, 124: 1.0, 125: 0.8333333333333334, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 0.9166666666666666, 132: 0.3333333333333333, 133: 1.0, 134: 0.8333333333333334, 135: 1.0, 136: 0.9166666666666666, 137: 0.8333333333333334, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 0.9166666666666666, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.6666666666666666, 149: 1.0, 150: 0.3333333333333333, 151: 0.9166666666666666, 152: 0.9166666666666666, 153: 0.8333333333333334, 154: 1.0, 155: 0.9166666666666666, 156: 0.4166666666666667, 157: 0.5833333333333334, 158: 0.6666666666666666, 159: 0.9166666666666666, 160: 0.25, 161: 0.8333333333333334, 162: 0.9166666666666666, 163: 1.0, 164: 0.8333333333333334, 165: 0.9166666666666666, 166: 0.75, 167: 0.8333333333333334, 168: 0.8333333333333334, 169: 0.8333333333333334, 170: 1.0, 171: 0.6666666666666666, 172: 1.0, 173: 0.9166666666666666, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 0.9166666666666666, 177: 0.8333333333333334, 178: 0.8333333333333334, 179: 0.0, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.5, 183: 0.5833333333333334, 184: 0.5833333333333334, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.6666666666666666, 189: 1.0, 190: 0.5833333333333334, 191: 0.4166666666666667, 192: 1.0, 193: 0.8333333333333334, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.9166666666666666, 198: 0.6666666666666666}

2025-01-12 21:28:16,773 [INFO] [21] TRAIN  loss: 0.9638453329317177 acc: 0.9854458647774527
2025-01-12 21:28:16,773 [INFO] [21] TRAIN  loss dict: {'classification_loss': 0.9638453329317177}
2025-01-12 21:28:16,773 [INFO] [21] VALIDATION loss: 1.6840861628603454 VALIDATION acc: 0.781986531986532
2025-01-12 21:28:16,773 [INFO] [21] VALIDATION loss dict: {'classification_loss': 1.6840861628603454}
2025-01-12 21:28:16,773 [INFO] 
2025-01-12 21:28:33,854 [INFO] Step[50/4329]: training loss : 0.9511457884311676 TRAIN  loss dict:  {'classification_loss': 0.9511457884311676}
2025-01-12 21:28:45,367 [INFO] Step[100/4329]: training loss : 0.9807090556621552 TRAIN  loss dict:  {'classification_loss': 0.9807090556621552}
2025-01-12 21:28:56,965 [INFO] Step[150/4329]: training loss : 0.9551342785358429 TRAIN  loss dict:  {'classification_loss': 0.9551342785358429}
2025-01-12 21:29:08,539 [INFO] Step[200/4329]: training loss : 0.9257867407798767 TRAIN  loss dict:  {'classification_loss': 0.9257867407798767}
2025-01-12 21:29:20,183 [INFO] Step[250/4329]: training loss : 0.9299467575550079 TRAIN  loss dict:  {'classification_loss': 0.9299467575550079}
2025-01-12 21:29:31,841 [INFO] Step[300/4329]: training loss : 0.9457781565189362 TRAIN  loss dict:  {'classification_loss': 0.9457781565189362}
2025-01-12 21:29:43,487 [INFO] Step[350/4329]: training loss : 0.9288924503326416 TRAIN  loss dict:  {'classification_loss': 0.9288924503326416}
2025-01-12 21:29:55,108 [INFO] Step[400/4329]: training loss : 0.9579634881019592 TRAIN  loss dict:  {'classification_loss': 0.9579634881019592}
2025-01-12 21:30:06,713 [INFO] Step[450/4329]: training loss : 0.9463169741630554 TRAIN  loss dict:  {'classification_loss': 0.9463169741630554}
2025-01-12 21:30:18,346 [INFO] Step[500/4329]: training loss : 0.9584806954860687 TRAIN  loss dict:  {'classification_loss': 0.9584806954860687}
2025-01-12 21:30:30,009 [INFO] Step[550/4329]: training loss : 0.9984450387954712 TRAIN  loss dict:  {'classification_loss': 0.9984450387954712}
2025-01-12 21:30:41,651 [INFO] Step[600/4329]: training loss : 0.9523211455345154 TRAIN  loss dict:  {'classification_loss': 0.9523211455345154}
2025-01-12 21:30:53,310 [INFO] Step[650/4329]: training loss : 0.9378727316856384 TRAIN  loss dict:  {'classification_loss': 0.9378727316856384}
2025-01-12 21:31:04,891 [INFO] Step[700/4329]: training loss : 0.9907611060142517 TRAIN  loss dict:  {'classification_loss': 0.9907611060142517}
2025-01-12 21:31:16,534 [INFO] Step[750/4329]: training loss : 0.9611867940425873 TRAIN  loss dict:  {'classification_loss': 0.9611867940425873}
2025-01-12 21:31:28,140 [INFO] Step[800/4329]: training loss : 0.9600058960914611 TRAIN  loss dict:  {'classification_loss': 0.9600058960914611}
2025-01-12 21:31:39,802 [INFO] Step[850/4329]: training loss : 0.9279941892623902 TRAIN  loss dict:  {'classification_loss': 0.9279941892623902}
2025-01-12 21:31:51,442 [INFO] Step[900/4329]: training loss : 0.9242394876480102 TRAIN  loss dict:  {'classification_loss': 0.9242394876480102}
2025-01-12 21:32:03,093 [INFO] Step[950/4329]: training loss : 0.9425794494152069 TRAIN  loss dict:  {'classification_loss': 0.9425794494152069}
2025-01-12 21:32:14,699 [INFO] Step[1000/4329]: training loss : 0.9432487547397613 TRAIN  loss dict:  {'classification_loss': 0.9432487547397613}
2025-01-12 21:32:26,313 [INFO] Step[1050/4329]: training loss : 0.9435524201393127 TRAIN  loss dict:  {'classification_loss': 0.9435524201393127}
2025-01-12 21:32:37,974 [INFO] Step[1100/4329]: training loss : 0.9943056058883667 TRAIN  loss dict:  {'classification_loss': 0.9943056058883667}
2025-01-12 21:32:49,635 [INFO] Step[1150/4329]: training loss : 0.9334920597076416 TRAIN  loss dict:  {'classification_loss': 0.9334920597076416}
2025-01-12 21:33:01,269 [INFO] Step[1200/4329]: training loss : 0.9225322043895722 TRAIN  loss dict:  {'classification_loss': 0.9225322043895722}
2025-01-12 21:33:12,950 [INFO] Step[1250/4329]: training loss : 0.9569550323486328 TRAIN  loss dict:  {'classification_loss': 0.9569550323486328}
2025-01-12 21:33:24,579 [INFO] Step[1300/4329]: training loss : 0.9174185264110565 TRAIN  loss dict:  {'classification_loss': 0.9174185264110565}
2025-01-12 21:33:36,225 [INFO] Step[1350/4329]: training loss : 0.9268593597412109 TRAIN  loss dict:  {'classification_loss': 0.9268593597412109}
2025-01-12 21:33:47,842 [INFO] Step[1400/4329]: training loss : 0.9977268624305725 TRAIN  loss dict:  {'classification_loss': 0.9977268624305725}
2025-01-12 21:33:59,446 [INFO] Step[1450/4329]: training loss : 0.960470688343048 TRAIN  loss dict:  {'classification_loss': 0.960470688343048}
2025-01-12 21:34:11,043 [INFO] Step[1500/4329]: training loss : 0.9466851735115052 TRAIN  loss dict:  {'classification_loss': 0.9466851735115052}
2025-01-12 21:34:22,660 [INFO] Step[1550/4329]: training loss : 0.9335716760158539 TRAIN  loss dict:  {'classification_loss': 0.9335716760158539}
2025-01-12 21:34:34,305 [INFO] Step[1600/4329]: training loss : 0.9353472602367401 TRAIN  loss dict:  {'classification_loss': 0.9353472602367401}
2025-01-12 21:34:45,932 [INFO] Step[1650/4329]: training loss : 0.987882559299469 TRAIN  loss dict:  {'classification_loss': 0.987882559299469}
2025-01-12 21:34:57,556 [INFO] Step[1700/4329]: training loss : 0.9310853433609009 TRAIN  loss dict:  {'classification_loss': 0.9310853433609009}
2025-01-12 21:35:09,167 [INFO] Step[1750/4329]: training loss : 0.9339456343650818 TRAIN  loss dict:  {'classification_loss': 0.9339456343650818}
2025-01-12 21:35:20,964 [INFO] Step[1800/4329]: training loss : 0.9536001896858215 TRAIN  loss dict:  {'classification_loss': 0.9536001896858215}
2025-01-12 21:35:33,373 [INFO] Step[1850/4329]: training loss : 0.9819146299362183 TRAIN  loss dict:  {'classification_loss': 0.9819146299362183}
2025-01-12 21:35:45,648 [INFO] Step[1900/4329]: training loss : 0.9454862749576569 TRAIN  loss dict:  {'classification_loss': 0.9454862749576569}
2025-01-12 21:35:58,448 [INFO] Step[1950/4329]: training loss : 0.977669804096222 TRAIN  loss dict:  {'classification_loss': 0.977669804096222}
2025-01-12 21:36:11,826 [INFO] Step[2000/4329]: training loss : 0.9274153792858124 TRAIN  loss dict:  {'classification_loss': 0.9274153792858124}
2025-01-12 21:36:24,776 [INFO] Step[2050/4329]: training loss : 0.9219572532176972 TRAIN  loss dict:  {'classification_loss': 0.9219572532176972}
2025-01-12 21:36:36,709 [INFO] Step[2100/4329]: training loss : 0.9556069648265839 TRAIN  loss dict:  {'classification_loss': 0.9556069648265839}
2025-01-12 21:36:48,650 [INFO] Step[2150/4329]: training loss : 0.9952443325519562 TRAIN  loss dict:  {'classification_loss': 0.9952443325519562}
2025-01-12 21:37:00,241 [INFO] Step[2200/4329]: training loss : 0.9166347408294677 TRAIN  loss dict:  {'classification_loss': 0.9166347408294677}
2025-01-12 21:37:11,864 [INFO] Step[2250/4329]: training loss : 0.9334747648239136 TRAIN  loss dict:  {'classification_loss': 0.9334747648239136}
2025-01-12 21:37:23,454 [INFO] Step[2300/4329]: training loss : 0.9476908993721008 TRAIN  loss dict:  {'classification_loss': 0.9476908993721008}
2025-01-12 21:37:35,084 [INFO] Step[2350/4329]: training loss : 1.011315735578537 TRAIN  loss dict:  {'classification_loss': 1.011315735578537}
2025-01-12 21:37:46,658 [INFO] Step[2400/4329]: training loss : 0.9709440338611602 TRAIN  loss dict:  {'classification_loss': 0.9709440338611602}
2025-01-12 21:37:58,243 [INFO] Step[2450/4329]: training loss : 0.9504748857021332 TRAIN  loss dict:  {'classification_loss': 0.9504748857021332}
2025-01-12 21:38:09,848 [INFO] Step[2500/4329]: training loss : 0.9375691127777099 TRAIN  loss dict:  {'classification_loss': 0.9375691127777099}
2025-01-12 21:38:21,444 [INFO] Step[2550/4329]: training loss : 0.9407241511344909 TRAIN  loss dict:  {'classification_loss': 0.9407241511344909}
2025-01-12 21:38:33,030 [INFO] Step[2600/4329]: training loss : 0.9691002488136291 TRAIN  loss dict:  {'classification_loss': 0.9691002488136291}
2025-01-12 21:38:44,598 [INFO] Step[2650/4329]: training loss : 0.9346091520786285 TRAIN  loss dict:  {'classification_loss': 0.9346091520786285}
2025-01-12 21:38:56,165 [INFO] Step[2700/4329]: training loss : 0.9888372254371643 TRAIN  loss dict:  {'classification_loss': 0.9888372254371643}
2025-01-12 21:39:07,778 [INFO] Step[2750/4329]: training loss : 0.955915845632553 TRAIN  loss dict:  {'classification_loss': 0.955915845632553}
2025-01-12 21:39:19,394 [INFO] Step[2800/4329]: training loss : 0.9615047049522399 TRAIN  loss dict:  {'classification_loss': 0.9615047049522399}
2025-01-12 21:39:31,012 [INFO] Step[2850/4329]: training loss : 0.9428630542755126 TRAIN  loss dict:  {'classification_loss': 0.9428630542755126}
2025-01-12 21:39:42,613 [INFO] Step[2900/4329]: training loss : 0.9648431730270386 TRAIN  loss dict:  {'classification_loss': 0.9648431730270386}
2025-01-12 21:39:54,259 [INFO] Step[2950/4329]: training loss : 0.9599115455150604 TRAIN  loss dict:  {'classification_loss': 0.9599115455150604}
2025-01-12 21:40:05,864 [INFO] Step[3000/4329]: training loss : 0.9700502014160156 TRAIN  loss dict:  {'classification_loss': 0.9700502014160156}
2025-01-12 21:40:17,460 [INFO] Step[3050/4329]: training loss : 0.9302087843418121 TRAIN  loss dict:  {'classification_loss': 0.9302087843418121}
2025-01-12 21:40:29,032 [INFO] Step[3100/4329]: training loss : 0.9558498406410217 TRAIN  loss dict:  {'classification_loss': 0.9558498406410217}
2025-01-12 21:40:40,653 [INFO] Step[3150/4329]: training loss : 0.9492637050151825 TRAIN  loss dict:  {'classification_loss': 0.9492637050151825}
2025-01-12 21:40:52,241 [INFO] Step[3200/4329]: training loss : 0.9407687437534332 TRAIN  loss dict:  {'classification_loss': 0.9407687437534332}
2025-01-12 21:41:03,860 [INFO] Step[3250/4329]: training loss : 0.9393714129924774 TRAIN  loss dict:  {'classification_loss': 0.9393714129924774}
2025-01-12 21:41:15,507 [INFO] Step[3300/4329]: training loss : 0.9317760682106018 TRAIN  loss dict:  {'classification_loss': 0.9317760682106018}
2025-01-12 21:41:27,156 [INFO] Step[3350/4329]: training loss : 0.9567222571372986 TRAIN  loss dict:  {'classification_loss': 0.9567222571372986}
2025-01-12 21:41:38,787 [INFO] Step[3400/4329]: training loss : 0.9931587064266205 TRAIN  loss dict:  {'classification_loss': 0.9931587064266205}
2025-01-12 21:41:50,445 [INFO] Step[3450/4329]: training loss : 0.9632524919509887 TRAIN  loss dict:  {'classification_loss': 0.9632524919509887}
2025-01-12 21:42:02,074 [INFO] Step[3500/4329]: training loss : 0.9530137538909912 TRAIN  loss dict:  {'classification_loss': 0.9530137538909912}
2025-01-12 21:42:13,706 [INFO] Step[3550/4329]: training loss : 0.9783973813056945 TRAIN  loss dict:  {'classification_loss': 0.9783973813056945}
2025-01-12 21:42:25,298 [INFO] Step[3600/4329]: training loss : 0.952482956647873 TRAIN  loss dict:  {'classification_loss': 0.952482956647873}
2025-01-12 21:42:36,909 [INFO] Step[3650/4329]: training loss : 0.9491808176040649 TRAIN  loss dict:  {'classification_loss': 0.9491808176040649}
2025-01-12 21:42:48,565 [INFO] Step[3700/4329]: training loss : 0.9312774455547332 TRAIN  loss dict:  {'classification_loss': 0.9312774455547332}
2025-01-12 21:43:00,180 [INFO] Step[3750/4329]: training loss : 1.0002138638496398 TRAIN  loss dict:  {'classification_loss': 1.0002138638496398}
2025-01-12 21:43:11,810 [INFO] Step[3800/4329]: training loss : 0.9793696749210358 TRAIN  loss dict:  {'classification_loss': 0.9793696749210358}
2025-01-12 21:43:23,396 [INFO] Step[3850/4329]: training loss : 0.9778506672382354 TRAIN  loss dict:  {'classification_loss': 0.9778506672382354}
2025-01-12 21:43:34,969 [INFO] Step[3900/4329]: training loss : 0.9773811423778533 TRAIN  loss dict:  {'classification_loss': 0.9773811423778533}
2025-01-12 21:43:46,597 [INFO] Step[3950/4329]: training loss : 0.9552982985973358 TRAIN  loss dict:  {'classification_loss': 0.9552982985973358}
2025-01-12 21:43:58,204 [INFO] Step[4000/4329]: training loss : 0.9543212974071502 TRAIN  loss dict:  {'classification_loss': 0.9543212974071502}
2025-01-12 21:44:09,775 [INFO] Step[4050/4329]: training loss : 0.9500047767162323 TRAIN  loss dict:  {'classification_loss': 0.9500047767162323}
2025-01-12 21:44:21,369 [INFO] Step[4100/4329]: training loss : 0.9529318928718566 TRAIN  loss dict:  {'classification_loss': 0.9529318928718566}
2025-01-12 21:44:33,020 [INFO] Step[4150/4329]: training loss : 0.9890921890735627 TRAIN  loss dict:  {'classification_loss': 0.9890921890735627}
2025-01-12 21:44:44,632 [INFO] Step[4200/4329]: training loss : 0.9980144953727722 TRAIN  loss dict:  {'classification_loss': 0.9980144953727722}
2025-01-12 21:44:56,257 [INFO] Step[4250/4329]: training loss : 0.9724762237071991 TRAIN  loss dict:  {'classification_loss': 0.9724762237071991}
2025-01-12 21:45:07,817 [INFO] Step[4300/4329]: training loss : 0.944981368780136 TRAIN  loss dict:  {'classification_loss': 0.944981368780136}
2025-01-12 21:47:08,081 [INFO] Label accuracies statistics:
2025-01-12 21:47:08,081 [INFO] {0: 0.6666666666666666, 1: 0.7777777777777778, 2: 0.5833333333333334, 3: 0.75, 4: 0.5, 5: 0.8333333333333334, 6: 0.6666666666666666, 7: 0.5833333333333334, 8: 0.6666666666666666, 9: 0.75, 10: 1.0, 11: 1.0, 12: 0.5833333333333334, 13: 0.5, 14: 0.5, 15: 0.7777777777777778, 16: 0.5833333333333334, 17: 0.5, 18: 0.5833333333333334, 19: 0.5833333333333334, 20: 0.5833333333333334, 21: 0.6666666666666666, 22: 0.75, 23: 0.8333333333333334, 24: 1.0, 25: 0.9166666666666666, 26: 0.6666666666666666, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.5833333333333334, 32: 0.6666666666666666, 33: 0.75, 34: 1.0, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 0.8333333333333334, 38: 1.0, 39: 1.0, 40: 0.8333333333333334, 41: 0.4166666666666667, 42: 0.9166666666666666, 43: 0.8333333333333334, 44: 0.4166666666666667, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.6666666666666666, 54: 0.3333333333333333, 55: 0.6666666666666666, 56: 0.75, 57: 0.5833333333333334, 58: 0.5, 59: 0.75, 60: 0.5833333333333334, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.9166666666666666, 65: 1.0, 66: 0.6666666666666666, 67: 0.6666666666666666, 68: 0.5833333333333334, 69: 0.5833333333333334, 70: 0.3333333333333333, 71: 0.3333333333333333, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.5833333333333334, 77: 0.5833333333333334, 78: 1.0, 79: 0.5833333333333334, 80: 1.0, 81: 1.0, 82: 0.8333333333333334, 83: 0.5833333333333334, 84: 0.5, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.5833333333333334, 89: 0.5833333333333334, 90: 0.4166666666666667, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 0.8333333333333334, 96: 0.25, 97: 0.75, 98: 0.75, 99: 0.9333333333333333, 100: 0.9166666666666666, 101: 1.0, 102: 1.0, 103: 0.8333333333333334, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.9166666666666666, 111: 0.9166666666666666, 112: 0.9166666666666666, 113: 0.4166666666666667, 114: 0.5, 115: 0.8333333333333334, 116: 0.8333333333333334, 117: 0.6666666666666666, 118: 1.0, 119: 0.6666666666666666, 120: 0.25, 121: 0.6666666666666666, 122: 0.9166666666666666, 123: 0.9166666666666666, 124: 0.9166666666666666, 125: 0.8333333333333334, 126: 0.9166666666666666, 127: 0.5833333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.5833333333333334, 131: 1.0, 132: 0.5, 133: 1.0, 134: 0.8333333333333334, 135: 1.0, 136: 0.8333333333333334, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 0.4166666666666667, 143: 1.0, 144: 0.8333333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.6666666666666666, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 0.9166666666666666, 153: 0.75, 154: 1.0, 155: 0.9166666666666666, 156: 0.6666666666666666, 157: 0.5833333333333334, 158: 0.7777777777777778, 159: 1.0, 160: 0.4166666666666667, 161: 0.9166666666666666, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.6666666666666666, 166: 0.6666666666666666, 167: 0.9166666666666666, 168: 0.75, 169: 0.8333333333333334, 170: 0.9166666666666666, 171: 0.4166666666666667, 172: 1.0, 173: 0.8333333333333334, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 0.8333333333333334, 177: 0.75, 178: 0.8333333333333334, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.4166666666666667, 183: 0.75, 184: 0.8333333333333334, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.6666666666666666, 189: 1.0, 190: 0.5833333333333334, 191: 0.25, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.8333333333333334}

2025-01-12 21:47:08,083 [INFO] [22] TRAIN  loss: 0.9550797043647467 acc: 0.9864469428615432
2025-01-12 21:47:08,083 [INFO] [22] TRAIN  loss dict: {'classification_loss': 0.9550797043647467}
2025-01-12 21:47:08,083 [INFO] [22] VALIDATION loss: 1.6936017551807443 VALIDATION acc: 0.7727272727272727
2025-01-12 21:47:08,083 [INFO] [22] VALIDATION loss dict: {'classification_loss': 1.6936017551807443}
2025-01-12 21:47:08,083 [INFO] 
2025-01-12 21:47:25,440 [INFO] Step[50/4329]: training loss : 0.9455478739738464 TRAIN  loss dict:  {'classification_loss': 0.9455478739738464}
2025-01-12 21:47:37,036 [INFO] Step[100/4329]: training loss : 0.943778611421585 TRAIN  loss dict:  {'classification_loss': 0.943778611421585}
2025-01-12 21:47:48,864 [INFO] Step[150/4329]: training loss : 0.9220355999469757 TRAIN  loss dict:  {'classification_loss': 0.9220355999469757}
2025-01-12 21:48:01,251 [INFO] Step[200/4329]: training loss : 0.9381894969940185 TRAIN  loss dict:  {'classification_loss': 0.9381894969940185}
2025-01-12 21:48:13,593 [INFO] Step[250/4329]: training loss : 0.9309290623664856 TRAIN  loss dict:  {'classification_loss': 0.9309290623664856}
2025-01-12 21:48:26,897 [INFO] Step[300/4329]: training loss : 0.9664890325069427 TRAIN  loss dict:  {'classification_loss': 0.9664890325069427}
2025-01-12 21:48:40,723 [INFO] Step[350/4329]: training loss : 0.9131588625907898 TRAIN  loss dict:  {'classification_loss': 0.9131588625907898}
2025-01-12 21:48:52,891 [INFO] Step[400/4329]: training loss : 0.935504196882248 TRAIN  loss dict:  {'classification_loss': 0.935504196882248}
2025-01-12 21:49:04,862 [INFO] Step[450/4329]: training loss : 0.940994861125946 TRAIN  loss dict:  {'classification_loss': 0.940994861125946}
2025-01-12 21:49:16,608 [INFO] Step[500/4329]: training loss : 0.9533857715129852 TRAIN  loss dict:  {'classification_loss': 0.9533857715129852}
2025-01-12 21:49:28,211 [INFO] Step[550/4329]: training loss : 0.9423508715629577 TRAIN  loss dict:  {'classification_loss': 0.9423508715629577}
2025-01-12 21:49:39,891 [INFO] Step[600/4329]: training loss : 0.9561092555522919 TRAIN  loss dict:  {'classification_loss': 0.9561092555522919}
2025-01-12 21:49:51,525 [INFO] Step[650/4329]: training loss : 0.9138232195377349 TRAIN  loss dict:  {'classification_loss': 0.9138232195377349}
2025-01-12 21:50:03,183 [INFO] Step[700/4329]: training loss : 0.9631935548782349 TRAIN  loss dict:  {'classification_loss': 0.9631935548782349}
2025-01-12 21:50:14,792 [INFO] Step[750/4329]: training loss : 0.9757131195068359 TRAIN  loss dict:  {'classification_loss': 0.9757131195068359}
2025-01-12 21:50:26,416 [INFO] Step[800/4329]: training loss : 0.9367398309707642 TRAIN  loss dict:  {'classification_loss': 0.9367398309707642}
2025-01-12 21:50:38,042 [INFO] Step[850/4329]: training loss : 0.9577649843692779 TRAIN  loss dict:  {'classification_loss': 0.9577649843692779}
2025-01-12 21:50:49,672 [INFO] Step[900/4329]: training loss : 0.9133044934272766 TRAIN  loss dict:  {'classification_loss': 0.9133044934272766}
2025-01-12 21:51:01,292 [INFO] Step[950/4329]: training loss : 0.9321553111076355 TRAIN  loss dict:  {'classification_loss': 0.9321553111076355}
2025-01-12 21:51:12,940 [INFO] Step[1000/4329]: training loss : 0.9411378252506256 TRAIN  loss dict:  {'classification_loss': 0.9411378252506256}
2025-01-12 21:51:24,519 [INFO] Step[1050/4329]: training loss : 0.9178307533264161 TRAIN  loss dict:  {'classification_loss': 0.9178307533264161}
2025-01-12 21:51:36,141 [INFO] Step[1100/4329]: training loss : 0.9274251139163971 TRAIN  loss dict:  {'classification_loss': 0.9274251139163971}
2025-01-12 21:51:47,804 [INFO] Step[1150/4329]: training loss : 0.9147607636451721 TRAIN  loss dict:  {'classification_loss': 0.9147607636451721}
2025-01-12 21:51:59,413 [INFO] Step[1200/4329]: training loss : 0.928322925567627 TRAIN  loss dict:  {'classification_loss': 0.928322925567627}
2025-01-12 21:52:11,056 [INFO] Step[1250/4329]: training loss : 0.92893430352211 TRAIN  loss dict:  {'classification_loss': 0.92893430352211}
2025-01-12 21:52:22,684 [INFO] Step[1300/4329]: training loss : 0.9264925634860992 TRAIN  loss dict:  {'classification_loss': 0.9264925634860992}
2025-01-12 21:52:34,339 [INFO] Step[1350/4329]: training loss : 0.9422673320770264 TRAIN  loss dict:  {'classification_loss': 0.9422673320770264}
2025-01-12 21:52:45,978 [INFO] Step[1400/4329]: training loss : 0.9550450789928436 TRAIN  loss dict:  {'classification_loss': 0.9550450789928436}
2025-01-12 21:52:57,601 [INFO] Step[1450/4329]: training loss : 0.9191083681583404 TRAIN  loss dict:  {'classification_loss': 0.9191083681583404}
2025-01-12 21:53:09,295 [INFO] Step[1500/4329]: training loss : 0.9559166562557221 TRAIN  loss dict:  {'classification_loss': 0.9559166562557221}
2025-01-12 21:53:20,931 [INFO] Step[1550/4329]: training loss : 0.9250125193595886 TRAIN  loss dict:  {'classification_loss': 0.9250125193595886}
2025-01-12 21:53:32,587 [INFO] Step[1600/4329]: training loss : 0.925410532951355 TRAIN  loss dict:  {'classification_loss': 0.925410532951355}
2025-01-12 21:53:44,243 [INFO] Step[1650/4329]: training loss : 0.9259162271022796 TRAIN  loss dict:  {'classification_loss': 0.9259162271022796}
2025-01-12 21:53:55,923 [INFO] Step[1700/4329]: training loss : 0.9239293444156647 TRAIN  loss dict:  {'classification_loss': 0.9239293444156647}
2025-01-12 21:54:07,536 [INFO] Step[1750/4329]: training loss : 0.9307290434837341 TRAIN  loss dict:  {'classification_loss': 0.9307290434837341}
2025-01-12 21:54:19,114 [INFO] Step[1800/4329]: training loss : 0.941171760559082 TRAIN  loss dict:  {'classification_loss': 0.941171760559082}
2025-01-12 21:54:30,751 [INFO] Step[1850/4329]: training loss : 0.9748895704746247 TRAIN  loss dict:  {'classification_loss': 0.9748895704746247}
2025-01-12 21:54:42,315 [INFO] Step[1900/4329]: training loss : 0.9307935464382172 TRAIN  loss dict:  {'classification_loss': 0.9307935464382172}
2025-01-12 21:54:53,918 [INFO] Step[1950/4329]: training loss : 0.9668397045135498 TRAIN  loss dict:  {'classification_loss': 0.9668397045135498}
2025-01-12 21:55:05,545 [INFO] Step[2000/4329]: training loss : 0.9666306376457214 TRAIN  loss dict:  {'classification_loss': 0.9666306376457214}
2025-01-12 21:55:17,212 [INFO] Step[2050/4329]: training loss : 0.9580012369155884 TRAIN  loss dict:  {'classification_loss': 0.9580012369155884}
2025-01-12 21:55:28,838 [INFO] Step[2100/4329]: training loss : 0.9496347379684448 TRAIN  loss dict:  {'classification_loss': 0.9496347379684448}
2025-01-12 21:55:40,458 [INFO] Step[2150/4329]: training loss : 0.96337562084198 TRAIN  loss dict:  {'classification_loss': 0.96337562084198}
2025-01-12 21:55:52,056 [INFO] Step[2200/4329]: training loss : 0.9626915824413299 TRAIN  loss dict:  {'classification_loss': 0.9626915824413299}
2025-01-12 21:56:03,668 [INFO] Step[2250/4329]: training loss : 0.9455632030963897 TRAIN  loss dict:  {'classification_loss': 0.9455632030963897}
2025-01-12 21:56:15,302 [INFO] Step[2300/4329]: training loss : 0.9793251466751098 TRAIN  loss dict:  {'classification_loss': 0.9793251466751098}
2025-01-12 21:56:26,944 [INFO] Step[2350/4329]: training loss : 0.9412124884128571 TRAIN  loss dict:  {'classification_loss': 0.9412124884128571}
2025-01-12 21:56:38,580 [INFO] Step[2400/4329]: training loss : 0.9132718193531036 TRAIN  loss dict:  {'classification_loss': 0.9132718193531036}
2025-01-12 21:56:50,195 [INFO] Step[2450/4329]: training loss : 0.9157326817512512 TRAIN  loss dict:  {'classification_loss': 0.9157326817512512}
2025-01-12 21:57:01,796 [INFO] Step[2500/4329]: training loss : 0.9245110118389129 TRAIN  loss dict:  {'classification_loss': 0.9245110118389129}
2025-01-12 21:57:13,434 [INFO] Step[2550/4329]: training loss : 0.944374053478241 TRAIN  loss dict:  {'classification_loss': 0.944374053478241}
2025-01-12 21:57:25,055 [INFO] Step[2600/4329]: training loss : 0.9490666234493256 TRAIN  loss dict:  {'classification_loss': 0.9490666234493256}
2025-01-12 21:57:36,678 [INFO] Step[2650/4329]: training loss : 0.9338082718849182 TRAIN  loss dict:  {'classification_loss': 0.9338082718849182}
2025-01-12 21:57:48,284 [INFO] Step[2700/4329]: training loss : 0.9171745955944062 TRAIN  loss dict:  {'classification_loss': 0.9171745955944062}
2025-01-12 21:57:59,947 [INFO] Step[2750/4329]: training loss : 0.9247678279876709 TRAIN  loss dict:  {'classification_loss': 0.9247678279876709}
2025-01-12 21:58:11,588 [INFO] Step[2800/4329]: training loss : 0.9461121845245362 TRAIN  loss dict:  {'classification_loss': 0.9461121845245362}
2025-01-12 21:58:23,204 [INFO] Step[2850/4329]: training loss : 0.9218099021911621 TRAIN  loss dict:  {'classification_loss': 0.9218099021911621}
2025-01-12 21:58:34,853 [INFO] Step[2900/4329]: training loss : 0.9376006555557251 TRAIN  loss dict:  {'classification_loss': 0.9376006555557251}
2025-01-12 21:58:46,442 [INFO] Step[2950/4329]: training loss : 0.9459171342849731 TRAIN  loss dict:  {'classification_loss': 0.9459171342849731}
2025-01-12 21:58:58,077 [INFO] Step[3000/4329]: training loss : 0.9405572164058685 TRAIN  loss dict:  {'classification_loss': 0.9405572164058685}
2025-01-12 21:59:09,735 [INFO] Step[3050/4329]: training loss : 0.936610769033432 TRAIN  loss dict:  {'classification_loss': 0.936610769033432}
2025-01-12 21:59:21,371 [INFO] Step[3100/4329]: training loss : 0.9753528881072998 TRAIN  loss dict:  {'classification_loss': 0.9753528881072998}
2025-01-12 21:59:32,976 [INFO] Step[3150/4329]: training loss : 0.9637158560752869 TRAIN  loss dict:  {'classification_loss': 0.9637158560752869}
2025-01-12 21:59:44,635 [INFO] Step[3200/4329]: training loss : 0.9406510758399963 TRAIN  loss dict:  {'classification_loss': 0.9406510758399963}
2025-01-12 21:59:56,353 [INFO] Step[3250/4329]: training loss : 0.96354456782341 TRAIN  loss dict:  {'classification_loss': 0.96354456782341}
2025-01-12 22:00:08,469 [INFO] Step[3300/4329]: training loss : 0.9539212942123413 TRAIN  loss dict:  {'classification_loss': 0.9539212942123413}
2025-01-12 22:00:20,744 [INFO] Step[3350/4329]: training loss : 0.9281192326545715 TRAIN  loss dict:  {'classification_loss': 0.9281192326545715}
2025-01-12 22:00:33,241 [INFO] Step[3400/4329]: training loss : 0.9524093651771546 TRAIN  loss dict:  {'classification_loss': 0.9524093651771546}
2025-01-12 22:00:46,679 [INFO] Step[3450/4329]: training loss : 0.9276272547245026 TRAIN  loss dict:  {'classification_loss': 0.9276272547245026}
2025-01-12 22:01:00,053 [INFO] Step[3500/4329]: training loss : 0.9518401288986206 TRAIN  loss dict:  {'classification_loss': 0.9518401288986206}
2025-01-12 22:01:11,981 [INFO] Step[3550/4329]: training loss : 0.9345934581756592 TRAIN  loss dict:  {'classification_loss': 0.9345934581756592}
2025-01-12 22:01:23,845 [INFO] Step[3600/4329]: training loss : 0.9586013996601105 TRAIN  loss dict:  {'classification_loss': 0.9586013996601105}
2025-01-12 22:01:35,566 [INFO] Step[3650/4329]: training loss : 0.9345488667488098 TRAIN  loss dict:  {'classification_loss': 0.9345488667488098}
2025-01-12 22:01:47,165 [INFO] Step[3700/4329]: training loss : 0.9561333096027375 TRAIN  loss dict:  {'classification_loss': 0.9561333096027375}
2025-01-12 22:01:58,780 [INFO] Step[3750/4329]: training loss : 0.9474255931377411 TRAIN  loss dict:  {'classification_loss': 0.9474255931377411}
2025-01-12 22:02:10,398 [INFO] Step[3800/4329]: training loss : 0.9353748142719269 TRAIN  loss dict:  {'classification_loss': 0.9353748142719269}
2025-01-12 22:02:22,015 [INFO] Step[3850/4329]: training loss : 0.9542575573921204 TRAIN  loss dict:  {'classification_loss': 0.9542575573921204}
2025-01-12 22:02:33,610 [INFO] Step[3900/4329]: training loss : 0.9442274439334869 TRAIN  loss dict:  {'classification_loss': 0.9442274439334869}
2025-01-12 22:02:45,231 [INFO] Step[3950/4329]: training loss : 0.9933095109462738 TRAIN  loss dict:  {'classification_loss': 0.9933095109462738}
2025-01-12 22:02:56,859 [INFO] Step[4000/4329]: training loss : 0.9247076749801636 TRAIN  loss dict:  {'classification_loss': 0.9247076749801636}
2025-01-12 22:03:08,464 [INFO] Step[4050/4329]: training loss : 0.9447217655181884 TRAIN  loss dict:  {'classification_loss': 0.9447217655181884}
2025-01-12 22:03:20,111 [INFO] Step[4100/4329]: training loss : 0.9231135177612305 TRAIN  loss dict:  {'classification_loss': 0.9231135177612305}
2025-01-12 22:03:31,692 [INFO] Step[4150/4329]: training loss : 0.9450071549415588 TRAIN  loss dict:  {'classification_loss': 0.9450071549415588}
2025-01-12 22:03:43,291 [INFO] Step[4200/4329]: training loss : 0.9579973077774048 TRAIN  loss dict:  {'classification_loss': 0.9579973077774048}
2025-01-12 22:03:54,931 [INFO] Step[4250/4329]: training loss : 0.9370130741596222 TRAIN  loss dict:  {'classification_loss': 0.9370130741596222}
2025-01-12 22:04:06,567 [INFO] Step[4300/4329]: training loss : 0.9618624556064606 TRAIN  loss dict:  {'classification_loss': 0.9618624556064606}
2025-01-12 22:06:06,747 [INFO] Label accuracies statistics:
2025-01-12 22:06:06,747 [INFO] {0: 0.6666666666666666, 1: 0.7777777777777778, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.25, 5: 0.9166666666666666, 6: 0.5833333333333334, 7: 0.4166666666666667, 8: 0.3333333333333333, 9: 0.8333333333333334, 10: 1.0, 11: 0.9166666666666666, 12: 0.5, 13: 0.5833333333333334, 14: 0.75, 15: 0.6666666666666666, 16: 0.5833333333333334, 17: 0.5, 18: 0.6666666666666666, 19: 0.6666666666666666, 20: 0.6666666666666666, 21: 0.75, 22: 0.6666666666666666, 23: 1.0, 24: 1.0, 25: 0.8333333333333334, 26: 0.8333333333333334, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.6666666666666666, 32: 0.6666666666666666, 33: 0.75, 34: 1.0, 35: 0.9166666666666666, 36: 0.5, 37: 1.0, 38: 0.9166666666666666, 39: 0.9166666666666666, 40: 0.8333333333333334, 41: 0.5833333333333334, 42: 0.9166666666666666, 43: 0.8333333333333334, 44: 0.5833333333333334, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 0.9166666666666666, 50: 0.6666666666666666, 51: 0.75, 52: 0.9166666666666666, 53: 0.6666666666666666, 54: 0.5833333333333334, 55: 0.5833333333333334, 56: 0.8333333333333334, 57: 0.75, 58: 0.5833333333333334, 59: 0.5833333333333334, 60: 0.6666666666666666, 61: 0.9166666666666666, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.9166666666666666, 66: 0.5833333333333334, 67: 0.75, 68: 0.75, 69: 0.6666666666666666, 70: 0.3333333333333333, 71: 0.5833333333333334, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.4166666666666667, 77: 0.5833333333333334, 78: 0.9166666666666666, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.6666666666666666, 83: 0.5833333333333334, 84: 0.5, 85: 0.75, 86: 0.5833333333333334, 87: 0.8333333333333334, 88: 0.8333333333333334, 89: 0.5, 90: 0.5833333333333334, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 0.9166666666666666, 96: 0.5, 97: 0.75, 98: 0.75, 99: 0.9333333333333333, 100: 0.8333333333333334, 101: 0.9166666666666666, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.8333333333333334, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 1.0, 111: 1.0, 112: 0.8333333333333334, 113: 0.5, 114: 0.5833333333333334, 115: 0.75, 116: 0.75, 117: 0.9166666666666666, 118: 0.9166666666666666, 119: 0.8333333333333334, 120: 0.75, 121: 0.6666666666666666, 122: 0.8333333333333334, 123: 0.9166666666666666, 124: 1.0, 125: 0.8333333333333334, 126: 0.9166666666666666, 127: 0.75, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.9166666666666666, 132: 0.4166666666666667, 133: 1.0, 134: 0.8333333333333334, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.8333333333333334, 138: 0.8333333333333334, 139: 0.8333333333333334, 140: 0.6666666666666666, 141: 1.0, 142: 0.25, 143: 1.0, 144: 0.5833333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.5833333333333334, 151: 0.8333333333333334, 152: 0.9166666666666666, 153: 0.6666666666666666, 154: 1.0, 155: 0.9166666666666666, 156: 0.8333333333333334, 157: 0.75, 158: 0.8888888888888888, 159: 1.0, 160: 0.3333333333333333, 161: 0.9166666666666666, 162: 0.9166666666666666, 163: 1.0, 164: 0.75, 165: 0.9166666666666666, 166: 0.75, 167: 0.9166666666666666, 168: 0.9166666666666666, 169: 0.8333333333333334, 170: 0.9166666666666666, 171: 0.5833333333333334, 172: 1.0, 173: 0.75, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 0.9166666666666666, 177: 0.8333333333333334, 178: 0.9166666666666666, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.75, 183: 0.9166666666666666, 184: 0.8333333333333334, 185: 1.0, 186: 0.75, 187: 0.9166666666666666, 188: 0.6666666666666666, 189: 0.75, 190: 0.5833333333333334, 191: 0.75, 192: 1.0, 193: 0.9166666666666666, 194: 0.8333333333333334, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.5833333333333334}

2025-01-12 22:06:07,679 [INFO] [23] TRAIN  loss: 0.9421686334322495 acc: 0.9901432311720314
2025-01-12 22:06:07,679 [INFO] [23] TRAIN  loss dict: {'classification_loss': 0.9421686334322495}
2025-01-12 22:06:07,679 [INFO] [23] VALIDATION loss: 1.6697188098773812 VALIDATION acc: 0.7870370370370371
2025-01-12 22:06:07,679 [INFO] [23] VALIDATION loss dict: {'classification_loss': 1.6697188098773812}
2025-01-12 22:06:07,679 [INFO] 
2025-01-12 22:06:24,280 [INFO] Step[50/4329]: training loss : 0.929092561006546 TRAIN  loss dict:  {'classification_loss': 0.929092561006546}
2025-01-12 22:06:35,808 [INFO] Step[100/4329]: training loss : 0.9284773218631744 TRAIN  loss dict:  {'classification_loss': 0.9284773218631744}
2025-01-12 22:06:47,414 [INFO] Step[150/4329]: training loss : 0.9216129219532013 TRAIN  loss dict:  {'classification_loss': 0.9216129219532013}
2025-01-12 22:06:58,942 [INFO] Step[200/4329]: training loss : 0.9236779284477233 TRAIN  loss dict:  {'classification_loss': 0.9236779284477233}
2025-01-12 22:07:10,583 [INFO] Step[250/4329]: training loss : 0.9324092864990234 TRAIN  loss dict:  {'classification_loss': 0.9324092864990234}
2025-01-12 22:07:22,183 [INFO] Step[300/4329]: training loss : 0.921596783399582 TRAIN  loss dict:  {'classification_loss': 0.921596783399582}
2025-01-12 22:07:33,811 [INFO] Step[350/4329]: training loss : 0.9409791100025177 TRAIN  loss dict:  {'classification_loss': 0.9409791100025177}
2025-01-12 22:07:45,443 [INFO] Step[400/4329]: training loss : 0.9548925733566285 TRAIN  loss dict:  {'classification_loss': 0.9548925733566285}
2025-01-12 22:07:57,095 [INFO] Step[450/4329]: training loss : 0.9393988811969757 TRAIN  loss dict:  {'classification_loss': 0.9393988811969757}
2025-01-12 22:08:08,730 [INFO] Step[500/4329]: training loss : 0.9162393355369568 TRAIN  loss dict:  {'classification_loss': 0.9162393355369568}
2025-01-12 22:08:20,342 [INFO] Step[550/4329]: training loss : 0.9263609838485718 TRAIN  loss dict:  {'classification_loss': 0.9263609838485718}
2025-01-12 22:08:31,939 [INFO] Step[600/4329]: training loss : 0.9366355514526368 TRAIN  loss dict:  {'classification_loss': 0.9366355514526368}
2025-01-12 22:08:43,544 [INFO] Step[650/4329]: training loss : 0.9487405669689178 TRAIN  loss dict:  {'classification_loss': 0.9487405669689178}
2025-01-12 22:08:55,154 [INFO] Step[700/4329]: training loss : 0.940187760591507 TRAIN  loss dict:  {'classification_loss': 0.940187760591507}
2025-01-12 22:09:06,788 [INFO] Step[750/4329]: training loss : 0.9117302179336548 TRAIN  loss dict:  {'classification_loss': 0.9117302179336548}
2025-01-12 22:09:18,400 [INFO] Step[800/4329]: training loss : 0.9276875352859497 TRAIN  loss dict:  {'classification_loss': 0.9276875352859497}
2025-01-12 22:09:30,051 [INFO] Step[850/4329]: training loss : 0.9445109069347382 TRAIN  loss dict:  {'classification_loss': 0.9445109069347382}
2025-01-12 22:09:41,667 [INFO] Step[900/4329]: training loss : 0.9380092561244965 TRAIN  loss dict:  {'classification_loss': 0.9380092561244965}
2025-01-12 22:09:53,302 [INFO] Step[950/4329]: training loss : 0.9238964664936066 TRAIN  loss dict:  {'classification_loss': 0.9238964664936066}
2025-01-12 22:10:04,903 [INFO] Step[1000/4329]: training loss : 0.9181098926067353 TRAIN  loss dict:  {'classification_loss': 0.9181098926067353}
2025-01-12 22:10:16,524 [INFO] Step[1050/4329]: training loss : 0.9260700011253357 TRAIN  loss dict:  {'classification_loss': 0.9260700011253357}
2025-01-12 22:10:28,102 [INFO] Step[1100/4329]: training loss : 0.9490794289112091 TRAIN  loss dict:  {'classification_loss': 0.9490794289112091}
2025-01-12 22:10:39,728 [INFO] Step[1150/4329]: training loss : 0.923438949584961 TRAIN  loss dict:  {'classification_loss': 0.923438949584961}
2025-01-12 22:10:51,314 [INFO] Step[1200/4329]: training loss : 0.9669631564617157 TRAIN  loss dict:  {'classification_loss': 0.9669631564617157}
2025-01-12 22:11:02,976 [INFO] Step[1250/4329]: training loss : 0.9340659344196319 TRAIN  loss dict:  {'classification_loss': 0.9340659344196319}
2025-01-12 22:11:14,596 [INFO] Step[1300/4329]: training loss : 0.9486451494693756 TRAIN  loss dict:  {'classification_loss': 0.9486451494693756}
2025-01-12 22:11:26,251 [INFO] Step[1350/4329]: training loss : 0.9718840789794921 TRAIN  loss dict:  {'classification_loss': 0.9718840789794921}
2025-01-12 22:11:37,863 [INFO] Step[1400/4329]: training loss : 0.9242419075965881 TRAIN  loss dict:  {'classification_loss': 0.9242419075965881}
2025-01-12 22:11:49,493 [INFO] Step[1450/4329]: training loss : 0.9163749861717224 TRAIN  loss dict:  {'classification_loss': 0.9163749861717224}
2025-01-12 22:12:01,121 [INFO] Step[1500/4329]: training loss : 1.0150516903400422 TRAIN  loss dict:  {'classification_loss': 1.0150516903400422}
2025-01-12 22:12:12,769 [INFO] Step[1550/4329]: training loss : 0.926359132528305 TRAIN  loss dict:  {'classification_loss': 0.926359132528305}
2025-01-12 22:12:24,503 [INFO] Step[1600/4329]: training loss : 0.9761471486091614 TRAIN  loss dict:  {'classification_loss': 0.9761471486091614}
2025-01-12 22:12:36,732 [INFO] Step[1650/4329]: training loss : 0.9688765406608582 TRAIN  loss dict:  {'classification_loss': 0.9688765406608582}
2025-01-12 22:12:48,948 [INFO] Step[1700/4329]: training loss : 0.9073245513439179 TRAIN  loss dict:  {'classification_loss': 0.9073245513439179}
2025-01-12 22:13:01,918 [INFO] Step[1750/4329]: training loss : 0.9181101870536804 TRAIN  loss dict:  {'classification_loss': 0.9181101870536804}
2025-01-12 22:13:15,128 [INFO] Step[1800/4329]: training loss : 0.9116453361511231 TRAIN  loss dict:  {'classification_loss': 0.9116453361511231}
2025-01-12 22:13:28,445 [INFO] Step[1850/4329]: training loss : 0.9554229426383972 TRAIN  loss dict:  {'classification_loss': 0.9554229426383972}
2025-01-12 22:13:40,430 [INFO] Step[1900/4329]: training loss : 0.9103450918197632 TRAIN  loss dict:  {'classification_loss': 0.9103450918197632}
2025-01-12 22:13:52,309 [INFO] Step[1950/4329]: training loss : 0.9362947964668273 TRAIN  loss dict:  {'classification_loss': 0.9362947964668273}
2025-01-12 22:14:03,943 [INFO] Step[2000/4329]: training loss : 0.9059001815319061 TRAIN  loss dict:  {'classification_loss': 0.9059001815319061}
2025-01-12 22:14:15,567 [INFO] Step[2050/4329]: training loss : 0.9453096997737884 TRAIN  loss dict:  {'classification_loss': 0.9453096997737884}
2025-01-12 22:14:27,166 [INFO] Step[2100/4329]: training loss : 0.9482247471809387 TRAIN  loss dict:  {'classification_loss': 0.9482247471809387}
2025-01-12 22:14:38,811 [INFO] Step[2150/4329]: training loss : 0.9212913703918457 TRAIN  loss dict:  {'classification_loss': 0.9212913703918457}
2025-01-12 22:14:50,452 [INFO] Step[2200/4329]: training loss : 0.9231743681430816 TRAIN  loss dict:  {'classification_loss': 0.9231743681430816}
2025-01-12 22:15:02,087 [INFO] Step[2250/4329]: training loss : 0.9229114556312561 TRAIN  loss dict:  {'classification_loss': 0.9229114556312561}
2025-01-12 22:15:13,706 [INFO] Step[2300/4329]: training loss : 0.9250772786140442 TRAIN  loss dict:  {'classification_loss': 0.9250772786140442}
2025-01-12 22:15:25,357 [INFO] Step[2350/4329]: training loss : 0.9518254685401917 TRAIN  loss dict:  {'classification_loss': 0.9518254685401917}
2025-01-12 22:15:36,955 [INFO] Step[2400/4329]: training loss : 0.943413177728653 TRAIN  loss dict:  {'classification_loss': 0.943413177728653}
2025-01-12 22:15:48,647 [INFO] Step[2450/4329]: training loss : 0.94155446767807 TRAIN  loss dict:  {'classification_loss': 0.94155446767807}
2025-01-12 22:16:00,237 [INFO] Step[2500/4329]: training loss : 0.9424285626411438 TRAIN  loss dict:  {'classification_loss': 0.9424285626411438}
2025-01-12 22:16:11,894 [INFO] Step[2550/4329]: training loss : 0.946020781993866 TRAIN  loss dict:  {'classification_loss': 0.946020781993866}
2025-01-12 22:16:23,476 [INFO] Step[2600/4329]: training loss : 0.9525408744812012 TRAIN  loss dict:  {'classification_loss': 0.9525408744812012}
2025-01-12 22:16:35,115 [INFO] Step[2650/4329]: training loss : 0.9884025526046752 TRAIN  loss dict:  {'classification_loss': 0.9884025526046752}
2025-01-12 22:16:46,743 [INFO] Step[2700/4329]: training loss : 0.926223121881485 TRAIN  loss dict:  {'classification_loss': 0.926223121881485}
2025-01-12 22:16:58,352 [INFO] Step[2750/4329]: training loss : 0.9547487139701843 TRAIN  loss dict:  {'classification_loss': 0.9547487139701843}
2025-01-12 22:17:09,965 [INFO] Step[2800/4329]: training loss : 0.9067518162727356 TRAIN  loss dict:  {'classification_loss': 0.9067518162727356}
2025-01-12 22:17:21,579 [INFO] Step[2850/4329]: training loss : 0.9167166030406952 TRAIN  loss dict:  {'classification_loss': 0.9167166030406952}
2025-01-12 22:17:33,182 [INFO] Step[2900/4329]: training loss : 0.9263961553573609 TRAIN  loss dict:  {'classification_loss': 0.9263961553573609}
2025-01-12 22:17:44,809 [INFO] Step[2950/4329]: training loss : 0.9288777244091034 TRAIN  loss dict:  {'classification_loss': 0.9288777244091034}
2025-01-12 22:17:56,437 [INFO] Step[3000/4329]: training loss : 0.9468556272983552 TRAIN  loss dict:  {'classification_loss': 0.9468556272983552}
2025-01-12 22:18:08,093 [INFO] Step[3050/4329]: training loss : 0.9443188464641571 TRAIN  loss dict:  {'classification_loss': 0.9443188464641571}
2025-01-12 22:18:19,693 [INFO] Step[3100/4329]: training loss : 0.9613077807426452 TRAIN  loss dict:  {'classification_loss': 0.9613077807426452}
2025-01-12 22:18:31,337 [INFO] Step[3150/4329]: training loss : 0.9584943652153015 TRAIN  loss dict:  {'classification_loss': 0.9584943652153015}
2025-01-12 22:18:43,008 [INFO] Step[3200/4329]: training loss : 0.9622325825691224 TRAIN  loss dict:  {'classification_loss': 0.9622325825691224}
2025-01-12 22:18:54,638 [INFO] Step[3250/4329]: training loss : 0.9176618564128876 TRAIN  loss dict:  {'classification_loss': 0.9176618564128876}
2025-01-12 22:19:06,222 [INFO] Step[3300/4329]: training loss : 0.941988011598587 TRAIN  loss dict:  {'classification_loss': 0.941988011598587}
2025-01-12 22:19:17,836 [INFO] Step[3350/4329]: training loss : 0.9818830478191376 TRAIN  loss dict:  {'classification_loss': 0.9818830478191376}
2025-01-12 22:19:29,473 [INFO] Step[3400/4329]: training loss : 0.9543685829639434 TRAIN  loss dict:  {'classification_loss': 0.9543685829639434}
2025-01-12 22:19:41,103 [INFO] Step[3450/4329]: training loss : 0.9637045240402222 TRAIN  loss dict:  {'classification_loss': 0.9637045240402222}
2025-01-12 22:19:52,754 [INFO] Step[3500/4329]: training loss : 0.9336786532402038 TRAIN  loss dict:  {'classification_loss': 0.9336786532402038}
2025-01-12 22:20:04,360 [INFO] Step[3550/4329]: training loss : 0.9240555167198181 TRAIN  loss dict:  {'classification_loss': 0.9240555167198181}
2025-01-12 22:20:15,983 [INFO] Step[3600/4329]: training loss : 0.9422027862071991 TRAIN  loss dict:  {'classification_loss': 0.9422027862071991}
2025-01-12 22:20:27,622 [INFO] Step[3650/4329]: training loss : 0.9629210686683655 TRAIN  loss dict:  {'classification_loss': 0.9629210686683655}
2025-01-12 22:20:39,257 [INFO] Step[3700/4329]: training loss : 0.9639701473712922 TRAIN  loss dict:  {'classification_loss': 0.9639701473712922}
2025-01-12 22:20:50,935 [INFO] Step[3750/4329]: training loss : 0.9416858518123626 TRAIN  loss dict:  {'classification_loss': 0.9416858518123626}
2025-01-12 22:21:02,572 [INFO] Step[3800/4329]: training loss : 0.9465874540805816 TRAIN  loss dict:  {'classification_loss': 0.9465874540805816}
2025-01-12 22:21:14,184 [INFO] Step[3850/4329]: training loss : 0.9495799314975738 TRAIN  loss dict:  {'classification_loss': 0.9495799314975738}
2025-01-12 22:21:25,806 [INFO] Step[3900/4329]: training loss : 0.9782236313819885 TRAIN  loss dict:  {'classification_loss': 0.9782236313819885}
2025-01-12 22:21:37,445 [INFO] Step[3950/4329]: training loss : 0.9669252705574035 TRAIN  loss dict:  {'classification_loss': 0.9669252705574035}
2025-01-12 22:21:49,059 [INFO] Step[4000/4329]: training loss : 0.9391770660877228 TRAIN  loss dict:  {'classification_loss': 0.9391770660877228}
2025-01-12 22:22:00,661 [INFO] Step[4050/4329]: training loss : 0.9412482810020447 TRAIN  loss dict:  {'classification_loss': 0.9412482810020447}
2025-01-12 22:22:12,267 [INFO] Step[4100/4329]: training loss : 0.9296946036815643 TRAIN  loss dict:  {'classification_loss': 0.9296946036815643}
2025-01-12 22:22:23,888 [INFO] Step[4150/4329]: training loss : 0.9371429479122162 TRAIN  loss dict:  {'classification_loss': 0.9371429479122162}
2025-01-12 22:22:35,517 [INFO] Step[4200/4329]: training loss : 0.9662793684005737 TRAIN  loss dict:  {'classification_loss': 0.9662793684005737}
2025-01-12 22:22:47,178 [INFO] Step[4250/4329]: training loss : 0.9479450583457947 TRAIN  loss dict:  {'classification_loss': 0.9479450583457947}
2025-01-12 22:22:58,763 [INFO] Step[4300/4329]: training loss : 0.9656245768070221 TRAIN  loss dict:  {'classification_loss': 0.9656245768070221}
2025-01-12 22:24:55,026 [INFO] Label accuracies statistics:
2025-01-12 22:24:55,027 [INFO] {0: 0.4444444444444444, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.3333333333333333, 5: 0.5833333333333334, 6: 0.5833333333333334, 7: 0.5833333333333334, 8: 0.5833333333333334, 9: 0.8333333333333334, 10: 0.9166666666666666, 11: 0.8333333333333334, 12: 0.5, 13: 0.5833333333333334, 14: 0.75, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.5833333333333334, 19: 0.75, 20: 0.6666666666666666, 21: 0.75, 22: 0.6666666666666666, 23: 0.75, 24: 1.0, 25: 0.8333333333333334, 26: 0.75, 27: 0.6666666666666666, 28: 0.8333333333333334, 29: 1.0, 30: 0.6666666666666666, 31: 0.75, 32: 0.6666666666666666, 33: 0.8333333333333334, 34: 0.5833333333333334, 35: 0.8333333333333334, 36: 0.5833333333333334, 37: 0.9166666666666666, 38: 0.8333333333333334, 39: 1.0, 40: 0.8333333333333334, 41: 0.5833333333333334, 42: 0.8333333333333334, 43: 0.9166666666666666, 44: 0.5, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 0.8333333333333334, 49: 0.8333333333333334, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.6666666666666666, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.8333333333333334, 60: 0.8333333333333334, 61: 0.75, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.9166666666666666, 68: 0.6666666666666666, 69: 0.6666666666666666, 70: 0.3333333333333333, 71: 0.5833333333333334, 72: 0.8333333333333334, 73: 1.0, 74: 0.6666666666666666, 75: 1.0, 76: 0.5833333333333334, 77: 0.75, 78: 1.0, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5833333333333334, 84: 0.5, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.3333333333333333, 89: 0.75, 90: 0.8333333333333334, 91: 0.9166666666666666, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 0.9166666666666666, 96: 0.4166666666666667, 97: 0.5833333333333334, 98: 0.75, 99: 1.0, 100: 0.9166666666666666, 101: 0.9166666666666666, 102: 0.9166666666666666, 103: 1.0, 104: 1.0, 105: 0.9166666666666666, 106: 1.0, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 1.0, 111: 1.0, 112: 0.9166666666666666, 113: 0.5, 114: 0.5833333333333334, 115: 0.75, 116: 0.75, 117: 0.9166666666666666, 118: 1.0, 119: 0.9166666666666666, 120: 0.6666666666666666, 121: 0.8333333333333334, 122: 0.9166666666666666, 123: 0.8333333333333334, 124: 0.9166666666666666, 125: 0.9166666666666666, 126: 0.8333333333333334, 127: 0.8333333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.9166666666666666, 132: 0.6666666666666666, 133: 1.0, 134: 0.4166666666666667, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 0.9166666666666666, 142: 0.6666666666666666, 143: 1.0, 144: 0.8333333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.5833333333333334, 149: 0.9166666666666666, 150: 0.4166666666666667, 151: 0.9166666666666666, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 1.0, 156: 0.6666666666666666, 157: 0.5833333333333334, 158: 0.5555555555555556, 159: 0.9166666666666666, 160: 0.3333333333333333, 161: 0.9166666666666666, 162: 0.9166666666666666, 163: 1.0, 164: 0.8333333333333334, 165: 0.75, 166: 0.8333333333333334, 167: 0.8333333333333334, 168: 0.75, 169: 0.9166666666666666, 170: 0.9166666666666666, 171: 0.5833333333333334, 172: 1.0, 173: 0.9166666666666666, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 0.9166666666666666, 177: 0.9166666666666666, 178: 1.0, 179: 0.0, 180: 0.8333333333333334, 181: 0.75, 182: 0.5833333333333334, 183: 0.5, 184: 0.75, 185: 1.0, 186: 0.6666666666666666, 187: 1.0, 188: 0.8333333333333334, 189: 0.9166666666666666, 190: 0.5833333333333334, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.6666666666666666, 198: 0.75}

2025-01-12 22:24:55,031 [INFO] [24] TRAIN  loss: 0.9408309119737405 acc: 0.9884490990297243
2025-01-12 22:24:55,031 [INFO] [24] TRAIN  loss dict: {'classification_loss': 0.9408309119737405}
2025-01-12 22:24:55,031 [INFO] [24] VALIDATION loss: 1.6758174709599427 VALIDATION acc: 0.7861952861952862
2025-01-12 22:24:55,031 [INFO] [24] VALIDATION loss dict: {'classification_loss': 1.6758174709599427}
2025-01-12 22:24:55,031 [INFO] 
2025-01-12 22:25:15,705 [INFO] Step[50/4329]: training loss : 0.9184696137905121 TRAIN  loss dict:  {'classification_loss': 0.9184696137905121}
2025-01-12 22:25:28,131 [INFO] Step[100/4329]: training loss : 0.920888466835022 TRAIN  loss dict:  {'classification_loss': 0.920888466835022}
2025-01-12 22:25:41,608 [INFO] Step[150/4329]: training loss : 0.9540851867198944 TRAIN  loss dict:  {'classification_loss': 0.9540851867198944}
2025-01-12 22:25:54,451 [INFO] Step[200/4329]: training loss : 0.9138614892959595 TRAIN  loss dict:  {'classification_loss': 0.9138614892959595}
2025-01-12 22:26:06,459 [INFO] Step[250/4329]: training loss : 0.9307987713813781 TRAIN  loss dict:  {'classification_loss': 0.9307987713813781}
2025-01-12 22:26:18,267 [INFO] Step[300/4329]: training loss : 0.926243953704834 TRAIN  loss dict:  {'classification_loss': 0.926243953704834}
2025-01-12 22:26:29,913 [INFO] Step[350/4329]: training loss : 0.9657289814949036 TRAIN  loss dict:  {'classification_loss': 0.9657289814949036}
2025-01-12 22:26:41,709 [INFO] Step[400/4329]: training loss : 0.9354894125461578 TRAIN  loss dict:  {'classification_loss': 0.9354894125461578}
2025-01-12 22:26:53,430 [INFO] Step[450/4329]: training loss : 0.9370447671413422 TRAIN  loss dict:  {'classification_loss': 0.9370447671413422}
2025-01-12 22:27:05,059 [INFO] Step[500/4329]: training loss : 0.9064371931552887 TRAIN  loss dict:  {'classification_loss': 0.9064371931552887}
2025-01-12 22:27:16,715 [INFO] Step[550/4329]: training loss : 0.9229095017910004 TRAIN  loss dict:  {'classification_loss': 0.9229095017910004}
2025-01-12 22:27:28,371 [INFO] Step[600/4329]: training loss : 0.9348374378681182 TRAIN  loss dict:  {'classification_loss': 0.9348374378681182}
2025-01-12 22:27:39,972 [INFO] Step[650/4329]: training loss : 0.9275948143005371 TRAIN  loss dict:  {'classification_loss': 0.9275948143005371}
2025-01-12 22:27:51,571 [INFO] Step[700/4329]: training loss : 0.9466561830043793 TRAIN  loss dict:  {'classification_loss': 0.9466561830043793}
2025-01-12 22:28:03,226 [INFO] Step[750/4329]: training loss : 0.9432027947902679 TRAIN  loss dict:  {'classification_loss': 0.9432027947902679}
2025-01-12 22:28:14,839 [INFO] Step[800/4329]: training loss : 0.9073245203495026 TRAIN  loss dict:  {'classification_loss': 0.9073245203495026}
2025-01-12 22:28:26,498 [INFO] Step[850/4329]: training loss : 0.9496923148632049 TRAIN  loss dict:  {'classification_loss': 0.9496923148632049}
2025-01-12 22:28:38,148 [INFO] Step[900/4329]: training loss : 0.9420014142990112 TRAIN  loss dict:  {'classification_loss': 0.9420014142990112}
2025-01-12 22:28:49,801 [INFO] Step[950/4329]: training loss : 0.9210267996788025 TRAIN  loss dict:  {'classification_loss': 0.9210267996788025}
2025-01-12 22:29:01,402 [INFO] Step[1000/4329]: training loss : 0.9371844124794007 TRAIN  loss dict:  {'classification_loss': 0.9371844124794007}
2025-01-12 22:29:13,039 [INFO] Step[1050/4329]: training loss : 0.9142473721504212 TRAIN  loss dict:  {'classification_loss': 0.9142473721504212}
2025-01-12 22:29:24,677 [INFO] Step[1100/4329]: training loss : 0.9316451907157898 TRAIN  loss dict:  {'classification_loss': 0.9316451907157898}
2025-01-12 22:29:36,303 [INFO] Step[1150/4329]: training loss : 0.9378753423690795 TRAIN  loss dict:  {'classification_loss': 0.9378753423690795}
2025-01-12 22:29:47,938 [INFO] Step[1200/4329]: training loss : 0.9674438261985778 TRAIN  loss dict:  {'classification_loss': 0.9674438261985778}
2025-01-12 22:29:59,577 [INFO] Step[1250/4329]: training loss : 0.9839009022712708 TRAIN  loss dict:  {'classification_loss': 0.9839009022712708}
2025-01-12 22:30:11,209 [INFO] Step[1300/4329]: training loss : 0.9167846059799194 TRAIN  loss dict:  {'classification_loss': 0.9167846059799194}
2025-01-12 22:30:22,861 [INFO] Step[1350/4329]: training loss : 0.9399380731582642 TRAIN  loss dict:  {'classification_loss': 0.9399380731582642}
2025-01-12 22:30:34,495 [INFO] Step[1400/4329]: training loss : 0.9149957203865051 TRAIN  loss dict:  {'classification_loss': 0.9149957203865051}
2025-01-12 22:30:46,149 [INFO] Step[1450/4329]: training loss : 0.9431395924091339 TRAIN  loss dict:  {'classification_loss': 0.9431395924091339}
2025-01-12 22:30:57,767 [INFO] Step[1500/4329]: training loss : 0.9198907709121704 TRAIN  loss dict:  {'classification_loss': 0.9198907709121704}
2025-01-12 22:31:09,407 [INFO] Step[1550/4329]: training loss : 0.9270733201503754 TRAIN  loss dict:  {'classification_loss': 0.9270733201503754}
2025-01-12 22:31:21,042 [INFO] Step[1600/4329]: training loss : 0.9228284013271332 TRAIN  loss dict:  {'classification_loss': 0.9228284013271332}
2025-01-12 22:31:32,665 [INFO] Step[1650/4329]: training loss : 0.9211917531490326 TRAIN  loss dict:  {'classification_loss': 0.9211917531490326}
2025-01-12 22:31:44,276 [INFO] Step[1700/4329]: training loss : 0.970002475976944 TRAIN  loss dict:  {'classification_loss': 0.970002475976944}
2025-01-12 22:31:55,903 [INFO] Step[1750/4329]: training loss : 0.9444141376018524 TRAIN  loss dict:  {'classification_loss': 0.9444141376018524}
2025-01-12 22:32:07,543 [INFO] Step[1800/4329]: training loss : 0.9110551619529724 TRAIN  loss dict:  {'classification_loss': 0.9110551619529724}
2025-01-12 22:32:19,171 [INFO] Step[1850/4329]: training loss : 0.9678289830684662 TRAIN  loss dict:  {'classification_loss': 0.9678289830684662}
2025-01-12 22:32:30,774 [INFO] Step[1900/4329]: training loss : 0.9104942512512207 TRAIN  loss dict:  {'classification_loss': 0.9104942512512207}
2025-01-12 22:32:42,431 [INFO] Step[1950/4329]: training loss : 0.9184673869609833 TRAIN  loss dict:  {'classification_loss': 0.9184673869609833}
2025-01-12 22:32:54,046 [INFO] Step[2000/4329]: training loss : 0.9244460213184357 TRAIN  loss dict:  {'classification_loss': 0.9244460213184357}
2025-01-12 22:33:05,683 [INFO] Step[2050/4329]: training loss : 0.9389981782436371 TRAIN  loss dict:  {'classification_loss': 0.9389981782436371}
2025-01-12 22:33:17,278 [INFO] Step[2100/4329]: training loss : 0.9141909050941467 TRAIN  loss dict:  {'classification_loss': 0.9141909050941467}
2025-01-12 22:33:28,893 [INFO] Step[2150/4329]: training loss : 0.934504646062851 TRAIN  loss dict:  {'classification_loss': 0.934504646062851}
2025-01-12 22:33:40,488 [INFO] Step[2200/4329]: training loss : 0.9705746638774871 TRAIN  loss dict:  {'classification_loss': 0.9705746638774871}
2025-01-12 22:33:52,124 [INFO] Step[2250/4329]: training loss : 0.9409511578083039 TRAIN  loss dict:  {'classification_loss': 0.9409511578083039}
2025-01-12 22:34:03,704 [INFO] Step[2300/4329]: training loss : 0.9267235743999481 TRAIN  loss dict:  {'classification_loss': 0.9267235743999481}
2025-01-12 22:34:15,325 [INFO] Step[2350/4329]: training loss : 0.9075661313533783 TRAIN  loss dict:  {'classification_loss': 0.9075661313533783}
2025-01-12 22:34:26,903 [INFO] Step[2400/4329]: training loss : 0.9342978024482727 TRAIN  loss dict:  {'classification_loss': 0.9342978024482727}
2025-01-12 22:34:38,506 [INFO] Step[2450/4329]: training loss : 0.9405845141410828 TRAIN  loss dict:  {'classification_loss': 0.9405845141410828}
2025-01-12 22:34:50,102 [INFO] Step[2500/4329]: training loss : 0.9293173062801361 TRAIN  loss dict:  {'classification_loss': 0.9293173062801361}
2025-01-12 22:35:01,794 [INFO] Step[2550/4329]: training loss : 0.946982023715973 TRAIN  loss dict:  {'classification_loss': 0.946982023715973}
2025-01-12 22:35:13,377 [INFO] Step[2600/4329]: training loss : 0.9538982307910919 TRAIN  loss dict:  {'classification_loss': 0.9538982307910919}
2025-01-12 22:35:25,052 [INFO] Step[2650/4329]: training loss : 0.9229155051708221 TRAIN  loss dict:  {'classification_loss': 0.9229155051708221}
2025-01-12 22:35:36,641 [INFO] Step[2700/4329]: training loss : 0.9892482841014862 TRAIN  loss dict:  {'classification_loss': 0.9892482841014862}
2025-01-12 22:35:48,322 [INFO] Step[2750/4329]: training loss : 0.9239745771884919 TRAIN  loss dict:  {'classification_loss': 0.9239745771884919}
2025-01-12 22:35:59,914 [INFO] Step[2800/4329]: training loss : 0.9661193513870239 TRAIN  loss dict:  {'classification_loss': 0.9661193513870239}
2025-01-12 22:36:11,548 [INFO] Step[2850/4329]: training loss : 0.9143771946430206 TRAIN  loss dict:  {'classification_loss': 0.9143771946430206}
2025-01-12 22:36:23,184 [INFO] Step[2900/4329]: training loss : 0.9682192373275756 TRAIN  loss dict:  {'classification_loss': 0.9682192373275756}
2025-01-12 22:36:34,778 [INFO] Step[2950/4329]: training loss : 0.9364629340171814 TRAIN  loss dict:  {'classification_loss': 0.9364629340171814}
2025-01-12 22:36:46,383 [INFO] Step[3000/4329]: training loss : 0.9413978838920594 TRAIN  loss dict:  {'classification_loss': 0.9413978838920594}
2025-01-12 22:36:58,012 [INFO] Step[3050/4329]: training loss : 0.9224453449249268 TRAIN  loss dict:  {'classification_loss': 0.9224453449249268}
2025-01-12 22:37:09,650 [INFO] Step[3100/4329]: training loss : 0.9341216957569123 TRAIN  loss dict:  {'classification_loss': 0.9341216957569123}
2025-01-12 22:37:21,249 [INFO] Step[3150/4329]: training loss : 0.9151532006263733 TRAIN  loss dict:  {'classification_loss': 0.9151532006263733}
2025-01-12 22:37:32,888 [INFO] Step[3200/4329]: training loss : 0.912984414100647 TRAIN  loss dict:  {'classification_loss': 0.912984414100647}
2025-01-12 22:37:44,934 [INFO] Step[3250/4329]: training loss : 0.9214789855480194 TRAIN  loss dict:  {'classification_loss': 0.9214789855480194}
2025-01-12 22:37:57,206 [INFO] Step[3300/4329]: training loss : 0.9202985799312592 TRAIN  loss dict:  {'classification_loss': 0.9202985799312592}
2025-01-12 22:38:09,600 [INFO] Step[3350/4329]: training loss : 0.9433399426937104 TRAIN  loss dict:  {'classification_loss': 0.9433399426937104}
2025-01-12 22:38:23,072 [INFO] Step[3400/4329]: training loss : 0.9379815685749054 TRAIN  loss dict:  {'classification_loss': 0.9379815685749054}
2025-01-12 22:38:36,401 [INFO] Step[3450/4329]: training loss : 0.9136086356639862 TRAIN  loss dict:  {'classification_loss': 0.9136086356639862}
2025-01-12 22:38:48,460 [INFO] Step[3500/4329]: training loss : 0.9341969811916351 TRAIN  loss dict:  {'classification_loss': 0.9341969811916351}
2025-01-12 22:39:00,314 [INFO] Step[3550/4329]: training loss : 0.9561440420150756 TRAIN  loss dict:  {'classification_loss': 0.9561440420150756}
2025-01-12 22:39:12,097 [INFO] Step[3600/4329]: training loss : 0.9390283679962158 TRAIN  loss dict:  {'classification_loss': 0.9390283679962158}
2025-01-12 22:39:23,734 [INFO] Step[3650/4329]: training loss : 0.9541751360893249 TRAIN  loss dict:  {'classification_loss': 0.9541751360893249}
2025-01-12 22:39:35,374 [INFO] Step[3700/4329]: training loss : 0.9245718622207642 TRAIN  loss dict:  {'classification_loss': 0.9245718622207642}
2025-01-12 22:39:46,949 [INFO] Step[3750/4329]: training loss : 0.9704742002487182 TRAIN  loss dict:  {'classification_loss': 0.9704742002487182}
2025-01-12 22:39:58,614 [INFO] Step[3800/4329]: training loss : 0.961993215084076 TRAIN  loss dict:  {'classification_loss': 0.961993215084076}
2025-01-12 22:40:10,278 [INFO] Step[3850/4329]: training loss : 0.9353106105327607 TRAIN  loss dict:  {'classification_loss': 0.9353106105327607}
2025-01-12 22:40:21,859 [INFO] Step[3900/4329]: training loss : 0.9188692700862885 TRAIN  loss dict:  {'classification_loss': 0.9188692700862885}
2025-01-12 22:40:33,490 [INFO] Step[3950/4329]: training loss : 0.9586760306358337 TRAIN  loss dict:  {'classification_loss': 0.9586760306358337}
2025-01-12 22:40:45,059 [INFO] Step[4000/4329]: training loss : 0.9208735692501068 TRAIN  loss dict:  {'classification_loss': 0.9208735692501068}
2025-01-12 22:40:56,705 [INFO] Step[4050/4329]: training loss : 0.9360905301570892 TRAIN  loss dict:  {'classification_loss': 0.9360905301570892}
2025-01-12 22:41:08,316 [INFO] Step[4100/4329]: training loss : 0.9443917536735534 TRAIN  loss dict:  {'classification_loss': 0.9443917536735534}
2025-01-12 22:41:19,965 [INFO] Step[4150/4329]: training loss : 0.9173627877235413 TRAIN  loss dict:  {'classification_loss': 0.9173627877235413}
2025-01-12 22:41:31,622 [INFO] Step[4200/4329]: training loss : 0.9086412143707275 TRAIN  loss dict:  {'classification_loss': 0.9086412143707275}
2025-01-12 22:41:43,325 [INFO] Step[4250/4329]: training loss : 0.9173374497890472 TRAIN  loss dict:  {'classification_loss': 0.9173374497890472}
2025-01-12 22:41:54,883 [INFO] Step[4300/4329]: training loss : 0.9829210841655731 TRAIN  loss dict:  {'classification_loss': 0.9829210841655731}
2025-01-12 22:43:55,654 [INFO] Label accuracies statistics:
2025-01-12 22:43:55,655 [INFO] {0: 0.5555555555555556, 1: 1.0, 2: 0.5833333333333334, 3: 0.8333333333333334, 4: 0.25, 5: 0.9166666666666666, 6: 0.75, 7: 0.4166666666666667, 8: 0.4166666666666667, 9: 0.8333333333333334, 10: 1.0, 11: 0.9166666666666666, 12: 0.3333333333333333, 13: 0.5833333333333334, 14: 0.75, 15: 0.5555555555555556, 16: 0.4166666666666667, 17: 0.5833333333333334, 18: 0.6666666666666666, 19: 0.8333333333333334, 20: 0.5, 21: 0.75, 22: 0.6666666666666666, 23: 1.0, 24: 1.0, 25: 0.6666666666666666, 26: 0.9166666666666666, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.6666666666666666, 32: 0.75, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 0.9166666666666666, 36: 0.6666666666666666, 37: 1.0, 38: 1.0, 39: 0.9166666666666666, 40: 0.8333333333333334, 41: 0.5833333333333334, 42: 0.9166666666666666, 43: 0.8333333333333334, 44: 0.5, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.5833333333333334, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.3333333333333333, 55: 0.6666666666666666, 56: 0.8333333333333334, 57: 0.6666666666666666, 58: 0.5833333333333334, 59: 0.6666666666666666, 60: 0.75, 61: 0.8333333333333334, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.8333333333333334, 68: 0.5833333333333334, 69: 0.6666666666666666, 70: 0.4166666666666667, 71: 0.5833333333333334, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.5833333333333334, 77: 0.75, 78: 1.0, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5833333333333334, 84: 0.5, 85: 0.75, 86: 0.5833333333333334, 87: 0.9166666666666666, 88: 0.9166666666666666, 89: 0.5833333333333334, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.5, 97: 0.75, 98: 0.75, 99: 0.9333333333333333, 100: 0.75, 101: 0.8333333333333334, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 0.9166666666666666, 109: 0.6666666666666666, 110: 1.0, 111: 0.9166666666666666, 112: 0.9166666666666666, 113: 0.4166666666666667, 114: 0.6666666666666666, 115: 0.8333333333333334, 116: 0.75, 117: 0.75, 118: 0.9166666666666666, 119: 0.75, 120: 0.8333333333333334, 121: 0.75, 122: 0.8333333333333334, 123: 0.9166666666666666, 124: 0.8333333333333334, 125: 0.6666666666666666, 126: 0.6666666666666666, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.9166666666666666, 131: 0.8333333333333334, 132: 0.5, 133: 1.0, 134: 0.75, 135: 0.8333333333333334, 136: 1.0, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.8333333333333334, 140: 1.0, 141: 1.0, 142: 0.5833333333333334, 143: 1.0, 144: 0.5833333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.6666666666666666, 149: 1.0, 150: 0.4166666666666667, 151: 0.9166666666666666, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 1.0, 156: 0.9166666666666666, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.25, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.9166666666666666, 166: 0.5833333333333334, 167: 0.75, 168: 0.8333333333333334, 169: 0.8333333333333334, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.8333333333333334, 174: 1.0, 175: 0.9166666666666666, 176: 1.0, 177: 0.8333333333333334, 178: 1.0, 179: 0.0, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.75, 183: 0.9166666666666666, 184: 0.8333333333333334, 185: 1.0, 186: 0.8333333333333334, 187: 0.9166666666666666, 188: 0.5833333333333334, 189: 0.9166666666666666, 190: 0.4166666666666667, 191: 0.3333333333333333, 192: 1.0, 193: 0.9166666666666666, 194: 0.8333333333333334, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.75, 198: 0.5833333333333334}

2025-01-12 22:43:56,599 [INFO] [25] TRAIN  loss: 0.9356036899573921 acc: 0.9898352071461574
2025-01-12 22:43:56,599 [INFO] [25] TRAIN  loss dict: {'classification_loss': 0.9356036899573921}
2025-01-12 22:43:56,599 [INFO] [25] VALIDATION loss: 1.6762240501967343 VALIDATION acc: 0.7916666666666666
2025-01-12 22:43:56,599 [INFO] [25] VALIDATION loss dict: {'classification_loss': 1.6762240501967343}
2025-01-12 22:43:56,599 [INFO] 
2025-01-12 22:44:14,293 [INFO] Step[50/4329]: training loss : 0.959716054201126 TRAIN  loss dict:  {'classification_loss': 0.959716054201126}
2025-01-12 22:44:25,836 [INFO] Step[100/4329]: training loss : 0.9275377535820007 TRAIN  loss dict:  {'classification_loss': 0.9275377535820007}
2025-01-12 22:44:37,444 [INFO] Step[150/4329]: training loss : 0.9526164090633392 TRAIN  loss dict:  {'classification_loss': 0.9526164090633392}
2025-01-12 22:44:49,030 [INFO] Step[200/4329]: training loss : 0.9524602854251861 TRAIN  loss dict:  {'classification_loss': 0.9524602854251861}
2025-01-12 22:45:00,680 [INFO] Step[250/4329]: training loss : 0.9484975218772889 TRAIN  loss dict:  {'classification_loss': 0.9484975218772889}
2025-01-12 22:45:12,296 [INFO] Step[300/4329]: training loss : 0.92931685090065 TRAIN  loss dict:  {'classification_loss': 0.92931685090065}
2025-01-12 22:45:23,941 [INFO] Step[350/4329]: training loss : 0.915978502035141 TRAIN  loss dict:  {'classification_loss': 0.915978502035141}
2025-01-12 22:45:35,591 [INFO] Step[400/4329]: training loss : 0.9504861688613891 TRAIN  loss dict:  {'classification_loss': 0.9504861688613891}
2025-01-12 22:45:47,254 [INFO] Step[450/4329]: training loss : 0.932762314081192 TRAIN  loss dict:  {'classification_loss': 0.932762314081192}
2025-01-12 22:45:58,830 [INFO] Step[500/4329]: training loss : 0.9370874845981598 TRAIN  loss dict:  {'classification_loss': 0.9370874845981598}
2025-01-12 22:46:10,474 [INFO] Step[550/4329]: training loss : 0.9172109699249268 TRAIN  loss dict:  {'classification_loss': 0.9172109699249268}
2025-01-12 22:46:22,118 [INFO] Step[600/4329]: training loss : 0.9604146194458008 TRAIN  loss dict:  {'classification_loss': 0.9604146194458008}
2025-01-12 22:46:33,765 [INFO] Step[650/4329]: training loss : 0.9713221788406372 TRAIN  loss dict:  {'classification_loss': 0.9713221788406372}
2025-01-12 22:46:45,407 [INFO] Step[700/4329]: training loss : 0.9197525668144226 TRAIN  loss dict:  {'classification_loss': 0.9197525668144226}
2025-01-12 22:46:57,051 [INFO] Step[750/4329]: training loss : 0.9228170275688171 TRAIN  loss dict:  {'classification_loss': 0.9228170275688171}
2025-01-12 22:47:08,659 [INFO] Step[800/4329]: training loss : 0.910483502149582 TRAIN  loss dict:  {'classification_loss': 0.910483502149582}
2025-01-12 22:47:20,303 [INFO] Step[850/4329]: training loss : 0.9205656158924103 TRAIN  loss dict:  {'classification_loss': 0.9205656158924103}
2025-01-12 22:47:31,903 [INFO] Step[900/4329]: training loss : 0.905701824426651 TRAIN  loss dict:  {'classification_loss': 0.905701824426651}
2025-01-12 22:47:43,535 [INFO] Step[950/4329]: training loss : 0.9039503633975983 TRAIN  loss dict:  {'classification_loss': 0.9039503633975983}
2025-01-12 22:47:55,133 [INFO] Step[1000/4329]: training loss : 0.9220278072357178 TRAIN  loss dict:  {'classification_loss': 0.9220278072357178}
2025-01-12 22:48:06,703 [INFO] Step[1050/4329]: training loss : 0.916402337551117 TRAIN  loss dict:  {'classification_loss': 0.916402337551117}
2025-01-12 22:48:18,335 [INFO] Step[1100/4329]: training loss : 0.9213929176330566 TRAIN  loss dict:  {'classification_loss': 0.9213929176330566}
2025-01-12 22:48:29,957 [INFO] Step[1150/4329]: training loss : 0.9550751507282257 TRAIN  loss dict:  {'classification_loss': 0.9550751507282257}
2025-01-12 22:48:41,589 [INFO] Step[1200/4329]: training loss : 0.9417228209972381 TRAIN  loss dict:  {'classification_loss': 0.9417228209972381}
2025-01-12 22:48:53,260 [INFO] Step[1250/4329]: training loss : 0.9695622324943542 TRAIN  loss dict:  {'classification_loss': 0.9695622324943542}
2025-01-12 22:49:04,885 [INFO] Step[1300/4329]: training loss : 0.9425389981269836 TRAIN  loss dict:  {'classification_loss': 0.9425389981269836}
2025-01-12 22:49:16,534 [INFO] Step[1350/4329]: training loss : 0.949529185295105 TRAIN  loss dict:  {'classification_loss': 0.949529185295105}
2025-01-12 22:49:28,129 [INFO] Step[1400/4329]: training loss : 0.9014546012878418 TRAIN  loss dict:  {'classification_loss': 0.9014546012878418}
2025-01-12 22:49:39,767 [INFO] Step[1450/4329]: training loss : 0.9262123477458953 TRAIN  loss dict:  {'classification_loss': 0.9262123477458953}
2025-01-12 22:49:51,396 [INFO] Step[1500/4329]: training loss : 0.9215458500385284 TRAIN  loss dict:  {'classification_loss': 0.9215458500385284}
2025-01-12 22:50:03,159 [INFO] Step[1550/4329]: training loss : 0.9267748260498047 TRAIN  loss dict:  {'classification_loss': 0.9267748260498047}
2025-01-12 22:50:15,508 [INFO] Step[1600/4329]: training loss : 0.9348656523227692 TRAIN  loss dict:  {'classification_loss': 0.9348656523227692}
2025-01-12 22:50:27,737 [INFO] Step[1650/4329]: training loss : 0.9094871652126312 TRAIN  loss dict:  {'classification_loss': 0.9094871652126312}
2025-01-12 22:50:40,971 [INFO] Step[1700/4329]: training loss : 0.9670320129394532 TRAIN  loss dict:  {'classification_loss': 0.9670320129394532}
2025-01-12 22:50:55,018 [INFO] Step[1750/4329]: training loss : 0.9460164320468902 TRAIN  loss dict:  {'classification_loss': 0.9460164320468902}
2025-01-12 22:51:08,532 [INFO] Step[1800/4329]: training loss : 0.9614761364459992 TRAIN  loss dict:  {'classification_loss': 0.9614761364459992}
2025-01-12 22:51:20,466 [INFO] Step[1850/4329]: training loss : 0.9234594738483429 TRAIN  loss dict:  {'classification_loss': 0.9234594738483429}
2025-01-12 22:51:32,302 [INFO] Step[1900/4329]: training loss : 0.9067397677898407 TRAIN  loss dict:  {'classification_loss': 0.9067397677898407}
2025-01-12 22:51:43,948 [INFO] Step[1950/4329]: training loss : 0.9284543716907501 TRAIN  loss dict:  {'classification_loss': 0.9284543716907501}
2025-01-12 22:51:55,567 [INFO] Step[2000/4329]: training loss : 0.941571033000946 TRAIN  loss dict:  {'classification_loss': 0.941571033000946}
2025-01-12 22:52:07,222 [INFO] Step[2050/4329]: training loss : 0.9266427493095398 TRAIN  loss dict:  {'classification_loss': 0.9266427493095398}
2025-01-12 22:52:18,838 [INFO] Step[2100/4329]: training loss : 0.9445966553688049 TRAIN  loss dict:  {'classification_loss': 0.9445966553688049}
2025-01-12 22:52:30,444 [INFO] Step[2150/4329]: training loss : 0.9468667149543762 TRAIN  loss dict:  {'classification_loss': 0.9468667149543762}
2025-01-12 22:52:42,035 [INFO] Step[2200/4329]: training loss : 0.9189400577545166 TRAIN  loss dict:  {'classification_loss': 0.9189400577545166}
2025-01-12 22:52:53,663 [INFO] Step[2250/4329]: training loss : 0.9319675552845001 TRAIN  loss dict:  {'classification_loss': 0.9319675552845001}
2025-01-12 22:53:05,299 [INFO] Step[2300/4329]: training loss : 0.9127355718612671 TRAIN  loss dict:  {'classification_loss': 0.9127355718612671}
2025-01-12 22:53:16,960 [INFO] Step[2350/4329]: training loss : 0.9811605906486511 TRAIN  loss dict:  {'classification_loss': 0.9811605906486511}
2025-01-12 22:53:28,577 [INFO] Step[2400/4329]: training loss : 0.9869165062904358 TRAIN  loss dict:  {'classification_loss': 0.9869165062904358}
2025-01-12 22:53:40,254 [INFO] Step[2450/4329]: training loss : 0.9410213911533356 TRAIN  loss dict:  {'classification_loss': 0.9410213911533356}
2025-01-12 22:53:51,937 [INFO] Step[2500/4329]: training loss : 0.9142678153514862 TRAIN  loss dict:  {'classification_loss': 0.9142678153514862}
2025-01-12 22:54:03,621 [INFO] Step[2550/4329]: training loss : 0.9266566383838654 TRAIN  loss dict:  {'classification_loss': 0.9266566383838654}
2025-01-12 22:54:15,209 [INFO] Step[2600/4329]: training loss : 0.931483291387558 TRAIN  loss dict:  {'classification_loss': 0.931483291387558}
2025-01-12 22:54:26,807 [INFO] Step[2650/4329]: training loss : 0.9295304262638092 TRAIN  loss dict:  {'classification_loss': 0.9295304262638092}
2025-01-12 22:54:38,405 [INFO] Step[2700/4329]: training loss : 0.9532733619213104 TRAIN  loss dict:  {'classification_loss': 0.9532733619213104}
2025-01-12 22:54:50,067 [INFO] Step[2750/4329]: training loss : 0.9127602112293244 TRAIN  loss dict:  {'classification_loss': 0.9127602112293244}
2025-01-12 22:55:01,692 [INFO] Step[2800/4329]: training loss : 0.9624334216117859 TRAIN  loss dict:  {'classification_loss': 0.9624334216117859}
2025-01-12 22:55:13,322 [INFO] Step[2850/4329]: training loss : 0.9717210257053375 TRAIN  loss dict:  {'classification_loss': 0.9717210257053375}
2025-01-12 22:55:24,976 [INFO] Step[2900/4329]: training loss : 0.9251746273040772 TRAIN  loss dict:  {'classification_loss': 0.9251746273040772}
2025-01-12 22:55:36,607 [INFO] Step[2950/4329]: training loss : 0.9296276962757111 TRAIN  loss dict:  {'classification_loss': 0.9296276962757111}
2025-01-12 22:55:48,263 [INFO] Step[3000/4329]: training loss : 0.9260825884342193 TRAIN  loss dict:  {'classification_loss': 0.9260825884342193}
2025-01-12 22:55:59,865 [INFO] Step[3050/4329]: training loss : 0.9516429793834686 TRAIN  loss dict:  {'classification_loss': 0.9516429793834686}
2025-01-12 22:56:11,502 [INFO] Step[3100/4329]: training loss : 0.9320991230010987 TRAIN  loss dict:  {'classification_loss': 0.9320991230010987}
2025-01-12 22:56:23,169 [INFO] Step[3150/4329]: training loss : 0.9314287626743316 TRAIN  loss dict:  {'classification_loss': 0.9314287626743316}
2025-01-12 22:56:34,800 [INFO] Step[3200/4329]: training loss : 0.9355449056625367 TRAIN  loss dict:  {'classification_loss': 0.9355449056625367}
2025-01-12 22:56:46,422 [INFO] Step[3250/4329]: training loss : 0.9366891479492188 TRAIN  loss dict:  {'classification_loss': 0.9366891479492188}
2025-01-12 22:56:58,050 [INFO] Step[3300/4329]: training loss : 0.9198799276351929 TRAIN  loss dict:  {'classification_loss': 0.9198799276351929}
2025-01-12 22:57:09,657 [INFO] Step[3350/4329]: training loss : 0.9319649732112885 TRAIN  loss dict:  {'classification_loss': 0.9319649732112885}
2025-01-12 22:57:21,311 [INFO] Step[3400/4329]: training loss : 0.9518866467475892 TRAIN  loss dict:  {'classification_loss': 0.9518866467475892}
2025-01-12 22:57:32,934 [INFO] Step[3450/4329]: training loss : 0.9278451716899871 TRAIN  loss dict:  {'classification_loss': 0.9278451716899871}
2025-01-12 22:57:44,583 [INFO] Step[3500/4329]: training loss : 0.9290050458908081 TRAIN  loss dict:  {'classification_loss': 0.9290050458908081}
2025-01-12 22:57:56,168 [INFO] Step[3550/4329]: training loss : 0.9244729626178741 TRAIN  loss dict:  {'classification_loss': 0.9244729626178741}
2025-01-12 22:58:07,800 [INFO] Step[3600/4329]: training loss : 0.9540368735790252 TRAIN  loss dict:  {'classification_loss': 0.9540368735790252}
2025-01-12 22:58:19,409 [INFO] Step[3650/4329]: training loss : 0.9521862006187439 TRAIN  loss dict:  {'classification_loss': 0.9521862006187439}
2025-01-12 22:58:31,076 [INFO] Step[3700/4329]: training loss : 0.9184339654445648 TRAIN  loss dict:  {'classification_loss': 0.9184339654445648}
2025-01-12 22:58:42,711 [INFO] Step[3750/4329]: training loss : 0.9233001887798309 TRAIN  loss dict:  {'classification_loss': 0.9233001887798309}
2025-01-12 22:58:54,358 [INFO] Step[3800/4329]: training loss : 0.9164199542999267 TRAIN  loss dict:  {'classification_loss': 0.9164199542999267}
2025-01-12 22:59:06,004 [INFO] Step[3850/4329]: training loss : 0.91302565574646 TRAIN  loss dict:  {'classification_loss': 0.91302565574646}
2025-01-12 22:59:17,595 [INFO] Step[3900/4329]: training loss : 0.9182703912258148 TRAIN  loss dict:  {'classification_loss': 0.9182703912258148}
2025-01-12 22:59:29,224 [INFO] Step[3950/4329]: training loss : 0.9350511729717255 TRAIN  loss dict:  {'classification_loss': 0.9350511729717255}
2025-01-12 22:59:40,874 [INFO] Step[4000/4329]: training loss : 0.9201744842529297 TRAIN  loss dict:  {'classification_loss': 0.9201744842529297}
2025-01-12 22:59:52,451 [INFO] Step[4050/4329]: training loss : 0.949974148273468 TRAIN  loss dict:  {'classification_loss': 0.949974148273468}
2025-01-12 23:00:04,100 [INFO] Step[4100/4329]: training loss : 0.9318576383590699 TRAIN  loss dict:  {'classification_loss': 0.9318576383590699}
2025-01-12 23:00:15,712 [INFO] Step[4150/4329]: training loss : 0.9168156278133393 TRAIN  loss dict:  {'classification_loss': 0.9168156278133393}
2025-01-12 23:00:27,311 [INFO] Step[4200/4329]: training loss : 0.9288757717609406 TRAIN  loss dict:  {'classification_loss': 0.9288757717609406}
2025-01-12 23:00:38,963 [INFO] Step[4250/4329]: training loss : 0.9270803534984589 TRAIN  loss dict:  {'classification_loss': 0.9270803534984589}
2025-01-12 23:00:50,545 [INFO] Step[4300/4329]: training loss : 0.9269707202911377 TRAIN  loss dict:  {'classification_loss': 0.9269707202911377}
2025-01-12 23:02:47,747 [INFO] Label accuracies statistics:
2025-01-12 23:02:47,747 [INFO] {0: 0.5555555555555556, 1: 0.8888888888888888, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.5, 8: 0.4166666666666667, 9: 0.8333333333333334, 10: 1.0, 11: 1.0, 12: 0.5833333333333334, 13: 0.4166666666666667, 14: 0.4166666666666667, 15: 0.7777777777777778, 16: 0.5, 17: 0.5, 18: 0.5833333333333334, 19: 0.8333333333333334, 20: 0.6666666666666666, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.8333333333333334, 26: 1.0, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.6666666666666666, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.9166666666666666, 41: 0.4166666666666667, 42: 0.9166666666666666, 43: 1.0, 44: 0.5833333333333334, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.5833333333333334, 54: 0.4166666666666667, 55: 0.6666666666666666, 56: 0.75, 57: 0.75, 58: 0.6666666666666666, 59: 0.6666666666666666, 60: 0.75, 61: 0.8333333333333334, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.75, 68: 0.8333333333333334, 69: 0.5833333333333334, 70: 0.4166666666666667, 71: 0.5, 72: 0.8333333333333334, 73: 0.8333333333333334, 74: 0.6666666666666666, 75: 1.0, 76: 0.5833333333333334, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.8333333333333334, 83: 0.5, 84: 0.4166666666666667, 85: 0.75, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.5, 89: 0.75, 90: 0.5833333333333334, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.5, 97: 0.5833333333333334, 98: 0.75, 99: 0.9333333333333333, 100: 0.9166666666666666, 101: 0.75, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 0.9166666666666666, 105: 1.0, 106: 1.0, 107: 0.8333333333333334, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 1.0, 111: 1.0, 112: 0.9166666666666666, 113: 0.4166666666666667, 114: 0.5833333333333334, 115: 1.0, 116: 0.8333333333333334, 117: 0.8333333333333334, 118: 1.0, 119: 0.6666666666666666, 120: 0.6666666666666666, 121: 0.75, 122: 0.75, 123: 0.8333333333333334, 124: 1.0, 125: 0.75, 126: 0.9166666666666666, 127: 0.75, 128: 1.0, 129: 0.9166666666666666, 130: 1.0, 131: 0.8333333333333334, 132: 0.6666666666666666, 133: 1.0, 134: 0.8333333333333334, 135: 0.8333333333333334, 136: 0.8333333333333334, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.8333333333333334, 140: 1.0, 141: 1.0, 142: 0.9166666666666666, 143: 1.0, 144: 0.8333333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.9166666666666666, 148: 0.75, 149: 1.0, 150: 0.4166666666666667, 151: 0.9166666666666666, 152: 0.8333333333333334, 153: 0.75, 154: 1.0, 155: 0.9166666666666666, 156: 0.75, 157: 0.8333333333333334, 158: 0.5555555555555556, 159: 0.9166666666666666, 160: 0.4166666666666667, 161: 0.6666666666666666, 162: 0.9166666666666666, 163: 0.8333333333333334, 164: 0.9166666666666666, 165: 0.8333333333333334, 166: 0.5833333333333334, 167: 0.75, 168: 0.9166666666666666, 169: 0.9166666666666666, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.9166666666666666, 174: 1.0, 175: 0.8333333333333334, 176: 0.9166666666666666, 177: 0.8333333333333334, 178: 0.8333333333333334, 179: 0.5555555555555556, 180: 0.8333333333333334, 181: 0.75, 182: 0.5833333333333334, 183: 0.8333333333333334, 184: 0.8333333333333334, 185: 1.0, 186: 0.75, 187: 0.9166666666666666, 188: 0.6666666666666666, 189: 1.0, 190: 0.6666666666666666, 191: 0.4166666666666667, 192: 1.0, 193: 0.9166666666666666, 194: 0.8333333333333334, 195: 0.75, 196: 0.9166666666666666, 197: 0.5833333333333334, 198: 0.5833333333333334}

2025-01-12 23:02:49,294 [INFO] [26] TRAIN  loss: 0.9340988213373238 acc: 0.9903742491914369
2025-01-12 23:02:49,294 [INFO] [26] TRAIN  loss dict: {'classification_loss': 0.9340988213373238}
2025-01-12 23:02:49,295 [INFO] [26] VALIDATION loss: 1.6553604925672214 VALIDATION acc: 0.7908249158249159
2025-01-12 23:02:49,295 [INFO] [26] VALIDATION loss dict: {'classification_loss': 1.6553604925672214}
2025-01-12 23:02:49,295 [INFO] 
2025-01-12 23:03:09,789 [INFO] Step[50/4329]: training loss : 0.9201398956775665 TRAIN  loss dict:  {'classification_loss': 0.9201398956775665}
2025-01-12 23:03:24,090 [INFO] Step[100/4329]: training loss : 0.9192798233032227 TRAIN  loss dict:  {'classification_loss': 0.9192798233032227}
2025-01-12 23:03:37,298 [INFO] Step[150/4329]: training loss : 0.9220989537239075 TRAIN  loss dict:  {'classification_loss': 0.9220989537239075}
2025-01-12 23:03:49,320 [INFO] Step[200/4329]: training loss : 0.9307761037349701 TRAIN  loss dict:  {'classification_loss': 0.9307761037349701}
2025-01-12 23:04:01,273 [INFO] Step[250/4329]: training loss : 0.9326823759078979 TRAIN  loss dict:  {'classification_loss': 0.9326823759078979}
2025-01-12 23:04:13,123 [INFO] Step[300/4329]: training loss : 0.9389008390903473 TRAIN  loss dict:  {'classification_loss': 0.9389008390903473}
2025-01-12 23:04:24,801 [INFO] Step[350/4329]: training loss : 0.9213512885570526 TRAIN  loss dict:  {'classification_loss': 0.9213512885570526}
2025-01-12 23:04:36,422 [INFO] Step[400/4329]: training loss : 0.946906830072403 TRAIN  loss dict:  {'classification_loss': 0.946906830072403}
2025-01-12 23:04:48,104 [INFO] Step[450/4329]: training loss : 0.9054787707328796 TRAIN  loss dict:  {'classification_loss': 0.9054787707328796}
2025-01-12 23:04:59,788 [INFO] Step[500/4329]: training loss : 0.9227355074882507 TRAIN  loss dict:  {'classification_loss': 0.9227355074882507}
2025-01-12 23:05:11,466 [INFO] Step[550/4329]: training loss : 0.9126272797584534 TRAIN  loss dict:  {'classification_loss': 0.9126272797584534}
2025-01-12 23:05:23,113 [INFO] Step[600/4329]: training loss : 0.9283716833591461 TRAIN  loss dict:  {'classification_loss': 0.9283716833591461}
2025-01-12 23:05:34,782 [INFO] Step[650/4329]: training loss : 0.9373828220367432 TRAIN  loss dict:  {'classification_loss': 0.9373828220367432}
2025-01-12 23:05:46,441 [INFO] Step[700/4329]: training loss : 0.9360407054424286 TRAIN  loss dict:  {'classification_loss': 0.9360407054424286}
2025-01-12 23:05:58,071 [INFO] Step[750/4329]: training loss : 0.9130336165428161 TRAIN  loss dict:  {'classification_loss': 0.9130336165428161}
2025-01-12 23:06:09,705 [INFO] Step[800/4329]: training loss : 0.9054526889324188 TRAIN  loss dict:  {'classification_loss': 0.9054526889324188}
2025-01-12 23:06:21,407 [INFO] Step[850/4329]: training loss : 0.9230705440044403 TRAIN  loss dict:  {'classification_loss': 0.9230705440044403}
2025-01-12 23:06:33,066 [INFO] Step[900/4329]: training loss : 0.9502237844467163 TRAIN  loss dict:  {'classification_loss': 0.9502237844467163}
2025-01-12 23:06:44,736 [INFO] Step[950/4329]: training loss : 0.9399149906635285 TRAIN  loss dict:  {'classification_loss': 0.9399149906635285}
2025-01-12 23:06:56,416 [INFO] Step[1000/4329]: training loss : 0.9419745314121246 TRAIN  loss dict:  {'classification_loss': 0.9419745314121246}
2025-01-12 23:07:08,131 [INFO] Step[1050/4329]: training loss : 0.9353183996677399 TRAIN  loss dict:  {'classification_loss': 0.9353183996677399}
2025-01-12 23:07:19,852 [INFO] Step[1100/4329]: training loss : 0.9101061463356018 TRAIN  loss dict:  {'classification_loss': 0.9101061463356018}
2025-01-12 23:07:31,489 [INFO] Step[1150/4329]: training loss : 0.9325573861598968 TRAIN  loss dict:  {'classification_loss': 0.9325573861598968}
2025-01-12 23:07:43,142 [INFO] Step[1200/4329]: training loss : 0.9435970854759216 TRAIN  loss dict:  {'classification_loss': 0.9435970854759216}
2025-01-12 23:07:54,761 [INFO] Step[1250/4329]: training loss : 0.9273024570941925 TRAIN  loss dict:  {'classification_loss': 0.9273024570941925}
2025-01-12 23:08:06,392 [INFO] Step[1300/4329]: training loss : 0.9463758754730225 TRAIN  loss dict:  {'classification_loss': 0.9463758754730225}
2025-01-12 23:08:18,116 [INFO] Step[1350/4329]: training loss : 0.9204507744312287 TRAIN  loss dict:  {'classification_loss': 0.9204507744312287}
2025-01-12 23:08:29,788 [INFO] Step[1400/4329]: training loss : 0.9325915753841401 TRAIN  loss dict:  {'classification_loss': 0.9325915753841401}
2025-01-12 23:08:41,422 [INFO] Step[1450/4329]: training loss : 0.9270516300201416 TRAIN  loss dict:  {'classification_loss': 0.9270516300201416}
2025-01-12 23:08:53,096 [INFO] Step[1500/4329]: training loss : 0.9399154543876648 TRAIN  loss dict:  {'classification_loss': 0.9399154543876648}
2025-01-12 23:09:04,777 [INFO] Step[1550/4329]: training loss : 0.9736091387271881 TRAIN  loss dict:  {'classification_loss': 0.9736091387271881}
2025-01-12 23:09:16,451 [INFO] Step[1600/4329]: training loss : 0.9312764525413513 TRAIN  loss dict:  {'classification_loss': 0.9312764525413513}
2025-01-12 23:09:28,099 [INFO] Step[1650/4329]: training loss : 0.9400968527793885 TRAIN  loss dict:  {'classification_loss': 0.9400968527793885}
2025-01-12 23:09:39,747 [INFO] Step[1700/4329]: training loss : 0.9452296650409698 TRAIN  loss dict:  {'classification_loss': 0.9452296650409698}
2025-01-12 23:09:51,400 [INFO] Step[1750/4329]: training loss : 0.9350267314910888 TRAIN  loss dict:  {'classification_loss': 0.9350267314910888}
2025-01-12 23:10:03,032 [INFO] Step[1800/4329]: training loss : 0.9224165141582489 TRAIN  loss dict:  {'classification_loss': 0.9224165141582489}
2025-01-12 23:10:14,724 [INFO] Step[1850/4329]: training loss : 0.953102742433548 TRAIN  loss dict:  {'classification_loss': 0.953102742433548}
2025-01-12 23:10:26,379 [INFO] Step[1900/4329]: training loss : 0.9317803823947907 TRAIN  loss dict:  {'classification_loss': 0.9317803823947907}
2025-01-12 23:10:38,048 [INFO] Step[1950/4329]: training loss : 0.8997791993618012 TRAIN  loss dict:  {'classification_loss': 0.8997791993618012}
2025-01-12 23:10:49,664 [INFO] Step[2000/4329]: training loss : 0.9379840397834778 TRAIN  loss dict:  {'classification_loss': 0.9379840397834778}
2025-01-12 23:11:01,321 [INFO] Step[2050/4329]: training loss : 0.9044428443908692 TRAIN  loss dict:  {'classification_loss': 0.9044428443908692}
2025-01-12 23:11:12,947 [INFO] Step[2100/4329]: training loss : 0.9154919981956482 TRAIN  loss dict:  {'classification_loss': 0.9154919981956482}
2025-01-12 23:11:24,566 [INFO] Step[2150/4329]: training loss : 0.917115124464035 TRAIN  loss dict:  {'classification_loss': 0.917115124464035}
2025-01-12 23:11:36,209 [INFO] Step[2200/4329]: training loss : 0.9139222002029419 TRAIN  loss dict:  {'classification_loss': 0.9139222002029419}
2025-01-12 23:11:47,868 [INFO] Step[2250/4329]: training loss : 0.9221257472038269 TRAIN  loss dict:  {'classification_loss': 0.9221257472038269}
2025-01-12 23:11:59,535 [INFO] Step[2300/4329]: training loss : 0.9230269908905029 TRAIN  loss dict:  {'classification_loss': 0.9230269908905029}
2025-01-12 23:12:11,154 [INFO] Step[2350/4329]: training loss : 0.9492634761333466 TRAIN  loss dict:  {'classification_loss': 0.9492634761333466}
2025-01-12 23:12:22,804 [INFO] Step[2400/4329]: training loss : 0.9250502383708954 TRAIN  loss dict:  {'classification_loss': 0.9250502383708954}
2025-01-12 23:12:34,449 [INFO] Step[2450/4329]: training loss : 0.9643581438064576 TRAIN  loss dict:  {'classification_loss': 0.9643581438064576}
2025-01-12 23:12:46,101 [INFO] Step[2500/4329]: training loss : 0.9368253827095032 TRAIN  loss dict:  {'classification_loss': 0.9368253827095032}
2025-01-12 23:12:57,822 [INFO] Step[2550/4329]: training loss : 0.9186202764511109 TRAIN  loss dict:  {'classification_loss': 0.9186202764511109}
2025-01-12 23:13:09,424 [INFO] Step[2600/4329]: training loss : 0.9167179489135742 TRAIN  loss dict:  {'classification_loss': 0.9167179489135742}
2025-01-12 23:13:21,114 [INFO] Step[2650/4329]: training loss : 0.9360456693172455 TRAIN  loss dict:  {'classification_loss': 0.9360456693172455}
2025-01-12 23:13:32,774 [INFO] Step[2700/4329]: training loss : 0.9543209660053253 TRAIN  loss dict:  {'classification_loss': 0.9543209660053253}
2025-01-12 23:13:44,432 [INFO] Step[2750/4329]: training loss : 0.9272186279296875 TRAIN  loss dict:  {'classification_loss': 0.9272186279296875}
2025-01-12 23:13:56,095 [INFO] Step[2800/4329]: training loss : 0.9338757610321045 TRAIN  loss dict:  {'classification_loss': 0.9338757610321045}
2025-01-12 23:14:07,810 [INFO] Step[2850/4329]: training loss : 0.9513457977771759 TRAIN  loss dict:  {'classification_loss': 0.9513457977771759}
2025-01-12 23:14:19,440 [INFO] Step[2900/4329]: training loss : 0.9257378196716308 TRAIN  loss dict:  {'classification_loss': 0.9257378196716308}
2025-01-12 23:14:31,145 [INFO] Step[2950/4329]: training loss : 0.9274377000331878 TRAIN  loss dict:  {'classification_loss': 0.9274377000331878}
2025-01-12 23:14:42,825 [INFO] Step[3000/4329]: training loss : 0.9404276275634765 TRAIN  loss dict:  {'classification_loss': 0.9404276275634765}
2025-01-12 23:14:54,516 [INFO] Step[3050/4329]: training loss : 0.9424116909503937 TRAIN  loss dict:  {'classification_loss': 0.9424116909503937}
2025-01-12 23:15:06,705 [INFO] Step[3100/4329]: training loss : 0.9195594477653504 TRAIN  loss dict:  {'classification_loss': 0.9195594477653504}
2025-01-12 23:15:18,984 [INFO] Step[3150/4329]: training loss : 0.9184570372104645 TRAIN  loss dict:  {'classification_loss': 0.9184570372104645}
2025-01-12 23:15:31,984 [INFO] Step[3200/4329]: training loss : 0.9127731478214264 TRAIN  loss dict:  {'classification_loss': 0.9127731478214264}
2025-01-12 23:15:45,433 [INFO] Step[3250/4329]: training loss : 0.9192440116405487 TRAIN  loss dict:  {'classification_loss': 0.9192440116405487}
2025-01-12 23:15:58,516 [INFO] Step[3300/4329]: training loss : 0.9446211075782776 TRAIN  loss dict:  {'classification_loss': 0.9446211075782776}
2025-01-12 23:16:10,450 [INFO] Step[3350/4329]: training loss : 0.9223056399822235 TRAIN  loss dict:  {'classification_loss': 0.9223056399822235}
2025-01-12 23:16:22,296 [INFO] Step[3400/4329]: training loss : 0.957930783033371 TRAIN  loss dict:  {'classification_loss': 0.957930783033371}
2025-01-12 23:16:33,916 [INFO] Step[3450/4329]: training loss : 0.9115545165538788 TRAIN  loss dict:  {'classification_loss': 0.9115545165538788}
2025-01-12 23:16:45,515 [INFO] Step[3500/4329]: training loss : 0.9261142027378082 TRAIN  loss dict:  {'classification_loss': 0.9261142027378082}
2025-01-12 23:16:57,148 [INFO] Step[3550/4329]: training loss : 0.9082711744308472 TRAIN  loss dict:  {'classification_loss': 0.9082711744308472}
2025-01-12 23:17:08,800 [INFO] Step[3600/4329]: training loss : 0.953184894323349 TRAIN  loss dict:  {'classification_loss': 0.953184894323349}
2025-01-12 23:17:20,434 [INFO] Step[3650/4329]: training loss : 0.9377946722507476 TRAIN  loss dict:  {'classification_loss': 0.9377946722507476}
2025-01-12 23:17:32,064 [INFO] Step[3700/4329]: training loss : 0.9178307831287384 TRAIN  loss dict:  {'classification_loss': 0.9178307831287384}
2025-01-12 23:17:43,693 [INFO] Step[3750/4329]: training loss : 0.93210928440094 TRAIN  loss dict:  {'classification_loss': 0.93210928440094}
2025-01-12 23:17:55,360 [INFO] Step[3800/4329]: training loss : 0.9531912517547607 TRAIN  loss dict:  {'classification_loss': 0.9531912517547607}
2025-01-12 23:18:07,017 [INFO] Step[3850/4329]: training loss : 0.9336354279518128 TRAIN  loss dict:  {'classification_loss': 0.9336354279518128}
2025-01-12 23:18:18,624 [INFO] Step[3900/4329]: training loss : 0.9524895405769348 TRAIN  loss dict:  {'classification_loss': 0.9524895405769348}
2025-01-12 23:18:30,242 [INFO] Step[3950/4329]: training loss : 0.9669912707805634 TRAIN  loss dict:  {'classification_loss': 0.9669912707805634}
2025-01-12 23:18:41,846 [INFO] Step[4000/4329]: training loss : 0.9303887939453125 TRAIN  loss dict:  {'classification_loss': 0.9303887939453125}
2025-01-12 23:18:53,449 [INFO] Step[4050/4329]: training loss : 0.9155435240268708 TRAIN  loss dict:  {'classification_loss': 0.9155435240268708}
2025-01-12 23:19:05,095 [INFO] Step[4100/4329]: training loss : 0.9139797055721283 TRAIN  loss dict:  {'classification_loss': 0.9139797055721283}
2025-01-12 23:19:16,683 [INFO] Step[4150/4329]: training loss : 0.9165055966377258 TRAIN  loss dict:  {'classification_loss': 0.9165055966377258}
2025-01-12 23:19:28,296 [INFO] Step[4200/4329]: training loss : 0.9340607678890228 TRAIN  loss dict:  {'classification_loss': 0.9340607678890228}
2025-01-12 23:19:39,920 [INFO] Step[4250/4329]: training loss : 0.9352362418174743 TRAIN  loss dict:  {'classification_loss': 0.9352362418174743}
2025-01-12 23:19:51,537 [INFO] Step[4300/4329]: training loss : 0.9187421691417694 TRAIN  loss dict:  {'classification_loss': 0.9187421691417694}
2025-01-12 23:21:50,998 [INFO] Label accuracies statistics:
2025-01-12 23:21:50,998 [INFO] {0: 0.5555555555555556, 1: 0.8888888888888888, 2: 0.5833333333333334, 3: 0.8333333333333334, 4: 0.25, 5: 0.8333333333333334, 6: 0.75, 7: 0.4166666666666667, 8: 0.3333333333333333, 9: 0.9166666666666666, 10: 1.0, 11: 0.8333333333333334, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.5555555555555556, 16: 0.5, 17: 0.6666666666666666, 18: 0.5833333333333334, 19: 0.75, 20: 0.5833333333333334, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.8333333333333334, 27: 0.8333333333333334, 28: 0.8333333333333334, 29: 1.0, 30: 0.6666666666666666, 31: 0.75, 32: 0.6666666666666666, 33: 0.8333333333333334, 34: 1.0, 35: 0.9166666666666666, 36: 0.5, 37: 0.9166666666666666, 38: 0.9166666666666666, 39: 0.9166666666666666, 40: 0.8333333333333334, 41: 0.4166666666666667, 42: 0.9166666666666666, 43: 1.0, 44: 0.6666666666666666, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.4166666666666667, 55: 0.5833333333333334, 56: 0.75, 57: 0.6666666666666666, 58: 0.6666666666666666, 59: 0.8333333333333334, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.4166666666666667, 64: 1.0, 65: 0.9166666666666666, 66: 0.6666666666666666, 67: 0.8333333333333334, 68: 0.75, 69: 0.6666666666666666, 70: 0.3333333333333333, 71: 0.4166666666666667, 72: 0.8333333333333334, 73: 0.9166666666666666, 74: 0.5833333333333334, 75: 1.0, 76: 0.5833333333333334, 77: 0.6666666666666666, 78: 0.9166666666666666, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.6666666666666666, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.75, 89: 0.5833333333333334, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 1.0, 96: 0.4166666666666667, 97: 0.75, 98: 0.8333333333333334, 99: 1.0, 100: 0.8333333333333334, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.9166666666666666, 105: 1.0, 106: 0.9166666666666666, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 1.0, 111: 1.0, 112: 0.9166666666666666, 113: 0.5, 114: 0.3333333333333333, 115: 1.0, 116: 0.6666666666666666, 117: 0.9166666666666666, 118: 1.0, 119: 0.75, 120: 0.8333333333333334, 121: 0.75, 122: 0.75, 123: 0.9166666666666666, 124: 0.8333333333333334, 125: 0.8333333333333334, 126: 0.9166666666666666, 127: 0.5, 128: 1.0, 129: 0.9166666666666666, 130: 0.5833333333333334, 131: 0.8333333333333334, 132: 0.5, 133: 1.0, 134: 0.75, 135: 0.8333333333333334, 136: 0.8333333333333334, 137: 0.8333333333333334, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 1.0, 141: 0.9166666666666666, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.5833333333333334, 149: 1.0, 150: 0.5, 151: 0.8333333333333334, 152: 1.0, 153: 0.6666666666666666, 154: 0.9166666666666666, 155: 1.0, 156: 1.0, 157: 0.9166666666666666, 158: 0.5555555555555556, 159: 1.0, 160: 0.5, 161: 0.8333333333333334, 162: 1.0, 163: 0.8333333333333334, 164: 0.8333333333333334, 165: 0.6666666666666666, 166: 0.75, 167: 0.8333333333333334, 168: 0.8333333333333334, 169: 0.9166666666666666, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.8333333333333334, 174: 1.0, 175: 0.5833333333333334, 176: 0.9166666666666666, 177: 0.9166666666666666, 178: 1.0, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.6666666666666666, 183: 0.8333333333333334, 184: 0.8333333333333334, 185: 0.9166666666666666, 186: 0.5833333333333334, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.5833333333333334, 191: 0.4166666666666667, 192: 1.0, 193: 0.75, 194: 0.8333333333333334, 195: 0.75, 196: 0.9166666666666666, 197: 0.6666666666666666, 198: 0.5833333333333334}

2025-01-12 23:21:51,001 [INFO] [27] TRAIN  loss: 0.9309167565085591 acc: 0.9904512551979054
2025-01-12 23:21:51,001 [INFO] [27] TRAIN  loss dict: {'classification_loss': 0.9309167565085591}
2025-01-12 23:21:51,001 [INFO] [27] VALIDATION loss: 1.6680274019488182 VALIDATION acc: 0.781986531986532
2025-01-12 23:21:51,001 [INFO] [27] VALIDATION loss dict: {'classification_loss': 1.6680274019488182}
2025-01-12 23:21:51,001 [INFO] 
2025-01-12 23:22:08,202 [INFO] Step[50/4329]: training loss : 0.9428680658340454 TRAIN  loss dict:  {'classification_loss': 0.9428680658340454}
2025-01-12 23:22:19,751 [INFO] Step[100/4329]: training loss : 0.9441178166866302 TRAIN  loss dict:  {'classification_loss': 0.9441178166866302}
2025-01-12 23:22:31,382 [INFO] Step[150/4329]: training loss : 0.9037440407276154 TRAIN  loss dict:  {'classification_loss': 0.9037440407276154}
2025-01-12 23:22:42,972 [INFO] Step[200/4329]: training loss : 0.9517192721366883 TRAIN  loss dict:  {'classification_loss': 0.9517192721366883}
2025-01-12 23:22:54,604 [INFO] Step[250/4329]: training loss : 0.932204567193985 TRAIN  loss dict:  {'classification_loss': 0.932204567193985}
2025-01-12 23:23:06,233 [INFO] Step[300/4329]: training loss : 0.9575271117687225 TRAIN  loss dict:  {'classification_loss': 0.9575271117687225}
2025-01-12 23:23:17,853 [INFO] Step[350/4329]: training loss : 0.930844087600708 TRAIN  loss dict:  {'classification_loss': 0.930844087600708}
2025-01-12 23:23:29,510 [INFO] Step[400/4329]: training loss : 0.9851199603080749 TRAIN  loss dict:  {'classification_loss': 0.9851199603080749}
2025-01-12 23:23:41,167 [INFO] Step[450/4329]: training loss : 0.9188140249252319 TRAIN  loss dict:  {'classification_loss': 0.9188140249252319}
2025-01-12 23:23:52,757 [INFO] Step[500/4329]: training loss : 0.9068647015094757 TRAIN  loss dict:  {'classification_loss': 0.9068647015094757}
2025-01-12 23:24:04,353 [INFO] Step[550/4329]: training loss : 0.9258169543743133 TRAIN  loss dict:  {'classification_loss': 0.9258169543743133}
2025-01-12 23:24:15,955 [INFO] Step[600/4329]: training loss : 0.9190781772136688 TRAIN  loss dict:  {'classification_loss': 0.9190781772136688}
2025-01-12 23:24:27,592 [INFO] Step[650/4329]: training loss : 0.9349327373504639 TRAIN  loss dict:  {'classification_loss': 0.9349327373504639}
2025-01-12 23:24:39,226 [INFO] Step[700/4329]: training loss : 0.9437803018093109 TRAIN  loss dict:  {'classification_loss': 0.9437803018093109}
2025-01-12 23:24:50,884 [INFO] Step[750/4329]: training loss : 0.9113780665397644 TRAIN  loss dict:  {'classification_loss': 0.9113780665397644}
2025-01-12 23:25:02,492 [INFO] Step[800/4329]: training loss : 0.9310069954395295 TRAIN  loss dict:  {'classification_loss': 0.9310069954395295}
2025-01-12 23:25:14,128 [INFO] Step[850/4329]: training loss : 0.9540877544879913 TRAIN  loss dict:  {'classification_loss': 0.9540877544879913}
2025-01-12 23:25:25,769 [INFO] Step[900/4329]: training loss : 0.9092040920257568 TRAIN  loss dict:  {'classification_loss': 0.9092040920257568}
2025-01-12 23:25:37,387 [INFO] Step[950/4329]: training loss : 0.9064328944683075 TRAIN  loss dict:  {'classification_loss': 0.9064328944683075}
2025-01-12 23:25:49,066 [INFO] Step[1000/4329]: training loss : 0.931368215084076 TRAIN  loss dict:  {'classification_loss': 0.931368215084076}
2025-01-12 23:26:00,726 [INFO] Step[1050/4329]: training loss : 0.9280615675449372 TRAIN  loss dict:  {'classification_loss': 0.9280615675449372}
2025-01-12 23:26:12,355 [INFO] Step[1100/4329]: training loss : 0.9316209995746613 TRAIN  loss dict:  {'classification_loss': 0.9316209995746613}
2025-01-12 23:26:24,032 [INFO] Step[1150/4329]: training loss : 0.9263997340202331 TRAIN  loss dict:  {'classification_loss': 0.9263997340202331}
2025-01-12 23:26:35,621 [INFO] Step[1200/4329]: training loss : 0.9499252593517303 TRAIN  loss dict:  {'classification_loss': 0.9499252593517303}
2025-01-12 23:26:47,224 [INFO] Step[1250/4329]: training loss : 0.9645521330833435 TRAIN  loss dict:  {'classification_loss': 0.9645521330833435}
2025-01-12 23:26:58,866 [INFO] Step[1300/4329]: training loss : 0.9354937469959259 TRAIN  loss dict:  {'classification_loss': 0.9354937469959259}
2025-01-12 23:27:10,493 [INFO] Step[1350/4329]: training loss : 0.9439115929603576 TRAIN  loss dict:  {'classification_loss': 0.9439115929603576}
2025-01-12 23:27:22,239 [INFO] Step[1400/4329]: training loss : 0.9165801417827606 TRAIN  loss dict:  {'classification_loss': 0.9165801417827606}
2025-01-12 23:27:34,609 [INFO] Step[1450/4329]: training loss : 0.9305565762519836 TRAIN  loss dict:  {'classification_loss': 0.9305565762519836}
2025-01-12 23:27:46,812 [INFO] Step[1500/4329]: training loss : 0.9342450547218323 TRAIN  loss dict:  {'classification_loss': 0.9342450547218323}
2025-01-12 23:27:59,535 [INFO] Step[1550/4329]: training loss : 0.9589562547206879 TRAIN  loss dict:  {'classification_loss': 0.9589562547206879}
2025-01-12 23:28:12,664 [INFO] Step[1600/4329]: training loss : 0.9412767815589905 TRAIN  loss dict:  {'classification_loss': 0.9412767815589905}
2025-01-12 23:28:25,377 [INFO] Step[1650/4329]: training loss : 0.9355713188648224 TRAIN  loss dict:  {'classification_loss': 0.9355713188648224}
2025-01-12 23:28:37,368 [INFO] Step[1700/4329]: training loss : 0.9156771492958069 TRAIN  loss dict:  {'classification_loss': 0.9156771492958069}
2025-01-12 23:28:49,242 [INFO] Step[1750/4329]: training loss : 0.9556911480426789 TRAIN  loss dict:  {'classification_loss': 0.9556911480426789}
2025-01-12 23:29:00,867 [INFO] Step[1800/4329]: training loss : 0.9165648674964905 TRAIN  loss dict:  {'classification_loss': 0.9165648674964905}
2025-01-12 23:29:12,487 [INFO] Step[1850/4329]: training loss : 0.9268769502639771 TRAIN  loss dict:  {'classification_loss': 0.9268769502639771}
2025-01-12 23:29:24,124 [INFO] Step[1900/4329]: training loss : 0.9259988415241241 TRAIN  loss dict:  {'classification_loss': 0.9259988415241241}
2025-01-12 23:29:35,730 [INFO] Step[1950/4329]: training loss : 0.9495012724399566 TRAIN  loss dict:  {'classification_loss': 0.9495012724399566}
2025-01-12 23:29:47,382 [INFO] Step[2000/4329]: training loss : 0.9107412338256836 TRAIN  loss dict:  {'classification_loss': 0.9107412338256836}
2025-01-12 23:29:59,000 [INFO] Step[2050/4329]: training loss : 0.9188664281368255 TRAIN  loss dict:  {'classification_loss': 0.9188664281368255}
2025-01-12 23:30:10,613 [INFO] Step[2100/4329]: training loss : 0.949716831445694 TRAIN  loss dict:  {'classification_loss': 0.949716831445694}
2025-01-12 23:30:22,235 [INFO] Step[2150/4329]: training loss : 0.9353312361240387 TRAIN  loss dict:  {'classification_loss': 0.9353312361240387}
2025-01-12 23:30:33,865 [INFO] Step[2200/4329]: training loss : 0.9302410423755646 TRAIN  loss dict:  {'classification_loss': 0.9302410423755646}
2025-01-12 23:30:45,497 [INFO] Step[2250/4329]: training loss : 0.9343210887908936 TRAIN  loss dict:  {'classification_loss': 0.9343210887908936}
2025-01-12 23:30:57,131 [INFO] Step[2300/4329]: training loss : 0.913513970375061 TRAIN  loss dict:  {'classification_loss': 0.913513970375061}
2025-01-12 23:31:08,782 [INFO] Step[2350/4329]: training loss : 0.9074745595455169 TRAIN  loss dict:  {'classification_loss': 0.9074745595455169}
2025-01-12 23:31:20,426 [INFO] Step[2400/4329]: training loss : 0.9254623448848724 TRAIN  loss dict:  {'classification_loss': 0.9254623448848724}
2025-01-12 23:31:32,030 [INFO] Step[2450/4329]: training loss : 0.9058118212223053 TRAIN  loss dict:  {'classification_loss': 0.9058118212223053}
2025-01-12 23:31:43,635 [INFO] Step[2500/4329]: training loss : 0.9181867706775665 TRAIN  loss dict:  {'classification_loss': 0.9181867706775665}
2025-01-12 23:31:55,281 [INFO] Step[2550/4329]: training loss : 0.9120737540721894 TRAIN  loss dict:  {'classification_loss': 0.9120737540721894}
2025-01-12 23:32:06,897 [INFO] Step[2600/4329]: training loss : 0.9189701998233795 TRAIN  loss dict:  {'classification_loss': 0.9189701998233795}
2025-01-12 23:32:18,525 [INFO] Step[2650/4329]: training loss : 0.9352450907230377 TRAIN  loss dict:  {'classification_loss': 0.9352450907230377}
2025-01-12 23:32:30,164 [INFO] Step[2700/4329]: training loss : 0.9127959775924682 TRAIN  loss dict:  {'classification_loss': 0.9127959775924682}
2025-01-12 23:32:41,757 [INFO] Step[2750/4329]: training loss : 0.918920521736145 TRAIN  loss dict:  {'classification_loss': 0.918920521736145}
2025-01-12 23:32:53,331 [INFO] Step[2800/4329]: training loss : 0.9087800216674805 TRAIN  loss dict:  {'classification_loss': 0.9087800216674805}
2025-01-12 23:33:04,960 [INFO] Step[2850/4329]: training loss : 0.9235658967494964 TRAIN  loss dict:  {'classification_loss': 0.9235658967494964}
2025-01-12 23:33:16,550 [INFO] Step[2900/4329]: training loss : 0.9241560232639313 TRAIN  loss dict:  {'classification_loss': 0.9241560232639313}
2025-01-12 23:33:28,203 [INFO] Step[2950/4329]: training loss : 0.9485753870010376 TRAIN  loss dict:  {'classification_loss': 0.9485753870010376}
2025-01-12 23:33:39,841 [INFO] Step[3000/4329]: training loss : 0.9458863425254822 TRAIN  loss dict:  {'classification_loss': 0.9458863425254822}
2025-01-12 23:33:51,500 [INFO] Step[3050/4329]: training loss : 0.9298424530029297 TRAIN  loss dict:  {'classification_loss': 0.9298424530029297}
2025-01-12 23:34:03,122 [INFO] Step[3100/4329]: training loss : 0.9445238816738128 TRAIN  loss dict:  {'classification_loss': 0.9445238816738128}
2025-01-12 23:34:14,760 [INFO] Step[3150/4329]: training loss : 0.9416286981105805 TRAIN  loss dict:  {'classification_loss': 0.9416286981105805}
2025-01-12 23:34:26,394 [INFO] Step[3200/4329]: training loss : 0.9154707098007202 TRAIN  loss dict:  {'classification_loss': 0.9154707098007202}
2025-01-12 23:34:38,034 [INFO] Step[3250/4329]: training loss : 0.9177985239028931 TRAIN  loss dict:  {'classification_loss': 0.9177985239028931}
2025-01-12 23:34:49,665 [INFO] Step[3300/4329]: training loss : 0.9102857077121734 TRAIN  loss dict:  {'classification_loss': 0.9102857077121734}
2025-01-12 23:35:01,290 [INFO] Step[3350/4329]: training loss : 0.9328647124767303 TRAIN  loss dict:  {'classification_loss': 0.9328647124767303}
2025-01-12 23:35:12,899 [INFO] Step[3400/4329]: training loss : 0.9334593117237091 TRAIN  loss dict:  {'classification_loss': 0.9334593117237091}
2025-01-12 23:35:24,556 [INFO] Step[3450/4329]: training loss : 0.9377455484867095 TRAIN  loss dict:  {'classification_loss': 0.9377455484867095}
2025-01-12 23:35:36,183 [INFO] Step[3500/4329]: training loss : 0.9152939176559448 TRAIN  loss dict:  {'classification_loss': 0.9152939176559448}
2025-01-12 23:35:47,799 [INFO] Step[3550/4329]: training loss : 0.952406324148178 TRAIN  loss dict:  {'classification_loss': 0.952406324148178}
2025-01-12 23:35:59,401 [INFO] Step[3600/4329]: training loss : 0.9111987328529358 TRAIN  loss dict:  {'classification_loss': 0.9111987328529358}
2025-01-12 23:36:11,030 [INFO] Step[3650/4329]: training loss : 0.9320332825183868 TRAIN  loss dict:  {'classification_loss': 0.9320332825183868}
2025-01-12 23:36:22,649 [INFO] Step[3700/4329]: training loss : 0.9511517286300659 TRAIN  loss dict:  {'classification_loss': 0.9511517286300659}
2025-01-12 23:36:34,250 [INFO] Step[3750/4329]: training loss : 0.923425452709198 TRAIN  loss dict:  {'classification_loss': 0.923425452709198}
2025-01-12 23:36:45,859 [INFO] Step[3800/4329]: training loss : 0.9127579212188721 TRAIN  loss dict:  {'classification_loss': 0.9127579212188721}
2025-01-12 23:36:57,487 [INFO] Step[3850/4329]: training loss : 0.9143737030029296 TRAIN  loss dict:  {'classification_loss': 0.9143737030029296}
2025-01-12 23:37:09,084 [INFO] Step[3900/4329]: training loss : 0.97658855676651 TRAIN  loss dict:  {'classification_loss': 0.97658855676651}
2025-01-12 23:37:20,716 [INFO] Step[3950/4329]: training loss : 0.9167811501026154 TRAIN  loss dict:  {'classification_loss': 0.9167811501026154}
2025-01-12 23:37:32,344 [INFO] Step[4000/4329]: training loss : 0.924525215625763 TRAIN  loss dict:  {'classification_loss': 0.924525215625763}
2025-01-12 23:37:43,965 [INFO] Step[4050/4329]: training loss : 0.9353127717971802 TRAIN  loss dict:  {'classification_loss': 0.9353127717971802}
2025-01-12 23:37:55,592 [INFO] Step[4100/4329]: training loss : 0.932186222076416 TRAIN  loss dict:  {'classification_loss': 0.932186222076416}
2025-01-12 23:38:07,217 [INFO] Step[4150/4329]: training loss : 0.9476803767681122 TRAIN  loss dict:  {'classification_loss': 0.9476803767681122}
2025-01-12 23:38:18,837 [INFO] Step[4200/4329]: training loss : 0.902387592792511 TRAIN  loss dict:  {'classification_loss': 0.902387592792511}
2025-01-12 23:38:30,408 [INFO] Step[4250/4329]: training loss : 0.9374995970726013 TRAIN  loss dict:  {'classification_loss': 0.9374995970726013}
2025-01-12 23:38:42,049 [INFO] Step[4300/4329]: training loss : 0.8982315540313721 TRAIN  loss dict:  {'classification_loss': 0.8982315540313721}
2025-01-12 23:41:01,282 [INFO] Label accuracies statistics:
2025-01-12 23:41:01,283 [INFO] {0: 0.4444444444444444, 1: 0.8888888888888888, 2: 0.6666666666666666, 3: 0.75, 4: 0.25, 5: 0.9166666666666666, 6: 0.5833333333333334, 7: 0.5833333333333334, 8: 0.5, 9: 0.6666666666666666, 10: 1.0, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.5, 14: 0.5833333333333334, 15: 0.7777777777777778, 16: 0.5833333333333334, 17: 0.4166666666666667, 18: 0.6666666666666666, 19: 0.6666666666666666, 20: 0.5, 21: 0.5833333333333334, 22: 0.6666666666666666, 23: 1.0, 24: 1.0, 25: 0.8333333333333334, 26: 1.0, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.6666666666666666, 32: 0.5, 33: 0.8333333333333334, 34: 0.9166666666666666, 35: 0.9166666666666666, 36: 0.75, 37: 1.0, 38: 0.9166666666666666, 39: 1.0, 40: 0.8333333333333334, 41: 0.3333333333333333, 42: 0.8333333333333334, 43: 0.8333333333333334, 44: 0.5, 45: 0.6666666666666666, 46: 1.0, 47: 0.9166666666666666, 48: 1.0, 49: 1.0, 50: 0.5833333333333334, 51: 0.75, 52: 1.0, 53: 0.6666666666666666, 54: 0.4166666666666667, 55: 0.5, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.6666666666666666, 59: 0.75, 60: 0.6666666666666666, 61: 0.9166666666666666, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.6666666666666666, 69: 0.75, 70: 0.4166666666666667, 71: 0.4166666666666667, 72: 0.75, 73: 1.0, 74: 0.6666666666666666, 75: 1.0, 76: 0.5833333333333334, 77: 0.5833333333333334, 78: 0.9166666666666666, 79: 0.5833333333333334, 80: 1.0, 81: 1.0, 82: 0.6666666666666666, 83: 0.3333333333333333, 84: 0.5, 85: 0.75, 86: 0.5833333333333334, 87: 0.8333333333333334, 88: 0.6666666666666666, 89: 0.5, 90: 0.6666666666666666, 91: 0.8333333333333334, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.5833333333333334, 97: 0.75, 98: 0.8333333333333334, 99: 1.0, 100: 0.8333333333333334, 101: 0.9166666666666666, 102: 0.9166666666666666, 103: 1.0, 104: 1.0, 105: 0.9166666666666666, 106: 0.8333333333333334, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.8333333333333334, 111: 1.0, 112: 1.0, 113: 0.5, 114: 0.5833333333333334, 115: 1.0, 116: 0.75, 117: 0.75, 118: 0.9166666666666666, 119: 0.75, 120: 0.9166666666666666, 121: 0.75, 122: 0.6666666666666666, 123: 1.0, 124: 0.9166666666666666, 125: 0.9166666666666666, 126: 0.9166666666666666, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.8333333333333334, 132: 0.75, 133: 1.0, 134: 0.5833333333333334, 135: 0.9166666666666666, 136: 0.8333333333333334, 137: 1.0, 138: 0.8333333333333334, 139: 0.75, 140: 0.9166666666666666, 141: 0.9166666666666666, 142: 0.6666666666666666, 143: 1.0, 144: 0.75, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.4166666666666667, 151: 0.9166666666666666, 152: 0.9166666666666666, 153: 0.8333333333333334, 154: 1.0, 155: 1.0, 156: 0.6666666666666666, 157: 0.9166666666666666, 158: 0.6666666666666666, 159: 0.9166666666666666, 160: 0.16666666666666666, 161: 0.9166666666666666, 162: 0.9166666666666666, 163: 1.0, 164: 0.8333333333333334, 165: 0.8333333333333334, 166: 0.75, 167: 0.9166666666666666, 168: 0.75, 169: 0.8333333333333334, 170: 1.0, 171: 0.8333333333333334, 172: 1.0, 173: 0.75, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.6666666666666666, 178: 0.9166666666666666, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.5, 183: 0.75, 184: 0.8333333333333334, 185: 0.9166666666666666, 186: 0.9166666666666666, 187: 1.0, 188: 0.6666666666666666, 189: 1.0, 190: 0.6666666666666666, 191: 0.5, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.75, 198: 0.5833333333333334}

2025-01-12 23:41:01,295 [INFO] [28] TRAIN  loss: 0.930034882506258 acc: 0.9901432311720314
2025-01-12 23:41:01,295 [INFO] [28] TRAIN  loss dict: {'classification_loss': 0.930034882506258}
2025-01-12 23:41:01,296 [INFO] [28] VALIDATION loss: 1.6821558392710156 VALIDATION acc: 0.7853535353535354
2025-01-12 23:41:01,297 [INFO] [28] VALIDATION loss dict: {'classification_loss': 1.6821558392710156}
2025-01-12 23:41:01,298 [INFO] 
2025-01-12 23:41:20,376 [INFO] Step[50/4329]: training loss : 0.9225162982940673 TRAIN  loss dict:  {'classification_loss': 0.9225162982940673}
2025-01-12 23:41:32,171 [INFO] Step[100/4329]: training loss : 0.9287855982780456 TRAIN  loss dict:  {'classification_loss': 0.9287855982780456}
2025-01-12 23:41:43,808 [INFO] Step[150/4329]: training loss : 0.9131355845928192 TRAIN  loss dict:  {'classification_loss': 0.9131355845928192}
2025-01-12 23:41:55,416 [INFO] Step[200/4329]: training loss : 0.9059915637969971 TRAIN  loss dict:  {'classification_loss': 0.9059915637969971}
2025-01-12 23:42:07,079 [INFO] Step[250/4329]: training loss : 0.9269842076301574 TRAIN  loss dict:  {'classification_loss': 0.9269842076301574}
2025-01-12 23:42:18,718 [INFO] Step[300/4329]: training loss : 0.9585293281078339 TRAIN  loss dict:  {'classification_loss': 0.9585293281078339}
2025-01-12 23:42:30,423 [INFO] Step[350/4329]: training loss : 0.9144915866851807 TRAIN  loss dict:  {'classification_loss': 0.9144915866851807}
2025-01-12 23:42:42,020 [INFO] Step[400/4329]: training loss : 0.9289775133132935 TRAIN  loss dict:  {'classification_loss': 0.9289775133132935}
2025-01-12 23:42:53,630 [INFO] Step[450/4329]: training loss : 0.9080648839473724 TRAIN  loss dict:  {'classification_loss': 0.9080648839473724}
2025-01-12 23:43:05,238 [INFO] Step[500/4329]: training loss : 0.9281810224056244 TRAIN  loss dict:  {'classification_loss': 0.9281810224056244}
2025-01-12 23:43:16,868 [INFO] Step[550/4329]: training loss : 0.911559944152832 TRAIN  loss dict:  {'classification_loss': 0.911559944152832}
2025-01-12 23:43:28,483 [INFO] Step[600/4329]: training loss : 0.9274377429485321 TRAIN  loss dict:  {'classification_loss': 0.9274377429485321}
2025-01-12 23:43:40,150 [INFO] Step[650/4329]: training loss : 0.9169282984733581 TRAIN  loss dict:  {'classification_loss': 0.9169282984733581}
2025-01-12 23:43:51,801 [INFO] Step[700/4329]: training loss : 0.9156551861763 TRAIN  loss dict:  {'classification_loss': 0.9156551861763}
2025-01-12 23:44:03,416 [INFO] Step[750/4329]: training loss : 0.9022484385967254 TRAIN  loss dict:  {'classification_loss': 0.9022484385967254}
2025-01-12 23:44:15,042 [INFO] Step[800/4329]: training loss : 0.930919133424759 TRAIN  loss dict:  {'classification_loss': 0.930919133424759}
2025-01-12 23:44:26,684 [INFO] Step[850/4329]: training loss : 0.9266994953155517 TRAIN  loss dict:  {'classification_loss': 0.9266994953155517}
2025-01-12 23:44:38,329 [INFO] Step[900/4329]: training loss : 0.9081705915927887 TRAIN  loss dict:  {'classification_loss': 0.9081705915927887}
2025-01-12 23:44:49,967 [INFO] Step[950/4329]: training loss : 0.9507565808296203 TRAIN  loss dict:  {'classification_loss': 0.9507565808296203}
2025-01-12 23:45:01,617 [INFO] Step[1000/4329]: training loss : 0.9335773110389709 TRAIN  loss dict:  {'classification_loss': 0.9335773110389709}
2025-01-12 23:45:13,244 [INFO] Step[1050/4329]: training loss : 0.919162654876709 TRAIN  loss dict:  {'classification_loss': 0.919162654876709}
2025-01-12 23:45:24,864 [INFO] Step[1100/4329]: training loss : 0.9196862006187438 TRAIN  loss dict:  {'classification_loss': 0.9196862006187438}
2025-01-12 23:45:36,482 [INFO] Step[1150/4329]: training loss : 0.9314118540287017 TRAIN  loss dict:  {'classification_loss': 0.9314118540287017}
2025-01-12 23:45:48,108 [INFO] Step[1200/4329]: training loss : 0.9302998507022857 TRAIN  loss dict:  {'classification_loss': 0.9302998507022857}
2025-01-12 23:45:59,744 [INFO] Step[1250/4329]: training loss : 0.9008672451972961 TRAIN  loss dict:  {'classification_loss': 0.9008672451972961}
2025-01-12 23:46:11,404 [INFO] Step[1300/4329]: training loss : 0.937087504863739 TRAIN  loss dict:  {'classification_loss': 0.937087504863739}
2025-01-12 23:46:23,031 [INFO] Step[1350/4329]: training loss : 0.9363395285606384 TRAIN  loss dict:  {'classification_loss': 0.9363395285606384}
2025-01-12 23:46:34,636 [INFO] Step[1400/4329]: training loss : 0.9089887595176697 TRAIN  loss dict:  {'classification_loss': 0.9089887595176697}
2025-01-12 23:46:46,311 [INFO] Step[1450/4329]: training loss : 0.957514979839325 TRAIN  loss dict:  {'classification_loss': 0.957514979839325}
2025-01-12 23:46:57,936 [INFO] Step[1500/4329]: training loss : 0.9355972886085511 TRAIN  loss dict:  {'classification_loss': 0.9355972886085511}
2025-01-12 23:47:09,552 [INFO] Step[1550/4329]: training loss : 0.9506494414806366 TRAIN  loss dict:  {'classification_loss': 0.9506494414806366}
2025-01-12 23:47:21,172 [INFO] Step[1600/4329]: training loss : 0.9007199513912201 TRAIN  loss dict:  {'classification_loss': 0.9007199513912201}
2025-01-12 23:47:32,827 [INFO] Step[1650/4329]: training loss : 0.9133765149116516 TRAIN  loss dict:  {'classification_loss': 0.9133765149116516}
2025-01-12 23:47:44,457 [INFO] Step[1700/4329]: training loss : 0.9107181954383851 TRAIN  loss dict:  {'classification_loss': 0.9107181954383851}
2025-01-12 23:47:56,097 [INFO] Step[1750/4329]: training loss : 0.9171217572689057 TRAIN  loss dict:  {'classification_loss': 0.9171217572689057}
2025-01-12 23:48:07,745 [INFO] Step[1800/4329]: training loss : 0.9512760746479034 TRAIN  loss dict:  {'classification_loss': 0.9512760746479034}
2025-01-12 23:48:19,371 [INFO] Step[1850/4329]: training loss : 0.9211430037021637 TRAIN  loss dict:  {'classification_loss': 0.9211430037021637}
2025-01-12 23:48:30,995 [INFO] Step[1900/4329]: training loss : 0.938099913597107 TRAIN  loss dict:  {'classification_loss': 0.938099913597107}
2025-01-12 23:48:42,666 [INFO] Step[1950/4329]: training loss : 0.9183477187156677 TRAIN  loss dict:  {'classification_loss': 0.9183477187156677}
2025-01-12 23:48:54,278 [INFO] Step[2000/4329]: training loss : 0.9115708959102631 TRAIN  loss dict:  {'classification_loss': 0.9115708959102631}
2025-01-12 23:49:05,939 [INFO] Step[2050/4329]: training loss : 0.897020868062973 TRAIN  loss dict:  {'classification_loss': 0.897020868062973}
2025-01-12 23:49:17,561 [INFO] Step[2100/4329]: training loss : 0.912728899717331 TRAIN  loss dict:  {'classification_loss': 0.912728899717331}
2025-01-12 23:49:29,217 [INFO] Step[2150/4329]: training loss : 0.9417089807987213 TRAIN  loss dict:  {'classification_loss': 0.9417089807987213}
2025-01-12 23:49:40,847 [INFO] Step[2200/4329]: training loss : 0.9310693264007568 TRAIN  loss dict:  {'classification_loss': 0.9310693264007568}
2025-01-12 23:49:52,507 [INFO] Step[2250/4329]: training loss : 0.9348596394062042 TRAIN  loss dict:  {'classification_loss': 0.9348596394062042}
2025-01-12 23:50:04,155 [INFO] Step[2300/4329]: training loss : 0.9587659955024719 TRAIN  loss dict:  {'classification_loss': 0.9587659955024719}
2025-01-12 23:50:15,789 [INFO] Step[2350/4329]: training loss : 0.907397427558899 TRAIN  loss dict:  {'classification_loss': 0.907397427558899}
2025-01-12 23:50:27,411 [INFO] Step[2400/4329]: training loss : 0.9227740669250488 TRAIN  loss dict:  {'classification_loss': 0.9227740669250488}
2025-01-12 23:50:39,008 [INFO] Step[2450/4329]: training loss : 0.9280893063545227 TRAIN  loss dict:  {'classification_loss': 0.9280893063545227}
2025-01-12 23:50:50,680 [INFO] Step[2500/4329]: training loss : 0.9237572050094605 TRAIN  loss dict:  {'classification_loss': 0.9237572050094605}
2025-01-12 23:51:02,279 [INFO] Step[2550/4329]: training loss : 0.9237487745285035 TRAIN  loss dict:  {'classification_loss': 0.9237487745285035}
2025-01-12 23:51:13,963 [INFO] Step[2600/4329]: training loss : 0.9016441464424133 TRAIN  loss dict:  {'classification_loss': 0.9016441464424133}
2025-01-12 23:51:25,628 [INFO] Step[2650/4329]: training loss : 0.9133272898197174 TRAIN  loss dict:  {'classification_loss': 0.9133272898197174}
2025-01-12 23:51:37,223 [INFO] Step[2700/4329]: training loss : 0.9109846794605255 TRAIN  loss dict:  {'classification_loss': 0.9109846794605255}
2025-01-12 23:51:48,884 [INFO] Step[2750/4329]: training loss : 0.9377224791049957 TRAIN  loss dict:  {'classification_loss': 0.9377224791049957}
2025-01-12 23:52:00,547 [INFO] Step[2800/4329]: training loss : 0.9255018639564514 TRAIN  loss dict:  {'classification_loss': 0.9255018639564514}
2025-01-12 23:52:12,197 [INFO] Step[2850/4329]: training loss : 0.9287811267375946 TRAIN  loss dict:  {'classification_loss': 0.9287811267375946}
2025-01-12 23:52:23,901 [INFO] Step[2900/4329]: training loss : 0.9168552136421204 TRAIN  loss dict:  {'classification_loss': 0.9168552136421204}
2025-01-12 23:52:35,591 [INFO] Step[2950/4329]: training loss : 0.9036202216148377 TRAIN  loss dict:  {'classification_loss': 0.9036202216148377}
2025-01-12 23:52:47,672 [INFO] Step[3000/4329]: training loss : 0.9341206336021424 TRAIN  loss dict:  {'classification_loss': 0.9341206336021424}
2025-01-12 23:52:59,989 [INFO] Step[3050/4329]: training loss : 0.9371942186355591 TRAIN  loss dict:  {'classification_loss': 0.9371942186355591}
2025-01-12 23:53:12,503 [INFO] Step[3100/4329]: training loss : 0.9322427427768707 TRAIN  loss dict:  {'classification_loss': 0.9322427427768707}
2025-01-12 23:53:26,379 [INFO] Step[3150/4329]: training loss : 0.9374121391773224 TRAIN  loss dict:  {'classification_loss': 0.9374121391773224}
2025-01-12 23:53:39,750 [INFO] Step[3200/4329]: training loss : 0.9353650343418122 TRAIN  loss dict:  {'classification_loss': 0.9353650343418122}
2025-01-12 23:53:51,744 [INFO] Step[3250/4329]: training loss : 0.9000501430034638 TRAIN  loss dict:  {'classification_loss': 0.9000501430034638}
2025-01-12 23:54:03,654 [INFO] Step[3300/4329]: training loss : 0.9002280449867248 TRAIN  loss dict:  {'classification_loss': 0.9002280449867248}
2025-01-12 23:54:15,420 [INFO] Step[3350/4329]: training loss : 0.9187184178829193 TRAIN  loss dict:  {'classification_loss': 0.9187184178829193}
2025-01-12 23:54:27,047 [INFO] Step[3400/4329]: training loss : 0.9322556746006012 TRAIN  loss dict:  {'classification_loss': 0.9322556746006012}
2025-01-12 23:54:38,701 [INFO] Step[3450/4329]: training loss : 0.897389007806778 TRAIN  loss dict:  {'classification_loss': 0.897389007806778}
2025-01-12 23:54:50,314 [INFO] Step[3500/4329]: training loss : 0.9221962368488312 TRAIN  loss dict:  {'classification_loss': 0.9221962368488312}
2025-01-12 23:55:01,947 [INFO] Step[3550/4329]: training loss : 0.9326236355304718 TRAIN  loss dict:  {'classification_loss': 0.9326236355304718}
2025-01-12 23:55:13,547 [INFO] Step[3600/4329]: training loss : 0.9319231200218201 TRAIN  loss dict:  {'classification_loss': 0.9319231200218201}
2025-01-12 23:55:25,142 [INFO] Step[3650/4329]: training loss : 0.9440768301486969 TRAIN  loss dict:  {'classification_loss': 0.9440768301486969}
2025-01-12 23:55:36,751 [INFO] Step[3700/4329]: training loss : 0.922434071302414 TRAIN  loss dict:  {'classification_loss': 0.922434071302414}
2025-01-12 23:55:48,348 [INFO] Step[3750/4329]: training loss : 0.933577481508255 TRAIN  loss dict:  {'classification_loss': 0.933577481508255}
2025-01-12 23:55:59,969 [INFO] Step[3800/4329]: training loss : 0.9256165039539337 TRAIN  loss dict:  {'classification_loss': 0.9256165039539337}
2025-01-12 23:56:11,588 [INFO] Step[3850/4329]: training loss : 0.9040337872505187 TRAIN  loss dict:  {'classification_loss': 0.9040337872505187}
2025-01-12 23:56:23,207 [INFO] Step[3900/4329]: training loss : 0.9347527301311493 TRAIN  loss dict:  {'classification_loss': 0.9347527301311493}
2025-01-12 23:56:34,876 [INFO] Step[3950/4329]: training loss : 0.9715039527416229 TRAIN  loss dict:  {'classification_loss': 0.9715039527416229}
2025-01-12 23:56:46,490 [INFO] Step[4000/4329]: training loss : 0.9242660164833069 TRAIN  loss dict:  {'classification_loss': 0.9242660164833069}
2025-01-12 23:56:58,073 [INFO] Step[4050/4329]: training loss : 0.9239797103404999 TRAIN  loss dict:  {'classification_loss': 0.9239797103404999}
2025-01-12 23:57:09,675 [INFO] Step[4100/4329]: training loss : 0.9570961570739747 TRAIN  loss dict:  {'classification_loss': 0.9570961570739747}
2025-01-12 23:57:21,299 [INFO] Step[4150/4329]: training loss : 0.9293331634998322 TRAIN  loss dict:  {'classification_loss': 0.9293331634998322}
2025-01-12 23:57:32,891 [INFO] Step[4200/4329]: training loss : 0.9199495840072632 TRAIN  loss dict:  {'classification_loss': 0.9199495840072632}
2025-01-12 23:57:44,489 [INFO] Step[4250/4329]: training loss : 0.9303761804103852 TRAIN  loss dict:  {'classification_loss': 0.9303761804103852}
2025-01-12 23:57:56,132 [INFO] Step[4300/4329]: training loss : 0.9062978291511535 TRAIN  loss dict:  {'classification_loss': 0.9062978291511535}
2025-01-12 23:59:55,221 [INFO] Label accuracies statistics:
2025-01-12 23:59:55,221 [INFO] {0: 0.6666666666666666, 1: 0.8888888888888888, 2: 0.5833333333333334, 3: 0.75, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.6666666666666666, 8: 0.3333333333333333, 9: 0.9166666666666666, 10: 1.0, 11: 1.0, 12: 0.5, 13: 0.4166666666666667, 14: 0.75, 15: 0.5555555555555556, 16: 0.6666666666666666, 17: 0.5, 18: 0.5833333333333334, 19: 0.8333333333333334, 20: 0.5, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.9166666666666666, 24: 0.9166666666666666, 25: 0.6666666666666666, 26: 0.9166666666666666, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5833333333333334, 33: 0.8333333333333334, 34: 0.9166666666666666, 35: 0.6666666666666666, 36: 0.5833333333333334, 37: 1.0, 38: 0.9166666666666666, 39: 0.9166666666666666, 40: 0.8333333333333334, 41: 0.4166666666666667, 42: 0.9166666666666666, 43: 1.0, 44: 0.75, 45: 0.5833333333333334, 46: 1.0, 47: 0.9166666666666666, 48: 1.0, 49: 1.0, 50: 0.6666666666666666, 51: 0.8333333333333334, 52: 1.0, 53: 0.5833333333333334, 54: 0.4166666666666667, 55: 0.6666666666666666, 56: 0.75, 57: 0.75, 58: 0.3333333333333333, 59: 0.9166666666666666, 60: 0.75, 61: 0.8333333333333334, 62: 0.75, 63: 0.4166666666666667, 64: 1.0, 65: 1.0, 66: 0.5833333333333334, 67: 0.8333333333333334, 68: 0.5, 69: 0.6666666666666666, 70: 0.5, 71: 0.5833333333333334, 72: 0.8333333333333334, 73: 0.9166666666666666, 74: 0.75, 75: 0.9166666666666666, 76: 0.6666666666666666, 77: 0.6666666666666666, 78: 0.9166666666666666, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.4166666666666667, 84: 0.25, 85: 0.8333333333333334, 86: 0.5, 87: 0.8333333333333334, 88: 0.75, 89: 0.6666666666666666, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.4166666666666667, 95: 1.0, 96: 0.4166666666666667, 97: 0.8333333333333334, 98: 0.8333333333333334, 99: 1.0, 100: 0.8333333333333334, 101: 0.9166666666666666, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.6666666666666666, 108: 0.9166666666666666, 109: 0.75, 110: 0.9166666666666666, 111: 1.0, 112: 1.0, 113: 0.5, 114: 0.3333333333333333, 115: 0.75, 116: 0.9166666666666666, 117: 0.9166666666666666, 118: 0.8333333333333334, 119: 0.9166666666666666, 120: 0.8333333333333334, 121: 0.75, 122: 0.8333333333333334, 123: 0.8333333333333334, 124: 1.0, 125: 0.8333333333333334, 126: 0.9166666666666666, 127: 0.6666666666666666, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.4166666666666667, 133: 1.0, 134: 0.5, 135: 1.0, 136: 0.8333333333333334, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 0.8333333333333334, 143: 1.0, 144: 0.8333333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.5, 151: 0.8333333333333334, 152: 0.8333333333333334, 153: 1.0, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.9166666666666666, 160: 0.16666666666666666, 161: 0.9166666666666666, 162: 0.9166666666666666, 163: 0.9166666666666666, 164: 0.8333333333333334, 165: 0.75, 166: 0.8333333333333334, 167: 0.8333333333333334, 168: 0.9166666666666666, 169: 1.0, 170: 1.0, 171: 0.3333333333333333, 172: 1.0, 173: 0.8333333333333334, 174: 1.0, 175: 0.8333333333333334, 176: 1.0, 177: 0.9166666666666666, 178: 1.0, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.6666666666666666, 183: 0.8333333333333334, 184: 0.5833333333333334, 185: 1.0, 186: 0.9166666666666666, 187: 0.9166666666666666, 188: 0.5, 189: 1.0, 190: 0.5, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 1.0, 195: 0.75, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.6666666666666666}

2025-01-12 23:59:55,223 [INFO] [29] TRAIN  loss: 0.92467253784793 acc: 0.9909132912367165
2025-01-12 23:59:55,223 [INFO] [29] TRAIN  loss dict: {'classification_loss': 0.92467253784793}
2025-01-12 23:59:55,224 [INFO] [29] VALIDATION loss: 1.657241187086611 VALIDATION acc: 0.789983164983165
2025-01-12 23:59:55,224 [INFO] [29] VALIDATION loss dict: {'classification_loss': 1.657241187086611}
2025-01-12 23:59:55,224 [INFO] 
2025-01-13 00:00:12,512 [INFO] Step[50/4329]: training loss : 0.9503633868694306 TRAIN  loss dict:  {'classification_loss': 0.9503633868694306}
2025-01-13 00:00:24,070 [INFO] Step[100/4329]: training loss : 0.9617403316497802 TRAIN  loss dict:  {'classification_loss': 0.9617403316497802}
2025-01-13 00:00:35,664 [INFO] Step[150/4329]: training loss : 0.925104774236679 TRAIN  loss dict:  {'classification_loss': 0.925104774236679}
2025-01-13 00:00:47,304 [INFO] Step[200/4329]: training loss : 0.9024951982498169 TRAIN  loss dict:  {'classification_loss': 0.9024951982498169}
2025-01-13 00:00:58,936 [INFO] Step[250/4329]: training loss : 0.912732527256012 TRAIN  loss dict:  {'classification_loss': 0.912732527256012}
2025-01-13 00:01:10,554 [INFO] Step[300/4329]: training loss : 0.908364952802658 TRAIN  loss dict:  {'classification_loss': 0.908364952802658}
2025-01-13 00:01:22,197 [INFO] Step[350/4329]: training loss : 0.9624068737030029 TRAIN  loss dict:  {'classification_loss': 0.9624068737030029}
2025-01-13 00:01:33,803 [INFO] Step[400/4329]: training loss : 0.9114675080776214 TRAIN  loss dict:  {'classification_loss': 0.9114675080776214}
2025-01-13 00:01:45,478 [INFO] Step[450/4329]: training loss : 0.9302854669094086 TRAIN  loss dict:  {'classification_loss': 0.9302854669094086}
2025-01-13 00:01:57,086 [INFO] Step[500/4329]: training loss : 0.9239991867542267 TRAIN  loss dict:  {'classification_loss': 0.9239991867542267}
2025-01-13 00:02:08,672 [INFO] Step[550/4329]: training loss : 0.904228001832962 TRAIN  loss dict:  {'classification_loss': 0.904228001832962}
2025-01-13 00:02:20,342 [INFO] Step[600/4329]: training loss : 0.9056253242492676 TRAIN  loss dict:  {'classification_loss': 0.9056253242492676}
2025-01-13 00:02:32,008 [INFO] Step[650/4329]: training loss : 0.911359474658966 TRAIN  loss dict:  {'classification_loss': 0.911359474658966}
2025-01-13 00:02:43,640 [INFO] Step[700/4329]: training loss : 0.9038243341445923 TRAIN  loss dict:  {'classification_loss': 0.9038243341445923}
2025-01-13 00:02:55,249 [INFO] Step[750/4329]: training loss : 0.9230859971046448 TRAIN  loss dict:  {'classification_loss': 0.9230859971046448}
2025-01-13 00:03:06,884 [INFO] Step[800/4329]: training loss : 0.914241988658905 TRAIN  loss dict:  {'classification_loss': 0.914241988658905}
2025-01-13 00:03:18,511 [INFO] Step[850/4329]: training loss : 0.9358599781990051 TRAIN  loss dict:  {'classification_loss': 0.9358599781990051}
2025-01-13 00:03:30,168 [INFO] Step[900/4329]: training loss : 0.8990508472919464 TRAIN  loss dict:  {'classification_loss': 0.8990508472919464}
2025-01-13 00:03:41,735 [INFO] Step[950/4329]: training loss : 0.8948914551734924 TRAIN  loss dict:  {'classification_loss': 0.8948914551734924}
2025-01-13 00:03:53,395 [INFO] Step[1000/4329]: training loss : 0.916577605009079 TRAIN  loss dict:  {'classification_loss': 0.916577605009079}
2025-01-13 00:04:05,041 [INFO] Step[1050/4329]: training loss : 0.9079613494873047 TRAIN  loss dict:  {'classification_loss': 0.9079613494873047}
2025-01-13 00:04:16,656 [INFO] Step[1100/4329]: training loss : 0.9098549473285675 TRAIN  loss dict:  {'classification_loss': 0.9098549473285675}
2025-01-13 00:04:28,300 [INFO] Step[1150/4329]: training loss : 0.9171273922920227 TRAIN  loss dict:  {'classification_loss': 0.9171273922920227}
2025-01-13 00:04:39,899 [INFO] Step[1200/4329]: training loss : 0.8970221066474915 TRAIN  loss dict:  {'classification_loss': 0.8970221066474915}
2025-01-13 00:04:51,543 [INFO] Step[1250/4329]: training loss : 0.9142262303829193 TRAIN  loss dict:  {'classification_loss': 0.9142262303829193}
2025-01-13 00:05:03,270 [INFO] Step[1300/4329]: training loss : 0.9325639271736145 TRAIN  loss dict:  {'classification_loss': 0.9325639271736145}
2025-01-13 00:05:15,519 [INFO] Step[1350/4329]: training loss : 0.9223167264461517 TRAIN  loss dict:  {'classification_loss': 0.9223167264461517}
2025-01-13 00:05:27,781 [INFO] Step[1400/4329]: training loss : 0.9486521184444427 TRAIN  loss dict:  {'classification_loss': 0.9486521184444427}
2025-01-13 00:05:40,377 [INFO] Step[1450/4329]: training loss : 0.9363663160800934 TRAIN  loss dict:  {'classification_loss': 0.9363663160800934}
2025-01-13 00:05:53,864 [INFO] Step[1500/4329]: training loss : 0.9096829903125763 TRAIN  loss dict:  {'classification_loss': 0.9096829903125763}
2025-01-13 00:06:06,485 [INFO] Step[1550/4329]: training loss : 0.8999967014789582 TRAIN  loss dict:  {'classification_loss': 0.8999967014789582}
2025-01-13 00:06:18,491 [INFO] Step[1600/4329]: training loss : 0.9069248938560486 TRAIN  loss dict:  {'classification_loss': 0.9069248938560486}
2025-01-13 00:06:30,415 [INFO] Step[1650/4329]: training loss : 0.9237633645534515 TRAIN  loss dict:  {'classification_loss': 0.9237633645534515}
2025-01-13 00:06:42,116 [INFO] Step[1700/4329]: training loss : 0.9088508141040802 TRAIN  loss dict:  {'classification_loss': 0.9088508141040802}
2025-01-13 00:06:53,766 [INFO] Step[1750/4329]: training loss : 0.9132113242149353 TRAIN  loss dict:  {'classification_loss': 0.9132113242149353}
2025-01-13 00:07:05,394 [INFO] Step[1800/4329]: training loss : 0.9182151281833648 TRAIN  loss dict:  {'classification_loss': 0.9182151281833648}
2025-01-13 00:07:17,050 [INFO] Step[1850/4329]: training loss : 0.9028711903095246 TRAIN  loss dict:  {'classification_loss': 0.9028711903095246}
2025-01-13 00:07:28,706 [INFO] Step[1900/4329]: training loss : 0.9194073522090912 TRAIN  loss dict:  {'classification_loss': 0.9194073522090912}
2025-01-13 00:07:40,311 [INFO] Step[1950/4329]: training loss : 0.9416662073135376 TRAIN  loss dict:  {'classification_loss': 0.9416662073135376}
2025-01-13 00:07:51,942 [INFO] Step[2000/4329]: training loss : 0.986129035949707 TRAIN  loss dict:  {'classification_loss': 0.986129035949707}
2025-01-13 00:08:03,597 [INFO] Step[2050/4329]: training loss : 0.9246533203125 TRAIN  loss dict:  {'classification_loss': 0.9246533203125}
2025-01-13 00:08:15,221 [INFO] Step[2100/4329]: training loss : 0.9302416229248047 TRAIN  loss dict:  {'classification_loss': 0.9302416229248047}
2025-01-13 00:08:26,862 [INFO] Step[2150/4329]: training loss : 0.9124032330513 TRAIN  loss dict:  {'classification_loss': 0.9124032330513}
2025-01-13 00:08:38,480 [INFO] Step[2200/4329]: training loss : 0.9064051365852356 TRAIN  loss dict:  {'classification_loss': 0.9064051365852356}
2025-01-13 00:08:50,100 [INFO] Step[2250/4329]: training loss : 0.9284260141849517 TRAIN  loss dict:  {'classification_loss': 0.9284260141849517}
2025-01-13 00:09:01,660 [INFO] Step[2300/4329]: training loss : 0.9114377748966217 TRAIN  loss dict:  {'classification_loss': 0.9114377748966217}
2025-01-13 00:09:13,279 [INFO] Step[2350/4329]: training loss : 0.949521598815918 TRAIN  loss dict:  {'classification_loss': 0.949521598815918}
2025-01-13 00:09:24,930 [INFO] Step[2400/4329]: training loss : 0.9254974102973939 TRAIN  loss dict:  {'classification_loss': 0.9254974102973939}
2025-01-13 00:09:36,550 [INFO] Step[2450/4329]: training loss : 0.924804517030716 TRAIN  loss dict:  {'classification_loss': 0.924804517030716}
2025-01-13 00:09:48,169 [INFO] Step[2500/4329]: training loss : 0.9309163653850555 TRAIN  loss dict:  {'classification_loss': 0.9309163653850555}
2025-01-13 00:09:59,812 [INFO] Step[2550/4329]: training loss : 0.9122924733161927 TRAIN  loss dict:  {'classification_loss': 0.9122924733161927}
2025-01-13 00:10:11,438 [INFO] Step[2600/4329]: training loss : 0.9432821106910706 TRAIN  loss dict:  {'classification_loss': 0.9432821106910706}
2025-01-13 00:10:23,059 [INFO] Step[2650/4329]: training loss : 0.911303722858429 TRAIN  loss dict:  {'classification_loss': 0.911303722858429}
2025-01-13 00:10:34,745 [INFO] Step[2700/4329]: training loss : 0.9461253643035888 TRAIN  loss dict:  {'classification_loss': 0.9461253643035888}
2025-01-13 00:10:46,363 [INFO] Step[2750/4329]: training loss : 0.9081939935684205 TRAIN  loss dict:  {'classification_loss': 0.9081939935684205}
2025-01-13 00:10:57,997 [INFO] Step[2800/4329]: training loss : 0.9123527908325195 TRAIN  loss dict:  {'classification_loss': 0.9123527908325195}
2025-01-13 00:11:09,649 [INFO] Step[2850/4329]: training loss : 0.9318288969993591 TRAIN  loss dict:  {'classification_loss': 0.9318288969993591}
2025-01-13 00:11:21,264 [INFO] Step[2900/4329]: training loss : 0.9052360498905182 TRAIN  loss dict:  {'classification_loss': 0.9052360498905182}
2025-01-13 00:11:32,909 [INFO] Step[2950/4329]: training loss : 0.9071718752384186 TRAIN  loss dict:  {'classification_loss': 0.9071718752384186}
2025-01-13 00:11:44,566 [INFO] Step[3000/4329]: training loss : 0.9207668018341064 TRAIN  loss dict:  {'classification_loss': 0.9207668018341064}
2025-01-13 00:11:56,161 [INFO] Step[3050/4329]: training loss : 0.9086951696872712 TRAIN  loss dict:  {'classification_loss': 0.9086951696872712}
2025-01-13 00:12:07,775 [INFO] Step[3100/4329]: training loss : 0.9034655845165253 TRAIN  loss dict:  {'classification_loss': 0.9034655845165253}
2025-01-13 00:12:19,401 [INFO] Step[3150/4329]: training loss : 0.9134730780124665 TRAIN  loss dict:  {'classification_loss': 0.9134730780124665}
2025-01-13 00:12:31,046 [INFO] Step[3200/4329]: training loss : 0.9273531305789947 TRAIN  loss dict:  {'classification_loss': 0.9273531305789947}
2025-01-13 00:12:42,681 [INFO] Step[3250/4329]: training loss : 0.9168902683258057 TRAIN  loss dict:  {'classification_loss': 0.9168902683258057}
2025-01-13 00:12:54,301 [INFO] Step[3300/4329]: training loss : 0.9752103817462922 TRAIN  loss dict:  {'classification_loss': 0.9752103817462922}
2025-01-13 00:13:05,944 [INFO] Step[3350/4329]: training loss : 0.9049236011505127 TRAIN  loss dict:  {'classification_loss': 0.9049236011505127}
2025-01-13 00:13:17,532 [INFO] Step[3400/4329]: training loss : 0.908291039466858 TRAIN  loss dict:  {'classification_loss': 0.908291039466858}
2025-01-13 00:13:29,198 [INFO] Step[3450/4329]: training loss : 0.9098058915138245 TRAIN  loss dict:  {'classification_loss': 0.9098058915138245}
2025-01-13 00:13:40,810 [INFO] Step[3500/4329]: training loss : 0.9316194474697113 TRAIN  loss dict:  {'classification_loss': 0.9316194474697113}
2025-01-13 00:13:52,493 [INFO] Step[3550/4329]: training loss : 0.9001875233650207 TRAIN  loss dict:  {'classification_loss': 0.9001875233650207}
2025-01-13 00:14:04,109 [INFO] Step[3600/4329]: training loss : 0.9223229277133942 TRAIN  loss dict:  {'classification_loss': 0.9223229277133942}
2025-01-13 00:14:15,766 [INFO] Step[3650/4329]: training loss : 0.9492543625831604 TRAIN  loss dict:  {'classification_loss': 0.9492543625831604}
2025-01-13 00:14:27,395 [INFO] Step[3700/4329]: training loss : 0.9140596950054168 TRAIN  loss dict:  {'classification_loss': 0.9140596950054168}
2025-01-13 00:14:38,994 [INFO] Step[3750/4329]: training loss : 0.9254072928428649 TRAIN  loss dict:  {'classification_loss': 0.9254072928428649}
2025-01-13 00:14:50,584 [INFO] Step[3800/4329]: training loss : 0.9048868644237519 TRAIN  loss dict:  {'classification_loss': 0.9048868644237519}
2025-01-13 00:15:02,237 [INFO] Step[3850/4329]: training loss : 0.9263748741149902 TRAIN  loss dict:  {'classification_loss': 0.9263748741149902}
2025-01-13 00:15:13,863 [INFO] Step[3900/4329]: training loss : 0.9284490692615509 TRAIN  loss dict:  {'classification_loss': 0.9284490692615509}
2025-01-13 00:15:25,478 [INFO] Step[3950/4329]: training loss : 0.9108554947376252 TRAIN  loss dict:  {'classification_loss': 0.9108554947376252}
2025-01-13 00:15:37,076 [INFO] Step[4000/4329]: training loss : 0.9564037227630615 TRAIN  loss dict:  {'classification_loss': 0.9564037227630615}
2025-01-13 00:15:48,697 [INFO] Step[4050/4329]: training loss : 0.9092840766906738 TRAIN  loss dict:  {'classification_loss': 0.9092840766906738}
2025-01-13 00:16:00,323 [INFO] Step[4100/4329]: training loss : 0.9164581382274628 TRAIN  loss dict:  {'classification_loss': 0.9164581382274628}
2025-01-13 00:16:11,929 [INFO] Step[4150/4329]: training loss : 0.9287459301948547 TRAIN  loss dict:  {'classification_loss': 0.9287459301948547}
2025-01-13 00:16:23,565 [INFO] Step[4200/4329]: training loss : 0.9427904558181762 TRAIN  loss dict:  {'classification_loss': 0.9427904558181762}
2025-01-13 00:16:35,177 [INFO] Step[4250/4329]: training loss : 0.898426228761673 TRAIN  loss dict:  {'classification_loss': 0.898426228761673}
2025-01-13 00:16:46,828 [INFO] Step[4300/4329]: training loss : 0.94710404753685 TRAIN  loss dict:  {'classification_loss': 0.94710404753685}
2025-01-13 00:19:11,888 [INFO] Label accuracies statistics:
2025-01-13 00:19:11,889 [INFO] {0: 0.6666666666666666, 1: 0.8888888888888888, 2: 0.5833333333333334, 3: 0.75, 4: 0.5, 5: 0.8333333333333334, 6: 0.5, 7: 0.5833333333333334, 8: 0.4166666666666667, 9: 0.9166666666666666, 10: 1.0, 11: 0.8333333333333334, 12: 0.4166666666666667, 13: 0.5, 14: 0.6666666666666666, 15: 0.6666666666666666, 16: 0.75, 17: 0.4166666666666667, 18: 0.5833333333333334, 19: 0.8333333333333334, 20: 0.5, 21: 0.5833333333333334, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5833333333333334, 26: 0.9166666666666666, 27: 0.5833333333333334, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.6666666666666666, 32: 0.6666666666666666, 33: 0.8333333333333334, 34: 1.0, 35: 1.0, 36: 0.6666666666666666, 37: 1.0, 38: 0.8333333333333334, 39: 1.0, 40: 0.75, 41: 0.5833333333333334, 42: 0.9166666666666666, 43: 0.8333333333333334, 44: 0.5, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.3333333333333333, 55: 0.5833333333333334, 56: 0.8333333333333334, 57: 0.75, 58: 0.5833333333333334, 59: 0.75, 60: 0.5833333333333334, 61: 1.0, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.9166666666666666, 68: 0.5833333333333334, 69: 0.6666666666666666, 70: 0.3333333333333333, 71: 0.4166666666666667, 72: 0.8333333333333334, 73: 1.0, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.6666666666666666, 78: 0.9166666666666666, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.8333333333333334, 83: 0.4166666666666667, 84: 0.4166666666666667, 85: 0.6666666666666666, 86: 0.5833333333333334, 87: 0.9166666666666666, 88: 0.5, 89: 0.5833333333333334, 90: 0.4166666666666667, 91: 0.9166666666666666, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 1.0, 96: 0.5, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.9166666666666666, 101: 0.75, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 0.8333333333333334, 107: 1.0, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 0.9166666666666666, 111: 1.0, 112: 0.8333333333333334, 113: 0.4166666666666667, 114: 0.75, 115: 0.9166666666666666, 116: 0.6666666666666666, 117: 0.9166666666666666, 118: 1.0, 119: 0.8333333333333334, 120: 0.75, 121: 0.8333333333333334, 122: 0.9166666666666666, 123: 0.6666666666666666, 124: 1.0, 125: 0.5833333333333334, 126: 0.9166666666666666, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.8333333333333334, 132: 0.5833333333333334, 133: 1.0, 134: 0.3333333333333333, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.8333333333333334, 140: 1.0, 141: 0.9166666666666666, 142: 0.9166666666666666, 143: 0.9166666666666666, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 0.8333333333333334, 153: 0.9166666666666666, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.8333333333333334, 158: 0.7777777777777778, 159: 1.0, 160: 0.25, 161: 0.8333333333333334, 162: 0.8333333333333334, 163: 1.0, 164: 0.8333333333333334, 165: 0.75, 166: 0.6666666666666666, 167: 0.8333333333333334, 168: 0.9166666666666666, 169: 1.0, 170: 0.9166666666666666, 171: 0.4166666666666667, 172: 1.0, 173: 0.75, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 1.0, 177: 0.8333333333333334, 178: 0.8333333333333334, 179: 0.1111111111111111, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.5, 183: 0.9166666666666666, 184: 0.9166666666666666, 185: 1.0, 186: 0.8333333333333334, 187: 0.9166666666666666, 188: 0.4166666666666667, 189: 0.9166666666666666, 190: 0.5833333333333334, 191: 0.5, 192: 1.0, 193: 0.9166666666666666, 194: 0.8333333333333334, 195: 0.75, 196: 0.9166666666666666, 197: 0.75, 198: 0.6666666666666666}

2025-01-13 00:19:11,892 [INFO] [30] TRAIN  loss: 0.9214584458284605 acc: 0.9916833513014015
2025-01-13 00:19:11,892 [INFO] [30] TRAIN  loss dict: {'classification_loss': 0.9214584458284605}
2025-01-13 00:19:11,892 [INFO] [30] VALIDATION loss: 1.6848463988063311 VALIDATION acc: 0.7836700336700336
2025-01-13 00:19:11,892 [INFO] [30] VALIDATION loss dict: {'classification_loss': 1.6848463988063311}
2025-01-13 00:19:11,892 [INFO] 
2025-01-13 00:19:29,419 [INFO] Step[50/4329]: training loss : 0.9141283345222473 TRAIN  loss dict:  {'classification_loss': 0.9141283345222473}
2025-01-13 00:19:41,020 [INFO] Step[100/4329]: training loss : 0.897062417268753 TRAIN  loss dict:  {'classification_loss': 0.897062417268753}
2025-01-13 00:19:52,649 [INFO] Step[150/4329]: training loss : 0.9021732294559479 TRAIN  loss dict:  {'classification_loss': 0.9021732294559479}
2025-01-13 00:20:04,308 [INFO] Step[200/4329]: training loss : 0.9128099191188812 TRAIN  loss dict:  {'classification_loss': 0.9128099191188812}
2025-01-13 00:20:15,972 [INFO] Step[250/4329]: training loss : 0.9010925817489625 TRAIN  loss dict:  {'classification_loss': 0.9010925817489625}
2025-01-13 00:20:27,621 [INFO] Step[300/4329]: training loss : 0.9034540939331055 TRAIN  loss dict:  {'classification_loss': 0.9034540939331055}
2025-01-13 00:20:39,316 [INFO] Step[350/4329]: training loss : 0.8908903968334198 TRAIN  loss dict:  {'classification_loss': 0.8908903968334198}
2025-01-13 00:20:50,992 [INFO] Step[400/4329]: training loss : 0.911867401599884 TRAIN  loss dict:  {'classification_loss': 0.911867401599884}
2025-01-13 00:21:02,638 [INFO] Step[450/4329]: training loss : 0.9117166531085968 TRAIN  loss dict:  {'classification_loss': 0.9117166531085968}
2025-01-13 00:21:14,268 [INFO] Step[500/4329]: training loss : 0.8962458062171936 TRAIN  loss dict:  {'classification_loss': 0.8962458062171936}
2025-01-13 00:21:25,916 [INFO] Step[550/4329]: training loss : 0.9137687659263611 TRAIN  loss dict:  {'classification_loss': 0.9137687659263611}
2025-01-13 00:21:37,558 [INFO] Step[600/4329]: training loss : 0.9238128769397735 TRAIN  loss dict:  {'classification_loss': 0.9238128769397735}
2025-01-13 00:21:49,195 [INFO] Step[650/4329]: training loss : 0.9158789038658142 TRAIN  loss dict:  {'classification_loss': 0.9158789038658142}
2025-01-13 00:22:00,856 [INFO] Step[700/4329]: training loss : 0.8919967210292816 TRAIN  loss dict:  {'classification_loss': 0.8919967210292816}
2025-01-13 00:22:12,501 [INFO] Step[750/4329]: training loss : 0.9203474307060242 TRAIN  loss dict:  {'classification_loss': 0.9203474307060242}
2025-01-13 00:22:24,147 [INFO] Step[800/4329]: training loss : 0.8982983553409576 TRAIN  loss dict:  {'classification_loss': 0.8982983553409576}
2025-01-13 00:22:35,840 [INFO] Step[850/4329]: training loss : 0.9017834687232971 TRAIN  loss dict:  {'classification_loss': 0.9017834687232971}
2025-01-13 00:22:47,481 [INFO] Step[900/4329]: training loss : 0.9084170544147492 TRAIN  loss dict:  {'classification_loss': 0.9084170544147492}
2025-01-13 00:22:59,148 [INFO] Step[950/4329]: training loss : 0.9157302868366242 TRAIN  loss dict:  {'classification_loss': 0.9157302868366242}
2025-01-13 00:23:10,795 [INFO] Step[1000/4329]: training loss : 0.9141207408905029 TRAIN  loss dict:  {'classification_loss': 0.9141207408905029}
2025-01-13 00:23:22,427 [INFO] Step[1050/4329]: training loss : 0.8994532251358032 TRAIN  loss dict:  {'classification_loss': 0.8994532251358032}
2025-01-13 00:23:34,114 [INFO] Step[1100/4329]: training loss : 0.9046208930015563 TRAIN  loss dict:  {'classification_loss': 0.9046208930015563}
2025-01-13 00:23:45,756 [INFO] Step[1150/4329]: training loss : 0.9158034336566925 TRAIN  loss dict:  {'classification_loss': 0.9158034336566925}
2025-01-13 00:23:57,431 [INFO] Step[1200/4329]: training loss : 0.8864787650108338 TRAIN  loss dict:  {'classification_loss': 0.8864787650108338}
2025-01-13 00:24:09,087 [INFO] Step[1250/4329]: training loss : 0.898033926486969 TRAIN  loss dict:  {'classification_loss': 0.898033926486969}
2025-01-13 00:24:20,703 [INFO] Step[1300/4329]: training loss : 0.8960732424259186 TRAIN  loss dict:  {'classification_loss': 0.8960732424259186}
2025-01-13 00:24:32,345 [INFO] Step[1350/4329]: training loss : 0.8929048228263855 TRAIN  loss dict:  {'classification_loss': 0.8929048228263855}
2025-01-13 00:24:43,989 [INFO] Step[1400/4329]: training loss : 0.9154289126396179 TRAIN  loss dict:  {'classification_loss': 0.9154289126396179}
2025-01-13 00:24:55,621 [INFO] Step[1450/4329]: training loss : 0.893906615972519 TRAIN  loss dict:  {'classification_loss': 0.893906615972519}
2025-01-13 00:25:07,313 [INFO] Step[1500/4329]: training loss : 0.9340024065971374 TRAIN  loss dict:  {'classification_loss': 0.9340024065971374}
2025-01-13 00:25:18,968 [INFO] Step[1550/4329]: training loss : 0.8901861476898193 TRAIN  loss dict:  {'classification_loss': 0.8901861476898193}
2025-01-13 00:25:30,573 [INFO] Step[1600/4329]: training loss : 0.9147420692443847 TRAIN  loss dict:  {'classification_loss': 0.9147420692443847}
2025-01-13 00:25:42,241 [INFO] Step[1650/4329]: training loss : 0.9136293303966522 TRAIN  loss dict:  {'classification_loss': 0.9136293303966522}
2025-01-13 00:25:53,902 [INFO] Step[1700/4329]: training loss : 0.9213963389396668 TRAIN  loss dict:  {'classification_loss': 0.9213963389396668}
2025-01-13 00:26:05,547 [INFO] Step[1750/4329]: training loss : 0.8900734615325928 TRAIN  loss dict:  {'classification_loss': 0.8900734615325928}
2025-01-13 00:26:17,174 [INFO] Step[1800/4329]: training loss : 0.9065891933441163 TRAIN  loss dict:  {'classification_loss': 0.9065891933441163}
2025-01-13 00:26:28,852 [INFO] Step[1850/4329]: training loss : 0.8909947788715362 TRAIN  loss dict:  {'classification_loss': 0.8909947788715362}
2025-01-13 00:26:40,503 [INFO] Step[1900/4329]: training loss : 0.9215798318386078 TRAIN  loss dict:  {'classification_loss': 0.9215798318386078}
2025-01-13 00:26:52,136 [INFO] Step[1950/4329]: training loss : 0.9429370832443237 TRAIN  loss dict:  {'classification_loss': 0.9429370832443237}
2025-01-13 00:27:03,782 [INFO] Step[2000/4329]: training loss : 0.8891587138175965 TRAIN  loss dict:  {'classification_loss': 0.8891587138175965}
2025-01-13 00:27:15,481 [INFO] Step[2050/4329]: training loss : 0.8990509867668152 TRAIN  loss dict:  {'classification_loss': 0.8990509867668152}
2025-01-13 00:27:27,113 [INFO] Step[2100/4329]: training loss : 0.9032994866371155 TRAIN  loss dict:  {'classification_loss': 0.9032994866371155}
2025-01-13 00:27:38,761 [INFO] Step[2150/4329]: training loss : 0.9082525110244751 TRAIN  loss dict:  {'classification_loss': 0.9082525110244751}
2025-01-13 00:27:50,419 [INFO] Step[2200/4329]: training loss : 0.9201833307743073 TRAIN  loss dict:  {'classification_loss': 0.9201833307743073}
2025-01-13 00:28:02,091 [INFO] Step[2250/4329]: training loss : 0.9317284107208252 TRAIN  loss dict:  {'classification_loss': 0.9317284107208252}
2025-01-13 00:28:13,734 [INFO] Step[2300/4329]: training loss : 0.8969408810138703 TRAIN  loss dict:  {'classification_loss': 0.8969408810138703}
2025-01-13 00:28:25,432 [INFO] Step[2350/4329]: training loss : 0.9310752046108246 TRAIN  loss dict:  {'classification_loss': 0.9310752046108246}
2025-01-13 00:28:37,067 [INFO] Step[2400/4329]: training loss : 0.9112863337993622 TRAIN  loss dict:  {'classification_loss': 0.9112863337993622}
2025-01-13 00:28:48,816 [INFO] Step[2450/4329]: training loss : 0.9092153608798981 TRAIN  loss dict:  {'classification_loss': 0.9092153608798981}
2025-01-13 00:29:00,484 [INFO] Step[2500/4329]: training loss : 0.9106314849853515 TRAIN  loss dict:  {'classification_loss': 0.9106314849853515}
2025-01-13 00:29:12,158 [INFO] Step[2550/4329]: training loss : 0.8941898047924042 TRAIN  loss dict:  {'classification_loss': 0.8941898047924042}
2025-01-13 00:29:23,772 [INFO] Step[2600/4329]: training loss : 0.9144729733467102 TRAIN  loss dict:  {'classification_loss': 0.9144729733467102}
2025-01-13 00:29:35,402 [INFO] Step[2650/4329]: training loss : 0.919979246854782 TRAIN  loss dict:  {'classification_loss': 0.919979246854782}
2025-01-13 00:29:47,050 [INFO] Step[2700/4329]: training loss : 0.9260273587703705 TRAIN  loss dict:  {'classification_loss': 0.9260273587703705}
2025-01-13 00:29:58,700 [INFO] Step[2750/4329]: training loss : 0.9393947732448578 TRAIN  loss dict:  {'classification_loss': 0.9393947732448578}
2025-01-13 00:30:10,451 [INFO] Step[2800/4329]: training loss : 0.8941724467277526 TRAIN  loss dict:  {'classification_loss': 0.8941724467277526}
2025-01-13 00:30:22,732 [INFO] Step[2850/4329]: training loss : 0.9394425213336944 TRAIN  loss dict:  {'classification_loss': 0.9394425213336944}
2025-01-13 00:30:35,071 [INFO] Step[2900/4329]: training loss : 0.9148234570026398 TRAIN  loss dict:  {'classification_loss': 0.9148234570026398}
2025-01-13 00:30:47,872 [INFO] Step[2950/4329]: training loss : 0.89430389046669 TRAIN  loss dict:  {'classification_loss': 0.89430389046669}
2025-01-13 00:31:01,076 [INFO] Step[3000/4329]: training loss : 0.9278897368907928 TRAIN  loss dict:  {'classification_loss': 0.9278897368907928}
2025-01-13 00:31:14,118 [INFO] Step[3050/4329]: training loss : 0.9143495988845826 TRAIN  loss dict:  {'classification_loss': 0.9143495988845826}
2025-01-13 00:31:26,102 [INFO] Step[3100/4329]: training loss : 0.9046056580543518 TRAIN  loss dict:  {'classification_loss': 0.9046056580543518}
2025-01-13 00:31:38,004 [INFO] Step[3150/4329]: training loss : 0.9027133178710938 TRAIN  loss dict:  {'classification_loss': 0.9027133178710938}
2025-01-13 00:31:49,622 [INFO] Step[3200/4329]: training loss : 0.8965488445758819 TRAIN  loss dict:  {'classification_loss': 0.8965488445758819}
2025-01-13 00:32:01,246 [INFO] Step[3250/4329]: training loss : 0.9028360950946808 TRAIN  loss dict:  {'classification_loss': 0.9028360950946808}
2025-01-13 00:32:12,905 [INFO] Step[3300/4329]: training loss : 0.914283629655838 TRAIN  loss dict:  {'classification_loss': 0.914283629655838}
2025-01-13 00:32:24,550 [INFO] Step[3350/4329]: training loss : 0.8925296115875244 TRAIN  loss dict:  {'classification_loss': 0.8925296115875244}
2025-01-13 00:32:36,150 [INFO] Step[3400/4329]: training loss : 0.8975968873500824 TRAIN  loss dict:  {'classification_loss': 0.8975968873500824}
2025-01-13 00:32:47,807 [INFO] Step[3450/4329]: training loss : 0.9174230396747589 TRAIN  loss dict:  {'classification_loss': 0.9174230396747589}
2025-01-13 00:32:59,433 [INFO] Step[3500/4329]: training loss : 0.9080815780162811 TRAIN  loss dict:  {'classification_loss': 0.9080815780162811}
2025-01-13 00:33:11,095 [INFO] Step[3550/4329]: training loss : 0.93110689163208 TRAIN  loss dict:  {'classification_loss': 0.93110689163208}
2025-01-13 00:33:22,731 [INFO] Step[3600/4329]: training loss : 0.9116887450218201 TRAIN  loss dict:  {'classification_loss': 0.9116887450218201}
2025-01-13 00:33:34,356 [INFO] Step[3650/4329]: training loss : 0.9163236904144287 TRAIN  loss dict:  {'classification_loss': 0.9163236904144287}
2025-01-13 00:33:45,991 [INFO] Step[3700/4329]: training loss : 0.912162617444992 TRAIN  loss dict:  {'classification_loss': 0.912162617444992}
2025-01-13 00:33:57,639 [INFO] Step[3750/4329]: training loss : 0.9133905744552613 TRAIN  loss dict:  {'classification_loss': 0.9133905744552613}
2025-01-13 00:34:09,235 [INFO] Step[3800/4329]: training loss : 0.9451220965385437 TRAIN  loss dict:  {'classification_loss': 0.9451220965385437}
2025-01-13 00:34:20,842 [INFO] Step[3850/4329]: training loss : 0.8990559720993042 TRAIN  loss dict:  {'classification_loss': 0.8990559720993042}
2025-01-13 00:34:32,456 [INFO] Step[3900/4329]: training loss : 0.90994708776474 TRAIN  loss dict:  {'classification_loss': 0.90994708776474}
2025-01-13 00:34:44,079 [INFO] Step[3950/4329]: training loss : 0.8958536219596863 TRAIN  loss dict:  {'classification_loss': 0.8958536219596863}
2025-01-13 00:34:55,716 [INFO] Step[4000/4329]: training loss : 0.8883497142791748 TRAIN  loss dict:  {'classification_loss': 0.8883497142791748}
2025-01-13 00:35:07,372 [INFO] Step[4050/4329]: training loss : 0.9375668156147003 TRAIN  loss dict:  {'classification_loss': 0.9375668156147003}
2025-01-13 00:35:18,986 [INFO] Step[4100/4329]: training loss : 0.9146798861026764 TRAIN  loss dict:  {'classification_loss': 0.9146798861026764}
2025-01-13 00:35:30,647 [INFO] Step[4150/4329]: training loss : 0.9533880627155304 TRAIN  loss dict:  {'classification_loss': 0.9533880627155304}
2025-01-13 00:35:42,257 [INFO] Step[4200/4329]: training loss : 0.9125240969657898 TRAIN  loss dict:  {'classification_loss': 0.9125240969657898}
2025-01-13 00:35:53,896 [INFO] Step[4250/4329]: training loss : 0.9216360855102539 TRAIN  loss dict:  {'classification_loss': 0.9216360855102539}
2025-01-13 00:36:05,517 [INFO] Step[4300/4329]: training loss : 0.909723629951477 TRAIN  loss dict:  {'classification_loss': 0.909723629951477}
2025-01-13 00:38:04,713 [INFO] Label accuracies statistics:
2025-01-13 00:38:04,714 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5833333333333334, 3: 0.8333333333333334, 4: 0.4166666666666667, 5: 0.8333333333333334, 6: 0.5, 7: 0.5833333333333334, 8: 0.5, 9: 0.75, 10: 1.0, 11: 1.0, 12: 0.4166666666666667, 13: 0.4166666666666667, 14: 0.75, 15: 0.7777777777777778, 16: 0.6666666666666666, 17: 0.5833333333333334, 18: 0.6666666666666666, 19: 0.6666666666666666, 20: 0.5833333333333334, 21: 0.5833333333333334, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.8333333333333334, 26: 0.8333333333333334, 27: 0.6666666666666666, 28: 0.8333333333333334, 29: 1.0, 30: 0.6666666666666666, 31: 0.6666666666666666, 32: 0.6666666666666666, 33: 0.8333333333333334, 34: 0.9166666666666666, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 1.0, 38: 0.9166666666666666, 39: 1.0, 40: 1.0, 41: 0.5833333333333334, 42: 0.6666666666666666, 43: 0.9166666666666666, 44: 0.6666666666666666, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.5833333333333334, 54: 0.4166666666666667, 55: 0.6666666666666666, 56: 0.8333333333333334, 57: 0.75, 58: 0.5833333333333334, 59: 0.8333333333333334, 60: 0.6666666666666666, 61: 0.8333333333333334, 62: 0.75, 63: 0.4166666666666667, 64: 0.9166666666666666, 65: 1.0, 66: 0.6666666666666666, 67: 0.75, 68: 0.5, 69: 0.5833333333333334, 70: 0.5, 71: 0.5833333333333334, 72: 0.9166666666666666, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5833333333333334, 77: 0.6666666666666666, 78: 0.9166666666666666, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5833333333333334, 84: 0.5833333333333334, 85: 0.75, 86: 0.75, 87: 0.8333333333333334, 88: 0.5833333333333334, 89: 0.6666666666666666, 90: 0.4166666666666667, 91: 1.0, 92: 1.0, 93: 0.9166666666666666, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.75, 98: 0.9166666666666666, 99: 0.9333333333333333, 100: 0.75, 101: 0.9166666666666666, 102: 0.8333333333333334, 103: 1.0, 104: 1.0, 105: 0.9166666666666666, 106: 1.0, 107: 0.8333333333333334, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.9166666666666666, 111: 1.0, 112: 0.9166666666666666, 113: 0.4166666666666667, 114: 0.6666666666666666, 115: 0.8333333333333334, 116: 0.6666666666666666, 117: 0.8333333333333334, 118: 1.0, 119: 0.75, 120: 0.9166666666666666, 121: 0.8333333333333334, 122: 0.9166666666666666, 123: 0.9166666666666666, 124: 1.0, 125: 0.9166666666666666, 126: 1.0, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.9166666666666666, 131: 0.9166666666666666, 132: 0.4166666666666667, 133: 1.0, 134: 0.6666666666666666, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 0.9166666666666666, 142: 0.6666666666666666, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.6666666666666666, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 0.8333333333333334, 153: 0.8333333333333334, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.6666666666666666, 158: 0.7777777777777778, 159: 1.0, 160: 0.25, 161: 0.8333333333333334, 162: 0.9166666666666666, 163: 0.9166666666666666, 164: 0.6666666666666666, 165: 0.6666666666666666, 166: 0.8333333333333334, 167: 0.5833333333333334, 168: 0.8333333333333334, 169: 0.9166666666666666, 170: 1.0, 171: 0.4166666666666667, 172: 1.0, 173: 0.8333333333333334, 174: 1.0, 175: 0.9166666666666666, 176: 1.0, 177: 0.9166666666666666, 178: 1.0, 179: 0.1111111111111111, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.5, 183: 0.8333333333333334, 184: 0.75, 185: 1.0, 186: 0.9166666666666666, 187: 0.9166666666666666, 188: 0.5, 189: 1.0, 190: 0.5833333333333334, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.8333333333333334, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.6666666666666666}

2025-01-13 00:38:06,876 [INFO] [31] TRAIN  loss: 0.9099946631022705 acc: 0.9942245495148622
2025-01-13 00:38:06,877 [INFO] [31] TRAIN  loss dict: {'classification_loss': 0.9099946631022705}
2025-01-13 00:38:06,877 [INFO] [31] VALIDATION loss: 1.6460488334749683 VALIDATION acc: 0.7946127946127947
2025-01-13 00:38:06,877 [INFO] [31] VALIDATION loss dict: {'classification_loss': 1.6460488334749683}
2025-01-13 00:38:06,877 [INFO] 
2025-01-13 00:38:24,348 [INFO] Step[50/4329]: training loss : 0.8895800983905793 TRAIN  loss dict:  {'classification_loss': 0.8895800983905793}
2025-01-13 00:38:35,896 [INFO] Step[100/4329]: training loss : 0.895879328250885 TRAIN  loss dict:  {'classification_loss': 0.895879328250885}
2025-01-13 00:38:47,537 [INFO] Step[150/4329]: training loss : 0.8941809594631195 TRAIN  loss dict:  {'classification_loss': 0.8941809594631195}
2025-01-13 00:38:59,112 [INFO] Step[200/4329]: training loss : 0.8908220136165619 TRAIN  loss dict:  {'classification_loss': 0.8908220136165619}
2025-01-13 00:39:10,693 [INFO] Step[250/4329]: training loss : 0.9038666784763336 TRAIN  loss dict:  {'classification_loss': 0.9038666784763336}
2025-01-13 00:39:22,312 [INFO] Step[300/4329]: training loss : 0.8915075755119324 TRAIN  loss dict:  {'classification_loss': 0.8915075755119324}
2025-01-13 00:39:33,977 [INFO] Step[350/4329]: training loss : 0.9015147542953491 TRAIN  loss dict:  {'classification_loss': 0.9015147542953491}
2025-01-13 00:39:45,605 [INFO] Step[400/4329]: training loss : 0.8951881504058838 TRAIN  loss dict:  {'classification_loss': 0.8951881504058838}
2025-01-13 00:39:57,232 [INFO] Step[450/4329]: training loss : 0.897213966846466 TRAIN  loss dict:  {'classification_loss': 0.897213966846466}
2025-01-13 00:40:08,822 [INFO] Step[500/4329]: training loss : 0.921362681388855 TRAIN  loss dict:  {'classification_loss': 0.921362681388855}
2025-01-13 00:40:20,440 [INFO] Step[550/4329]: training loss : 0.8826033115386963 TRAIN  loss dict:  {'classification_loss': 0.8826033115386963}
2025-01-13 00:40:32,045 [INFO] Step[600/4329]: training loss : 0.9043761563301086 TRAIN  loss dict:  {'classification_loss': 0.9043761563301086}
2025-01-13 00:40:43,693 [INFO] Step[650/4329]: training loss : 0.9151526939868927 TRAIN  loss dict:  {'classification_loss': 0.9151526939868927}
2025-01-13 00:40:55,292 [INFO] Step[700/4329]: training loss : 0.9238323938846588 TRAIN  loss dict:  {'classification_loss': 0.9238323938846588}
2025-01-13 00:41:06,954 [INFO] Step[750/4329]: training loss : 0.8957473158836364 TRAIN  loss dict:  {'classification_loss': 0.8957473158836364}
2025-01-13 00:41:18,569 [INFO] Step[800/4329]: training loss : 0.9042198097705841 TRAIN  loss dict:  {'classification_loss': 0.9042198097705841}
2025-01-13 00:41:30,218 [INFO] Step[850/4329]: training loss : 0.8911430740356445 TRAIN  loss dict:  {'classification_loss': 0.8911430740356445}
2025-01-13 00:41:41,795 [INFO] Step[900/4329]: training loss : 0.8828743636608124 TRAIN  loss dict:  {'classification_loss': 0.8828743636608124}
2025-01-13 00:41:53,408 [INFO] Step[950/4329]: training loss : 0.9031110608577728 TRAIN  loss dict:  {'classification_loss': 0.9031110608577728}
2025-01-13 00:42:05,033 [INFO] Step[1000/4329]: training loss : 0.8880886566638947 TRAIN  loss dict:  {'classification_loss': 0.8880886566638947}
2025-01-13 00:42:16,673 [INFO] Step[1050/4329]: training loss : 0.8970495581626892 TRAIN  loss dict:  {'classification_loss': 0.8970495581626892}
2025-01-13 00:42:28,291 [INFO] Step[1100/4329]: training loss : 0.908460122346878 TRAIN  loss dict:  {'classification_loss': 0.908460122346878}
2025-01-13 00:42:40,082 [INFO] Step[1150/4329]: training loss : 0.9229316806793213 TRAIN  loss dict:  {'classification_loss': 0.9229316806793213}
2025-01-13 00:42:52,374 [INFO] Step[1200/4329]: training loss : 0.8902125656604767 TRAIN  loss dict:  {'classification_loss': 0.8902125656604767}
2025-01-13 00:43:04,578 [INFO] Step[1250/4329]: training loss : 0.8864776456356048 TRAIN  loss dict:  {'classification_loss': 0.8864776456356048}
2025-01-13 00:43:17,868 [INFO] Step[1300/4329]: training loss : 0.9211353063583374 TRAIN  loss dict:  {'classification_loss': 0.9211353063583374}
2025-01-13 00:43:31,333 [INFO] Step[1350/4329]: training loss : 0.9097812533378601 TRAIN  loss dict:  {'classification_loss': 0.9097812533378601}
2025-01-13 00:43:43,719 [INFO] Step[1400/4329]: training loss : 0.900000205039978 TRAIN  loss dict:  {'classification_loss': 0.900000205039978}
2025-01-13 00:43:55,603 [INFO] Step[1450/4329]: training loss : 0.9262408292293549 TRAIN  loss dict:  {'classification_loss': 0.9262408292293549}
2025-01-13 00:44:07,422 [INFO] Step[1500/4329]: training loss : 0.8994187068939209 TRAIN  loss dict:  {'classification_loss': 0.8994187068939209}
2025-01-13 00:44:19,057 [INFO] Step[1550/4329]: training loss : 0.8925643754005432 TRAIN  loss dict:  {'classification_loss': 0.8925643754005432}
2025-01-13 00:44:30,705 [INFO] Step[1600/4329]: training loss : 0.9217900562286377 TRAIN  loss dict:  {'classification_loss': 0.9217900562286377}
2025-01-13 00:44:42,372 [INFO] Step[1650/4329]: training loss : 0.8914028966426849 TRAIN  loss dict:  {'classification_loss': 0.8914028966426849}
2025-01-13 00:44:53,995 [INFO] Step[1700/4329]: training loss : 0.8967785358428955 TRAIN  loss dict:  {'classification_loss': 0.8967785358428955}
2025-01-13 00:45:05,599 [INFO] Step[1750/4329]: training loss : 0.913288277387619 TRAIN  loss dict:  {'classification_loss': 0.913288277387619}
2025-01-13 00:45:17,208 [INFO] Step[1800/4329]: training loss : 0.8960744094848633 TRAIN  loss dict:  {'classification_loss': 0.8960744094848633}
2025-01-13 00:45:28,840 [INFO] Step[1850/4329]: training loss : 0.9148971104621887 TRAIN  loss dict:  {'classification_loss': 0.9148971104621887}
2025-01-13 00:45:40,420 [INFO] Step[1900/4329]: training loss : 0.9016148245334625 TRAIN  loss dict:  {'classification_loss': 0.9016148245334625}
2025-01-13 00:45:52,072 [INFO] Step[1950/4329]: training loss : 0.9200417733192444 TRAIN  loss dict:  {'classification_loss': 0.9200417733192444}
2025-01-13 00:46:03,704 [INFO] Step[2000/4329]: training loss : 0.9083882176876068 TRAIN  loss dict:  {'classification_loss': 0.9083882176876068}
2025-01-13 00:46:15,330 [INFO] Step[2050/4329]: training loss : 0.9166993749141693 TRAIN  loss dict:  {'classification_loss': 0.9166993749141693}
2025-01-13 00:46:26,926 [INFO] Step[2100/4329]: training loss : 0.8863348054885865 TRAIN  loss dict:  {'classification_loss': 0.8863348054885865}
2025-01-13 00:46:38,564 [INFO] Step[2150/4329]: training loss : 0.962029242515564 TRAIN  loss dict:  {'classification_loss': 0.962029242515564}
2025-01-13 00:46:50,187 [INFO] Step[2200/4329]: training loss : 0.9071813631057739 TRAIN  loss dict:  {'classification_loss': 0.9071813631057739}
2025-01-13 00:47:01,813 [INFO] Step[2250/4329]: training loss : 0.9122002029418945 TRAIN  loss dict:  {'classification_loss': 0.9122002029418945}
2025-01-13 00:47:13,407 [INFO] Step[2300/4329]: training loss : 0.8961171483993531 TRAIN  loss dict:  {'classification_loss': 0.8961171483993531}
2025-01-13 00:47:25,059 [INFO] Step[2350/4329]: training loss : 0.9009693551063538 TRAIN  loss dict:  {'classification_loss': 0.9009693551063538}
2025-01-13 00:47:36,730 [INFO] Step[2400/4329]: training loss : 0.9273835861682892 TRAIN  loss dict:  {'classification_loss': 0.9273835861682892}
2025-01-13 00:47:48,351 [INFO] Step[2450/4329]: training loss : 0.8922077131271362 TRAIN  loss dict:  {'classification_loss': 0.8922077131271362}
2025-01-13 00:47:59,987 [INFO] Step[2500/4329]: training loss : 0.8993636131286621 TRAIN  loss dict:  {'classification_loss': 0.8993636131286621}
2025-01-13 00:48:11,662 [INFO] Step[2550/4329]: training loss : 0.9034860503673553 TRAIN  loss dict:  {'classification_loss': 0.9034860503673553}
2025-01-13 00:48:23,280 [INFO] Step[2600/4329]: training loss : 0.8954946410655975 TRAIN  loss dict:  {'classification_loss': 0.8954946410655975}
2025-01-13 00:48:34,965 [INFO] Step[2650/4329]: training loss : 0.9015394353866577 TRAIN  loss dict:  {'classification_loss': 0.9015394353866577}
2025-01-13 00:48:46,524 [INFO] Step[2700/4329]: training loss : 0.9110903656482696 TRAIN  loss dict:  {'classification_loss': 0.9110903656482696}
2025-01-13 00:48:58,148 [INFO] Step[2750/4329]: training loss : 0.9076520836353302 TRAIN  loss dict:  {'classification_loss': 0.9076520836353302}
2025-01-13 00:49:09,788 [INFO] Step[2800/4329]: training loss : 0.9087644612789154 TRAIN  loss dict:  {'classification_loss': 0.9087644612789154}
2025-01-13 00:49:21,429 [INFO] Step[2850/4329]: training loss : 0.8889644241333008 TRAIN  loss dict:  {'classification_loss': 0.8889644241333008}
2025-01-13 00:49:33,040 [INFO] Step[2900/4329]: training loss : 0.926971480846405 TRAIN  loss dict:  {'classification_loss': 0.926971480846405}
2025-01-13 00:49:44,685 [INFO] Step[2950/4329]: training loss : 0.9226911175251007 TRAIN  loss dict:  {'classification_loss': 0.9226911175251007}
2025-01-13 00:49:56,281 [INFO] Step[3000/4329]: training loss : 0.9074999785423279 TRAIN  loss dict:  {'classification_loss': 0.9074999785423279}
2025-01-13 00:50:07,925 [INFO] Step[3050/4329]: training loss : 0.8907423007488251 TRAIN  loss dict:  {'classification_loss': 0.8907423007488251}
2025-01-13 00:50:19,541 [INFO] Step[3100/4329]: training loss : 0.9248514950275422 TRAIN  loss dict:  {'classification_loss': 0.9248514950275422}
2025-01-13 00:50:31,138 [INFO] Step[3150/4329]: training loss : 0.89363614320755 TRAIN  loss dict:  {'classification_loss': 0.89363614320755}
2025-01-13 00:50:42,745 [INFO] Step[3200/4329]: training loss : 0.8944242799282074 TRAIN  loss dict:  {'classification_loss': 0.8944242799282074}
2025-01-13 00:50:54,376 [INFO] Step[3250/4329]: training loss : 0.9047504270076752 TRAIN  loss dict:  {'classification_loss': 0.9047504270076752}
2025-01-13 00:51:05,999 [INFO] Step[3300/4329]: training loss : 0.9121441280841828 TRAIN  loss dict:  {'classification_loss': 0.9121441280841828}
2025-01-13 00:51:17,648 [INFO] Step[3350/4329]: training loss : 0.9002625465393066 TRAIN  loss dict:  {'classification_loss': 0.9002625465393066}
2025-01-13 00:51:29,292 [INFO] Step[3400/4329]: training loss : 0.9085551953315735 TRAIN  loss dict:  {'classification_loss': 0.9085551953315735}
2025-01-13 00:51:40,922 [INFO] Step[3450/4329]: training loss : 0.9017986845970154 TRAIN  loss dict:  {'classification_loss': 0.9017986845970154}
2025-01-13 00:51:52,550 [INFO] Step[3500/4329]: training loss : 0.8955703294277191 TRAIN  loss dict:  {'classification_loss': 0.8955703294277191}
2025-01-13 00:52:04,224 [INFO] Step[3550/4329]: training loss : 0.9057622373104095 TRAIN  loss dict:  {'classification_loss': 0.9057622373104095}
2025-01-13 00:52:15,857 [INFO] Step[3600/4329]: training loss : 0.8981564521789551 TRAIN  loss dict:  {'classification_loss': 0.8981564521789551}
2025-01-13 00:52:27,580 [INFO] Step[3650/4329]: training loss : 0.8990359115600586 TRAIN  loss dict:  {'classification_loss': 0.8990359115600586}
2025-01-13 00:52:39,184 [INFO] Step[3700/4329]: training loss : 0.8919470691680909 TRAIN  loss dict:  {'classification_loss': 0.8919470691680909}
2025-01-13 00:52:50,832 [INFO] Step[3750/4329]: training loss : 0.8928167855739594 TRAIN  loss dict:  {'classification_loss': 0.8928167855739594}
2025-01-13 00:53:02,462 [INFO] Step[3800/4329]: training loss : 0.9260630345344544 TRAIN  loss dict:  {'classification_loss': 0.9260630345344544}
2025-01-13 00:53:14,061 [INFO] Step[3850/4329]: training loss : 0.9094021844863892 TRAIN  loss dict:  {'classification_loss': 0.9094021844863892}
2025-01-13 00:53:25,732 [INFO] Step[3900/4329]: training loss : 0.920916508436203 TRAIN  loss dict:  {'classification_loss': 0.920916508436203}
2025-01-13 00:53:37,345 [INFO] Step[3950/4329]: training loss : 0.9012312340736389 TRAIN  loss dict:  {'classification_loss': 0.9012312340736389}
2025-01-13 00:53:48,937 [INFO] Step[4000/4329]: training loss : 0.9116621720790863 TRAIN  loss dict:  {'classification_loss': 0.9116621720790863}
2025-01-13 00:54:00,577 [INFO] Step[4050/4329]: training loss : 0.9064765739440918 TRAIN  loss dict:  {'classification_loss': 0.9064765739440918}
2025-01-13 00:54:12,197 [INFO] Step[4100/4329]: training loss : 0.9096202492713928 TRAIN  loss dict:  {'classification_loss': 0.9096202492713928}
2025-01-13 00:54:23,798 [INFO] Step[4150/4329]: training loss : 0.9064520478248597 TRAIN  loss dict:  {'classification_loss': 0.9064520478248597}
2025-01-13 00:54:35,426 [INFO] Step[4200/4329]: training loss : 0.9040297400951386 TRAIN  loss dict:  {'classification_loss': 0.9040297400951386}
2025-01-13 00:54:47,096 [INFO] Step[4250/4329]: training loss : 0.9152135443687439 TRAIN  loss dict:  {'classification_loss': 0.9152135443687439}
2025-01-13 00:54:58,922 [INFO] Step[4300/4329]: training loss : 0.9266701483726502 TRAIN  loss dict:  {'classification_loss': 0.9266701483726502}
2025-01-13 00:57:25,746 [INFO] Label accuracies statistics:
2025-01-13 00:57:25,746 [INFO] {0: 0.5555555555555556, 1: 0.8888888888888888, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.4166666666666667, 5: 0.9166666666666666, 6: 0.6666666666666666, 7: 0.5833333333333334, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.3333333333333333, 13: 0.5, 14: 0.6666666666666666, 15: 0.5555555555555556, 16: 0.5833333333333334, 17: 0.4166666666666667, 18: 0.5, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.8333333333333334, 26: 0.8333333333333334, 27: 0.5833333333333334, 28: 0.9166666666666666, 29: 1.0, 30: 0.5833333333333334, 31: 0.6666666666666666, 32: 0.6666666666666666, 33: 0.8333333333333334, 34: 0.8333333333333334, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 1.0, 38: 0.9166666666666666, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.9166666666666666, 43: 1.0, 44: 0.5833333333333334, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.6666666666666666, 54: 0.4166666666666667, 55: 0.6666666666666666, 56: 0.8333333333333334, 57: 0.75, 58: 0.4166666666666667, 59: 0.9166666666666666, 60: 0.5833333333333334, 61: 0.9166666666666666, 62: 0.75, 63: 0.5, 64: 0.9166666666666666, 65: 1.0, 66: 0.6666666666666666, 67: 0.8333333333333334, 68: 0.6666666666666666, 69: 0.75, 70: 0.4166666666666667, 71: 0.3333333333333333, 72: 1.0, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 1.0, 79: 0.8333333333333334, 80: 1.0, 81: 1.0, 82: 0.6666666666666666, 83: 0.5833333333333334, 84: 0.5833333333333334, 85: 0.75, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.6666666666666666, 89: 0.6666666666666666, 90: 0.5833333333333334, 91: 0.9166666666666666, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.4166666666666667, 97: 0.75, 98: 0.8333333333333334, 99: 1.0, 100: 0.9166666666666666, 101: 0.9166666666666666, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.9166666666666666, 111: 1.0, 112: 1.0, 113: 0.4166666666666667, 114: 0.4166666666666667, 115: 1.0, 116: 0.75, 117: 0.9166666666666666, 118: 1.0, 119: 0.8333333333333334, 120: 0.6666666666666666, 121: 1.0, 122: 0.8333333333333334, 123: 1.0, 124: 1.0, 125: 0.9166666666666666, 126: 0.9166666666666666, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.9166666666666666, 131: 0.8333333333333334, 132: 0.75, 133: 1.0, 134: 0.5, 135: 1.0, 136: 0.8333333333333334, 137: 0.8333333333333334, 138: 0.8333333333333334, 139: 0.8333333333333334, 140: 0.9166666666666666, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.5833333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.75, 149: 0.9166666666666666, 150: 0.5, 151: 0.8333333333333334, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 0.9166666666666666, 156: 0.6666666666666666, 157: 0.8333333333333334, 158: 0.6666666666666666, 159: 0.9166666666666666, 160: 0.4166666666666667, 161: 0.8333333333333334, 162: 0.9166666666666666, 163: 1.0, 164: 0.6666666666666666, 165: 0.75, 166: 0.6666666666666666, 167: 0.75, 168: 0.8333333333333334, 169: 0.8333333333333334, 170: 1.0, 171: 0.5833333333333334, 172: 1.0, 173: 0.9166666666666666, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 1.0, 177: 0.75, 178: 0.9166666666666666, 179: 0.1111111111111111, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.5, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.6666666666666666, 187: 1.0, 188: 0.5833333333333334, 189: 1.0, 190: 0.5833333333333334, 191: 0.3333333333333333, 192: 0.9166666666666666, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.75, 198: 0.6666666666666666}

2025-01-13 00:57:27,697 [INFO] [32] TRAIN  loss: 0.9047760560568168 acc: 0.9952256275989527
2025-01-13 00:57:27,697 [INFO] [32] TRAIN  loss dict: {'classification_loss': 0.9047760560568168}
2025-01-13 00:57:27,697 [INFO] [32] VALIDATION loss: 1.6297682444706107 VALIDATION acc: 0.7975589225589226
2025-01-13 00:57:27,697 [INFO] [32] VALIDATION loss dict: {'classification_loss': 1.6297682444706107}
2025-01-13 00:57:27,697 [INFO] 
2025-01-13 00:57:45,374 [INFO] Step[50/4329]: training loss : 0.8890524268150329 TRAIN  loss dict:  {'classification_loss': 0.8890524268150329}
2025-01-13 00:57:56,940 [INFO] Step[100/4329]: training loss : 0.8903006947040558 TRAIN  loss dict:  {'classification_loss': 0.8903006947040558}
2025-01-13 00:58:08,525 [INFO] Step[150/4329]: training loss : 0.8960926914215088 TRAIN  loss dict:  {'classification_loss': 0.8960926914215088}
2025-01-13 00:58:20,122 [INFO] Step[200/4329]: training loss : 0.8880419886112213 TRAIN  loss dict:  {'classification_loss': 0.8880419886112213}
2025-01-13 00:58:31,778 [INFO] Step[250/4329]: training loss : 0.900782105922699 TRAIN  loss dict:  {'classification_loss': 0.900782105922699}
2025-01-13 00:58:43,400 [INFO] Step[300/4329]: training loss : 0.8966061449050904 TRAIN  loss dict:  {'classification_loss': 0.8966061449050904}
2025-01-13 00:58:55,054 [INFO] Step[350/4329]: training loss : 0.8907331156730652 TRAIN  loss dict:  {'classification_loss': 0.8907331156730652}
2025-01-13 00:59:06,705 [INFO] Step[400/4329]: training loss : 0.9151430630683899 TRAIN  loss dict:  {'classification_loss': 0.9151430630683899}
2025-01-13 00:59:18,321 [INFO] Step[450/4329]: training loss : 0.9037712371349335 TRAIN  loss dict:  {'classification_loss': 0.9037712371349335}
2025-01-13 00:59:29,986 [INFO] Step[500/4329]: training loss : 0.9216583955287934 TRAIN  loss dict:  {'classification_loss': 0.9216583955287934}
2025-01-13 00:59:41,606 [INFO] Step[550/4329]: training loss : 0.8912234008312225 TRAIN  loss dict:  {'classification_loss': 0.8912234008312225}
2025-01-13 00:59:53,202 [INFO] Step[600/4329]: training loss : 0.9111024522781372 TRAIN  loss dict:  {'classification_loss': 0.9111024522781372}
2025-01-13 01:00:04,812 [INFO] Step[650/4329]: training loss : 0.9319152796268463 TRAIN  loss dict:  {'classification_loss': 0.9319152796268463}
2025-01-13 01:00:16,438 [INFO] Step[700/4329]: training loss : 0.912417516708374 TRAIN  loss dict:  {'classification_loss': 0.912417516708374}
2025-01-13 01:00:28,082 [INFO] Step[750/4329]: training loss : 0.9501054549217224 TRAIN  loss dict:  {'classification_loss': 0.9501054549217224}
2025-01-13 01:00:39,686 [INFO] Step[800/4329]: training loss : 0.8857127451896667 TRAIN  loss dict:  {'classification_loss': 0.8857127451896667}
2025-01-13 01:00:51,346 [INFO] Step[850/4329]: training loss : 0.912998640537262 TRAIN  loss dict:  {'classification_loss': 0.912998640537262}
2025-01-13 01:01:02,985 [INFO] Step[900/4329]: training loss : 0.8913003635406495 TRAIN  loss dict:  {'classification_loss': 0.8913003635406495}
2025-01-13 01:01:14,610 [INFO] Step[950/4329]: training loss : 0.9074737966060639 TRAIN  loss dict:  {'classification_loss': 0.9074737966060639}
2025-01-13 01:01:26,210 [INFO] Step[1000/4329]: training loss : 0.8827662146091462 TRAIN  loss dict:  {'classification_loss': 0.8827662146091462}
2025-01-13 01:01:37,894 [INFO] Step[1050/4329]: training loss : 0.9087266576290131 TRAIN  loss dict:  {'classification_loss': 0.9087266576290131}
2025-01-13 01:01:49,525 [INFO] Step[1100/4329]: training loss : 0.8924193334579468 TRAIN  loss dict:  {'classification_loss': 0.8924193334579468}
2025-01-13 01:02:01,158 [INFO] Step[1150/4329]: training loss : 0.8906412994861603 TRAIN  loss dict:  {'classification_loss': 0.8906412994861603}
2025-01-13 01:02:12,783 [INFO] Step[1200/4329]: training loss : 0.9042629587650299 TRAIN  loss dict:  {'classification_loss': 0.9042629587650299}
2025-01-13 01:02:24,387 [INFO] Step[1250/4329]: training loss : 0.8938007342815399 TRAIN  loss dict:  {'classification_loss': 0.8938007342815399}
2025-01-13 01:02:35,953 [INFO] Step[1300/4329]: training loss : 0.8990385913848877 TRAIN  loss dict:  {'classification_loss': 0.8990385913848877}
2025-01-13 01:02:47,586 [INFO] Step[1350/4329]: training loss : 0.8920752310752869 TRAIN  loss dict:  {'classification_loss': 0.8920752310752869}
2025-01-13 01:02:59,205 [INFO] Step[1400/4329]: training loss : 0.8833931517601014 TRAIN  loss dict:  {'classification_loss': 0.8833931517601014}
2025-01-13 01:03:10,823 [INFO] Step[1450/4329]: training loss : 0.8839405477046967 TRAIN  loss dict:  {'classification_loss': 0.8839405477046967}
2025-01-13 01:03:22,425 [INFO] Step[1500/4329]: training loss : 0.895354481935501 TRAIN  loss dict:  {'classification_loss': 0.895354481935501}
2025-01-13 01:03:34,062 [INFO] Step[1550/4329]: training loss : 0.8982113993167877 TRAIN  loss dict:  {'classification_loss': 0.8982113993167877}
2025-01-13 01:03:45,690 [INFO] Step[1600/4329]: training loss : 0.9148025846481324 TRAIN  loss dict:  {'classification_loss': 0.9148025846481324}
2025-01-13 01:03:57,343 [INFO] Step[1650/4329]: training loss : 0.9195845532417297 TRAIN  loss dict:  {'classification_loss': 0.9195845532417297}
2025-01-13 01:04:08,934 [INFO] Step[1700/4329]: training loss : 0.9180299532413483 TRAIN  loss dict:  {'classification_loss': 0.9180299532413483}
2025-01-13 01:04:20,543 [INFO] Step[1750/4329]: training loss : 0.9091366064548493 TRAIN  loss dict:  {'classification_loss': 0.9091366064548493}
2025-01-13 01:04:32,185 [INFO] Step[1800/4329]: training loss : 0.8911858451366425 TRAIN  loss dict:  {'classification_loss': 0.8911858451366425}
2025-01-13 01:04:43,818 [INFO] Step[1850/4329]: training loss : 0.8835219979286194 TRAIN  loss dict:  {'classification_loss': 0.8835219979286194}
2025-01-13 01:04:55,422 [INFO] Step[1900/4329]: training loss : 0.8950944197177887 TRAIN  loss dict:  {'classification_loss': 0.8950944197177887}
2025-01-13 01:05:07,064 [INFO] Step[1950/4329]: training loss : 0.905801911354065 TRAIN  loss dict:  {'classification_loss': 0.905801911354065}
2025-01-13 01:05:18,645 [INFO] Step[2000/4329]: training loss : 0.9094468009471893 TRAIN  loss dict:  {'classification_loss': 0.9094468009471893}
2025-01-13 01:05:30,301 [INFO] Step[2050/4329]: training loss : 0.9079092848300934 TRAIN  loss dict:  {'classification_loss': 0.9079092848300934}
2025-01-13 01:05:41,909 [INFO] Step[2100/4329]: training loss : 0.9026580452919006 TRAIN  loss dict:  {'classification_loss': 0.9026580452919006}
2025-01-13 01:05:53,547 [INFO] Step[2150/4329]: training loss : 0.8992340910434723 TRAIN  loss dict:  {'classification_loss': 0.8992340910434723}
2025-01-13 01:06:05,167 [INFO] Step[2200/4329]: training loss : 0.9044890892505646 TRAIN  loss dict:  {'classification_loss': 0.9044890892505646}
2025-01-13 01:06:16,821 [INFO] Step[2250/4329]: training loss : 0.898737004995346 TRAIN  loss dict:  {'classification_loss': 0.898737004995346}
2025-01-13 01:06:28,506 [INFO] Step[2300/4329]: training loss : 0.9775129592418671 TRAIN  loss dict:  {'classification_loss': 0.9775129592418671}
2025-01-13 01:06:40,108 [INFO] Step[2350/4329]: training loss : 0.9299040722846985 TRAIN  loss dict:  {'classification_loss': 0.9299040722846985}
2025-01-13 01:06:51,726 [INFO] Step[2400/4329]: training loss : 0.9054906797409058 TRAIN  loss dict:  {'classification_loss': 0.9054906797409058}
2025-01-13 01:07:03,398 [INFO] Step[2450/4329]: training loss : 0.90822021484375 TRAIN  loss dict:  {'classification_loss': 0.90822021484375}
2025-01-13 01:07:15,014 [INFO] Step[2500/4329]: training loss : 0.8946311390399933 TRAIN  loss dict:  {'classification_loss': 0.8946311390399933}
2025-01-13 01:07:26,758 [INFO] Step[2550/4329]: training loss : 0.9443618607521057 TRAIN  loss dict:  {'classification_loss': 0.9443618607521057}
2025-01-13 01:07:38,997 [INFO] Step[2600/4329]: training loss : 0.9011390495300293 TRAIN  loss dict:  {'classification_loss': 0.9011390495300293}
2025-01-13 01:07:51,260 [INFO] Step[2650/4329]: training loss : 0.8971545314788818 TRAIN  loss dict:  {'classification_loss': 0.8971545314788818}
2025-01-13 01:08:04,277 [INFO] Step[2700/4329]: training loss : 0.9125143516063691 TRAIN  loss dict:  {'classification_loss': 0.9125143516063691}
2025-01-13 01:08:18,110 [INFO] Step[2750/4329]: training loss : 0.8956103646755218 TRAIN  loss dict:  {'classification_loss': 0.8956103646755218}
2025-01-13 01:08:30,926 [INFO] Step[2800/4329]: training loss : 0.8902643573284149 TRAIN  loss dict:  {'classification_loss': 0.8902643573284149}
2025-01-13 01:08:42,879 [INFO] Step[2850/4329]: training loss : 0.9184896516799926 TRAIN  loss dict:  {'classification_loss': 0.9184896516799926}
2025-01-13 01:08:54,808 [INFO] Step[2900/4329]: training loss : 0.8990869748592377 TRAIN  loss dict:  {'classification_loss': 0.8990869748592377}
2025-01-13 01:09:06,467 [INFO] Step[2950/4329]: training loss : 0.8912392628192901 TRAIN  loss dict:  {'classification_loss': 0.8912392628192901}
2025-01-13 01:09:18,071 [INFO] Step[3000/4329]: training loss : 0.8977397072315216 TRAIN  loss dict:  {'classification_loss': 0.8977397072315216}
2025-01-13 01:09:29,681 [INFO] Step[3050/4329]: training loss : 0.9209268236160278 TRAIN  loss dict:  {'classification_loss': 0.9209268236160278}
2025-01-13 01:09:41,309 [INFO] Step[3100/4329]: training loss : 0.9052879583835601 TRAIN  loss dict:  {'classification_loss': 0.9052879583835601}
2025-01-13 01:09:52,974 [INFO] Step[3150/4329]: training loss : 0.8884832561016083 TRAIN  loss dict:  {'classification_loss': 0.8884832561016083}
2025-01-13 01:10:04,607 [INFO] Step[3200/4329]: training loss : 0.9127521634101867 TRAIN  loss dict:  {'classification_loss': 0.9127521634101867}
2025-01-13 01:10:16,238 [INFO] Step[3250/4329]: training loss : 0.9003823351860046 TRAIN  loss dict:  {'classification_loss': 0.9003823351860046}
2025-01-13 01:10:27,860 [INFO] Step[3300/4329]: training loss : 0.914243255853653 TRAIN  loss dict:  {'classification_loss': 0.914243255853653}
2025-01-13 01:10:39,517 [INFO] Step[3350/4329]: training loss : 0.9545334899425506 TRAIN  loss dict:  {'classification_loss': 0.9545334899425506}
2025-01-13 01:10:51,124 [INFO] Step[3400/4329]: training loss : 0.8921260118484498 TRAIN  loss dict:  {'classification_loss': 0.8921260118484498}
2025-01-13 01:11:02,777 [INFO] Step[3450/4329]: training loss : 0.8854732704162598 TRAIN  loss dict:  {'classification_loss': 0.8854732704162598}
2025-01-13 01:11:14,404 [INFO] Step[3500/4329]: training loss : 0.9022656297683715 TRAIN  loss dict:  {'classification_loss': 0.9022656297683715}
2025-01-13 01:11:26,006 [INFO] Step[3550/4329]: training loss : 0.9006692826747894 TRAIN  loss dict:  {'classification_loss': 0.9006692826747894}
2025-01-13 01:11:37,670 [INFO] Step[3600/4329]: training loss : 0.8868538582324982 TRAIN  loss dict:  {'classification_loss': 0.8868538582324982}
2025-01-13 01:11:49,283 [INFO] Step[3650/4329]: training loss : 0.9020827531814575 TRAIN  loss dict:  {'classification_loss': 0.9020827531814575}
2025-01-13 01:12:00,886 [INFO] Step[3700/4329]: training loss : 0.9024414134025573 TRAIN  loss dict:  {'classification_loss': 0.9024414134025573}
2025-01-13 01:12:12,494 [INFO] Step[3750/4329]: training loss : 0.9148053538799286 TRAIN  loss dict:  {'classification_loss': 0.9148053538799286}
2025-01-13 01:12:24,071 [INFO] Step[3800/4329]: training loss : 0.8929984819889069 TRAIN  loss dict:  {'classification_loss': 0.8929984819889069}
2025-01-13 01:12:35,670 [INFO] Step[3850/4329]: training loss : 0.88696275472641 TRAIN  loss dict:  {'classification_loss': 0.88696275472641}
2025-01-13 01:12:47,262 [INFO] Step[3900/4329]: training loss : 0.8879746067523956 TRAIN  loss dict:  {'classification_loss': 0.8879746067523956}
2025-01-13 01:12:58,892 [INFO] Step[3950/4329]: training loss : 0.8910170781612397 TRAIN  loss dict:  {'classification_loss': 0.8910170781612397}
2025-01-13 01:13:10,514 [INFO] Step[4000/4329]: training loss : 0.889560055732727 TRAIN  loss dict:  {'classification_loss': 0.889560055732727}
2025-01-13 01:13:22,118 [INFO] Step[4050/4329]: training loss : 0.897740306854248 TRAIN  loss dict:  {'classification_loss': 0.897740306854248}
2025-01-13 01:13:33,671 [INFO] Step[4100/4329]: training loss : 0.9160925018787384 TRAIN  loss dict:  {'classification_loss': 0.9160925018787384}
2025-01-13 01:13:45,296 [INFO] Step[4150/4329]: training loss : 0.9094596207141876 TRAIN  loss dict:  {'classification_loss': 0.9094596207141876}
2025-01-13 01:13:56,934 [INFO] Step[4200/4329]: training loss : 0.8907389712333679 TRAIN  loss dict:  {'classification_loss': 0.8907389712333679}
2025-01-13 01:14:08,568 [INFO] Step[4250/4329]: training loss : 0.9075604403018951 TRAIN  loss dict:  {'classification_loss': 0.9075604403018951}
2025-01-13 01:14:20,148 [INFO] Step[4300/4329]: training loss : 0.9041432416439057 TRAIN  loss dict:  {'classification_loss': 0.9041432416439057}
2025-01-13 01:16:20,191 [INFO] Label accuracies statistics:
2025-01-13 01:16:20,191 [INFO] {0: 0.5555555555555556, 1: 1.0, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.5833333333333334, 8: 0.4166666666666667, 9: 0.9166666666666666, 10: 1.0, 11: 1.0, 12: 0.5833333333333334, 13: 0.5833333333333334, 14: 0.5833333333333334, 15: 0.6666666666666666, 16: 0.5833333333333334, 17: 0.5, 18: 0.6666666666666666, 19: 0.6666666666666666, 20: 0.5, 21: 0.4166666666666667, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.6666666666666666, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.8333333333333334, 34: 0.9166666666666666, 35: 0.8333333333333334, 36: 0.6666666666666666, 37: 1.0, 38: 0.8333333333333334, 39: 1.0, 40: 0.9166666666666666, 41: 0.5, 42: 0.8333333333333334, 43: 0.8333333333333334, 44: 0.6666666666666666, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.6666666666666666, 56: 0.8333333333333334, 57: 0.75, 58: 0.5, 59: 0.8333333333333334, 60: 0.6666666666666666, 61: 0.9166666666666666, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.5833333333333334, 67: 0.75, 68: 0.6666666666666666, 69: 0.6666666666666666, 70: 0.5, 71: 0.4166666666666667, 72: 0.9166666666666666, 73: 1.0, 74: 0.6666666666666666, 75: 1.0, 76: 0.5833333333333334, 77: 0.75, 78: 1.0, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5833333333333334, 84: 0.4166666666666667, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.5833333333333334, 89: 0.5, 90: 0.8333333333333334, 91: 0.9166666666666666, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.6666666666666666, 97: 0.4166666666666667, 98: 0.75, 99: 1.0, 100: 0.8333333333333334, 101: 0.9166666666666666, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.6666666666666666, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.4166666666666667, 114: 0.5833333333333334, 115: 0.9166666666666666, 116: 0.6666666666666666, 117: 0.9166666666666666, 118: 1.0, 119: 0.8333333333333334, 120: 0.8333333333333334, 121: 0.9166666666666666, 122: 0.9166666666666666, 123: 1.0, 124: 0.9166666666666666, 125: 0.8333333333333334, 126: 0.9166666666666666, 127: 0.5833333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.9166666666666666, 132: 0.5833333333333334, 133: 1.0, 134: 0.75, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.8333333333333334, 140: 0.9166666666666666, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.5833333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.9166666666666666, 149: 1.0, 150: 0.4166666666666667, 151: 1.0, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 1.0, 156: 0.9166666666666666, 157: 0.6666666666666666, 158: 0.6666666666666666, 159: 1.0, 160: 0.3333333333333333, 161: 0.75, 162: 1.0, 163: 0.9166666666666666, 164: 0.75, 165: 0.6666666666666666, 166: 0.75, 167: 0.75, 168: 0.8333333333333334, 169: 0.8333333333333334, 170: 1.0, 171: 0.5833333333333334, 172: 1.0, 173: 0.8333333333333334, 174: 1.0, 175: 0.9166666666666666, 176: 1.0, 177: 0.8333333333333334, 178: 0.9166666666666666, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.75, 183: 0.9166666666666666, 184: 0.6666666666666666, 185: 1.0, 186: 0.75, 187: 0.9166666666666666, 188: 0.75, 189: 0.8333333333333334, 190: 0.6666666666666666, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.75, 195: 0.75, 196: 0.8333333333333334, 197: 0.6666666666666666, 198: 0.75}

2025-01-13 01:16:21,141 [INFO] [33] TRAIN  loss: 0.9034044490479575 acc: 0.9948405975666101
2025-01-13 01:16:21,142 [INFO] [33] TRAIN  loss dict: {'classification_loss': 0.9034044490479575}
2025-01-13 01:16:21,142 [INFO] [33] VALIDATION loss: 1.638788584883165 VALIDATION acc: 0.7984006734006734
2025-01-13 01:16:21,142 [INFO] [33] VALIDATION loss dict: {'classification_loss': 1.638788584883165}
2025-01-13 01:16:21,142 [INFO] 
2025-01-13 01:16:38,412 [INFO] Step[50/4329]: training loss : 0.8961299049854279 TRAIN  loss dict:  {'classification_loss': 0.8961299049854279}
2025-01-13 01:16:49,989 [INFO] Step[100/4329]: training loss : 0.9087289595603942 TRAIN  loss dict:  {'classification_loss': 0.9087289595603942}
2025-01-13 01:17:01,588 [INFO] Step[150/4329]: training loss : 0.9121926951408387 TRAIN  loss dict:  {'classification_loss': 0.9121926951408387}
2025-01-13 01:17:13,157 [INFO] Step[200/4329]: training loss : 0.889696079492569 TRAIN  loss dict:  {'classification_loss': 0.889696079492569}
2025-01-13 01:17:24,789 [INFO] Step[250/4329]: training loss : 0.9054995119571686 TRAIN  loss dict:  {'classification_loss': 0.9054995119571686}
2025-01-13 01:17:36,419 [INFO] Step[300/4329]: training loss : 0.9089757716655731 TRAIN  loss dict:  {'classification_loss': 0.9089757716655731}
2025-01-13 01:17:48,026 [INFO] Step[350/4329]: training loss : 0.9016463160514832 TRAIN  loss dict:  {'classification_loss': 0.9016463160514832}
2025-01-13 01:17:59,657 [INFO] Step[400/4329]: training loss : 0.8816852033138275 TRAIN  loss dict:  {'classification_loss': 0.8816852033138275}
2025-01-13 01:18:11,322 [INFO] Step[450/4329]: training loss : 0.897533836364746 TRAIN  loss dict:  {'classification_loss': 0.897533836364746}
2025-01-13 01:18:22,987 [INFO] Step[500/4329]: training loss : 0.9220169901847839 TRAIN  loss dict:  {'classification_loss': 0.9220169901847839}
2025-01-13 01:18:34,601 [INFO] Step[550/4329]: training loss : 0.897589863538742 TRAIN  loss dict:  {'classification_loss': 0.897589863538742}
2025-01-13 01:18:46,220 [INFO] Step[600/4329]: training loss : 0.921452271938324 TRAIN  loss dict:  {'classification_loss': 0.921452271938324}
2025-01-13 01:18:57,836 [INFO] Step[650/4329]: training loss : 0.8884667420387268 TRAIN  loss dict:  {'classification_loss': 0.8884667420387268}
2025-01-13 01:19:09,433 [INFO] Step[700/4329]: training loss : 0.8915165174007416 TRAIN  loss dict:  {'classification_loss': 0.8915165174007416}
2025-01-13 01:19:21,056 [INFO] Step[750/4329]: training loss : 0.8854058420658112 TRAIN  loss dict:  {'classification_loss': 0.8854058420658112}
2025-01-13 01:19:32,686 [INFO] Step[800/4329]: training loss : 0.8868776953220368 TRAIN  loss dict:  {'classification_loss': 0.8868776953220368}
2025-01-13 01:19:44,287 [INFO] Step[850/4329]: training loss : 0.9091068291664124 TRAIN  loss dict:  {'classification_loss': 0.9091068291664124}
2025-01-13 01:19:56,069 [INFO] Step[900/4329]: training loss : 0.8988000464439392 TRAIN  loss dict:  {'classification_loss': 0.8988000464439392}
2025-01-13 01:20:08,505 [INFO] Step[950/4329]: training loss : 0.8943351697921753 TRAIN  loss dict:  {'classification_loss': 0.8943351697921753}
2025-01-13 01:20:20,749 [INFO] Step[1000/4329]: training loss : 0.8890257048606872 TRAIN  loss dict:  {'classification_loss': 0.8890257048606872}
2025-01-13 01:20:33,529 [INFO] Step[1050/4329]: training loss : 0.9027674388885498 TRAIN  loss dict:  {'classification_loss': 0.9027674388885498}
2025-01-13 01:20:46,976 [INFO] Step[1100/4329]: training loss : 0.9114853930473328 TRAIN  loss dict:  {'classification_loss': 0.9114853930473328}
2025-01-13 01:20:59,220 [INFO] Step[1150/4329]: training loss : 0.9520616888999939 TRAIN  loss dict:  {'classification_loss': 0.9520616888999939}
2025-01-13 01:21:11,031 [INFO] Step[1200/4329]: training loss : 0.8925939190387726 TRAIN  loss dict:  {'classification_loss': 0.8925939190387726}
2025-01-13 01:21:22,940 [INFO] Step[1250/4329]: training loss : 0.8840298771858215 TRAIN  loss dict:  {'classification_loss': 0.8840298771858215}
2025-01-13 01:21:34,529 [INFO] Step[1300/4329]: training loss : 0.8901655554771424 TRAIN  loss dict:  {'classification_loss': 0.8901655554771424}
2025-01-13 01:21:46,174 [INFO] Step[1350/4329]: training loss : 0.9036234784126281 TRAIN  loss dict:  {'classification_loss': 0.9036234784126281}
2025-01-13 01:21:57,742 [INFO] Step[1400/4329]: training loss : 0.8952030670642853 TRAIN  loss dict:  {'classification_loss': 0.8952030670642853}
2025-01-13 01:22:09,346 [INFO] Step[1450/4329]: training loss : 0.9052435004711151 TRAIN  loss dict:  {'classification_loss': 0.9052435004711151}
2025-01-13 01:22:21,017 [INFO] Step[1500/4329]: training loss : 0.8993988919258118 TRAIN  loss dict:  {'classification_loss': 0.8993988919258118}
2025-01-13 01:22:32,655 [INFO] Step[1550/4329]: training loss : 0.8879120707511902 TRAIN  loss dict:  {'classification_loss': 0.8879120707511902}
2025-01-13 01:22:44,260 [INFO] Step[1600/4329]: training loss : 0.8915066397190095 TRAIN  loss dict:  {'classification_loss': 0.8915066397190095}
2025-01-13 01:22:55,941 [INFO] Step[1650/4329]: training loss : 0.9212328708171844 TRAIN  loss dict:  {'classification_loss': 0.9212328708171844}
2025-01-13 01:23:07,584 [INFO] Step[1700/4329]: training loss : 0.9059805035591125 TRAIN  loss dict:  {'classification_loss': 0.9059805035591125}
2025-01-13 01:23:19,184 [INFO] Step[1750/4329]: training loss : 0.8920704913139343 TRAIN  loss dict:  {'classification_loss': 0.8920704913139343}
2025-01-13 01:23:30,791 [INFO] Step[1800/4329]: training loss : 0.8979935050010681 TRAIN  loss dict:  {'classification_loss': 0.8979935050010681}
2025-01-13 01:23:42,391 [INFO] Step[1850/4329]: training loss : 0.9254665398597717 TRAIN  loss dict:  {'classification_loss': 0.9254665398597717}
2025-01-13 01:23:54,012 [INFO] Step[1900/4329]: training loss : 0.9025111711025238 TRAIN  loss dict:  {'classification_loss': 0.9025111711025238}
2025-01-13 01:24:05,687 [INFO] Step[1950/4329]: training loss : 0.8896564757823944 TRAIN  loss dict:  {'classification_loss': 0.8896564757823944}
2025-01-13 01:24:17,299 [INFO] Step[2000/4329]: training loss : 0.9011269748210907 TRAIN  loss dict:  {'classification_loss': 0.9011269748210907}
2025-01-13 01:24:28,912 [INFO] Step[2050/4329]: training loss : 0.9402244067192078 TRAIN  loss dict:  {'classification_loss': 0.9402244067192078}
2025-01-13 01:24:40,521 [INFO] Step[2100/4329]: training loss : 0.8862476062774658 TRAIN  loss dict:  {'classification_loss': 0.8862476062774658}
2025-01-13 01:24:52,159 [INFO] Step[2150/4329]: training loss : 0.8889594566822052 TRAIN  loss dict:  {'classification_loss': 0.8889594566822052}
2025-01-13 01:25:03,773 [INFO] Step[2200/4329]: training loss : 0.8918560218811035 TRAIN  loss dict:  {'classification_loss': 0.8918560218811035}
2025-01-13 01:25:15,440 [INFO] Step[2250/4329]: training loss : 0.8910244929790497 TRAIN  loss dict:  {'classification_loss': 0.8910244929790497}
2025-01-13 01:25:27,031 [INFO] Step[2300/4329]: training loss : 0.8903170073032379 TRAIN  loss dict:  {'classification_loss': 0.8903170073032379}
2025-01-13 01:25:38,692 [INFO] Step[2350/4329]: training loss : 0.893074802160263 TRAIN  loss dict:  {'classification_loss': 0.893074802160263}
2025-01-13 01:25:50,332 [INFO] Step[2400/4329]: training loss : 0.9224230813980102 TRAIN  loss dict:  {'classification_loss': 0.9224230813980102}
2025-01-13 01:26:01,989 [INFO] Step[2450/4329]: training loss : 0.9167542874813079 TRAIN  loss dict:  {'classification_loss': 0.9167542874813079}
2025-01-13 01:26:13,626 [INFO] Step[2500/4329]: training loss : 0.9056212258338928 TRAIN  loss dict:  {'classification_loss': 0.9056212258338928}
2025-01-13 01:26:25,232 [INFO] Step[2550/4329]: training loss : 0.9152725160121917 TRAIN  loss dict:  {'classification_loss': 0.9152725160121917}
2025-01-13 01:26:36,806 [INFO] Step[2600/4329]: training loss : 0.9010487377643586 TRAIN  loss dict:  {'classification_loss': 0.9010487377643586}
2025-01-13 01:26:48,455 [INFO] Step[2650/4329]: training loss : 0.8970813083648682 TRAIN  loss dict:  {'classification_loss': 0.8970813083648682}
2025-01-13 01:27:00,077 [INFO] Step[2700/4329]: training loss : 0.888430198431015 TRAIN  loss dict:  {'classification_loss': 0.888430198431015}
2025-01-13 01:27:11,689 [INFO] Step[2750/4329]: training loss : 0.9249226140975952 TRAIN  loss dict:  {'classification_loss': 0.9249226140975952}
2025-01-13 01:27:23,292 [INFO] Step[2800/4329]: training loss : 0.8918251764774322 TRAIN  loss dict:  {'classification_loss': 0.8918251764774322}
2025-01-13 01:27:34,933 [INFO] Step[2850/4329]: training loss : 0.9119133698940277 TRAIN  loss dict:  {'classification_loss': 0.9119133698940277}
2025-01-13 01:27:46,522 [INFO] Step[2900/4329]: training loss : 0.8844343268871308 TRAIN  loss dict:  {'classification_loss': 0.8844343268871308}
2025-01-13 01:27:58,128 [INFO] Step[2950/4329]: training loss : 0.8970038259029388 TRAIN  loss dict:  {'classification_loss': 0.8970038259029388}
2025-01-13 01:28:09,793 [INFO] Step[3000/4329]: training loss : 0.8929420650005341 TRAIN  loss dict:  {'classification_loss': 0.8929420650005341}
2025-01-13 01:28:21,438 [INFO] Step[3050/4329]: training loss : 0.9156523299217224 TRAIN  loss dict:  {'classification_loss': 0.9156523299217224}
2025-01-13 01:28:33,041 [INFO] Step[3100/4329]: training loss : 0.8915936374664306 TRAIN  loss dict:  {'classification_loss': 0.8915936374664306}
2025-01-13 01:28:44,649 [INFO] Step[3150/4329]: training loss : 0.897022430896759 TRAIN  loss dict:  {'classification_loss': 0.897022430896759}
2025-01-13 01:28:56,268 [INFO] Step[3200/4329]: training loss : 0.9091231071949005 TRAIN  loss dict:  {'classification_loss': 0.9091231071949005}
2025-01-13 01:29:07,847 [INFO] Step[3250/4329]: training loss : 0.9112758004665374 TRAIN  loss dict:  {'classification_loss': 0.9112758004665374}
2025-01-13 01:29:19,485 [INFO] Step[3300/4329]: training loss : 0.8989945518970489 TRAIN  loss dict:  {'classification_loss': 0.8989945518970489}
2025-01-13 01:29:31,136 [INFO] Step[3350/4329]: training loss : 0.9022256505489349 TRAIN  loss dict:  {'classification_loss': 0.9022256505489349}
2025-01-13 01:29:42,737 [INFO] Step[3400/4329]: training loss : 0.8983118844032287 TRAIN  loss dict:  {'classification_loss': 0.8983118844032287}
2025-01-13 01:29:54,356 [INFO] Step[3450/4329]: training loss : 0.8956737816333771 TRAIN  loss dict:  {'classification_loss': 0.8956737816333771}
2025-01-13 01:30:05,947 [INFO] Step[3500/4329]: training loss : 0.8984999179840087 TRAIN  loss dict:  {'classification_loss': 0.8984999179840087}
2025-01-13 01:30:17,560 [INFO] Step[3550/4329]: training loss : 0.8960322558879852 TRAIN  loss dict:  {'classification_loss': 0.8960322558879852}
2025-01-13 01:30:29,159 [INFO] Step[3600/4329]: training loss : 0.9072553431987762 TRAIN  loss dict:  {'classification_loss': 0.9072553431987762}
2025-01-13 01:30:40,752 [INFO] Step[3650/4329]: training loss : 0.9099853551387787 TRAIN  loss dict:  {'classification_loss': 0.9099853551387787}
2025-01-13 01:30:52,372 [INFO] Step[3700/4329]: training loss : 0.925765700340271 TRAIN  loss dict:  {'classification_loss': 0.925765700340271}
2025-01-13 01:31:03,996 [INFO] Step[3750/4329]: training loss : 0.9167331409454346 TRAIN  loss dict:  {'classification_loss': 0.9167331409454346}
2025-01-13 01:31:15,596 [INFO] Step[3800/4329]: training loss : 0.9270331132411956 TRAIN  loss dict:  {'classification_loss': 0.9270331132411956}
2025-01-13 01:31:27,230 [INFO] Step[3850/4329]: training loss : 0.9085293102264405 TRAIN  loss dict:  {'classification_loss': 0.9085293102264405}
2025-01-13 01:31:38,796 [INFO] Step[3900/4329]: training loss : 0.9002697861194611 TRAIN  loss dict:  {'classification_loss': 0.9002697861194611}
2025-01-13 01:31:50,433 [INFO] Step[3950/4329]: training loss : 0.9404803073406219 TRAIN  loss dict:  {'classification_loss': 0.9404803073406219}
2025-01-13 01:32:02,043 [INFO] Step[4000/4329]: training loss : 0.8947952020168305 TRAIN  loss dict:  {'classification_loss': 0.8947952020168305}
2025-01-13 01:32:13,845 [INFO] Step[4050/4329]: training loss : 0.8913175141811371 TRAIN  loss dict:  {'classification_loss': 0.8913175141811371}
2025-01-13 01:32:26,192 [INFO] Step[4100/4329]: training loss : 0.896120492219925 TRAIN  loss dict:  {'classification_loss': 0.896120492219925}
2025-01-13 01:32:38,424 [INFO] Step[4150/4329]: training loss : 0.8993204212188721 TRAIN  loss dict:  {'classification_loss': 0.8993204212188721}
2025-01-13 01:32:51,631 [INFO] Step[4200/4329]: training loss : 0.8869644045829773 TRAIN  loss dict:  {'classification_loss': 0.8869644045829773}
2025-01-13 01:33:05,605 [INFO] Step[4250/4329]: training loss : 0.8801629066467285 TRAIN  loss dict:  {'classification_loss': 0.8801629066467285}
2025-01-13 01:33:17,937 [INFO] Step[4300/4329]: training loss : 0.8928181755542756 TRAIN  loss dict:  {'classification_loss': 0.8928181755542756}
2025-01-13 01:35:19,499 [INFO] Label accuracies statistics:
2025-01-13 01:35:19,499 [INFO] {0: 0.6666666666666666, 1: 0.8888888888888888, 2: 0.5833333333333334, 3: 0.75, 4: 0.25, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.6666666666666666, 8: 0.4166666666666667, 9: 0.9166666666666666, 10: 1.0, 11: 0.8333333333333334, 12: 0.3333333333333333, 13: 0.4166666666666667, 14: 0.6666666666666666, 15: 0.6666666666666666, 16: 0.5833333333333334, 17: 0.5, 18: 0.6666666666666666, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.8333333333333334, 24: 1.0, 25: 0.6666666666666666, 26: 0.8333333333333334, 27: 0.5833333333333334, 28: 0.9166666666666666, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.6666666666666666, 33: 0.75, 34: 0.9166666666666666, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 1.0, 38: 0.9166666666666666, 39: 0.9166666666666666, 40: 0.8333333333333334, 41: 0.4166666666666667, 42: 0.8333333333333334, 43: 0.9166666666666666, 44: 0.6666666666666666, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.4166666666666667, 54: 0.4166666666666667, 55: 0.5833333333333334, 56: 0.8333333333333334, 57: 0.75, 58: 0.5833333333333334, 59: 0.75, 60: 0.5833333333333334, 61: 0.9166666666666666, 62: 0.75, 63: 0.6666666666666666, 64: 0.9166666666666666, 65: 1.0, 66: 0.6666666666666666, 67: 0.75, 68: 0.75, 69: 0.6666666666666666, 70: 0.5, 71: 0.5, 72: 0.75, 73: 0.9166666666666666, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.5833333333333334, 78: 1.0, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.8333333333333334, 83: 0.4166666666666667, 84: 0.5833333333333334, 85: 0.75, 86: 0.5833333333333334, 87: 0.9166666666666666, 88: 0.75, 89: 0.5, 90: 0.5, 91: 0.9166666666666666, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.5833333333333334, 97: 0.6666666666666666, 98: 0.75, 99: 1.0, 100: 0.8333333333333334, 101: 0.75, 102: 1.0, 103: 0.8333333333333334, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 0.9166666666666666, 111: 0.9166666666666666, 112: 0.9166666666666666, 113: 0.4166666666666667, 114: 0.5, 115: 0.9166666666666666, 116: 0.6666666666666666, 117: 0.8333333333333334, 118: 0.9166666666666666, 119: 0.75, 120: 0.75, 121: 0.75, 122: 0.9166666666666666, 123: 1.0, 124: 0.8333333333333334, 125: 0.5833333333333334, 126: 0.8333333333333334, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.9166666666666666, 132: 0.3333333333333333, 133: 1.0, 134: 0.9166666666666666, 135: 1.0, 136: 0.9166666666666666, 137: 0.75, 138: 0.9166666666666666, 139: 0.8333333333333334, 140: 1.0, 141: 0.9166666666666666, 142: 0.8333333333333334, 143: 1.0, 144: 0.5833333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.5833333333333334, 149: 1.0, 150: 0.4166666666666667, 151: 1.0, 152: 1.0, 153: 0.9166666666666666, 154: 1.0, 155: 0.8333333333333334, 156: 0.8333333333333334, 157: 0.5833333333333334, 158: 0.7777777777777778, 159: 1.0, 160: 0.4166666666666667, 161: 0.8333333333333334, 162: 0.9166666666666666, 163: 1.0, 164: 0.75, 165: 0.9166666666666666, 166: 0.8333333333333334, 167: 0.75, 168: 0.8333333333333334, 169: 0.8333333333333334, 170: 0.9166666666666666, 171: 0.4166666666666667, 172: 1.0, 173: 0.8333333333333334, 174: 1.0, 175: 0.8333333333333334, 176: 1.0, 177: 0.8333333333333334, 178: 0.9166666666666666, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.75, 182: 0.6666666666666666, 183: 0.8333333333333334, 184: 0.9166666666666666, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.8333333333333334, 189: 0.9166666666666666, 190: 0.5833333333333334, 191: 0.5, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.75, 196: 0.9166666666666666, 197: 0.6666666666666666, 198: 0.5833333333333334}

2025-01-13 01:35:19,502 [INFO] [34] TRAIN  loss: 0.9017673979925762 acc: 0.9946865855536732
2025-01-13 01:35:19,502 [INFO] [34] TRAIN  loss dict: {'classification_loss': 0.9017673979925762}
2025-01-13 01:35:19,502 [INFO] [34] VALIDATION loss: 1.6652398271241573 VALIDATION acc: 0.7840909090909091
2025-01-13 01:35:19,502 [INFO] [34] VALIDATION loss dict: {'classification_loss': 1.6652398271241573}
2025-01-13 01:35:19,502 [INFO] 
2025-01-13 01:35:36,838 [INFO] Step[50/4329]: training loss : 0.8892275249958038 TRAIN  loss dict:  {'classification_loss': 0.8892275249958038}
2025-01-13 01:35:48,435 [INFO] Step[100/4329]: training loss : 0.894592078924179 TRAIN  loss dict:  {'classification_loss': 0.894592078924179}
2025-01-13 01:36:00,112 [INFO] Step[150/4329]: training loss : 0.8796848475933075 TRAIN  loss dict:  {'classification_loss': 0.8796848475933075}
2025-01-13 01:36:11,752 [INFO] Step[200/4329]: training loss : 0.8849591505527497 TRAIN  loss dict:  {'classification_loss': 0.8849591505527497}
2025-01-13 01:36:23,385 [INFO] Step[250/4329]: training loss : 0.885676908493042 TRAIN  loss dict:  {'classification_loss': 0.885676908493042}
2025-01-13 01:36:35,026 [INFO] Step[300/4329]: training loss : 0.901869660615921 TRAIN  loss dict:  {'classification_loss': 0.901869660615921}
2025-01-13 01:36:46,704 [INFO] Step[350/4329]: training loss : 0.8859116804599761 TRAIN  loss dict:  {'classification_loss': 0.8859116804599761}
2025-01-13 01:36:58,352 [INFO] Step[400/4329]: training loss : 0.8895385932922363 TRAIN  loss dict:  {'classification_loss': 0.8895385932922363}
2025-01-13 01:37:10,035 [INFO] Step[450/4329]: training loss : 0.8892644834518433 TRAIN  loss dict:  {'classification_loss': 0.8892644834518433}
2025-01-13 01:37:21,681 [INFO] Step[500/4329]: training loss : 0.8871974158287048 TRAIN  loss dict:  {'classification_loss': 0.8871974158287048}
2025-01-13 01:37:33,324 [INFO] Step[550/4329]: training loss : 0.8954212415218353 TRAIN  loss dict:  {'classification_loss': 0.8954212415218353}
2025-01-13 01:37:44,961 [INFO] Step[600/4329]: training loss : 0.8833583152294159 TRAIN  loss dict:  {'classification_loss': 0.8833583152294159}
2025-01-13 01:37:56,585 [INFO] Step[650/4329]: training loss : 0.9038438677787781 TRAIN  loss dict:  {'classification_loss': 0.9038438677787781}
2025-01-13 01:38:08,231 [INFO] Step[700/4329]: training loss : 0.9208752989768982 TRAIN  loss dict:  {'classification_loss': 0.9208752989768982}
2025-01-13 01:38:19,896 [INFO] Step[750/4329]: training loss : 0.8805810928344726 TRAIN  loss dict:  {'classification_loss': 0.8805810928344726}
2025-01-13 01:38:31,554 [INFO] Step[800/4329]: training loss : 0.9015783762931824 TRAIN  loss dict:  {'classification_loss': 0.9015783762931824}
2025-01-13 01:38:43,218 [INFO] Step[850/4329]: training loss : 0.8811439096927642 TRAIN  loss dict:  {'classification_loss': 0.8811439096927642}
2025-01-13 01:38:54,898 [INFO] Step[900/4329]: training loss : 0.9046133363246918 TRAIN  loss dict:  {'classification_loss': 0.9046133363246918}
2025-01-13 01:39:06,573 [INFO] Step[950/4329]: training loss : 0.8949013602733612 TRAIN  loss dict:  {'classification_loss': 0.8949013602733612}
2025-01-13 01:39:18,259 [INFO] Step[1000/4329]: training loss : 0.8938591766357422 TRAIN  loss dict:  {'classification_loss': 0.8938591766357422}
2025-01-13 01:39:29,906 [INFO] Step[1050/4329]: training loss : 0.9121290183067322 TRAIN  loss dict:  {'classification_loss': 0.9121290183067322}
2025-01-13 01:39:41,573 [INFO] Step[1100/4329]: training loss : 0.8878986930847168 TRAIN  loss dict:  {'classification_loss': 0.8878986930847168}
2025-01-13 01:39:53,234 [INFO] Step[1150/4329]: training loss : 0.8799067199230194 TRAIN  loss dict:  {'classification_loss': 0.8799067199230194}
2025-01-13 01:40:04,871 [INFO] Step[1200/4329]: training loss : 0.9026604819297791 TRAIN  loss dict:  {'classification_loss': 0.9026604819297791}
2025-01-13 01:40:16,536 [INFO] Step[1250/4329]: training loss : 0.8902389025688171 TRAIN  loss dict:  {'classification_loss': 0.8902389025688171}
2025-01-13 01:40:28,172 [INFO] Step[1300/4329]: training loss : 0.8875713288784027 TRAIN  loss dict:  {'classification_loss': 0.8875713288784027}
2025-01-13 01:40:39,866 [INFO] Step[1350/4329]: training loss : 0.8967382216453552 TRAIN  loss dict:  {'classification_loss': 0.8967382216453552}
2025-01-13 01:40:51,532 [INFO] Step[1400/4329]: training loss : 0.8875175237655639 TRAIN  loss dict:  {'classification_loss': 0.8875175237655639}
2025-01-13 01:41:03,211 [INFO] Step[1450/4329]: training loss : 0.8811054611206055 TRAIN  loss dict:  {'classification_loss': 0.8811054611206055}
2025-01-13 01:41:14,892 [INFO] Step[1500/4329]: training loss : 0.8856026446819305 TRAIN  loss dict:  {'classification_loss': 0.8856026446819305}
2025-01-13 01:41:26,596 [INFO] Step[1550/4329]: training loss : 0.8957185137271881 TRAIN  loss dict:  {'classification_loss': 0.8957185137271881}
2025-01-13 01:41:38,277 [INFO] Step[1600/4329]: training loss : 0.899111533164978 TRAIN  loss dict:  {'classification_loss': 0.899111533164978}
2025-01-13 01:41:49,944 [INFO] Step[1650/4329]: training loss : 0.9036936008930206 TRAIN  loss dict:  {'classification_loss': 0.9036936008930206}
2025-01-13 01:42:01,575 [INFO] Step[1700/4329]: training loss : 0.9319413328170776 TRAIN  loss dict:  {'classification_loss': 0.9319413328170776}
2025-01-13 01:42:13,302 [INFO] Step[1750/4329]: training loss : 0.8964962756633759 TRAIN  loss dict:  {'classification_loss': 0.8964962756633759}
2025-01-13 01:42:24,946 [INFO] Step[1800/4329]: training loss : 0.9064750897884369 TRAIN  loss dict:  {'classification_loss': 0.9064750897884369}
2025-01-13 01:42:36,622 [INFO] Step[1850/4329]: training loss : 0.8948690390586853 TRAIN  loss dict:  {'classification_loss': 0.8948690390586853}
2025-01-13 01:42:48,270 [INFO] Step[1900/4329]: training loss : 0.8997834491729736 TRAIN  loss dict:  {'classification_loss': 0.8997834491729736}
2025-01-13 01:42:59,934 [INFO] Step[1950/4329]: training loss : 0.896689385175705 TRAIN  loss dict:  {'classification_loss': 0.896689385175705}
2025-01-13 01:43:11,618 [INFO] Step[2000/4329]: training loss : 0.9142191803455353 TRAIN  loss dict:  {'classification_loss': 0.9142191803455353}
2025-01-13 01:43:23,297 [INFO] Step[2050/4329]: training loss : 0.8927983236312866 TRAIN  loss dict:  {'classification_loss': 0.8927983236312866}
2025-01-13 01:43:34,988 [INFO] Step[2100/4329]: training loss : 0.907972183227539 TRAIN  loss dict:  {'classification_loss': 0.907972183227539}
2025-01-13 01:43:46,669 [INFO] Step[2150/4329]: training loss : 0.8924797916412354 TRAIN  loss dict:  {'classification_loss': 0.8924797916412354}
2025-01-13 01:43:58,329 [INFO] Step[2200/4329]: training loss : 0.8975268125534057 TRAIN  loss dict:  {'classification_loss': 0.8975268125534057}
2025-01-13 01:44:09,990 [INFO] Step[2250/4329]: training loss : 0.9011790347099304 TRAIN  loss dict:  {'classification_loss': 0.9011790347099304}
2025-01-13 01:44:21,653 [INFO] Step[2300/4329]: training loss : 0.9017764556407929 TRAIN  loss dict:  {'classification_loss': 0.9017764556407929}
2025-01-13 01:44:33,421 [INFO] Step[2350/4329]: training loss : 0.903588410615921 TRAIN  loss dict:  {'classification_loss': 0.903588410615921}
2025-01-13 01:44:45,581 [INFO] Step[2400/4329]: training loss : 0.9063250815868378 TRAIN  loss dict:  {'classification_loss': 0.9063250815868378}
2025-01-13 01:44:57,792 [INFO] Step[2450/4329]: training loss : 0.9578273797035217 TRAIN  loss dict:  {'classification_loss': 0.9578273797035217}
2025-01-13 01:45:10,565 [INFO] Step[2500/4329]: training loss : 0.9313764417171478 TRAIN  loss dict:  {'classification_loss': 0.9313764417171478}
2025-01-13 01:45:23,600 [INFO] Step[2550/4329]: training loss : 0.9430987060070037 TRAIN  loss dict:  {'classification_loss': 0.9430987060070037}
2025-01-13 01:45:36,590 [INFO] Step[2600/4329]: training loss : 0.9187152099609375 TRAIN  loss dict:  {'classification_loss': 0.9187152099609375}
2025-01-13 01:45:48,619 [INFO] Step[2650/4329]: training loss : 0.9131182670593262 TRAIN  loss dict:  {'classification_loss': 0.9131182670593262}
2025-01-13 01:46:00,613 [INFO] Step[2700/4329]: training loss : 0.9020396459102631 TRAIN  loss dict:  {'classification_loss': 0.9020396459102631}
2025-01-13 01:46:12,308 [INFO] Step[2750/4329]: training loss : 0.8838938784599304 TRAIN  loss dict:  {'classification_loss': 0.8838938784599304}
2025-01-13 01:46:23,966 [INFO] Step[2800/4329]: training loss : 0.9409504878520966 TRAIN  loss dict:  {'classification_loss': 0.9409504878520966}
2025-01-13 01:46:35,640 [INFO] Step[2850/4329]: training loss : 0.8892835283279419 TRAIN  loss dict:  {'classification_loss': 0.8892835283279419}
2025-01-13 01:46:47,289 [INFO] Step[2900/4329]: training loss : 0.8969149565696717 TRAIN  loss dict:  {'classification_loss': 0.8969149565696717}
2025-01-13 01:46:58,954 [INFO] Step[2950/4329]: training loss : 0.9109675514698029 TRAIN  loss dict:  {'classification_loss': 0.9109675514698029}
2025-01-13 01:47:10,638 [INFO] Step[3000/4329]: training loss : 0.9156441485881806 TRAIN  loss dict:  {'classification_loss': 0.9156441485881806}
2025-01-13 01:47:22,304 [INFO] Step[3050/4329]: training loss : 0.9016256856918335 TRAIN  loss dict:  {'classification_loss': 0.9016256856918335}
2025-01-13 01:47:33,942 [INFO] Step[3100/4329]: training loss : 0.8920147228240967 TRAIN  loss dict:  {'classification_loss': 0.8920147228240967}
2025-01-13 01:47:45,604 [INFO] Step[3150/4329]: training loss : 0.8939693892002105 TRAIN  loss dict:  {'classification_loss': 0.8939693892002105}
2025-01-13 01:47:57,277 [INFO] Step[3200/4329]: training loss : 0.8944307672977447 TRAIN  loss dict:  {'classification_loss': 0.8944307672977447}
2025-01-13 01:48:08,969 [INFO] Step[3250/4329]: training loss : 0.9124787366390228 TRAIN  loss dict:  {'classification_loss': 0.9124787366390228}
2025-01-13 01:48:20,618 [INFO] Step[3300/4329]: training loss : 0.8896503102779388 TRAIN  loss dict:  {'classification_loss': 0.8896503102779388}
2025-01-13 01:48:32,300 [INFO] Step[3350/4329]: training loss : 0.8887066447734833 TRAIN  loss dict:  {'classification_loss': 0.8887066447734833}
2025-01-13 01:48:43,930 [INFO] Step[3400/4329]: training loss : 0.8931815254688263 TRAIN  loss dict:  {'classification_loss': 0.8931815254688263}
2025-01-13 01:48:55,594 [INFO] Step[3450/4329]: training loss : 0.8969099700450898 TRAIN  loss dict:  {'classification_loss': 0.8969099700450898}
2025-01-13 01:49:07,227 [INFO] Step[3500/4329]: training loss : 0.885862741470337 TRAIN  loss dict:  {'classification_loss': 0.885862741470337}
2025-01-13 01:49:18,882 [INFO] Step[3550/4329]: training loss : 0.8928012573719024 TRAIN  loss dict:  {'classification_loss': 0.8928012573719024}
2025-01-13 01:49:30,507 [INFO] Step[3600/4329]: training loss : 0.908520849943161 TRAIN  loss dict:  {'classification_loss': 0.908520849943161}
2025-01-13 01:49:42,174 [INFO] Step[3650/4329]: training loss : 0.904994204044342 TRAIN  loss dict:  {'classification_loss': 0.904994204044342}
2025-01-13 01:49:53,838 [INFO] Step[3700/4329]: training loss : 0.9261269891262054 TRAIN  loss dict:  {'classification_loss': 0.9261269891262054}
2025-01-13 01:50:05,493 [INFO] Step[3750/4329]: training loss : 0.9029722845554352 TRAIN  loss dict:  {'classification_loss': 0.9029722845554352}
2025-01-13 01:50:17,152 [INFO] Step[3800/4329]: training loss : 0.896446043252945 TRAIN  loss dict:  {'classification_loss': 0.896446043252945}
2025-01-13 01:50:28,792 [INFO] Step[3850/4329]: training loss : 0.8925786638259887 TRAIN  loss dict:  {'classification_loss': 0.8925786638259887}
2025-01-13 01:50:40,417 [INFO] Step[3900/4329]: training loss : 0.9130726385116578 TRAIN  loss dict:  {'classification_loss': 0.9130726385116578}
2025-01-13 01:50:52,088 [INFO] Step[3950/4329]: training loss : 0.9311491334438324 TRAIN  loss dict:  {'classification_loss': 0.9311491334438324}
2025-01-13 01:51:03,737 [INFO] Step[4000/4329]: training loss : 0.8927683687210083 TRAIN  loss dict:  {'classification_loss': 0.8927683687210083}
2025-01-13 01:51:15,371 [INFO] Step[4050/4329]: training loss : 0.9108233094215393 TRAIN  loss dict:  {'classification_loss': 0.9108233094215393}
2025-01-13 01:51:27,042 [INFO] Step[4100/4329]: training loss : 0.8881015074253082 TRAIN  loss dict:  {'classification_loss': 0.8881015074253082}
2025-01-13 01:51:38,694 [INFO] Step[4150/4329]: training loss : 0.8999458777904511 TRAIN  loss dict:  {'classification_loss': 0.8999458777904511}
2025-01-13 01:51:50,316 [INFO] Step[4200/4329]: training loss : 0.8960430181026459 TRAIN  loss dict:  {'classification_loss': 0.8960430181026459}
2025-01-13 01:52:02,001 [INFO] Step[4250/4329]: training loss : 0.8932291197776795 TRAIN  loss dict:  {'classification_loss': 0.8932291197776795}
2025-01-13 01:52:13,673 [INFO] Step[4300/4329]: training loss : 0.942819709777832 TRAIN  loss dict:  {'classification_loss': 0.942819709777832}
2025-01-13 01:54:12,421 [INFO] Label accuracies statistics:
2025-01-13 01:54:12,421 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.4166666666666667, 5: 0.75, 6: 0.5833333333333334, 7: 0.5, 8: 0.5833333333333334, 9: 0.9166666666666666, 10: 1.0, 11: 0.8333333333333334, 12: 0.4166666666666667, 13: 0.5833333333333334, 14: 0.5, 15: 0.5555555555555556, 16: 0.6666666666666666, 17: 0.4166666666666667, 18: 0.5, 19: 0.75, 20: 0.5833333333333334, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.6666666666666666, 26: 0.8333333333333334, 27: 0.5833333333333334, 28: 0.9166666666666666, 29: 1.0, 30: 0.5833333333333334, 31: 0.75, 32: 0.75, 33: 0.9166666666666666, 34: 0.8333333333333334, 35: 0.8333333333333334, 36: 0.6666666666666666, 37: 0.9166666666666666, 38: 0.8333333333333334, 39: 1.0, 40: 0.8333333333333334, 41: 0.4166666666666667, 42: 0.8333333333333334, 43: 0.8333333333333334, 44: 0.6666666666666666, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5833333333333334, 56: 0.5, 57: 0.75, 58: 0.5833333333333334, 59: 0.6666666666666666, 60: 0.5833333333333334, 61: 1.0, 62: 0.75, 63: 0.4166666666666667, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.8333333333333334, 68: 0.8333333333333334, 69: 0.6666666666666666, 70: 0.4166666666666667, 71: 0.4166666666666667, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.5833333333333334, 77: 0.75, 78: 1.0, 79: 0.8333333333333334, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.5833333333333334, 87: 0.8333333333333334, 88: 0.6666666666666666, 89: 0.5833333333333334, 90: 0.6666666666666666, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.5833333333333334, 97: 0.6666666666666666, 98: 1.0, 99: 0.9333333333333333, 100: 0.75, 101: 0.75, 102: 1.0, 103: 0.8333333333333334, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.5833333333333334, 108: 0.8333333333333334, 109: 0.75, 110: 0.9166666666666666, 111: 1.0, 112: 0.9166666666666666, 113: 0.25, 114: 0.6666666666666666, 115: 1.0, 116: 0.8333333333333334, 117: 0.9166666666666666, 118: 0.8333333333333334, 119: 0.9166666666666666, 120: 0.75, 121: 0.8333333333333334, 122: 0.8333333333333334, 123: 1.0, 124: 1.0, 125: 0.6666666666666666, 126: 0.8333333333333334, 127: 0.75, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 1.0, 132: 0.4166666666666667, 133: 1.0, 134: 0.75, 135: 1.0, 136: 0.9166666666666666, 137: 0.8333333333333334, 138: 0.9166666666666666, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.9166666666666666, 143: 1.0, 144: 0.4166666666666667, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.6666666666666666, 149: 0.9166666666666666, 150: 0.5833333333333334, 151: 0.9166666666666666, 152: 1.0, 153: 0.8333333333333334, 154: 0.9166666666666666, 155: 0.9166666666666666, 156: 0.5833333333333334, 157: 0.6666666666666666, 158: 0.5555555555555556, 159: 1.0, 160: 0.6666666666666666, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.6666666666666666, 166: 0.6666666666666666, 167: 0.75, 168: 0.8333333333333334, 169: 0.9166666666666666, 170: 0.9166666666666666, 171: 0.8333333333333334, 172: 1.0, 173: 0.9166666666666666, 174: 1.0, 175: 0.9166666666666666, 176: 0.8333333333333334, 177: 0.75, 178: 0.8333333333333334, 179: 0.0, 180: 0.8333333333333334, 181: 0.75, 182: 0.5833333333333334, 183: 0.6666666666666666, 184: 0.8333333333333334, 185: 1.0, 186: 0.75, 187: 0.9166666666666666, 188: 0.75, 189: 0.9166666666666666, 190: 0.6666666666666666, 191: 0.6666666666666666, 192: 1.0, 193: 0.9166666666666666, 194: 0.8333333333333334, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.75}

2025-01-13 01:54:12,423 [INFO] [35] TRAIN  loss: 0.9005779730417239 acc: 0.9954566456183582
2025-01-13 01:54:12,423 [INFO] [35] TRAIN  loss dict: {'classification_loss': 0.9005779730417239}
2025-01-13 01:54:12,424 [INFO] [35] VALIDATION loss: 1.635013845231798 VALIDATION acc: 0.7891414141414141
2025-01-13 01:54:12,424 [INFO] [35] VALIDATION loss dict: {'classification_loss': 1.635013845231798}
2025-01-13 01:54:12,424 [INFO] 
2025-01-13 01:54:29,248 [INFO] Step[50/4329]: training loss : 0.8892265236377717 TRAIN  loss dict:  {'classification_loss': 0.8892265236377717}
2025-01-13 01:54:40,807 [INFO] Step[100/4329]: training loss : 0.8919219982624054 TRAIN  loss dict:  {'classification_loss': 0.8919219982624054}
2025-01-13 01:54:52,434 [INFO] Step[150/4329]: training loss : 0.9153302001953125 TRAIN  loss dict:  {'classification_loss': 0.9153302001953125}
2025-01-13 01:55:04,005 [INFO] Step[200/4329]: training loss : 0.8968991410732269 TRAIN  loss dict:  {'classification_loss': 0.8968991410732269}
2025-01-13 01:55:15,652 [INFO] Step[250/4329]: training loss : 0.897976199388504 TRAIN  loss dict:  {'classification_loss': 0.897976199388504}
2025-01-13 01:55:27,269 [INFO] Step[300/4329]: training loss : 0.8968022537231445 TRAIN  loss dict:  {'classification_loss': 0.8968022537231445}
2025-01-13 01:55:38,906 [INFO] Step[350/4329]: training loss : 0.8989930093288422 TRAIN  loss dict:  {'classification_loss': 0.8989930093288422}
2025-01-13 01:55:50,568 [INFO] Step[400/4329]: training loss : 0.8894400310516357 TRAIN  loss dict:  {'classification_loss': 0.8894400310516357}
2025-01-13 01:56:02,160 [INFO] Step[450/4329]: training loss : 0.9050260388851166 TRAIN  loss dict:  {'classification_loss': 0.9050260388851166}
2025-01-13 01:56:13,780 [INFO] Step[500/4329]: training loss : 0.8916991567611694 TRAIN  loss dict:  {'classification_loss': 0.8916991567611694}
2025-01-13 01:56:25,423 [INFO] Step[550/4329]: training loss : 0.8890079164505005 TRAIN  loss dict:  {'classification_loss': 0.8890079164505005}
2025-01-13 01:56:37,072 [INFO] Step[600/4329]: training loss : 0.9018004584312439 TRAIN  loss dict:  {'classification_loss': 0.9018004584312439}
2025-01-13 01:56:48,710 [INFO] Step[650/4329]: training loss : 0.9068357563018798 TRAIN  loss dict:  {'classification_loss': 0.9068357563018798}
2025-01-13 01:57:00,483 [INFO] Step[700/4329]: training loss : 0.8850237119197846 TRAIN  loss dict:  {'classification_loss': 0.8850237119197846}
2025-01-13 01:57:12,641 [INFO] Step[750/4329]: training loss : 0.9073307847976685 TRAIN  loss dict:  {'classification_loss': 0.9073307847976685}
2025-01-13 01:57:24,912 [INFO] Step[800/4329]: training loss : 0.891375653743744 TRAIN  loss dict:  {'classification_loss': 0.891375653743744}
2025-01-13 01:57:37,878 [INFO] Step[850/4329]: training loss : 0.8905265128612518 TRAIN  loss dict:  {'classification_loss': 0.8905265128612518}
2025-01-13 01:57:51,321 [INFO] Step[900/4329]: training loss : 0.8867295789718628 TRAIN  loss dict:  {'classification_loss': 0.8867295789718628}
2025-01-13 01:58:04,843 [INFO] Step[950/4329]: training loss : 0.881659004688263 TRAIN  loss dict:  {'classification_loss': 0.881659004688263}
2025-01-13 01:58:16,837 [INFO] Step[1000/4329]: training loss : 0.8937373352050781 TRAIN  loss dict:  {'classification_loss': 0.8937373352050781}
2025-01-13 01:58:28,766 [INFO] Step[1050/4329]: training loss : 0.9077231979370117 TRAIN  loss dict:  {'classification_loss': 0.9077231979370117}
2025-01-13 01:58:40,405 [INFO] Step[1100/4329]: training loss : 0.8862845969200134 TRAIN  loss dict:  {'classification_loss': 0.8862845969200134}
2025-01-13 01:58:52,055 [INFO] Step[1150/4329]: training loss : 0.8921779525279999 TRAIN  loss dict:  {'classification_loss': 0.8921779525279999}
2025-01-13 01:59:03,682 [INFO] Step[1200/4329]: training loss : 0.9042714846134186 TRAIN  loss dict:  {'classification_loss': 0.9042714846134186}
2025-01-13 01:59:15,337 [INFO] Step[1250/4329]: training loss : 0.8800196027755738 TRAIN  loss dict:  {'classification_loss': 0.8800196027755738}
2025-01-13 01:59:26,958 [INFO] Step[1300/4329]: training loss : 0.8848296225070953 TRAIN  loss dict:  {'classification_loss': 0.8848296225070953}
2025-01-13 01:59:38,584 [INFO] Step[1350/4329]: training loss : 0.8990246188640595 TRAIN  loss dict:  {'classification_loss': 0.8990246188640595}
2025-01-13 01:59:50,265 [INFO] Step[1400/4329]: training loss : 0.8827549767494202 TRAIN  loss dict:  {'classification_loss': 0.8827549767494202}
2025-01-13 02:00:01,881 [INFO] Step[1450/4329]: training loss : 0.8896574425697327 TRAIN  loss dict:  {'classification_loss': 0.8896574425697327}
2025-01-13 02:00:13,497 [INFO] Step[1500/4329]: training loss : 0.9056571066379547 TRAIN  loss dict:  {'classification_loss': 0.9056571066379547}
2025-01-13 02:00:25,161 [INFO] Step[1550/4329]: training loss : 0.887991670370102 TRAIN  loss dict:  {'classification_loss': 0.887991670370102}
2025-01-13 02:00:36,789 [INFO] Step[1600/4329]: training loss : 0.8819408881664276 TRAIN  loss dict:  {'classification_loss': 0.8819408881664276}
2025-01-13 02:00:48,418 [INFO] Step[1650/4329]: training loss : 0.8849814927577973 TRAIN  loss dict:  {'classification_loss': 0.8849814927577973}
2025-01-13 02:00:59,979 [INFO] Step[1700/4329]: training loss : 0.8974824285507202 TRAIN  loss dict:  {'classification_loss': 0.8974824285507202}
2025-01-13 02:01:11,670 [INFO] Step[1750/4329]: training loss : 0.9096734619140625 TRAIN  loss dict:  {'classification_loss': 0.9096734619140625}
2025-01-13 02:01:23,326 [INFO] Step[1800/4329]: training loss : 0.9107532572746276 TRAIN  loss dict:  {'classification_loss': 0.9107532572746276}
2025-01-13 02:01:34,950 [INFO] Step[1850/4329]: training loss : 0.9051173973083496 TRAIN  loss dict:  {'classification_loss': 0.9051173973083496}
2025-01-13 02:01:46,554 [INFO] Step[1900/4329]: training loss : 0.897630842924118 TRAIN  loss dict:  {'classification_loss': 0.897630842924118}
2025-01-13 02:01:58,199 [INFO] Step[1950/4329]: training loss : 0.9143562412261963 TRAIN  loss dict:  {'classification_loss': 0.9143562412261963}
2025-01-13 02:02:09,824 [INFO] Step[2000/4329]: training loss : 0.8858257579803467 TRAIN  loss dict:  {'classification_loss': 0.8858257579803467}
2025-01-13 02:02:21,446 [INFO] Step[2050/4329]: training loss : 0.8956899762153625 TRAIN  loss dict:  {'classification_loss': 0.8956899762153625}
2025-01-13 02:02:33,047 [INFO] Step[2100/4329]: training loss : 0.8966101396083832 TRAIN  loss dict:  {'classification_loss': 0.8966101396083832}
2025-01-13 02:02:44,649 [INFO] Step[2150/4329]: training loss : 0.8965620231628418 TRAIN  loss dict:  {'classification_loss': 0.8965620231628418}
2025-01-13 02:02:56,282 [INFO] Step[2200/4329]: training loss : 0.9197961246967316 TRAIN  loss dict:  {'classification_loss': 0.9197961246967316}
2025-01-13 02:03:07,911 [INFO] Step[2250/4329]: training loss : 0.9005350923538208 TRAIN  loss dict:  {'classification_loss': 0.9005350923538208}
2025-01-13 02:03:19,518 [INFO] Step[2300/4329]: training loss : 0.880294953584671 TRAIN  loss dict:  {'classification_loss': 0.880294953584671}
2025-01-13 02:03:31,169 [INFO] Step[2350/4329]: training loss : 0.8899845397472381 TRAIN  loss dict:  {'classification_loss': 0.8899845397472381}
2025-01-13 02:03:42,802 [INFO] Step[2400/4329]: training loss : 0.9117374670505524 TRAIN  loss dict:  {'classification_loss': 0.9117374670505524}
2025-01-13 02:03:54,397 [INFO] Step[2450/4329]: training loss : 0.9128971767425537 TRAIN  loss dict:  {'classification_loss': 0.9128971767425537}
2025-01-13 02:04:06,061 [INFO] Step[2500/4329]: training loss : 0.8864072954654694 TRAIN  loss dict:  {'classification_loss': 0.8864072954654694}
2025-01-13 02:04:17,681 [INFO] Step[2550/4329]: training loss : 0.8948609483242035 TRAIN  loss dict:  {'classification_loss': 0.8948609483242035}
2025-01-13 02:04:29,280 [INFO] Step[2600/4329]: training loss : 0.8997090363502502 TRAIN  loss dict:  {'classification_loss': 0.8997090363502502}
2025-01-13 02:04:40,933 [INFO] Step[2650/4329]: training loss : 0.891369903087616 TRAIN  loss dict:  {'classification_loss': 0.891369903087616}
2025-01-13 02:04:52,545 [INFO] Step[2700/4329]: training loss : 0.8864463257789612 TRAIN  loss dict:  {'classification_loss': 0.8864463257789612}
2025-01-13 02:05:04,170 [INFO] Step[2750/4329]: training loss : 0.8968606638908386 TRAIN  loss dict:  {'classification_loss': 0.8968606638908386}
2025-01-13 02:05:15,789 [INFO] Step[2800/4329]: training loss : 0.8867989790439605 TRAIN  loss dict:  {'classification_loss': 0.8867989790439605}
2025-01-13 02:05:27,441 [INFO] Step[2850/4329]: training loss : 0.9151527297496795 TRAIN  loss dict:  {'classification_loss': 0.9151527297496795}
2025-01-13 02:05:39,065 [INFO] Step[2900/4329]: training loss : 0.8833038115501404 TRAIN  loss dict:  {'classification_loss': 0.8833038115501404}
2025-01-13 02:05:50,726 [INFO] Step[2950/4329]: training loss : 0.8911882889270782 TRAIN  loss dict:  {'classification_loss': 0.8911882889270782}
2025-01-13 02:06:02,349 [INFO] Step[3000/4329]: training loss : 0.919627730846405 TRAIN  loss dict:  {'classification_loss': 0.919627730846405}
2025-01-13 02:06:14,014 [INFO] Step[3050/4329]: training loss : 0.8871606695652008 TRAIN  loss dict:  {'classification_loss': 0.8871606695652008}
2025-01-13 02:06:25,613 [INFO] Step[3100/4329]: training loss : 0.9113269722461701 TRAIN  loss dict:  {'classification_loss': 0.9113269722461701}
2025-01-13 02:06:37,248 [INFO] Step[3150/4329]: training loss : 0.9104662704467773 TRAIN  loss dict:  {'classification_loss': 0.9104662704467773}
2025-01-13 02:06:48,818 [INFO] Step[3200/4329]: training loss : 0.9045102202892303 TRAIN  loss dict:  {'classification_loss': 0.9045102202892303}
2025-01-13 02:07:00,433 [INFO] Step[3250/4329]: training loss : 0.8828553652763367 TRAIN  loss dict:  {'classification_loss': 0.8828553652763367}
2025-01-13 02:07:12,043 [INFO] Step[3300/4329]: training loss : 0.8839645326137543 TRAIN  loss dict:  {'classification_loss': 0.8839645326137543}
2025-01-13 02:07:23,673 [INFO] Step[3350/4329]: training loss : 0.8815015864372253 TRAIN  loss dict:  {'classification_loss': 0.8815015864372253}
2025-01-13 02:07:35,307 [INFO] Step[3400/4329]: training loss : 0.8998541927337647 TRAIN  loss dict:  {'classification_loss': 0.8998541927337647}
2025-01-13 02:07:46,884 [INFO] Step[3450/4329]: training loss : 0.8798329281806946 TRAIN  loss dict:  {'classification_loss': 0.8798329281806946}
2025-01-13 02:07:58,464 [INFO] Step[3500/4329]: training loss : 0.9070117068290711 TRAIN  loss dict:  {'classification_loss': 0.9070117068290711}
2025-01-13 02:08:10,062 [INFO] Step[3550/4329]: training loss : 0.8992374849319458 TRAIN  loss dict:  {'classification_loss': 0.8992374849319458}
2025-01-13 02:08:21,671 [INFO] Step[3600/4329]: training loss : 0.9149328553676606 TRAIN  loss dict:  {'classification_loss': 0.9149328553676606}
2025-01-13 02:08:33,314 [INFO] Step[3650/4329]: training loss : 0.9115298295021057 TRAIN  loss dict:  {'classification_loss': 0.9115298295021057}
2025-01-13 02:08:44,931 [INFO] Step[3700/4329]: training loss : 0.8872568416595459 TRAIN  loss dict:  {'classification_loss': 0.8872568416595459}
2025-01-13 02:08:56,569 [INFO] Step[3750/4329]: training loss : 0.8921479511260987 TRAIN  loss dict:  {'classification_loss': 0.8921479511260987}
2025-01-13 02:09:08,212 [INFO] Step[3800/4329]: training loss : 0.9098211634159088 TRAIN  loss dict:  {'classification_loss': 0.9098211634159088}
2025-01-13 02:09:20,042 [INFO] Step[3850/4329]: training loss : 0.8796306991577149 TRAIN  loss dict:  {'classification_loss': 0.8796306991577149}
2025-01-13 02:09:32,284 [INFO] Step[3900/4329]: training loss : 0.8997005963325501 TRAIN  loss dict:  {'classification_loss': 0.8997005963325501}
2025-01-13 02:09:44,468 [INFO] Step[3950/4329]: training loss : 0.8849367940425873 TRAIN  loss dict:  {'classification_loss': 0.8849367940425873}
2025-01-13 02:09:57,410 [INFO] Step[4000/4329]: training loss : 0.8894771015644074 TRAIN  loss dict:  {'classification_loss': 0.8894771015644074}
2025-01-13 02:10:12,466 [INFO] Step[4050/4329]: training loss : 0.8856453990936279 TRAIN  loss dict:  {'classification_loss': 0.8856453990936279}
2025-01-13 02:10:25,067 [INFO] Step[4100/4329]: training loss : 0.888975328207016 TRAIN  loss dict:  {'classification_loss': 0.888975328207016}
2025-01-13 02:10:37,018 [INFO] Step[4150/4329]: training loss : 0.8888419485092163 TRAIN  loss dict:  {'classification_loss': 0.8888419485092163}
2025-01-13 02:10:48,852 [INFO] Step[4200/4329]: training loss : 0.8887082052230835 TRAIN  loss dict:  {'classification_loss': 0.8887082052230835}
2025-01-13 02:11:00,444 [INFO] Step[4250/4329]: training loss : 0.8908744835853577 TRAIN  loss dict:  {'classification_loss': 0.8908744835853577}
2025-01-13 02:11:12,068 [INFO] Step[4300/4329]: training loss : 0.8915309691429139 TRAIN  loss dict:  {'classification_loss': 0.8915309691429139}
2025-01-13 02:13:10,960 [INFO] Label accuracies statistics:
2025-01-13 02:13:10,960 [INFO] {0: 0.7777777777777778, 1: 0.7777777777777778, 2: 0.6666666666666666, 3: 0.75, 4: 0.25, 5: 0.9166666666666666, 6: 0.5, 7: 0.5, 8: 0.5, 9: 0.8333333333333334, 10: 0.9166666666666666, 11: 0.8333333333333334, 12: 0.5, 13: 0.4166666666666667, 14: 0.5, 15: 0.7777777777777778, 16: 0.6666666666666666, 17: 0.6666666666666666, 18: 0.4166666666666667, 19: 0.75, 20: 0.6666666666666666, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.5833333333333334, 26: 0.9166666666666666, 27: 0.5, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.8333333333333334, 32: 0.6666666666666666, 33: 0.75, 34: 0.9166666666666666, 35: 0.8333333333333334, 36: 0.75, 37: 1.0, 38: 0.9166666666666666, 39: 1.0, 40: 0.75, 41: 0.5833333333333334, 42: 0.8333333333333334, 43: 1.0, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.4166666666666667, 54: 0.4166666666666667, 55: 0.75, 56: 0.8333333333333334, 57: 0.75, 58: 0.5833333333333334, 59: 0.8333333333333334, 60: 0.6666666666666666, 61: 1.0, 62: 0.75, 63: 0.5, 64: 0.9166666666666666, 65: 1.0, 66: 0.75, 67: 0.9166666666666666, 68: 0.75, 69: 0.6666666666666666, 70: 0.5, 71: 0.4166666666666667, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.5833333333333334, 75: 1.0, 76: 0.5, 77: 0.75, 78: 0.9166666666666666, 79: 0.5833333333333334, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5833333333333334, 85: 0.75, 86: 0.5833333333333334, 87: 0.9166666666666666, 88: 0.75, 89: 0.5, 90: 0.9166666666666666, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 0.9166666666666666, 96: 0.5833333333333334, 97: 0.6666666666666666, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.8333333333333334, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.75, 110: 0.9166666666666666, 111: 1.0, 112: 1.0, 113: 0.5, 114: 0.5, 115: 0.9166666666666666, 116: 0.8333333333333334, 117: 0.6666666666666666, 118: 1.0, 119: 1.0, 120: 0.6666666666666666, 121: 0.75, 122: 0.9166666666666666, 123: 1.0, 124: 0.9166666666666666, 125: 0.9166666666666666, 126: 0.8333333333333334, 127: 0.5833333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.9166666666666666, 132: 0.4166666666666667, 133: 1.0, 134: 0.8333333333333334, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.8333333333333334, 140: 0.9166666666666666, 141: 1.0, 142: 0.8333333333333334, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.5833333333333334, 149: 1.0, 150: 0.4166666666666667, 151: 0.9166666666666666, 152: 1.0, 153: 0.9166666666666666, 154: 1.0, 155: 0.8333333333333334, 156: 0.9166666666666666, 157: 0.8333333333333334, 158: 0.5555555555555556, 159: 1.0, 160: 0.25, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.8333333333333334, 166: 0.75, 167: 0.75, 168: 0.8333333333333334, 169: 0.8333333333333334, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.9166666666666666, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 1.0, 177: 0.8333333333333334, 178: 1.0, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.5, 183: 0.9166666666666666, 184: 0.5833333333333334, 185: 1.0, 186: 0.8333333333333334, 187: 0.9166666666666666, 188: 0.4166666666666667, 189: 1.0, 190: 0.5833333333333334, 191: 0.5, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.6666666666666666, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.8333333333333334}

2025-01-13 02:13:10,963 [INFO] [36] TRAIN  loss: 0.8955348653395695 acc: 0.9959956876636378
2025-01-13 02:13:10,963 [INFO] [36] TRAIN  loss dict: {'classification_loss': 0.8955348653395695}
2025-01-13 02:13:10,963 [INFO] [36] VALIDATION loss: 1.633801084199939 VALIDATION acc: 0.7958754208754208
2025-01-13 02:13:10,963 [INFO] [36] VALIDATION loss dict: {'classification_loss': 1.633801084199939}
2025-01-13 02:13:10,963 [INFO] 
2025-01-13 02:13:28,820 [INFO] Step[50/4329]: training loss : 0.8904872250556946 TRAIN  loss dict:  {'classification_loss': 0.8904872250556946}
2025-01-13 02:13:40,372 [INFO] Step[100/4329]: training loss : 0.8789365553855896 TRAIN  loss dict:  {'classification_loss': 0.8789365553855896}
2025-01-13 02:13:51,974 [INFO] Step[150/4329]: training loss : 0.8856820511817932 TRAIN  loss dict:  {'classification_loss': 0.8856820511817932}
2025-01-13 02:14:03,609 [INFO] Step[200/4329]: training loss : 0.9021603810787201 TRAIN  loss dict:  {'classification_loss': 0.9021603810787201}
2025-01-13 02:14:15,232 [INFO] Step[250/4329]: training loss : 0.9043125104904175 TRAIN  loss dict:  {'classification_loss': 0.9043125104904175}
2025-01-13 02:14:26,832 [INFO] Step[300/4329]: training loss : 0.8879839968681336 TRAIN  loss dict:  {'classification_loss': 0.8879839968681336}
2025-01-13 02:14:38,473 [INFO] Step[350/4329]: training loss : 0.8963661050796509 TRAIN  loss dict:  {'classification_loss': 0.8963661050796509}
2025-01-13 02:14:50,076 [INFO] Step[400/4329]: training loss : 0.8858175492286682 TRAIN  loss dict:  {'classification_loss': 0.8858175492286682}
2025-01-13 02:15:01,782 [INFO] Step[450/4329]: training loss : 0.9114065313339234 TRAIN  loss dict:  {'classification_loss': 0.9114065313339234}
2025-01-13 02:15:13,422 [INFO] Step[500/4329]: training loss : 0.905780543088913 TRAIN  loss dict:  {'classification_loss': 0.905780543088913}
2025-01-13 02:15:25,108 [INFO] Step[550/4329]: training loss : 0.886972587108612 TRAIN  loss dict:  {'classification_loss': 0.886972587108612}
2025-01-13 02:15:36,747 [INFO] Step[600/4329]: training loss : 0.9084772074222565 TRAIN  loss dict:  {'classification_loss': 0.9084772074222565}
2025-01-13 02:15:48,423 [INFO] Step[650/4329]: training loss : 0.886971298456192 TRAIN  loss dict:  {'classification_loss': 0.886971298456192}
2025-01-13 02:16:00,022 [INFO] Step[700/4329]: training loss : 0.9105634343624115 TRAIN  loss dict:  {'classification_loss': 0.9105634343624115}
2025-01-13 02:16:11,675 [INFO] Step[750/4329]: training loss : 0.8915302670001983 TRAIN  loss dict:  {'classification_loss': 0.8915302670001983}
2025-01-13 02:16:23,273 [INFO] Step[800/4329]: training loss : 0.922897390127182 TRAIN  loss dict:  {'classification_loss': 0.922897390127182}
2025-01-13 02:16:34,920 [INFO] Step[850/4329]: training loss : 0.8868777656555176 TRAIN  loss dict:  {'classification_loss': 0.8868777656555176}
2025-01-13 02:16:46,536 [INFO] Step[900/4329]: training loss : 0.8919998502731323 TRAIN  loss dict:  {'classification_loss': 0.8919998502731323}
2025-01-13 02:16:58,221 [INFO] Step[950/4329]: training loss : 0.8797110462188721 TRAIN  loss dict:  {'classification_loss': 0.8797110462188721}
2025-01-13 02:17:09,838 [INFO] Step[1000/4329]: training loss : 0.8943016505241395 TRAIN  loss dict:  {'classification_loss': 0.8943016505241395}
2025-01-13 02:17:21,504 [INFO] Step[1050/4329]: training loss : 0.8862181305885315 TRAIN  loss dict:  {'classification_loss': 0.8862181305885315}
2025-01-13 02:17:33,104 [INFO] Step[1100/4329]: training loss : 0.8834493148326874 TRAIN  loss dict:  {'classification_loss': 0.8834493148326874}
2025-01-13 02:17:44,749 [INFO] Step[1150/4329]: training loss : 0.8837638127803803 TRAIN  loss dict:  {'classification_loss': 0.8837638127803803}
2025-01-13 02:17:56,382 [INFO] Step[1200/4329]: training loss : 0.8929886531829834 TRAIN  loss dict:  {'classification_loss': 0.8929886531829834}
2025-01-13 02:18:08,029 [INFO] Step[1250/4329]: training loss : 0.916200829744339 TRAIN  loss dict:  {'classification_loss': 0.916200829744339}
2025-01-13 02:18:19,599 [INFO] Step[1300/4329]: training loss : 0.8831987190246582 TRAIN  loss dict:  {'classification_loss': 0.8831987190246582}
2025-01-13 02:18:31,287 [INFO] Step[1350/4329]: training loss : 0.8962846791744232 TRAIN  loss dict:  {'classification_loss': 0.8962846791744232}
2025-01-13 02:18:42,910 [INFO] Step[1400/4329]: training loss : 0.9008621263504029 TRAIN  loss dict:  {'classification_loss': 0.9008621263504029}
2025-01-13 02:18:54,530 [INFO] Step[1450/4329]: training loss : 0.9048061466217041 TRAIN  loss dict:  {'classification_loss': 0.9048061466217041}
2025-01-13 02:19:06,160 [INFO] Step[1500/4329]: training loss : 0.893998556137085 TRAIN  loss dict:  {'classification_loss': 0.893998556137085}
2025-01-13 02:19:17,817 [INFO] Step[1550/4329]: training loss : 0.8998120427131653 TRAIN  loss dict:  {'classification_loss': 0.8998120427131653}
2025-01-13 02:19:29,487 [INFO] Step[1600/4329]: training loss : 0.883815039396286 TRAIN  loss dict:  {'classification_loss': 0.883815039396286}
2025-01-13 02:19:41,133 [INFO] Step[1650/4329]: training loss : 0.8893782329559327 TRAIN  loss dict:  {'classification_loss': 0.8893782329559327}
2025-01-13 02:19:52,740 [INFO] Step[1700/4329]: training loss : 0.8894809436798096 TRAIN  loss dict:  {'classification_loss': 0.8894809436798096}
2025-01-13 02:20:04,380 [INFO] Step[1750/4329]: training loss : 0.8975636529922485 TRAIN  loss dict:  {'classification_loss': 0.8975636529922485}
2025-01-13 02:20:16,047 [INFO] Step[1800/4329]: training loss : 0.8803975522518158 TRAIN  loss dict:  {'classification_loss': 0.8803975522518158}
2025-01-13 02:20:27,679 [INFO] Step[1850/4329]: training loss : 0.8874259686470032 TRAIN  loss dict:  {'classification_loss': 0.8874259686470032}
2025-01-13 02:20:39,299 [INFO] Step[1900/4329]: training loss : 0.9012335991859436 TRAIN  loss dict:  {'classification_loss': 0.9012335991859436}
2025-01-13 02:20:50,898 [INFO] Step[1950/4329]: training loss : 0.9075806963443757 TRAIN  loss dict:  {'classification_loss': 0.9075806963443757}
2025-01-13 02:21:02,529 [INFO] Step[2000/4329]: training loss : 0.8829489088058472 TRAIN  loss dict:  {'classification_loss': 0.8829489088058472}
2025-01-13 02:21:14,159 [INFO] Step[2050/4329]: training loss : 0.9283079993724823 TRAIN  loss dict:  {'classification_loss': 0.9283079993724823}
2025-01-13 02:21:25,800 [INFO] Step[2100/4329]: training loss : 0.8882605767250061 TRAIN  loss dict:  {'classification_loss': 0.8882605767250061}
2025-01-13 02:21:37,488 [INFO] Step[2150/4329]: training loss : 0.8826997220516205 TRAIN  loss dict:  {'classification_loss': 0.8826997220516205}
2025-01-13 02:21:49,491 [INFO] Step[2200/4329]: training loss : 0.9464944469928741 TRAIN  loss dict:  {'classification_loss': 0.9464944469928741}
2025-01-13 02:22:01,736 [INFO] Step[2250/4329]: training loss : 0.8987051689624787 TRAIN  loss dict:  {'classification_loss': 0.8987051689624787}
2025-01-13 02:22:14,202 [INFO] Step[2300/4329]: training loss : 0.9123552036285401 TRAIN  loss dict:  {'classification_loss': 0.9123552036285401}
2025-01-13 02:22:27,485 [INFO] Step[2350/4329]: training loss : 0.9163728666305542 TRAIN  loss dict:  {'classification_loss': 0.9163728666305542}
2025-01-13 02:22:40,449 [INFO] Step[2400/4329]: training loss : 0.9063530802726746 TRAIN  loss dict:  {'classification_loss': 0.9063530802726746}
2025-01-13 02:22:52,524 [INFO] Step[2450/4329]: training loss : 0.9096228766441345 TRAIN  loss dict:  {'classification_loss': 0.9096228766441345}
2025-01-13 02:23:04,438 [INFO] Step[2500/4329]: training loss : 0.8847787964344025 TRAIN  loss dict:  {'classification_loss': 0.8847787964344025}
2025-01-13 02:23:16,159 [INFO] Step[2550/4329]: training loss : 0.8958638930320739 TRAIN  loss dict:  {'classification_loss': 0.8958638930320739}
2025-01-13 02:23:27,756 [INFO] Step[2600/4329]: training loss : 0.8848558938503266 TRAIN  loss dict:  {'classification_loss': 0.8848558938503266}
2025-01-13 02:23:39,374 [INFO] Step[2650/4329]: training loss : 0.9128830516338349 TRAIN  loss dict:  {'classification_loss': 0.9128830516338349}
2025-01-13 02:23:50,981 [INFO] Step[2700/4329]: training loss : 0.8917159426212311 TRAIN  loss dict:  {'classification_loss': 0.8917159426212311}
2025-01-13 02:24:02,629 [INFO] Step[2750/4329]: training loss : 0.9286037528514862 TRAIN  loss dict:  {'classification_loss': 0.9286037528514862}
2025-01-13 02:24:14,241 [INFO] Step[2800/4329]: training loss : 0.9088776993751526 TRAIN  loss dict:  {'classification_loss': 0.9088776993751526}
2025-01-13 02:24:25,895 [INFO] Step[2850/4329]: training loss : 0.8910619485378265 TRAIN  loss dict:  {'classification_loss': 0.8910619485378265}
2025-01-13 02:24:37,572 [INFO] Step[2900/4329]: training loss : 0.9084078788757324 TRAIN  loss dict:  {'classification_loss': 0.9084078788757324}
2025-01-13 02:24:49,191 [INFO] Step[2950/4329]: training loss : 0.8999623191356659 TRAIN  loss dict:  {'classification_loss': 0.8999623191356659}
2025-01-13 02:25:00,825 [INFO] Step[3000/4329]: training loss : 0.894816882610321 TRAIN  loss dict:  {'classification_loss': 0.894816882610321}
2025-01-13 02:25:12,438 [INFO] Step[3050/4329]: training loss : 0.8933785951137543 TRAIN  loss dict:  {'classification_loss': 0.8933785951137543}
2025-01-13 02:25:24,028 [INFO] Step[3100/4329]: training loss : 0.8836539220809937 TRAIN  loss dict:  {'classification_loss': 0.8836539220809937}
2025-01-13 02:25:35,670 [INFO] Step[3150/4329]: training loss : 0.8949856400489807 TRAIN  loss dict:  {'classification_loss': 0.8949856400489807}
2025-01-13 02:25:47,257 [INFO] Step[3200/4329]: training loss : 0.9043097293376923 TRAIN  loss dict:  {'classification_loss': 0.9043097293376923}
2025-01-13 02:25:58,882 [INFO] Step[3250/4329]: training loss : 0.8844628000259399 TRAIN  loss dict:  {'classification_loss': 0.8844628000259399}
2025-01-13 02:26:10,524 [INFO] Step[3300/4329]: training loss : 0.8867751812934875 TRAIN  loss dict:  {'classification_loss': 0.8867751812934875}
2025-01-13 02:26:22,113 [INFO] Step[3350/4329]: training loss : 0.9305705726146698 TRAIN  loss dict:  {'classification_loss': 0.9305705726146698}
2025-01-13 02:26:33,734 [INFO] Step[3400/4329]: training loss : 0.8856837570667266 TRAIN  loss dict:  {'classification_loss': 0.8856837570667266}
2025-01-13 02:26:45,359 [INFO] Step[3450/4329]: training loss : 0.8879208469390869 TRAIN  loss dict:  {'classification_loss': 0.8879208469390869}
2025-01-13 02:26:56,989 [INFO] Step[3500/4329]: training loss : 0.8923969423770904 TRAIN  loss dict:  {'classification_loss': 0.8923969423770904}
2025-01-13 02:27:08,622 [INFO] Step[3550/4329]: training loss : 0.8969084060192108 TRAIN  loss dict:  {'classification_loss': 0.8969084060192108}
2025-01-13 02:27:20,239 [INFO] Step[3600/4329]: training loss : 0.8898414874076843 TRAIN  loss dict:  {'classification_loss': 0.8898414874076843}
2025-01-13 02:27:31,878 [INFO] Step[3650/4329]: training loss : 0.8990015852451324 TRAIN  loss dict:  {'classification_loss': 0.8990015852451324}
2025-01-13 02:27:43,502 [INFO] Step[3700/4329]: training loss : 0.9270526134967804 TRAIN  loss dict:  {'classification_loss': 0.9270526134967804}
2025-01-13 02:27:55,117 [INFO] Step[3750/4329]: training loss : 0.9250883519649505 TRAIN  loss dict:  {'classification_loss': 0.9250883519649505}
2025-01-13 02:28:06,733 [INFO] Step[3800/4329]: training loss : 0.8858245170116424 TRAIN  loss dict:  {'classification_loss': 0.8858245170116424}
2025-01-13 02:28:18,385 [INFO] Step[3850/4329]: training loss : 0.9071583759784698 TRAIN  loss dict:  {'classification_loss': 0.9071583759784698}
2025-01-13 02:28:30,001 [INFO] Step[3900/4329]: training loss : 0.8859539771080017 TRAIN  loss dict:  {'classification_loss': 0.8859539771080017}
2025-01-13 02:28:41,646 [INFO] Step[3950/4329]: training loss : 0.8879764652252198 TRAIN  loss dict:  {'classification_loss': 0.8879764652252198}
2025-01-13 02:28:53,294 [INFO] Step[4000/4329]: training loss : 0.894179390668869 TRAIN  loss dict:  {'classification_loss': 0.894179390668869}
2025-01-13 02:29:04,906 [INFO] Step[4050/4329]: training loss : 0.8816353845596313 TRAIN  loss dict:  {'classification_loss': 0.8816353845596313}
2025-01-13 02:29:16,546 [INFO] Step[4100/4329]: training loss : 0.9080267798900604 TRAIN  loss dict:  {'classification_loss': 0.9080267798900604}
2025-01-13 02:29:28,152 [INFO] Step[4150/4329]: training loss : 0.907528486251831 TRAIN  loss dict:  {'classification_loss': 0.907528486251831}
2025-01-13 02:29:39,767 [INFO] Step[4200/4329]: training loss : 0.9063706636428833 TRAIN  loss dict:  {'classification_loss': 0.9063706636428833}
2025-01-13 02:29:51,368 [INFO] Step[4250/4329]: training loss : 0.9264020872116089 TRAIN  loss dict:  {'classification_loss': 0.9264020872116089}
2025-01-13 02:30:02,999 [INFO] Step[4300/4329]: training loss : 0.8974334144592285 TRAIN  loss dict:  {'classification_loss': 0.8974334144592285}
2025-01-13 02:32:01,655 [INFO] Label accuracies statistics:
2025-01-13 02:32:01,656 [INFO] {0: 0.7777777777777778, 1: 1.0, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.4166666666666667, 5: 0.8333333333333334, 6: 0.5, 7: 0.75, 8: 0.5, 9: 0.75, 10: 1.0, 11: 0.9166666666666666, 12: 0.3333333333333333, 13: 0.5833333333333334, 14: 0.75, 15: 0.6666666666666666, 16: 0.5833333333333334, 17: 0.3333333333333333, 18: 0.5833333333333334, 19: 0.75, 20: 0.6666666666666666, 21: 0.75, 22: 0.75, 23: 0.9166666666666666, 24: 1.0, 25: 0.75, 26: 0.6666666666666666, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.5833333333333334, 31: 0.75, 32: 0.75, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 0.9166666666666666, 36: 0.6666666666666666, 37: 0.9166666666666666, 38: 1.0, 39: 1.0, 40: 0.9166666666666666, 41: 0.5, 42: 0.8333333333333334, 43: 1.0, 44: 0.6666666666666666, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.6666666666666666, 54: 0.4166666666666667, 55: 0.75, 56: 0.5833333333333334, 57: 0.75, 58: 0.5, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.6666666666666666, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.9166666666666666, 68: 0.75, 69: 0.6666666666666666, 70: 0.4166666666666667, 71: 0.5, 72: 0.9166666666666666, 73: 1.0, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.8333333333333334, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.9166666666666666, 83: 0.8333333333333334, 84: 0.5833333333333334, 85: 0.9166666666666666, 86: 0.5833333333333334, 87: 0.8333333333333334, 88: 0.6666666666666666, 89: 0.5, 90: 0.6666666666666666, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 0.9166666666666666, 96: 0.4166666666666667, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.8333333333333334, 101: 0.9166666666666666, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.9166666666666666, 111: 1.0, 112: 0.8333333333333334, 113: 0.4166666666666667, 114: 0.5833333333333334, 115: 0.9166666666666666, 116: 0.75, 117: 0.9166666666666666, 118: 1.0, 119: 0.8333333333333334, 120: 0.75, 121: 0.8333333333333334, 122: 0.8333333333333334, 123: 0.9166666666666666, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.8333333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 1.0, 132: 0.3333333333333333, 133: 1.0, 134: 0.5, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 0.9166666666666666, 142: 0.9166666666666666, 143: 1.0, 144: 0.6666666666666666, 145: 1.0, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 0.9166666666666666, 153: 0.8333333333333334, 154: 1.0, 155: 0.8333333333333334, 156: 0.5, 157: 0.8333333333333334, 158: 0.5555555555555556, 159: 1.0, 160: 0.4166666666666667, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.9166666666666666, 166: 0.6666666666666666, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.9166666666666666, 171: 0.5833333333333334, 172: 1.0, 173: 0.9166666666666666, 174: 0.8333333333333334, 175: 1.0, 176: 0.9166666666666666, 177: 0.75, 178: 0.9166666666666666, 179: 0.1111111111111111, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.5833333333333334, 183: 0.8333333333333334, 184: 0.5833333333333334, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.6666666666666666, 189: 1.0, 190: 0.6666666666666666, 191: 0.5, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.8333333333333334, 197: 0.75, 198: 0.6666666666666666}

2025-01-13 02:32:03,491 [INFO] [37] TRAIN  loss: 0.8980919374800577 acc: 0.9947635915601417
2025-01-13 02:32:03,491 [INFO] [37] TRAIN  loss dict: {'classification_loss': 0.8980919374800577}
2025-01-13 02:32:03,491 [INFO] [37] VALIDATION loss: 1.622937690805305 VALIDATION acc: 0.8038720538720538
2025-01-13 02:32:03,491 [INFO] [37] VALIDATION loss dict: {'classification_loss': 1.622937690805305}
2025-01-13 02:32:03,491 [INFO] 
2025-01-13 02:32:21,513 [INFO] Step[50/4329]: training loss : 0.8880310606956482 TRAIN  loss dict:  {'classification_loss': 0.8880310606956482}
2025-01-13 02:32:33,071 [INFO] Step[100/4329]: training loss : 0.8841055178642273 TRAIN  loss dict:  {'classification_loss': 0.8841055178642273}
2025-01-13 02:32:44,673 [INFO] Step[150/4329]: training loss : 0.8928122162818909 TRAIN  loss dict:  {'classification_loss': 0.8928122162818909}
2025-01-13 02:32:56,291 [INFO] Step[200/4329]: training loss : 0.8891099286079407 TRAIN  loss dict:  {'classification_loss': 0.8891099286079407}
2025-01-13 02:33:07,932 [INFO] Step[250/4329]: training loss : 0.903064067363739 TRAIN  loss dict:  {'classification_loss': 0.903064067363739}
2025-01-13 02:33:19,571 [INFO] Step[300/4329]: training loss : 0.9383302342891693 TRAIN  loss dict:  {'classification_loss': 0.9383302342891693}
2025-01-13 02:33:31,200 [INFO] Step[350/4329]: training loss : 0.8860286545753479 TRAIN  loss dict:  {'classification_loss': 0.8860286545753479}
2025-01-13 02:33:42,807 [INFO] Step[400/4329]: training loss : 0.881647777557373 TRAIN  loss dict:  {'classification_loss': 0.881647777557373}
2025-01-13 02:33:54,507 [INFO] Step[450/4329]: training loss : 0.8768184161186219 TRAIN  loss dict:  {'classification_loss': 0.8768184161186219}
2025-01-13 02:34:06,298 [INFO] Step[500/4329]: training loss : 0.8905005598068237 TRAIN  loss dict:  {'classification_loss': 0.8905005598068237}
2025-01-13 02:34:18,617 [INFO] Step[550/4329]: training loss : 0.8939865458011628 TRAIN  loss dict:  {'classification_loss': 0.8939865458011628}
2025-01-13 02:34:30,764 [INFO] Step[600/4329]: training loss : 0.8801367366313935 TRAIN  loss dict:  {'classification_loss': 0.8801367366313935}
2025-01-13 02:34:43,529 [INFO] Step[650/4329]: training loss : 0.915305324792862 TRAIN  loss dict:  {'classification_loss': 0.915305324792862}
2025-01-13 02:34:56,791 [INFO] Step[700/4329]: training loss : 0.884764951467514 TRAIN  loss dict:  {'classification_loss': 0.884764951467514}
2025-01-13 02:35:09,504 [INFO] Step[750/4329]: training loss : 0.9138041317462922 TRAIN  loss dict:  {'classification_loss': 0.9138041317462922}
2025-01-13 02:35:21,401 [INFO] Step[800/4329]: training loss : 0.899818422794342 TRAIN  loss dict:  {'classification_loss': 0.899818422794342}
2025-01-13 02:35:33,195 [INFO] Step[850/4329]: training loss : 0.8859616661071777 TRAIN  loss dict:  {'classification_loss': 0.8859616661071777}
2025-01-13 02:35:44,815 [INFO] Step[900/4329]: training loss : 0.884462867975235 TRAIN  loss dict:  {'classification_loss': 0.884462867975235}
2025-01-13 02:35:56,430 [INFO] Step[950/4329]: training loss : 0.8860251545906067 TRAIN  loss dict:  {'classification_loss': 0.8860251545906067}
2025-01-13 02:36:08,020 [INFO] Step[1000/4329]: training loss : 0.8789467406272888 TRAIN  loss dict:  {'classification_loss': 0.8789467406272888}
2025-01-13 02:36:19,629 [INFO] Step[1050/4329]: training loss : 0.8905610036849976 TRAIN  loss dict:  {'classification_loss': 0.8905610036849976}
2025-01-13 02:36:31,224 [INFO] Step[1100/4329]: training loss : 0.8983871138095856 TRAIN  loss dict:  {'classification_loss': 0.8983871138095856}
2025-01-13 02:36:42,846 [INFO] Step[1150/4329]: training loss : 0.9004544687271118 TRAIN  loss dict:  {'classification_loss': 0.9004544687271118}
2025-01-13 02:36:54,455 [INFO] Step[1200/4329]: training loss : 0.8820393145084381 TRAIN  loss dict:  {'classification_loss': 0.8820393145084381}
2025-01-13 02:37:06,057 [INFO] Step[1250/4329]: training loss : 0.8814233493804932 TRAIN  loss dict:  {'classification_loss': 0.8814233493804932}
2025-01-13 02:37:17,666 [INFO] Step[1300/4329]: training loss : 0.8844666755199433 TRAIN  loss dict:  {'classification_loss': 0.8844666755199433}
2025-01-13 02:37:29,271 [INFO] Step[1350/4329]: training loss : 0.8930795180797577 TRAIN  loss dict:  {'classification_loss': 0.8930795180797577}
2025-01-13 02:37:40,864 [INFO] Step[1400/4329]: training loss : 0.8937846028804779 TRAIN  loss dict:  {'classification_loss': 0.8937846028804779}
2025-01-13 02:37:52,510 [INFO] Step[1450/4329]: training loss : 0.8935494863986969 TRAIN  loss dict:  {'classification_loss': 0.8935494863986969}
2025-01-13 02:38:04,119 [INFO] Step[1500/4329]: training loss : 0.8924680840969086 TRAIN  loss dict:  {'classification_loss': 0.8924680840969086}
2025-01-13 02:38:15,750 [INFO] Step[1550/4329]: training loss : 0.8816838848590851 TRAIN  loss dict:  {'classification_loss': 0.8816838848590851}
2025-01-13 02:38:27,397 [INFO] Step[1600/4329]: training loss : 0.8777222263813019 TRAIN  loss dict:  {'classification_loss': 0.8777222263813019}
2025-01-13 02:38:39,076 [INFO] Step[1650/4329]: training loss : 0.8781384718418122 TRAIN  loss dict:  {'classification_loss': 0.8781384718418122}
2025-01-13 02:38:50,694 [INFO] Step[1700/4329]: training loss : 0.9004573059082032 TRAIN  loss dict:  {'classification_loss': 0.9004573059082032}
2025-01-13 02:39:02,291 [INFO] Step[1750/4329]: training loss : 0.890748633146286 TRAIN  loss dict:  {'classification_loss': 0.890748633146286}
2025-01-13 02:39:13,911 [INFO] Step[1800/4329]: training loss : 0.8847561275959015 TRAIN  loss dict:  {'classification_loss': 0.8847561275959015}
2025-01-13 02:39:25,543 [INFO] Step[1850/4329]: training loss : 0.8953612887859345 TRAIN  loss dict:  {'classification_loss': 0.8953612887859345}
2025-01-13 02:39:37,135 [INFO] Step[1900/4329]: training loss : 0.9014569163322449 TRAIN  loss dict:  {'classification_loss': 0.9014569163322449}
2025-01-13 02:39:48,764 [INFO] Step[1950/4329]: training loss : 0.8968571710586548 TRAIN  loss dict:  {'classification_loss': 0.8968571710586548}
2025-01-13 02:40:00,421 [INFO] Step[2000/4329]: training loss : 0.8826139914989471 TRAIN  loss dict:  {'classification_loss': 0.8826139914989471}
2025-01-13 02:40:12,029 [INFO] Step[2050/4329]: training loss : 0.8988792967796325 TRAIN  loss dict:  {'classification_loss': 0.8988792967796325}
2025-01-13 02:40:23,594 [INFO] Step[2100/4329]: training loss : 0.9025723779201508 TRAIN  loss dict:  {'classification_loss': 0.9025723779201508}
2025-01-13 02:40:35,176 [INFO] Step[2150/4329]: training loss : 0.9365116345882416 TRAIN  loss dict:  {'classification_loss': 0.9365116345882416}
2025-01-13 02:40:46,789 [INFO] Step[2200/4329]: training loss : 0.9511985504627227 TRAIN  loss dict:  {'classification_loss': 0.9511985504627227}
2025-01-13 02:40:58,395 [INFO] Step[2250/4329]: training loss : 0.8820968770980835 TRAIN  loss dict:  {'classification_loss': 0.8820968770980835}
2025-01-13 02:41:10,025 [INFO] Step[2300/4329]: training loss : 0.8810472738742828 TRAIN  loss dict:  {'classification_loss': 0.8810472738742828}
2025-01-13 02:41:21,673 [INFO] Step[2350/4329]: training loss : 0.8786404490470886 TRAIN  loss dict:  {'classification_loss': 0.8786404490470886}
2025-01-13 02:41:33,310 [INFO] Step[2400/4329]: training loss : 0.8800409245491028 TRAIN  loss dict:  {'classification_loss': 0.8800409245491028}
2025-01-13 02:41:44,931 [INFO] Step[2450/4329]: training loss : 0.8886557078361511 TRAIN  loss dict:  {'classification_loss': 0.8886557078361511}
2025-01-13 02:41:56,501 [INFO] Step[2500/4329]: training loss : 0.8917041039466858 TRAIN  loss dict:  {'classification_loss': 0.8917041039466858}
2025-01-13 02:42:08,121 [INFO] Step[2550/4329]: training loss : 0.9217485535144806 TRAIN  loss dict:  {'classification_loss': 0.9217485535144806}
2025-01-13 02:42:19,739 [INFO] Step[2600/4329]: training loss : 0.9073208355903626 TRAIN  loss dict:  {'classification_loss': 0.9073208355903626}
2025-01-13 02:42:31,402 [INFO] Step[2650/4329]: training loss : 0.8826363372802735 TRAIN  loss dict:  {'classification_loss': 0.8826363372802735}
2025-01-13 02:42:42,953 [INFO] Step[2700/4329]: training loss : 0.8891930603981018 TRAIN  loss dict:  {'classification_loss': 0.8891930603981018}
2025-01-13 02:42:54,512 [INFO] Step[2750/4329]: training loss : 0.8820797204971313 TRAIN  loss dict:  {'classification_loss': 0.8820797204971313}
2025-01-13 02:43:06,127 [INFO] Step[2800/4329]: training loss : 0.8922554302215576 TRAIN  loss dict:  {'classification_loss': 0.8922554302215576}
2025-01-13 02:43:17,707 [INFO] Step[2850/4329]: training loss : 0.8955950284004212 TRAIN  loss dict:  {'classification_loss': 0.8955950284004212}
2025-01-13 02:43:29,331 [INFO] Step[2900/4329]: training loss : 0.901396987438202 TRAIN  loss dict:  {'classification_loss': 0.901396987438202}
2025-01-13 02:43:40,970 [INFO] Step[2950/4329]: training loss : 0.8863412654399871 TRAIN  loss dict:  {'classification_loss': 0.8863412654399871}
2025-01-13 02:43:52,597 [INFO] Step[3000/4329]: training loss : 0.9056726121902465 TRAIN  loss dict:  {'classification_loss': 0.9056726121902465}
2025-01-13 02:44:04,217 [INFO] Step[3050/4329]: training loss : 0.8880480778217316 TRAIN  loss dict:  {'classification_loss': 0.8880480778217316}
2025-01-13 02:44:15,860 [INFO] Step[3100/4329]: training loss : 0.9060856890678406 TRAIN  loss dict:  {'classification_loss': 0.9060856890678406}
2025-01-13 02:44:27,508 [INFO] Step[3150/4329]: training loss : 0.9053771531581879 TRAIN  loss dict:  {'classification_loss': 0.9053771531581879}
2025-01-13 02:44:39,133 [INFO] Step[3200/4329]: training loss : 0.8823049008846283 TRAIN  loss dict:  {'classification_loss': 0.8823049008846283}
2025-01-13 02:44:50,728 [INFO] Step[3250/4329]: training loss : 0.8868381035327911 TRAIN  loss dict:  {'classification_loss': 0.8868381035327911}
2025-01-13 02:45:02,334 [INFO] Step[3300/4329]: training loss : 0.8877580010890961 TRAIN  loss dict:  {'classification_loss': 0.8877580010890961}
2025-01-13 02:45:13,979 [INFO] Step[3350/4329]: training loss : 0.8792890107631683 TRAIN  loss dict:  {'classification_loss': 0.8792890107631683}
2025-01-13 02:45:25,598 [INFO] Step[3400/4329]: training loss : 0.8949193370342254 TRAIN  loss dict:  {'classification_loss': 0.8949193370342254}
2025-01-13 02:45:37,167 [INFO] Step[3450/4329]: training loss : 0.8785373330116272 TRAIN  loss dict:  {'classification_loss': 0.8785373330116272}
2025-01-13 02:45:48,791 [INFO] Step[3500/4329]: training loss : 0.9023154938220977 TRAIN  loss dict:  {'classification_loss': 0.9023154938220977}
2025-01-13 02:46:00,405 [INFO] Step[3550/4329]: training loss : 0.8893498921394348 TRAIN  loss dict:  {'classification_loss': 0.8893498921394348}
2025-01-13 02:46:12,047 [INFO] Step[3600/4329]: training loss : 0.8925337362289428 TRAIN  loss dict:  {'classification_loss': 0.8925337362289428}
2025-01-13 02:46:23,813 [INFO] Step[3650/4329]: training loss : 0.8908110022544861 TRAIN  loss dict:  {'classification_loss': 0.8908110022544861}
2025-01-13 02:46:36,097 [INFO] Step[3700/4329]: training loss : 0.9371096837520599 TRAIN  loss dict:  {'classification_loss': 0.9371096837520599}
2025-01-13 02:46:48,317 [INFO] Step[3750/4329]: training loss : 0.9145811319351196 TRAIN  loss dict:  {'classification_loss': 0.9145811319351196}
2025-01-13 02:47:01,493 [INFO] Step[3800/4329]: training loss : 0.8836592292785644 TRAIN  loss dict:  {'classification_loss': 0.8836592292785644}
2025-01-13 02:47:17,704 [INFO] Step[3850/4329]: training loss : 0.8849101173877716 TRAIN  loss dict:  {'classification_loss': 0.8849101173877716}
2025-01-13 02:47:29,780 [INFO] Step[3900/4329]: training loss : 0.89272066116333 TRAIN  loss dict:  {'classification_loss': 0.89272066116333}
2025-01-13 02:47:41,600 [INFO] Step[3950/4329]: training loss : 0.8817229747772217 TRAIN  loss dict:  {'classification_loss': 0.8817229747772217}
2025-01-13 02:47:53,460 [INFO] Step[4000/4329]: training loss : 0.9106253159046173 TRAIN  loss dict:  {'classification_loss': 0.9106253159046173}
2025-01-13 02:48:05,134 [INFO] Step[4050/4329]: training loss : 0.9030643236637116 TRAIN  loss dict:  {'classification_loss': 0.9030643236637116}
2025-01-13 02:48:16,767 [INFO] Step[4100/4329]: training loss : 0.8869220781326294 TRAIN  loss dict:  {'classification_loss': 0.8869220781326294}
2025-01-13 02:48:28,383 [INFO] Step[4150/4329]: training loss : 0.8838912391662598 TRAIN  loss dict:  {'classification_loss': 0.8838912391662598}
2025-01-13 02:48:39,999 [INFO] Step[4200/4329]: training loss : 0.9034601628780365 TRAIN  loss dict:  {'classification_loss': 0.9034601628780365}
2025-01-13 02:48:51,613 [INFO] Step[4250/4329]: training loss : 0.9101923263072967 TRAIN  loss dict:  {'classification_loss': 0.9101923263072967}
2025-01-13 02:49:03,258 [INFO] Step[4300/4329]: training loss : 0.899887490272522 TRAIN  loss dict:  {'classification_loss': 0.899887490272522}
2025-01-13 02:51:01,992 [INFO] Label accuracies statistics:
2025-01-13 02:51:01,992 [INFO] {0: 0.6666666666666666, 1: 0.8888888888888888, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.25, 5: 0.9166666666666666, 6: 0.5833333333333334, 7: 0.5833333333333334, 8: 0.16666666666666666, 9: 0.8333333333333334, 10: 0.8333333333333334, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.5833333333333334, 14: 0.6666666666666666, 15: 0.6666666666666666, 16: 0.5, 17: 0.16666666666666666, 18: 0.5, 19: 0.5833333333333334, 20: 0.5833333333333334, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.9166666666666666, 27: 0.6666666666666666, 28: 0.8333333333333334, 29: 1.0, 30: 0.5833333333333334, 31: 0.6666666666666666, 32: 0.75, 33: 0.8333333333333334, 34: 1.0, 35: 0.9166666666666666, 36: 0.6666666666666666, 37: 1.0, 38: 0.9166666666666666, 39: 0.9166666666666666, 40: 0.75, 41: 0.5833333333333334, 42: 0.75, 43: 1.0, 44: 0.5833333333333334, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.6666666666666666, 54: 0.4166666666666667, 55: 0.6666666666666666, 56: 0.8333333333333334, 57: 0.75, 58: 0.6666666666666666, 59: 0.6666666666666666, 60: 0.8333333333333334, 61: 0.8333333333333334, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.75, 68: 0.6666666666666666, 69: 0.6666666666666666, 70: 0.5, 71: 0.5, 72: 0.9166666666666666, 73: 1.0, 74: 0.5833333333333334, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 1.0, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.8333333333333334, 83: 0.5833333333333334, 84: 0.5833333333333334, 85: 0.75, 86: 0.5, 87: 0.8333333333333334, 88: 0.5, 89: 0.5833333333333334, 90: 0.75, 91: 0.9166666666666666, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 1.0, 96: 0.5, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.8333333333333334, 101: 0.9166666666666666, 102: 1.0, 103: 0.8333333333333334, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.6666666666666666, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.6666666666666666, 111: 0.9166666666666666, 112: 0.9166666666666666, 113: 0.4166666666666667, 114: 0.6666666666666666, 115: 1.0, 116: 0.8333333333333334, 117: 1.0, 118: 0.9166666666666666, 119: 0.75, 120: 0.75, 121: 0.9166666666666666, 122: 0.9166666666666666, 123: 0.9166666666666666, 124: 0.8333333333333334, 125: 0.8333333333333334, 126: 1.0, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.8333333333333334, 132: 0.6666666666666666, 133: 1.0, 134: 0.6666666666666666, 135: 1.0, 136: 0.9166666666666666, 137: 0.8333333333333334, 138: 0.8333333333333334, 139: 0.8333333333333334, 140: 1.0, 141: 0.9166666666666666, 142: 0.75, 143: 1.0, 144: 0.5833333333333334, 145: 1.0, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 0.9166666666666666, 153: 0.8333333333333334, 154: 1.0, 155: 0.9166666666666666, 156: 0.75, 157: 0.8333333333333334, 158: 0.5555555555555556, 159: 0.9166666666666666, 160: 0.4166666666666667, 161: 0.8333333333333334, 162: 1.0, 163: 0.9166666666666666, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.8333333333333334, 168: 0.9166666666666666, 169: 0.9166666666666666, 170: 1.0, 171: 0.75, 172: 1.0, 173: 0.8333333333333334, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 0.9166666666666666, 177: 0.8333333333333334, 178: 1.0, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.5, 183: 0.8333333333333334, 184: 0.75, 185: 0.75, 186: 0.9166666666666666, 187: 1.0, 188: 0.5833333333333334, 189: 0.9166666666666666, 190: 0.5833333333333334, 191: 0.6666666666666666, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 1.0, 196: 0.9166666666666666, 197: 0.75, 198: 0.75}

2025-01-13 02:51:03,009 [INFO] [38] TRAIN  loss: 0.8939674672476825 acc: 0.9957646696442323
2025-01-13 02:51:03,010 [INFO] [38] TRAIN  loss dict: {'classification_loss': 0.8939674672476825}
2025-01-13 02:51:03,010 [INFO] [38] VALIDATION loss: 1.6098909173348936 VALIDATION acc: 0.79503367003367
2025-01-13 02:51:03,010 [INFO] [38] VALIDATION loss dict: {'classification_loss': 1.6098909173348936}
2025-01-13 02:51:03,010 [INFO] 
2025-01-13 02:51:20,557 [INFO] Step[50/4329]: training loss : 0.9095487213134765 TRAIN  loss dict:  {'classification_loss': 0.9095487213134765}
2025-01-13 02:51:32,115 [INFO] Step[100/4329]: training loss : 0.8941453075408936 TRAIN  loss dict:  {'classification_loss': 0.8941453075408936}
2025-01-13 02:51:43,700 [INFO] Step[150/4329]: training loss : 0.884889372587204 TRAIN  loss dict:  {'classification_loss': 0.884889372587204}
2025-01-13 02:51:55,329 [INFO] Step[200/4329]: training loss : 0.897773562669754 TRAIN  loss dict:  {'classification_loss': 0.897773562669754}
2025-01-13 02:52:06,962 [INFO] Step[250/4329]: training loss : 0.879162073135376 TRAIN  loss dict:  {'classification_loss': 0.879162073135376}
2025-01-13 02:52:18,602 [INFO] Step[300/4329]: training loss : 0.895797986984253 TRAIN  loss dict:  {'classification_loss': 0.895797986984253}
2025-01-13 02:52:30,182 [INFO] Step[350/4329]: training loss : 0.8893728530406952 TRAIN  loss dict:  {'classification_loss': 0.8893728530406952}
2025-01-13 02:52:41,812 [INFO] Step[400/4329]: training loss : 0.8926915669441223 TRAIN  loss dict:  {'classification_loss': 0.8926915669441223}
2025-01-13 02:52:53,448 [INFO] Step[450/4329]: training loss : 0.8816788697242737 TRAIN  loss dict:  {'classification_loss': 0.8816788697242737}
2025-01-13 02:53:05,057 [INFO] Step[500/4329]: training loss : 0.9103527212142944 TRAIN  loss dict:  {'classification_loss': 0.9103527212142944}
2025-01-13 02:53:16,670 [INFO] Step[550/4329]: training loss : 0.9055436265468597 TRAIN  loss dict:  {'classification_loss': 0.9055436265468597}
2025-01-13 02:53:28,297 [INFO] Step[600/4329]: training loss : 0.8789361357688904 TRAIN  loss dict:  {'classification_loss': 0.8789361357688904}
2025-01-13 02:53:39,950 [INFO] Step[650/4329]: training loss : 0.8857743108272552 TRAIN  loss dict:  {'classification_loss': 0.8857743108272552}
2025-01-13 02:53:51,556 [INFO] Step[700/4329]: training loss : 0.8720773589611054 TRAIN  loss dict:  {'classification_loss': 0.8720773589611054}
2025-01-13 02:54:03,240 [INFO] Step[750/4329]: training loss : 0.8926234936714172 TRAIN  loss dict:  {'classification_loss': 0.8926234936714172}
2025-01-13 02:54:14,889 [INFO] Step[800/4329]: training loss : 0.8783581829071045 TRAIN  loss dict:  {'classification_loss': 0.8783581829071045}
2025-01-13 02:54:26,504 [INFO] Step[850/4329]: training loss : 0.8870260095596314 TRAIN  loss dict:  {'classification_loss': 0.8870260095596314}
2025-01-13 02:54:38,118 [INFO] Step[900/4329]: training loss : 0.8816385054588318 TRAIN  loss dict:  {'classification_loss': 0.8816385054588318}
2025-01-13 02:54:49,726 [INFO] Step[950/4329]: training loss : 0.8837062704563141 TRAIN  loss dict:  {'classification_loss': 0.8837062704563141}
2025-01-13 02:55:01,359 [INFO] Step[1000/4329]: training loss : 0.8956156277656555 TRAIN  loss dict:  {'classification_loss': 0.8956156277656555}
2025-01-13 02:55:13,041 [INFO] Step[1050/4329]: training loss : 0.8811041438579559 TRAIN  loss dict:  {'classification_loss': 0.8811041438579559}
2025-01-13 02:55:24,614 [INFO] Step[1100/4329]: training loss : 0.8854306733608246 TRAIN  loss dict:  {'classification_loss': 0.8854306733608246}
2025-01-13 02:55:36,248 [INFO] Step[1150/4329]: training loss : 0.901441376209259 TRAIN  loss dict:  {'classification_loss': 0.901441376209259}
2025-01-13 02:55:47,843 [INFO] Step[1200/4329]: training loss : 0.8843607378005981 TRAIN  loss dict:  {'classification_loss': 0.8843607378005981}
2025-01-13 02:55:59,523 [INFO] Step[1250/4329]: training loss : 0.88720663189888 TRAIN  loss dict:  {'classification_loss': 0.88720663189888}
2025-01-13 02:56:11,131 [INFO] Step[1300/4329]: training loss : 0.8901188683509826 TRAIN  loss dict:  {'classification_loss': 0.8901188683509826}
2025-01-13 02:56:22,720 [INFO] Step[1350/4329]: training loss : 0.8979290854930878 TRAIN  loss dict:  {'classification_loss': 0.8979290854930878}
2025-01-13 02:56:34,336 [INFO] Step[1400/4329]: training loss : 0.9161956369876861 TRAIN  loss dict:  {'classification_loss': 0.9161956369876861}
2025-01-13 02:56:45,954 [INFO] Step[1450/4329]: training loss : 0.8871575403213501 TRAIN  loss dict:  {'classification_loss': 0.8871575403213501}
2025-01-13 02:56:57,572 [INFO] Step[1500/4329]: training loss : 0.8976069676876068 TRAIN  loss dict:  {'classification_loss': 0.8976069676876068}
2025-01-13 02:57:09,205 [INFO] Step[1550/4329]: training loss : 0.8843862855434418 TRAIN  loss dict:  {'classification_loss': 0.8843862855434418}
2025-01-13 02:57:20,850 [INFO] Step[1600/4329]: training loss : 0.8831601822376252 TRAIN  loss dict:  {'classification_loss': 0.8831601822376252}
2025-01-13 02:57:32,482 [INFO] Step[1650/4329]: training loss : 0.8814507734775543 TRAIN  loss dict:  {'classification_loss': 0.8814507734775543}
2025-01-13 02:57:44,079 [INFO] Step[1700/4329]: training loss : 0.8764502966403961 TRAIN  loss dict:  {'classification_loss': 0.8764502966403961}
2025-01-13 02:57:55,691 [INFO] Step[1750/4329]: training loss : 0.8771751642227172 TRAIN  loss dict:  {'classification_loss': 0.8771751642227172}
2025-01-13 02:58:07,291 [INFO] Step[1800/4329]: training loss : 0.886224399805069 TRAIN  loss dict:  {'classification_loss': 0.886224399805069}
2025-01-13 02:58:18,946 [INFO] Step[1850/4329]: training loss : 0.9192547142505646 TRAIN  loss dict:  {'classification_loss': 0.9192547142505646}
2025-01-13 02:58:30,577 [INFO] Step[1900/4329]: training loss : 0.8966284108161926 TRAIN  loss dict:  {'classification_loss': 0.8966284108161926}
2025-01-13 02:58:42,297 [INFO] Step[1950/4329]: training loss : 0.9009869718551635 TRAIN  loss dict:  {'classification_loss': 0.9009869718551635}
2025-01-13 02:58:54,462 [INFO] Step[2000/4329]: training loss : 0.9051418054103851 TRAIN  loss dict:  {'classification_loss': 0.9051418054103851}
2025-01-13 02:59:06,635 [INFO] Step[2050/4329]: training loss : 0.8800999975204468 TRAIN  loss dict:  {'classification_loss': 0.8800999975204468}
2025-01-13 02:59:19,338 [INFO] Step[2100/4329]: training loss : 0.9055844533443451 TRAIN  loss dict:  {'classification_loss': 0.9055844533443451}
2025-01-13 02:59:32,747 [INFO] Step[2150/4329]: training loss : 0.9065745830535888 TRAIN  loss dict:  {'classification_loss': 0.9065745830535888}
2025-01-13 02:59:45,905 [INFO] Step[2200/4329]: training loss : 0.9040150046348572 TRAIN  loss dict:  {'classification_loss': 0.9040150046348572}
2025-01-13 02:59:57,890 [INFO] Step[2250/4329]: training loss : 0.8860111367702485 TRAIN  loss dict:  {'classification_loss': 0.8860111367702485}
2025-01-13 03:00:09,794 [INFO] Step[2300/4329]: training loss : 0.9208218228816986 TRAIN  loss dict:  {'classification_loss': 0.9208218228816986}
2025-01-13 03:00:21,423 [INFO] Step[2350/4329]: training loss : 0.8853473174571991 TRAIN  loss dict:  {'classification_loss': 0.8853473174571991}
2025-01-13 03:00:33,035 [INFO] Step[2400/4329]: training loss : 0.8875593495368957 TRAIN  loss dict:  {'classification_loss': 0.8875593495368957}
2025-01-13 03:00:44,691 [INFO] Step[2450/4329]: training loss : 0.89585524559021 TRAIN  loss dict:  {'classification_loss': 0.89585524559021}
2025-01-13 03:00:56,333 [INFO] Step[2500/4329]: training loss : 0.8893542790412903 TRAIN  loss dict:  {'classification_loss': 0.8893542790412903}
2025-01-13 03:01:07,949 [INFO] Step[2550/4329]: training loss : 0.8863947463035583 TRAIN  loss dict:  {'classification_loss': 0.8863947463035583}
2025-01-13 03:01:19,568 [INFO] Step[2600/4329]: training loss : 0.8925154197216034 TRAIN  loss dict:  {'classification_loss': 0.8925154197216034}
2025-01-13 03:01:31,213 [INFO] Step[2650/4329]: training loss : 0.8915065014362336 TRAIN  loss dict:  {'classification_loss': 0.8915065014362336}
2025-01-13 03:01:42,816 [INFO] Step[2700/4329]: training loss : 0.8881565165519715 TRAIN  loss dict:  {'classification_loss': 0.8881565165519715}
2025-01-13 03:01:54,468 [INFO] Step[2750/4329]: training loss : 0.9022092139720916 TRAIN  loss dict:  {'classification_loss': 0.9022092139720916}
2025-01-13 03:02:06,080 [INFO] Step[2800/4329]: training loss : 0.8792469584941864 TRAIN  loss dict:  {'classification_loss': 0.8792469584941864}
2025-01-13 03:02:17,697 [INFO] Step[2850/4329]: training loss : 0.9079662680625915 TRAIN  loss dict:  {'classification_loss': 0.9079662680625915}
2025-01-13 03:02:29,313 [INFO] Step[2900/4329]: training loss : 0.8798387587070465 TRAIN  loss dict:  {'classification_loss': 0.8798387587070465}
2025-01-13 03:02:40,940 [INFO] Step[2950/4329]: training loss : 0.8802441382408142 TRAIN  loss dict:  {'classification_loss': 0.8802441382408142}
2025-01-13 03:02:52,594 [INFO] Step[3000/4329]: training loss : 0.9002989971637726 TRAIN  loss dict:  {'classification_loss': 0.9002989971637726}
2025-01-13 03:03:04,223 [INFO] Step[3050/4329]: training loss : 0.8944481921195984 TRAIN  loss dict:  {'classification_loss': 0.8944481921195984}
2025-01-13 03:03:15,858 [INFO] Step[3100/4329]: training loss : 0.9090248537063599 TRAIN  loss dict:  {'classification_loss': 0.9090248537063599}
2025-01-13 03:03:27,487 [INFO] Step[3150/4329]: training loss : 0.8792872881889343 TRAIN  loss dict:  {'classification_loss': 0.8792872881889343}
2025-01-13 03:03:39,102 [INFO] Step[3200/4329]: training loss : 0.8821172785758972 TRAIN  loss dict:  {'classification_loss': 0.8821172785758972}
2025-01-13 03:03:50,731 [INFO] Step[3250/4329]: training loss : 0.8930004036426544 TRAIN  loss dict:  {'classification_loss': 0.8930004036426544}
2025-01-13 03:04:02,337 [INFO] Step[3300/4329]: training loss : 0.8841250610351562 TRAIN  loss dict:  {'classification_loss': 0.8841250610351562}
2025-01-13 03:04:13,957 [INFO] Step[3350/4329]: training loss : 0.8954415321350098 TRAIN  loss dict:  {'classification_loss': 0.8954415321350098}
2025-01-13 03:04:25,604 [INFO] Step[3400/4329]: training loss : 0.887602310180664 TRAIN  loss dict:  {'classification_loss': 0.887602310180664}
2025-01-13 03:04:37,287 [INFO] Step[3450/4329]: training loss : 0.8855186092853546 TRAIN  loss dict:  {'classification_loss': 0.8855186092853546}
2025-01-13 03:04:48,888 [INFO] Step[3500/4329]: training loss : 0.9151908195018769 TRAIN  loss dict:  {'classification_loss': 0.9151908195018769}
2025-01-13 03:05:00,559 [INFO] Step[3550/4329]: training loss : 0.8977915585041046 TRAIN  loss dict:  {'classification_loss': 0.8977915585041046}
2025-01-13 03:05:12,152 [INFO] Step[3600/4329]: training loss : 0.881393951177597 TRAIN  loss dict:  {'classification_loss': 0.881393951177597}
2025-01-13 03:05:23,764 [INFO] Step[3650/4329]: training loss : 0.9112798225879669 TRAIN  loss dict:  {'classification_loss': 0.9112798225879669}
2025-01-13 03:05:35,437 [INFO] Step[3700/4329]: training loss : 0.8877302515506744 TRAIN  loss dict:  {'classification_loss': 0.8877302515506744}
2025-01-13 03:05:47,105 [INFO] Step[3750/4329]: training loss : 0.8807625877857208 TRAIN  loss dict:  {'classification_loss': 0.8807625877857208}
2025-01-13 03:05:58,690 [INFO] Step[3800/4329]: training loss : 0.9095310318470001 TRAIN  loss dict:  {'classification_loss': 0.9095310318470001}
2025-01-13 03:06:10,308 [INFO] Step[3850/4329]: training loss : 0.8840704441070557 TRAIN  loss dict:  {'classification_loss': 0.8840704441070557}
2025-01-13 03:06:21,909 [INFO] Step[3900/4329]: training loss : 0.8914538753032685 TRAIN  loss dict:  {'classification_loss': 0.8914538753032685}
2025-01-13 03:06:33,550 [INFO] Step[3950/4329]: training loss : 0.8881554329395294 TRAIN  loss dict:  {'classification_loss': 0.8881554329395294}
2025-01-13 03:06:45,175 [INFO] Step[4000/4329]: training loss : 0.8998652040958405 TRAIN  loss dict:  {'classification_loss': 0.8998652040958405}
2025-01-13 03:06:56,859 [INFO] Step[4050/4329]: training loss : 0.912092205286026 TRAIN  loss dict:  {'classification_loss': 0.912092205286026}
2025-01-13 03:07:08,443 [INFO] Step[4100/4329]: training loss : 0.8955433368682861 TRAIN  loss dict:  {'classification_loss': 0.8955433368682861}
2025-01-13 03:07:20,073 [INFO] Step[4150/4329]: training loss : 0.8922231340408325 TRAIN  loss dict:  {'classification_loss': 0.8922231340408325}
2025-01-13 03:07:31,733 [INFO] Step[4200/4329]: training loss : 0.9066125357151031 TRAIN  loss dict:  {'classification_loss': 0.9066125357151031}
2025-01-13 03:07:43,351 [INFO] Step[4250/4329]: training loss : 0.8847653663158417 TRAIN  loss dict:  {'classification_loss': 0.8847653663158417}
2025-01-13 03:07:55,002 [INFO] Step[4300/4329]: training loss : 0.905080703496933 TRAIN  loss dict:  {'classification_loss': 0.905080703496933}
2025-01-13 03:09:54,777 [INFO] Label accuracies statistics:
2025-01-13 03:09:54,777 [INFO] {0: 0.5555555555555556, 1: 0.8888888888888888, 2: 0.6666666666666666, 3: 0.75, 4: 0.4166666666666667, 5: 1.0, 6: 0.5, 7: 0.5833333333333334, 8: 0.5, 9: 0.8333333333333334, 10: 1.0, 11: 0.9166666666666666, 12: 0.5, 13: 0.5, 14: 0.6666666666666666, 15: 0.6666666666666666, 16: 0.5833333333333334, 17: 0.5833333333333334, 18: 0.5, 19: 0.8333333333333334, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.9166666666666666, 24: 1.0, 25: 0.8333333333333334, 26: 0.8333333333333334, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.5833333333333334, 31: 0.8333333333333334, 32: 0.75, 33: 0.8333333333333334, 34: 0.9166666666666666, 35: 1.0, 36: 0.6666666666666666, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.8333333333333334, 41: 0.3333333333333333, 42: 0.8333333333333334, 43: 1.0, 44: 0.6666666666666666, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.9166666666666666, 53: 0.5833333333333334, 54: 0.4166666666666667, 55: 0.8333333333333334, 56: 0.75, 57: 0.75, 58: 0.5833333333333334, 59: 0.8333333333333334, 60: 0.6666666666666666, 61: 0.9166666666666666, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.8333333333333334, 68: 0.8333333333333334, 69: 0.6666666666666666, 70: 0.25, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5833333333333334, 75: 1.0, 76: 0.5833333333333334, 77: 0.5833333333333334, 78: 0.9166666666666666, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.9166666666666666, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.5833333333333334, 87: 0.8333333333333334, 88: 0.6666666666666666, 89: 0.5, 90: 0.4166666666666667, 91: 0.8333333333333334, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.4166666666666667, 97: 0.6666666666666666, 98: 0.75, 99: 1.0, 100: 0.8333333333333334, 101: 0.9166666666666666, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 0.9166666666666666, 106: 1.0, 107: 0.8333333333333334, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 0.9166666666666666, 111: 1.0, 112: 0.9166666666666666, 113: 0.5, 114: 0.4166666666666667, 115: 1.0, 116: 0.8333333333333334, 117: 0.9166666666666666, 118: 1.0, 119: 0.75, 120: 0.75, 121: 0.75, 122: 0.8333333333333334, 123: 0.9166666666666666, 124: 1.0, 125: 0.8333333333333334, 126: 0.9166666666666666, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.8333333333333334, 132: 0.5833333333333334, 133: 1.0, 134: 0.75, 135: 1.0, 136: 0.8333333333333334, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.8333333333333334, 140: 1.0, 141: 0.9166666666666666, 142: 0.75, 143: 1.0, 144: 0.5833333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.9166666666666666, 148: 0.8333333333333334, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 0.8333333333333334, 153: 0.9166666666666666, 154: 1.0, 155: 1.0, 156: 0.8333333333333334, 157: 0.8333333333333334, 158: 0.6666666666666666, 159: 1.0, 160: 0.4166666666666667, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.75, 166: 0.6666666666666666, 167: 0.8333333333333334, 168: 0.8333333333333334, 169: 1.0, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.9166666666666666, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.8333333333333334, 178: 0.8333333333333334, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.75, 183: 0.8333333333333334, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.5833333333333334, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.6666666666666666, 196: 0.8333333333333334, 197: 0.8333333333333334, 198: 0.6666666666666666}

2025-01-13 03:09:55,740 [INFO] [39] TRAIN  loss: 0.8924635697743941 acc: 0.9962267056830433
2025-01-13 03:09:55,740 [INFO] [39] TRAIN  loss dict: {'classification_loss': 0.8924635697743941}
2025-01-13 03:09:55,740 [INFO] [39] VALIDATION loss: 1.607479572973468 VALIDATION acc: 0.8017676767676768
2025-01-13 03:09:55,740 [INFO] [39] VALIDATION loss dict: {'classification_loss': 1.607479572973468}
2025-01-13 03:09:55,740 [INFO] 
2025-01-13 03:10:13,171 [INFO] Step[50/4329]: training loss : 0.9029051268100738 TRAIN  loss dict:  {'classification_loss': 0.9029051268100738}
2025-01-13 03:10:24,772 [INFO] Step[100/4329]: training loss : 0.9022177958488464 TRAIN  loss dict:  {'classification_loss': 0.9022177958488464}
2025-01-13 03:10:36,351 [INFO] Step[150/4329]: training loss : 0.8810980069637299 TRAIN  loss dict:  {'classification_loss': 0.8810980069637299}
2025-01-13 03:10:47,942 [INFO] Step[200/4329]: training loss : 0.8792203056812287 TRAIN  loss dict:  {'classification_loss': 0.8792203056812287}
2025-01-13 03:10:59,568 [INFO] Step[250/4329]: training loss : 0.9057366704940796 TRAIN  loss dict:  {'classification_loss': 0.9057366704940796}
2025-01-13 03:11:11,387 [INFO] Step[300/4329]: training loss : 0.8978248083591461 TRAIN  loss dict:  {'classification_loss': 0.8978248083591461}
2025-01-13 03:11:23,761 [INFO] Step[350/4329]: training loss : 0.8830658280849457 TRAIN  loss dict:  {'classification_loss': 0.8830658280849457}
2025-01-13 03:11:35,974 [INFO] Step[400/4329]: training loss : 0.887523900270462 TRAIN  loss dict:  {'classification_loss': 0.887523900270462}
2025-01-13 03:11:50,283 [INFO] Step[450/4329]: training loss : 0.914283640384674 TRAIN  loss dict:  {'classification_loss': 0.914283640384674}
2025-01-13 03:12:03,719 [INFO] Step[500/4329]: training loss : 0.8893484282493591 TRAIN  loss dict:  {'classification_loss': 0.8893484282493591}
2025-01-13 03:12:15,989 [INFO] Step[550/4329]: training loss : 0.8983480858802796 TRAIN  loss dict:  {'classification_loss': 0.8983480858802796}
2025-01-13 03:12:27,844 [INFO] Step[600/4329]: training loss : 0.8901389074325562 TRAIN  loss dict:  {'classification_loss': 0.8901389074325562}
2025-01-13 03:12:39,734 [INFO] Step[650/4329]: training loss : 0.882336962223053 TRAIN  loss dict:  {'classification_loss': 0.882336962223053}
2025-01-13 03:12:51,343 [INFO] Step[700/4329]: training loss : 0.9397927033901214 TRAIN  loss dict:  {'classification_loss': 0.9397927033901214}
2025-01-13 03:13:03,011 [INFO] Step[750/4329]: training loss : 0.8785200154781342 TRAIN  loss dict:  {'classification_loss': 0.8785200154781342}
2025-01-13 03:13:14,647 [INFO] Step[800/4329]: training loss : 0.8872905123233795 TRAIN  loss dict:  {'classification_loss': 0.8872905123233795}
2025-01-13 03:13:26,296 [INFO] Step[850/4329]: training loss : 0.8891165292263031 TRAIN  loss dict:  {'classification_loss': 0.8891165292263031}
2025-01-13 03:13:37,916 [INFO] Step[900/4329]: training loss : 0.8942744541168213 TRAIN  loss dict:  {'classification_loss': 0.8942744541168213}
2025-01-13 03:13:49,549 [INFO] Step[950/4329]: training loss : 0.8950057733058929 TRAIN  loss dict:  {'classification_loss': 0.8950057733058929}
2025-01-13 03:14:01,186 [INFO] Step[1000/4329]: training loss : 0.8849238646030426 TRAIN  loss dict:  {'classification_loss': 0.8849238646030426}
2025-01-13 03:14:12,796 [INFO] Step[1050/4329]: training loss : 0.8921220946311951 TRAIN  loss dict:  {'classification_loss': 0.8921220946311951}
2025-01-13 03:14:24,413 [INFO] Step[1100/4329]: training loss : 0.8930720090866089 TRAIN  loss dict:  {'classification_loss': 0.8930720090866089}
2025-01-13 03:14:36,052 [INFO] Step[1150/4329]: training loss : 0.8821308791637421 TRAIN  loss dict:  {'classification_loss': 0.8821308791637421}
2025-01-13 03:14:47,677 [INFO] Step[1200/4329]: training loss : 0.8859445464611053 TRAIN  loss dict:  {'classification_loss': 0.8859445464611053}
2025-01-13 03:14:59,281 [INFO] Step[1250/4329]: training loss : 0.9016270029544831 TRAIN  loss dict:  {'classification_loss': 0.9016270029544831}
2025-01-13 03:15:10,867 [INFO] Step[1300/4329]: training loss : 0.8874755811691284 TRAIN  loss dict:  {'classification_loss': 0.8874755811691284}
2025-01-13 03:15:22,481 [INFO] Step[1350/4329]: training loss : 0.8994306552410126 TRAIN  loss dict:  {'classification_loss': 0.8994306552410126}
2025-01-13 03:15:34,117 [INFO] Step[1400/4329]: training loss : 0.8911085951328278 TRAIN  loss dict:  {'classification_loss': 0.8911085951328278}
2025-01-13 03:15:45,809 [INFO] Step[1450/4329]: training loss : 0.9004940748214721 TRAIN  loss dict:  {'classification_loss': 0.9004940748214721}
2025-01-13 03:15:57,463 [INFO] Step[1500/4329]: training loss : 0.8978826475143432 TRAIN  loss dict:  {'classification_loss': 0.8978826475143432}
2025-01-13 03:16:09,055 [INFO] Step[1550/4329]: training loss : 0.8964644408226013 TRAIN  loss dict:  {'classification_loss': 0.8964644408226013}
2025-01-13 03:16:20,677 [INFO] Step[1600/4329]: training loss : 0.8829761135578156 TRAIN  loss dict:  {'classification_loss': 0.8829761135578156}
2025-01-13 03:16:32,305 [INFO] Step[1650/4329]: training loss : 0.9068590366840362 TRAIN  loss dict:  {'classification_loss': 0.9068590366840362}
2025-01-13 03:16:43,910 [INFO] Step[1700/4329]: training loss : 0.888726887702942 TRAIN  loss dict:  {'classification_loss': 0.888726887702942}
2025-01-13 03:16:55,529 [INFO] Step[1750/4329]: training loss : 0.944511786699295 TRAIN  loss dict:  {'classification_loss': 0.944511786699295}
2025-01-13 03:17:07,114 [INFO] Step[1800/4329]: training loss : 0.8908287107944488 TRAIN  loss dict:  {'classification_loss': 0.8908287107944488}
2025-01-13 03:17:18,720 [INFO] Step[1850/4329]: training loss : 0.8811897921562195 TRAIN  loss dict:  {'classification_loss': 0.8811897921562195}
2025-01-13 03:17:30,356 [INFO] Step[1900/4329]: training loss : 0.9084408533573151 TRAIN  loss dict:  {'classification_loss': 0.9084408533573151}
2025-01-13 03:17:41,936 [INFO] Step[1950/4329]: training loss : 0.8988972866535186 TRAIN  loss dict:  {'classification_loss': 0.8988972866535186}
2025-01-13 03:17:53,524 [INFO] Step[2000/4329]: training loss : 0.8774992454051972 TRAIN  loss dict:  {'classification_loss': 0.8774992454051972}
2025-01-13 03:18:05,126 [INFO] Step[2050/4329]: training loss : 0.905307844877243 TRAIN  loss dict:  {'classification_loss': 0.905307844877243}
2025-01-13 03:18:16,774 [INFO] Step[2100/4329]: training loss : 0.8857333779335022 TRAIN  loss dict:  {'classification_loss': 0.8857333779335022}
2025-01-13 03:18:28,391 [INFO] Step[2150/4329]: training loss : 0.8856712830066681 TRAIN  loss dict:  {'classification_loss': 0.8856712830066681}
2025-01-13 03:18:40,056 [INFO] Step[2200/4329]: training loss : 0.8831306052207947 TRAIN  loss dict:  {'classification_loss': 0.8831306052207947}
2025-01-13 03:18:51,670 [INFO] Step[2250/4329]: training loss : 0.8795304727554322 TRAIN  loss dict:  {'classification_loss': 0.8795304727554322}
2025-01-13 03:19:03,344 [INFO] Step[2300/4329]: training loss : 0.8889358937740326 TRAIN  loss dict:  {'classification_loss': 0.8889358937740326}
2025-01-13 03:19:14,968 [INFO] Step[2350/4329]: training loss : 0.8991945219039917 TRAIN  loss dict:  {'classification_loss': 0.8991945219039917}
2025-01-13 03:19:26,564 [INFO] Step[2400/4329]: training loss : 0.9373826026916504 TRAIN  loss dict:  {'classification_loss': 0.9373826026916504}
2025-01-13 03:19:38,252 [INFO] Step[2450/4329]: training loss : 0.8882460427284241 TRAIN  loss dict:  {'classification_loss': 0.8882460427284241}
2025-01-13 03:19:49,846 [INFO] Step[2500/4329]: training loss : 0.8836526644229888 TRAIN  loss dict:  {'classification_loss': 0.8836526644229888}
2025-01-13 03:20:01,413 [INFO] Step[2550/4329]: training loss : 0.8796236515045166 TRAIN  loss dict:  {'classification_loss': 0.8796236515045166}
2025-01-13 03:20:13,019 [INFO] Step[2600/4329]: training loss : 0.890595121383667 TRAIN  loss dict:  {'classification_loss': 0.890595121383667}
2025-01-13 03:20:24,621 [INFO] Step[2650/4329]: training loss : 0.8911583304405213 TRAIN  loss dict:  {'classification_loss': 0.8911583304405213}
2025-01-13 03:20:36,214 [INFO] Step[2700/4329]: training loss : 0.8834517133235932 TRAIN  loss dict:  {'classification_loss': 0.8834517133235932}
2025-01-13 03:20:47,851 [INFO] Step[2750/4329]: training loss : 0.8800372290611267 TRAIN  loss dict:  {'classification_loss': 0.8800372290611267}
2025-01-13 03:20:59,478 [INFO] Step[2800/4329]: training loss : 0.8947950267791748 TRAIN  loss dict:  {'classification_loss': 0.8947950267791748}
2025-01-13 03:21:11,069 [INFO] Step[2850/4329]: training loss : 0.8879055678844452 TRAIN  loss dict:  {'classification_loss': 0.8879055678844452}
2025-01-13 03:21:22,695 [INFO] Step[2900/4329]: training loss : 0.8880109941959381 TRAIN  loss dict:  {'classification_loss': 0.8880109941959381}
2025-01-13 03:21:34,356 [INFO] Step[2950/4329]: training loss : 0.8877104866504669 TRAIN  loss dict:  {'classification_loss': 0.8877104866504669}
2025-01-13 03:21:45,991 [INFO] Step[3000/4329]: training loss : 0.8972053062915802 TRAIN  loss dict:  {'classification_loss': 0.8972053062915802}
2025-01-13 03:21:57,571 [INFO] Step[3050/4329]: training loss : 0.8873105490207672 TRAIN  loss dict:  {'classification_loss': 0.8873105490207672}
2025-01-13 03:22:09,164 [INFO] Step[3100/4329]: training loss : 0.8748492872714997 TRAIN  loss dict:  {'classification_loss': 0.8748492872714997}
2025-01-13 03:22:20,849 [INFO] Step[3150/4329]: training loss : 0.8885989391803741 TRAIN  loss dict:  {'classification_loss': 0.8885989391803741}
2025-01-13 03:22:32,472 [INFO] Step[3200/4329]: training loss : 0.8762333118915557 TRAIN  loss dict:  {'classification_loss': 0.8762333118915557}
2025-01-13 03:22:44,084 [INFO] Step[3250/4329]: training loss : 0.8953353202342987 TRAIN  loss dict:  {'classification_loss': 0.8953353202342987}
2025-01-13 03:22:55,765 [INFO] Step[3300/4329]: training loss : 0.8950069677829743 TRAIN  loss dict:  {'classification_loss': 0.8950069677829743}
2025-01-13 03:23:07,360 [INFO] Step[3350/4329]: training loss : 0.8907362866401672 TRAIN  loss dict:  {'classification_loss': 0.8907362866401672}
2025-01-13 03:23:18,997 [INFO] Step[3400/4329]: training loss : 0.8963520300388336 TRAIN  loss dict:  {'classification_loss': 0.8963520300388336}
2025-01-13 03:23:31,007 [INFO] Step[3450/4329]: training loss : 0.8833995747566223 TRAIN  loss dict:  {'classification_loss': 0.8833995747566223}
2025-01-13 03:23:43,300 [INFO] Step[3500/4329]: training loss : 0.9047091507911682 TRAIN  loss dict:  {'classification_loss': 0.9047091507911682}
2025-01-13 03:23:55,659 [INFO] Step[3550/4329]: training loss : 0.8803120732307435 TRAIN  loss dict:  {'classification_loss': 0.8803120732307435}
2025-01-13 03:24:09,158 [INFO] Step[3600/4329]: training loss : 0.8829062461853028 TRAIN  loss dict:  {'classification_loss': 0.8829062461853028}
2025-01-13 03:24:22,498 [INFO] Step[3650/4329]: training loss : 0.9104646980762482 TRAIN  loss dict:  {'classification_loss': 0.9104646980762482}
2025-01-13 03:24:34,472 [INFO] Step[3700/4329]: training loss : 0.9243463623523712 TRAIN  loss dict:  {'classification_loss': 0.9243463623523712}
2025-01-13 03:24:46,322 [INFO] Step[3750/4329]: training loss : 0.882311978340149 TRAIN  loss dict:  {'classification_loss': 0.882311978340149}
2025-01-13 03:24:58,061 [INFO] Step[3800/4329]: training loss : 0.8938985836505889 TRAIN  loss dict:  {'classification_loss': 0.8938985836505889}
2025-01-13 03:25:09,728 [INFO] Step[3850/4329]: training loss : 0.8930885636806488 TRAIN  loss dict:  {'classification_loss': 0.8930885636806488}
2025-01-13 03:25:21,340 [INFO] Step[3900/4329]: training loss : 0.909320456981659 TRAIN  loss dict:  {'classification_loss': 0.909320456981659}
2025-01-13 03:25:32,998 [INFO] Step[3950/4329]: training loss : 0.8770177245140076 TRAIN  loss dict:  {'classification_loss': 0.8770177245140076}
2025-01-13 03:25:44,607 [INFO] Step[4000/4329]: training loss : 0.8914515697956085 TRAIN  loss dict:  {'classification_loss': 0.8914515697956085}
2025-01-13 03:25:56,291 [INFO] Step[4050/4329]: training loss : 0.8831019103527069 TRAIN  loss dict:  {'classification_loss': 0.8831019103527069}
2025-01-13 03:26:07,955 [INFO] Step[4100/4329]: training loss : 0.8848841905593872 TRAIN  loss dict:  {'classification_loss': 0.8848841905593872}
2025-01-13 03:26:19,583 [INFO] Step[4150/4329]: training loss : 0.8767301106452942 TRAIN  loss dict:  {'classification_loss': 0.8767301106452942}
2025-01-13 03:26:31,160 [INFO] Step[4200/4329]: training loss : 0.9124245047569275 TRAIN  loss dict:  {'classification_loss': 0.9124245047569275}
2025-01-13 03:26:42,776 [INFO] Step[4250/4329]: training loss : 0.9025089418888093 TRAIN  loss dict:  {'classification_loss': 0.9025089418888093}
2025-01-13 03:26:54,393 [INFO] Step[4300/4329]: training loss : 0.9110310101509094 TRAIN  loss dict:  {'classification_loss': 0.9110310101509094}
2025-01-13 03:28:53,786 [INFO] Label accuracies statistics:
2025-01-13 03:28:53,786 [INFO] {0: 0.6666666666666666, 1: 0.8888888888888888, 2: 0.6666666666666666, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.5833333333333334, 7: 0.5, 8: 0.3333333333333333, 9: 0.8333333333333334, 10: 0.9166666666666666, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.5833333333333334, 14: 0.75, 15: 0.6666666666666666, 16: 0.5833333333333334, 17: 0.6666666666666666, 18: 0.5833333333333334, 19: 0.6666666666666666, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.9166666666666666, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5833333333333334, 28: 0.9166666666666666, 29: 1.0, 30: 0.5833333333333334, 31: 0.75, 32: 0.75, 33: 0.8333333333333334, 34: 0.8333333333333334, 35: 1.0, 36: 0.6666666666666666, 37: 1.0, 38: 1.0, 39: 0.9166666666666666, 40: 0.9166666666666666, 41: 0.5, 42: 0.8333333333333334, 43: 0.9166666666666666, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5833333333333334, 54: 0.5833333333333334, 55: 0.75, 56: 0.9166666666666666, 57: 0.75, 58: 0.6666666666666666, 59: 0.8333333333333334, 60: 0.5, 61: 0.9166666666666666, 62: 0.8333333333333334, 63: 0.5, 64: 1.0, 65: 0.9166666666666666, 66: 0.6666666666666666, 67: 0.8333333333333334, 68: 0.75, 69: 0.6666666666666666, 70: 0.5, 71: 0.5, 72: 1.0, 73: 0.8333333333333334, 74: 0.5833333333333334, 75: 1.0, 76: 0.5833333333333334, 77: 0.75, 78: 0.9166666666666666, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.6666666666666666, 83: 0.5833333333333334, 84: 0.5833333333333334, 85: 0.75, 86: 0.5, 87: 1.0, 88: 0.6666666666666666, 89: 0.5, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.5, 97: 0.75, 98: 0.8333333333333334, 99: 1.0, 100: 0.9166666666666666, 101: 0.8333333333333334, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 0.9166666666666666, 106: 1.0, 107: 0.5833333333333334, 108: 0.8333333333333334, 109: 0.9166666666666666, 110: 0.9166666666666666, 111: 1.0, 112: 0.9166666666666666, 113: 0.5, 114: 0.4166666666666667, 115: 1.0, 116: 0.75, 117: 0.8333333333333334, 118: 0.9166666666666666, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.8333333333333334, 123: 0.9166666666666666, 124: 1.0, 125: 0.8333333333333334, 126: 0.9166666666666666, 127: 0.9166666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.8333333333333334, 132: 0.75, 133: 1.0, 134: 0.9166666666666666, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.8333333333333334, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 0.9166666666666666, 141: 0.8333333333333334, 142: 0.75, 143: 1.0, 144: 0.6666666666666666, 145: 1.0, 146: 1.0, 147: 0.8333333333333334, 148: 0.5833333333333334, 149: 1.0, 150: 0.5, 151: 0.9166666666666666, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 1.0, 156: 0.6666666666666666, 157: 0.75, 158: 0.5555555555555556, 159: 1.0, 160: 0.5833333333333334, 161: 0.9166666666666666, 162: 0.9166666666666666, 163: 1.0, 164: 0.8333333333333334, 165: 0.75, 166: 0.75, 167: 0.8333333333333334, 168: 0.75, 169: 1.0, 170: 0.9166666666666666, 171: 0.75, 172: 1.0, 173: 0.9166666666666666, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.9166666666666666, 178: 0.9166666666666666, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.75, 183: 0.6666666666666666, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.8333333333333334, 190: 0.5833333333333334, 191: 0.5, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.75, 196: 0.9166666666666666, 197: 0.75, 198: 0.8333333333333334}

2025-01-13 03:28:54,729 [INFO] [40] TRAIN  loss: 0.8931827675968539 acc: 0.9952256275989527
2025-01-13 03:28:54,729 [INFO] [40] TRAIN  loss dict: {'classification_loss': 0.8931827675968539}
2025-01-13 03:28:54,730 [INFO] [40] VALIDATION loss: 1.5971873872960456 VALIDATION acc: 0.8034511784511784
2025-01-13 03:28:54,730 [INFO] [40] VALIDATION loss dict: {'classification_loss': 1.5971873872960456}
2025-01-13 03:28:54,730 [INFO] 
2025-01-13 03:29:11,681 [INFO] Step[50/4329]: training loss : 0.8818906676769257 TRAIN  loss dict:  {'classification_loss': 0.8818906676769257}
2025-01-13 03:29:23,271 [INFO] Step[100/4329]: training loss : 0.8815834176540375 TRAIN  loss dict:  {'classification_loss': 0.8815834176540375}
2025-01-13 03:29:34,886 [INFO] Step[150/4329]: training loss : 0.8801394891738892 TRAIN  loss dict:  {'classification_loss': 0.8801394891738892}
2025-01-13 03:29:46,461 [INFO] Step[200/4329]: training loss : 0.8884988260269165 TRAIN  loss dict:  {'classification_loss': 0.8884988260269165}
2025-01-13 03:29:58,100 [INFO] Step[250/4329]: training loss : 0.8885151159763336 TRAIN  loss dict:  {'classification_loss': 0.8885151159763336}
2025-01-13 03:30:09,702 [INFO] Step[300/4329]: training loss : 0.8896060788631439 TRAIN  loss dict:  {'classification_loss': 0.8896060788631439}
2025-01-13 03:30:21,328 [INFO] Step[350/4329]: training loss : 0.8815740442276001 TRAIN  loss dict:  {'classification_loss': 0.8815740442276001}
2025-01-13 03:30:32,961 [INFO] Step[400/4329]: training loss : 0.8802639305591583 TRAIN  loss dict:  {'classification_loss': 0.8802639305591583}
2025-01-13 03:30:44,600 [INFO] Step[450/4329]: training loss : 0.8796490788459778 TRAIN  loss dict:  {'classification_loss': 0.8796490788459778}
2025-01-13 03:30:56,210 [INFO] Step[500/4329]: training loss : 0.886444890499115 TRAIN  loss dict:  {'classification_loss': 0.886444890499115}
2025-01-13 03:31:07,889 [INFO] Step[550/4329]: training loss : 0.8765289914608002 TRAIN  loss dict:  {'classification_loss': 0.8765289914608002}
2025-01-13 03:31:19,501 [INFO] Step[600/4329]: training loss : 0.8814512121677399 TRAIN  loss dict:  {'classification_loss': 0.8814512121677399}
2025-01-13 03:31:31,096 [INFO] Step[650/4329]: training loss : 0.8754206454753876 TRAIN  loss dict:  {'classification_loss': 0.8754206454753876}
2025-01-13 03:31:42,703 [INFO] Step[700/4329]: training loss : 0.8884352290630341 TRAIN  loss dict:  {'classification_loss': 0.8884352290630341}
2025-01-13 03:31:54,340 [INFO] Step[750/4329]: training loss : 0.9048030197620391 TRAIN  loss dict:  {'classification_loss': 0.9048030197620391}
2025-01-13 03:32:05,966 [INFO] Step[800/4329]: training loss : 0.8792445290088654 TRAIN  loss dict:  {'classification_loss': 0.8792445290088654}
2025-01-13 03:32:17,608 [INFO] Step[850/4329]: training loss : 0.9014674592018127 TRAIN  loss dict:  {'classification_loss': 0.9014674592018127}
2025-01-13 03:32:29,234 [INFO] Step[900/4329]: training loss : 0.892792512178421 TRAIN  loss dict:  {'classification_loss': 0.892792512178421}
2025-01-13 03:32:40,855 [INFO] Step[950/4329]: training loss : 0.8877207589149475 TRAIN  loss dict:  {'classification_loss': 0.8877207589149475}
2025-01-13 03:32:52,448 [INFO] Step[1000/4329]: training loss : 0.8786623775959015 TRAIN  loss dict:  {'classification_loss': 0.8786623775959015}
2025-01-13 03:33:04,098 [INFO] Step[1050/4329]: training loss : 0.874318733215332 TRAIN  loss dict:  {'classification_loss': 0.874318733215332}
2025-01-13 03:33:15,751 [INFO] Step[1100/4329]: training loss : 0.9099549400806427 TRAIN  loss dict:  {'classification_loss': 0.9099549400806427}
2025-01-13 03:33:27,373 [INFO] Step[1150/4329]: training loss : 0.8789903080463409 TRAIN  loss dict:  {'classification_loss': 0.8789903080463409}
2025-01-13 03:33:38,967 [INFO] Step[1200/4329]: training loss : 0.8862561714649201 TRAIN  loss dict:  {'classification_loss': 0.8862561714649201}
2025-01-13 03:33:50,606 [INFO] Step[1250/4329]: training loss : 0.8891234481334687 TRAIN  loss dict:  {'classification_loss': 0.8891234481334687}
2025-01-13 03:34:02,212 [INFO] Step[1300/4329]: training loss : 0.8787668514251709 TRAIN  loss dict:  {'classification_loss': 0.8787668514251709}
2025-01-13 03:34:13,834 [INFO] Step[1350/4329]: training loss : 0.8853488302230835 TRAIN  loss dict:  {'classification_loss': 0.8853488302230835}
2025-01-13 03:34:25,432 [INFO] Step[1400/4329]: training loss : 0.8727150678634643 TRAIN  loss dict:  {'classification_loss': 0.8727150678634643}
2025-01-13 03:34:37,061 [INFO] Step[1450/4329]: training loss : 0.8776193535327912 TRAIN  loss dict:  {'classification_loss': 0.8776193535327912}
2025-01-13 03:34:48,707 [INFO] Step[1500/4329]: training loss : 0.8845310151576996 TRAIN  loss dict:  {'classification_loss': 0.8845310151576996}
2025-01-13 03:35:00,358 [INFO] Step[1550/4329]: training loss : 0.8821884322166443 TRAIN  loss dict:  {'classification_loss': 0.8821884322166443}
2025-01-13 03:35:11,916 [INFO] Step[1600/4329]: training loss : 0.913613828420639 TRAIN  loss dict:  {'classification_loss': 0.913613828420639}
2025-01-13 03:35:23,536 [INFO] Step[1650/4329]: training loss : 0.8765505647659302 TRAIN  loss dict:  {'classification_loss': 0.8765505647659302}
2025-01-13 03:35:35,142 [INFO] Step[1700/4329]: training loss : 0.8791135466098785 TRAIN  loss dict:  {'classification_loss': 0.8791135466098785}
2025-01-13 03:35:46,898 [INFO] Step[1750/4329]: training loss : 0.885486011505127 TRAIN  loss dict:  {'classification_loss': 0.885486011505127}
2025-01-13 03:35:59,338 [INFO] Step[1800/4329]: training loss : 0.8789701247215271 TRAIN  loss dict:  {'classification_loss': 0.8789701247215271}
2025-01-13 03:36:11,519 [INFO] Step[1850/4329]: training loss : 0.8749282193183899 TRAIN  loss dict:  {'classification_loss': 0.8749282193183899}
2025-01-13 03:36:24,404 [INFO] Step[1900/4329]: training loss : 0.8892238438129425 TRAIN  loss dict:  {'classification_loss': 0.8892238438129425}
2025-01-13 03:36:37,594 [INFO] Step[1950/4329]: training loss : 0.8881879556179046 TRAIN  loss dict:  {'classification_loss': 0.8881879556179046}
2025-01-13 03:36:49,981 [INFO] Step[2000/4329]: training loss : 0.8768190371990204 TRAIN  loss dict:  {'classification_loss': 0.8768190371990204}
2025-01-13 03:37:01,912 [INFO] Step[2050/4329]: training loss : 0.8847723245620728 TRAIN  loss dict:  {'classification_loss': 0.8847723245620728}
2025-01-13 03:37:13,755 [INFO] Step[2100/4329]: training loss : 0.8787972104549407 TRAIN  loss dict:  {'classification_loss': 0.8787972104549407}
2025-01-13 03:37:25,417 [INFO] Step[2150/4329]: training loss : 0.9001431119441986 TRAIN  loss dict:  {'classification_loss': 0.9001431119441986}
2025-01-13 03:37:37,066 [INFO] Step[2200/4329]: training loss : 0.8806840109825135 TRAIN  loss dict:  {'classification_loss': 0.8806840109825135}
2025-01-13 03:37:48,696 [INFO] Step[2250/4329]: training loss : 0.8915329658985138 TRAIN  loss dict:  {'classification_loss': 0.8915329658985138}
2025-01-13 03:38:00,316 [INFO] Step[2300/4329]: training loss : 0.8844308435916901 TRAIN  loss dict:  {'classification_loss': 0.8844308435916901}
2025-01-13 03:38:11,969 [INFO] Step[2350/4329]: training loss : 0.8769618606567383 TRAIN  loss dict:  {'classification_loss': 0.8769618606567383}
2025-01-13 03:38:23,573 [INFO] Step[2400/4329]: training loss : 0.8768883776664734 TRAIN  loss dict:  {'classification_loss': 0.8768883776664734}
2025-01-13 03:38:35,166 [INFO] Step[2450/4329]: training loss : 0.8937529098987579 TRAIN  loss dict:  {'classification_loss': 0.8937529098987579}
2025-01-13 03:38:46,739 [INFO] Step[2500/4329]: training loss : 0.8755658555030823 TRAIN  loss dict:  {'classification_loss': 0.8755658555030823}
2025-01-13 03:38:58,322 [INFO] Step[2550/4329]: training loss : 0.8854255402088165 TRAIN  loss dict:  {'classification_loss': 0.8854255402088165}
2025-01-13 03:39:09,959 [INFO] Step[2600/4329]: training loss : 0.8860360407829284 TRAIN  loss dict:  {'classification_loss': 0.8860360407829284}
2025-01-13 03:39:21,630 [INFO] Step[2650/4329]: training loss : 0.8819494640827179 TRAIN  loss dict:  {'classification_loss': 0.8819494640827179}
2025-01-13 03:39:33,242 [INFO] Step[2700/4329]: training loss : 0.8849210584163666 TRAIN  loss dict:  {'classification_loss': 0.8849210584163666}
2025-01-13 03:39:44,880 [INFO] Step[2750/4329]: training loss : 0.8911540067195892 TRAIN  loss dict:  {'classification_loss': 0.8911540067195892}
2025-01-13 03:39:56,510 [INFO] Step[2800/4329]: training loss : 0.8779898512363434 TRAIN  loss dict:  {'classification_loss': 0.8779898512363434}
2025-01-13 03:40:08,190 [INFO] Step[2850/4329]: training loss : 0.8726502645015717 TRAIN  loss dict:  {'classification_loss': 0.8726502645015717}
2025-01-13 03:40:19,789 [INFO] Step[2900/4329]: training loss : 0.8745062863826751 TRAIN  loss dict:  {'classification_loss': 0.8745062863826751}
2025-01-13 03:40:31,402 [INFO] Step[2950/4329]: training loss : 0.8726840782165527 TRAIN  loss dict:  {'classification_loss': 0.8726840782165527}
2025-01-13 03:40:43,040 [INFO] Step[3000/4329]: training loss : 0.8759865605831146 TRAIN  loss dict:  {'classification_loss': 0.8759865605831146}
2025-01-13 03:40:54,672 [INFO] Step[3050/4329]: training loss : 0.8831617212295533 TRAIN  loss dict:  {'classification_loss': 0.8831617212295533}
2025-01-13 03:41:06,277 [INFO] Step[3100/4329]: training loss : 0.8845095074176789 TRAIN  loss dict:  {'classification_loss': 0.8845095074176789}
2025-01-13 03:41:17,935 [INFO] Step[3150/4329]: training loss : 0.8823314654827118 TRAIN  loss dict:  {'classification_loss': 0.8823314654827118}
2025-01-13 03:41:29,576 [INFO] Step[3200/4329]: training loss : 0.8982287979125977 TRAIN  loss dict:  {'classification_loss': 0.8982287979125977}
2025-01-13 03:41:41,258 [INFO] Step[3250/4329]: training loss : 0.8867085337638855 TRAIN  loss dict:  {'classification_loss': 0.8867085337638855}
2025-01-13 03:41:52,904 [INFO] Step[3300/4329]: training loss : 0.8839604830741883 TRAIN  loss dict:  {'classification_loss': 0.8839604830741883}
2025-01-13 03:42:04,536 [INFO] Step[3350/4329]: training loss : 0.8770370554924011 TRAIN  loss dict:  {'classification_loss': 0.8770370554924011}
2025-01-13 03:42:16,190 [INFO] Step[3400/4329]: training loss : 0.8950678145885468 TRAIN  loss dict:  {'classification_loss': 0.8950678145885468}
2025-01-13 03:42:27,810 [INFO] Step[3450/4329]: training loss : 0.8822212564945221 TRAIN  loss dict:  {'classification_loss': 0.8822212564945221}
2025-01-13 03:42:39,455 [INFO] Step[3500/4329]: training loss : 0.8818485260009765 TRAIN  loss dict:  {'classification_loss': 0.8818485260009765}
2025-01-13 03:42:51,053 [INFO] Step[3550/4329]: training loss : 0.8731695973873138 TRAIN  loss dict:  {'classification_loss': 0.8731695973873138}
2025-01-13 03:43:02,670 [INFO] Step[3600/4329]: training loss : 0.8756449973583221 TRAIN  loss dict:  {'classification_loss': 0.8756449973583221}
2025-01-13 03:43:14,298 [INFO] Step[3650/4329]: training loss : 0.9033039081096649 TRAIN  loss dict:  {'classification_loss': 0.9033039081096649}
2025-01-13 03:43:25,899 [INFO] Step[3700/4329]: training loss : 0.8837567114830017 TRAIN  loss dict:  {'classification_loss': 0.8837567114830017}
2025-01-13 03:43:37,513 [INFO] Step[3750/4329]: training loss : 0.8945745146274566 TRAIN  loss dict:  {'classification_loss': 0.8945745146274566}
2025-01-13 03:43:49,110 [INFO] Step[3800/4329]: training loss : 0.8832638764381409 TRAIN  loss dict:  {'classification_loss': 0.8832638764381409}
2025-01-13 03:44:00,743 [INFO] Step[3850/4329]: training loss : 0.8872591519355774 TRAIN  loss dict:  {'classification_loss': 0.8872591519355774}
2025-01-13 03:44:12,305 [INFO] Step[3900/4329]: training loss : 0.8726223742961884 TRAIN  loss dict:  {'classification_loss': 0.8726223742961884}
2025-01-13 03:44:23,957 [INFO] Step[3950/4329]: training loss : 0.8889741933345795 TRAIN  loss dict:  {'classification_loss': 0.8889741933345795}
2025-01-13 03:44:35,583 [INFO] Step[4000/4329]: training loss : 0.8774290609359742 TRAIN  loss dict:  {'classification_loss': 0.8774290609359742}
2025-01-13 03:44:47,239 [INFO] Step[4050/4329]: training loss : 0.8788490104675293 TRAIN  loss dict:  {'classification_loss': 0.8788490104675293}
2025-01-13 03:44:58,836 [INFO] Step[4100/4329]: training loss : 0.9005776643753052 TRAIN  loss dict:  {'classification_loss': 0.9005776643753052}
2025-01-13 03:45:10,444 [INFO] Step[4150/4329]: training loss : 0.8934577548503876 TRAIN  loss dict:  {'classification_loss': 0.8934577548503876}
2025-01-13 03:45:22,055 [INFO] Step[4200/4329]: training loss : 0.8729852652549743 TRAIN  loss dict:  {'classification_loss': 0.8729852652549743}
2025-01-13 03:45:33,681 [INFO] Step[4250/4329]: training loss : 0.8880632436275482 TRAIN  loss dict:  {'classification_loss': 0.8880632436275482}
2025-01-13 03:45:45,321 [INFO] Step[4300/4329]: training loss : 0.9016836142539978 TRAIN  loss dict:  {'classification_loss': 0.9016836142539978}
2025-01-13 03:47:42,949 [INFO] Label accuracies statistics:
2025-01-13 03:47:42,949 [INFO] {0: 0.4444444444444444, 1: 1.0, 2: 0.6666666666666666, 3: 0.75, 4: 0.5, 5: 0.9166666666666666, 6: 0.5833333333333334, 7: 0.5833333333333334, 8: 0.5, 9: 0.8333333333333334, 10: 1.0, 11: 0.9166666666666666, 12: 0.25, 13: 0.4166666666666667, 14: 0.5833333333333334, 15: 0.6666666666666666, 16: 0.5, 17: 0.3333333333333333, 18: 0.5833333333333334, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 0.9166666666666666, 25: 0.6666666666666666, 26: 0.8333333333333334, 27: 0.5833333333333334, 28: 1.0, 29: 1.0, 30: 0.6666666666666666, 31: 0.9166666666666666, 32: 0.75, 33: 0.9166666666666666, 34: 1.0, 35: 1.0, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.9166666666666666, 41: 0.5, 42: 0.8333333333333334, 43: 0.9166666666666666, 44: 0.6666666666666666, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.6666666666666666, 51: 0.8333333333333334, 52: 1.0, 53: 0.6666666666666666, 54: 0.5, 55: 0.6666666666666666, 56: 0.8333333333333334, 57: 0.75, 58: 0.6666666666666666, 59: 0.9166666666666666, 60: 0.6666666666666666, 61: 0.9166666666666666, 62: 0.75, 63: 0.4166666666666667, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.8333333333333334, 68: 0.8333333333333334, 69: 0.75, 70: 0.3333333333333333, 71: 0.4166666666666667, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.6666666666666666, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.8333333333333334, 83: 0.75, 84: 0.3333333333333333, 85: 0.75, 86: 0.75, 87: 0.9166666666666666, 88: 0.5833333333333334, 89: 0.6666666666666666, 90: 0.9166666666666666, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.5, 97: 0.75, 98: 0.8333333333333334, 99: 1.0, 100: 0.8333333333333334, 101: 0.9166666666666666, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 0.9166666666666666, 106: 1.0, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 0.9166666666666666, 111: 0.9166666666666666, 112: 0.9166666666666666, 113: 0.4166666666666667, 114: 0.5833333333333334, 115: 1.0, 116: 0.8333333333333334, 117: 0.8333333333333334, 118: 1.0, 119: 0.9166666666666666, 120: 0.75, 121: 0.8333333333333334, 122: 0.8333333333333334, 123: 0.8333333333333334, 124: 1.0, 125: 1.0, 126: 0.9166666666666666, 127: 0.75, 128: 1.0, 129: 0.8333333333333334, 130: 0.75, 131: 0.8333333333333334, 132: 0.8333333333333334, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.9166666666666666, 138: 1.0, 139: 0.9166666666666666, 140: 0.9166666666666666, 141: 0.9166666666666666, 142: 0.9166666666666666, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.5, 151: 0.8333333333333334, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.9166666666666666, 156: 0.6666666666666666, 157: 0.6666666666666666, 158: 0.7777777777777778, 159: 0.9166666666666666, 160: 0.4166666666666667, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.8333333333333334, 166: 0.6666666666666666, 167: 0.8333333333333334, 168: 0.8333333333333334, 169: 0.9166666666666666, 170: 1.0, 171: 0.6666666666666666, 172: 1.0, 173: 0.9166666666666666, 174: 1.0, 175: 0.9166666666666666, 176: 1.0, 177: 0.9166666666666666, 178: 0.9166666666666666, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.75, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5833333333333334, 189: 1.0, 190: 0.5833333333333334, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.75, 196: 0.9166666666666666, 197: 0.6666666666666666, 198: 0.6666666666666666}

2025-01-13 03:47:44,798 [INFO] [41] TRAIN  loss: 0.8844208126118784 acc: 0.9973047897736024
2025-01-13 03:47:44,798 [INFO] [41] TRAIN  loss dict: {'classification_loss': 0.8844208126118784}
2025-01-13 03:47:44,799 [INFO] [41] VALIDATION loss: 1.5792748172475835 VALIDATION acc: 0.8106060606060606
2025-01-13 03:47:44,799 [INFO] [41] VALIDATION loss dict: {'classification_loss': 1.5792748172475835}
2025-01-13 03:47:44,799 [INFO] 
2025-01-13 03:48:01,630 [INFO] Step[50/4329]: training loss : 0.8775689136981965 TRAIN  loss dict:  {'classification_loss': 0.8775689136981965}
2025-01-13 03:48:13,412 [INFO] Step[100/4329]: training loss : 0.8756927394866943 TRAIN  loss dict:  {'classification_loss': 0.8756927394866943}
2025-01-13 03:48:25,843 [INFO] Step[150/4329]: training loss : 0.8755992829799653 TRAIN  loss dict:  {'classification_loss': 0.8755992829799653}
2025-01-13 03:48:38,126 [INFO] Step[200/4329]: training loss : 0.8783766996860504 TRAIN  loss dict:  {'classification_loss': 0.8783766996860504}
2025-01-13 03:48:51,542 [INFO] Step[250/4329]: training loss : 0.8856469595432281 TRAIN  loss dict:  {'classification_loss': 0.8856469595432281}
2025-01-13 03:49:05,831 [INFO] Step[300/4329]: training loss : 0.8823436033725739 TRAIN  loss dict:  {'classification_loss': 0.8823436033725739}
2025-01-13 03:49:17,874 [INFO] Step[350/4329]: training loss : 0.873807612657547 TRAIN  loss dict:  {'classification_loss': 0.873807612657547}
2025-01-13 03:49:29,771 [INFO] Step[400/4329]: training loss : 0.8705140817165374 TRAIN  loss dict:  {'classification_loss': 0.8705140817165374}
2025-01-13 03:49:41,517 [INFO] Step[450/4329]: training loss : 0.8701905131340026 TRAIN  loss dict:  {'classification_loss': 0.8701905131340026}
2025-01-13 03:49:53,108 [INFO] Step[500/4329]: training loss : 0.8718423891067505 TRAIN  loss dict:  {'classification_loss': 0.8718423891067505}
2025-01-13 03:50:04,723 [INFO] Step[550/4329]: training loss : 0.8704584801197052 TRAIN  loss dict:  {'classification_loss': 0.8704584801197052}
2025-01-13 03:50:16,347 [INFO] Step[600/4329]: training loss : 0.8882018208503724 TRAIN  loss dict:  {'classification_loss': 0.8882018208503724}
2025-01-13 03:50:27,960 [INFO] Step[650/4329]: training loss : 0.8695020556449891 TRAIN  loss dict:  {'classification_loss': 0.8695020556449891}
2025-01-13 03:50:39,605 [INFO] Step[700/4329]: training loss : 0.8767704784870147 TRAIN  loss dict:  {'classification_loss': 0.8767704784870147}
2025-01-13 03:50:51,211 [INFO] Step[750/4329]: training loss : 0.8715461266040802 TRAIN  loss dict:  {'classification_loss': 0.8715461266040802}
2025-01-13 03:51:02,802 [INFO] Step[800/4329]: training loss : 0.8705812621116639 TRAIN  loss dict:  {'classification_loss': 0.8705812621116639}
2025-01-13 03:51:14,420 [INFO] Step[850/4329]: training loss : 0.8717030560970307 TRAIN  loss dict:  {'classification_loss': 0.8717030560970307}
2025-01-13 03:51:26,009 [INFO] Step[900/4329]: training loss : 0.8711793792247772 TRAIN  loss dict:  {'classification_loss': 0.8711793792247772}
2025-01-13 03:51:37,660 [INFO] Step[950/4329]: training loss : 0.8740647518634796 TRAIN  loss dict:  {'classification_loss': 0.8740647518634796}
2025-01-13 03:51:49,295 [INFO] Step[1000/4329]: training loss : 0.8756037473678588 TRAIN  loss dict:  {'classification_loss': 0.8756037473678588}
2025-01-13 03:52:00,930 [INFO] Step[1050/4329]: training loss : 0.8742166614532471 TRAIN  loss dict:  {'classification_loss': 0.8742166614532471}
2025-01-13 03:52:12,566 [INFO] Step[1100/4329]: training loss : 0.8895442473888397 TRAIN  loss dict:  {'classification_loss': 0.8895442473888397}
2025-01-13 03:52:24,196 [INFO] Step[1150/4329]: training loss : 0.8710850834846496 TRAIN  loss dict:  {'classification_loss': 0.8710850834846496}
2025-01-13 03:52:35,794 [INFO] Step[1200/4329]: training loss : 0.8764080882072449 TRAIN  loss dict:  {'classification_loss': 0.8764080882072449}
2025-01-13 03:52:47,406 [INFO] Step[1250/4329]: training loss : 0.8924384474754333 TRAIN  loss dict:  {'classification_loss': 0.8924384474754333}
2025-01-13 03:52:59,006 [INFO] Step[1300/4329]: training loss : 0.872552421092987 TRAIN  loss dict:  {'classification_loss': 0.872552421092987}
2025-01-13 03:53:10,684 [INFO] Step[1350/4329]: training loss : 0.8909012532234192 TRAIN  loss dict:  {'classification_loss': 0.8909012532234192}
2025-01-13 03:53:22,300 [INFO] Step[1400/4329]: training loss : 0.8784343731403351 TRAIN  loss dict:  {'classification_loss': 0.8784343731403351}
2025-01-13 03:53:33,905 [INFO] Step[1450/4329]: training loss : 0.879987667798996 TRAIN  loss dict:  {'classification_loss': 0.879987667798996}
2025-01-13 03:53:45,473 [INFO] Step[1500/4329]: training loss : 0.8744113993644714 TRAIN  loss dict:  {'classification_loss': 0.8744113993644714}
2025-01-13 03:53:57,071 [INFO] Step[1550/4329]: training loss : 0.8869734418392181 TRAIN  loss dict:  {'classification_loss': 0.8869734418392181}
2025-01-13 03:54:08,693 [INFO] Step[1600/4329]: training loss : 0.8712008666992187 TRAIN  loss dict:  {'classification_loss': 0.8712008666992187}
2025-01-13 03:54:20,295 [INFO] Step[1650/4329]: training loss : 0.8759781181812286 TRAIN  loss dict:  {'classification_loss': 0.8759781181812286}
2025-01-13 03:54:31,944 [INFO] Step[1700/4329]: training loss : 0.8939297091960907 TRAIN  loss dict:  {'classification_loss': 0.8939297091960907}
2025-01-13 03:54:43,575 [INFO] Step[1750/4329]: training loss : 0.8703532552719117 TRAIN  loss dict:  {'classification_loss': 0.8703532552719117}
2025-01-13 03:54:55,188 [INFO] Step[1800/4329]: training loss : 0.8679423820972443 TRAIN  loss dict:  {'classification_loss': 0.8679423820972443}
2025-01-13 03:55:06,813 [INFO] Step[1850/4329]: training loss : 0.8824669754505158 TRAIN  loss dict:  {'classification_loss': 0.8824669754505158}
2025-01-13 03:55:18,377 [INFO] Step[1900/4329]: training loss : 0.8802228355407715 TRAIN  loss dict:  {'classification_loss': 0.8802228355407715}
2025-01-13 03:55:29,986 [INFO] Step[1950/4329]: training loss : 0.887751739025116 TRAIN  loss dict:  {'classification_loss': 0.887751739025116}
2025-01-13 03:55:41,592 [INFO] Step[2000/4329]: training loss : 0.8760230779647827 TRAIN  loss dict:  {'classification_loss': 0.8760230779647827}
2025-01-13 03:55:53,173 [INFO] Step[2050/4329]: training loss : 0.873730617761612 TRAIN  loss dict:  {'classification_loss': 0.873730617761612}
2025-01-13 03:56:04,788 [INFO] Step[2100/4329]: training loss : 0.8713264739513398 TRAIN  loss dict:  {'classification_loss': 0.8713264739513398}
2025-01-13 03:56:16,389 [INFO] Step[2150/4329]: training loss : 0.8751500964164733 TRAIN  loss dict:  {'classification_loss': 0.8751500964164733}
2025-01-13 03:56:28,012 [INFO] Step[2200/4329]: training loss : 0.9051306009292602 TRAIN  loss dict:  {'classification_loss': 0.9051306009292602}
2025-01-13 03:56:39,604 [INFO] Step[2250/4329]: training loss : 0.877451012134552 TRAIN  loss dict:  {'classification_loss': 0.877451012134552}
2025-01-13 03:56:51,201 [INFO] Step[2300/4329]: training loss : 0.8740611183643341 TRAIN  loss dict:  {'classification_loss': 0.8740611183643341}
2025-01-13 03:57:02,821 [INFO] Step[2350/4329]: training loss : 0.8853199899196624 TRAIN  loss dict:  {'classification_loss': 0.8853199899196624}
2025-01-13 03:57:14,389 [INFO] Step[2400/4329]: training loss : 0.87613889336586 TRAIN  loss dict:  {'classification_loss': 0.87613889336586}
2025-01-13 03:57:26,002 [INFO] Step[2450/4329]: training loss : 0.8815080642700195 TRAIN  loss dict:  {'classification_loss': 0.8815080642700195}
2025-01-13 03:57:37,606 [INFO] Step[2500/4329]: training loss : 0.8903046786785126 TRAIN  loss dict:  {'classification_loss': 0.8903046786785126}
2025-01-13 03:57:49,195 [INFO] Step[2550/4329]: training loss : 0.8893182182312012 TRAIN  loss dict:  {'classification_loss': 0.8893182182312012}
2025-01-13 03:58:00,788 [INFO] Step[2600/4329]: training loss : 0.8762142050266266 TRAIN  loss dict:  {'classification_loss': 0.8762142050266266}
2025-01-13 03:58:12,412 [INFO] Step[2650/4329]: training loss : 0.8762867140769959 TRAIN  loss dict:  {'classification_loss': 0.8762867140769959}
2025-01-13 03:58:24,037 [INFO] Step[2700/4329]: training loss : 0.8722683966159821 TRAIN  loss dict:  {'classification_loss': 0.8722683966159821}
2025-01-13 03:58:35,640 [INFO] Step[2750/4329]: training loss : 0.9003848111629487 TRAIN  loss dict:  {'classification_loss': 0.9003848111629487}
2025-01-13 03:58:47,228 [INFO] Step[2800/4329]: training loss : 0.9178124463558197 TRAIN  loss dict:  {'classification_loss': 0.9178124463558197}
2025-01-13 03:58:58,854 [INFO] Step[2850/4329]: training loss : 0.8880001723766326 TRAIN  loss dict:  {'classification_loss': 0.8880001723766326}
2025-01-13 03:59:10,450 [INFO] Step[2900/4329]: training loss : 0.9011427879333496 TRAIN  loss dict:  {'classification_loss': 0.9011427879333496}
2025-01-13 03:59:22,077 [INFO] Step[2950/4329]: training loss : 0.8832723104953766 TRAIN  loss dict:  {'classification_loss': 0.8832723104953766}
2025-01-13 03:59:33,701 [INFO] Step[3000/4329]: training loss : 0.8728947985172272 TRAIN  loss dict:  {'classification_loss': 0.8728947985172272}
2025-01-13 03:59:45,323 [INFO] Step[3050/4329]: training loss : 0.8826890957355499 TRAIN  loss dict:  {'classification_loss': 0.8826890957355499}
2025-01-13 03:59:56,923 [INFO] Step[3100/4329]: training loss : 0.8735590779781341 TRAIN  loss dict:  {'classification_loss': 0.8735590779781341}
2025-01-13 04:00:08,554 [INFO] Step[3150/4329]: training loss : 0.8825715756416321 TRAIN  loss dict:  {'classification_loss': 0.8825715756416321}
2025-01-13 04:00:20,191 [INFO] Step[3200/4329]: training loss : 0.8824229383468628 TRAIN  loss dict:  {'classification_loss': 0.8824229383468628}
2025-01-13 04:00:32,189 [INFO] Step[3250/4329]: training loss : 0.8800848817825317 TRAIN  loss dict:  {'classification_loss': 0.8800848817825317}
2025-01-13 04:00:44,442 [INFO] Step[3300/4329]: training loss : 0.8746378004550934 TRAIN  loss dict:  {'classification_loss': 0.8746378004550934}
2025-01-13 04:00:57,108 [INFO] Step[3350/4329]: training loss : 0.88062295794487 TRAIN  loss dict:  {'classification_loss': 0.88062295794487}
2025-01-13 04:01:10,430 [INFO] Step[3400/4329]: training loss : 0.8841695261001586 TRAIN  loss dict:  {'classification_loss': 0.8841695261001586}
2025-01-13 04:01:24,677 [INFO] Step[3450/4329]: training loss : 0.8851271843910218 TRAIN  loss dict:  {'classification_loss': 0.8851271843910218}
2025-01-13 04:01:36,646 [INFO] Step[3500/4329]: training loss : 0.8824310696125031 TRAIN  loss dict:  {'classification_loss': 0.8824310696125031}
2025-01-13 04:01:48,519 [INFO] Step[3550/4329]: training loss : 0.8747683763504028 TRAIN  loss dict:  {'classification_loss': 0.8747683763504028}
2025-01-13 04:02:00,176 [INFO] Step[3600/4329]: training loss : 0.8906453669071197 TRAIN  loss dict:  {'classification_loss': 0.8906453669071197}
2025-01-13 04:02:11,811 [INFO] Step[3650/4329]: training loss : 0.8807613384723664 TRAIN  loss dict:  {'classification_loss': 0.8807613384723664}
2025-01-13 04:02:23,411 [INFO] Step[3700/4329]: training loss : 0.8806686103343964 TRAIN  loss dict:  {'classification_loss': 0.8806686103343964}
2025-01-13 04:02:35,011 [INFO] Step[3750/4329]: training loss : 0.8757560074329376 TRAIN  loss dict:  {'classification_loss': 0.8757560074329376}
2025-01-13 04:02:46,601 [INFO] Step[3800/4329]: training loss : 0.8779327499866486 TRAIN  loss dict:  {'classification_loss': 0.8779327499866486}
2025-01-13 04:02:58,193 [INFO] Step[3850/4329]: training loss : 0.8716470432281495 TRAIN  loss dict:  {'classification_loss': 0.8716470432281495}
2025-01-13 04:03:09,779 [INFO] Step[3900/4329]: training loss : 0.878027845621109 TRAIN  loss dict:  {'classification_loss': 0.878027845621109}
2025-01-13 04:03:21,416 [INFO] Step[3950/4329]: training loss : 0.8719612205028534 TRAIN  loss dict:  {'classification_loss': 0.8719612205028534}
2025-01-13 04:03:32,990 [INFO] Step[4000/4329]: training loss : 0.8801790022850037 TRAIN  loss dict:  {'classification_loss': 0.8801790022850037}
2025-01-13 04:03:44,580 [INFO] Step[4050/4329]: training loss : 0.9042045664787293 TRAIN  loss dict:  {'classification_loss': 0.9042045664787293}
2025-01-13 04:03:56,234 [INFO] Step[4100/4329]: training loss : 0.8898157155513764 TRAIN  loss dict:  {'classification_loss': 0.8898157155513764}
2025-01-13 04:04:07,824 [INFO] Step[4150/4329]: training loss : 0.8978064489364624 TRAIN  loss dict:  {'classification_loss': 0.8978064489364624}
2025-01-13 04:04:19,471 [INFO] Step[4200/4329]: training loss : 0.8924347066879272 TRAIN  loss dict:  {'classification_loss': 0.8924347066879272}
2025-01-13 04:04:31,064 [INFO] Step[4250/4329]: training loss : 0.8791097295284271 TRAIN  loss dict:  {'classification_loss': 0.8791097295284271}
2025-01-13 04:04:42,665 [INFO] Step[4300/4329]: training loss : 0.8758568429946899 TRAIN  loss dict:  {'classification_loss': 0.8758568429946899}
2025-01-13 04:06:43,161 [INFO] Label accuracies statistics:
2025-01-13 04:06:43,162 [INFO] {0: 0.7777777777777778, 1: 1.0, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.25, 5: 0.9166666666666666, 6: 0.5, 7: 0.6666666666666666, 8: 0.5833333333333334, 9: 0.8333333333333334, 10: 1.0, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.5833333333333334, 14: 0.6666666666666666, 15: 0.6666666666666666, 16: 0.5833333333333334, 17: 0.5, 18: 0.6666666666666666, 19: 0.6666666666666666, 20: 0.5, 21: 0.6666666666666666, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.6666666666666666, 26: 0.75, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.5833333333333334, 31: 0.8333333333333334, 32: 0.75, 33: 0.9166666666666666, 34: 1.0, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 0.9166666666666666, 40: 0.8333333333333334, 41: 0.5, 42: 0.8333333333333334, 43: 0.9166666666666666, 44: 0.6666666666666666, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.4166666666666667, 55: 0.6666666666666666, 56: 0.9166666666666666, 57: 0.75, 58: 0.5833333333333334, 59: 0.8333333333333334, 60: 0.6666666666666666, 61: 0.9166666666666666, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.8333333333333334, 68: 0.8333333333333334, 69: 0.75, 70: 0.5, 71: 0.4166666666666667, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.5833333333333334, 75: 1.0, 76: 0.6666666666666666, 77: 0.5833333333333334, 78: 0.9166666666666666, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5833333333333334, 85: 0.75, 86: 0.5833333333333334, 87: 0.8333333333333334, 88: 0.8333333333333334, 89: 0.5833333333333334, 90: 0.5833333333333334, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.4166666666666667, 97: 0.75, 98: 0.8333333333333334, 99: 1.0, 100: 0.8333333333333334, 101: 0.9166666666666666, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 0.9166666666666666, 106: 1.0, 107: 0.6666666666666666, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 0.9166666666666666, 111: 1.0, 112: 0.9166666666666666, 113: 0.5833333333333334, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.9166666666666666, 118: 1.0, 119: 0.6666666666666666, 120: 0.8333333333333334, 121: 0.8333333333333334, 122: 0.9166666666666666, 123: 0.8333333333333334, 124: 0.9166666666666666, 125: 0.9166666666666666, 126: 1.0, 127: 0.8333333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.8333333333333334, 132: 0.5833333333333334, 133: 1.0, 134: 0.6666666666666666, 135: 1.0, 136: 0.9166666666666666, 137: 0.8333333333333334, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 0.9166666666666666, 142: 0.75, 143: 1.0, 144: 0.6666666666666666, 145: 1.0, 146: 1.0, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.4166666666666667, 151: 0.9166666666666666, 152: 1.0, 153: 0.75, 154: 0.8333333333333334, 155: 0.9166666666666666, 156: 0.8333333333333334, 157: 0.8333333333333334, 158: 0.6666666666666666, 159: 1.0, 160: 0.25, 161: 0.9166666666666666, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.9166666666666666, 166: 0.6666666666666666, 167: 0.6666666666666666, 168: 0.75, 169: 0.9166666666666666, 170: 1.0, 171: 0.6666666666666666, 172: 1.0, 173: 0.75, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 0.9166666666666666, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.9166666666666666, 181: 0.8333333333333334, 182: 0.75, 183: 0.9166666666666666, 184: 0.5833333333333334, 185: 1.0, 186: 0.8333333333333334, 187: 0.9166666666666666, 188: 0.5833333333333334, 189: 1.0, 190: 0.6666666666666666, 191: 0.6666666666666666, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.9166666666666666, 198: 0.5833333333333334}

2025-01-13 04:06:43,164 [INFO] [42] TRAIN  loss: 0.8803000799170485 acc: 0.9976898198059448
2025-01-13 04:06:43,164 [INFO] [42] TRAIN  loss dict: {'classification_loss': 0.8803000799170485}
2025-01-13 04:06:43,164 [INFO] [42] VALIDATION loss: 1.619263431565328 VALIDATION acc: 0.8038720538720538
2025-01-13 04:06:43,164 [INFO] [42] VALIDATION loss dict: {'classification_loss': 1.619263431565328}
2025-01-13 04:06:43,164 [INFO] 
2025-01-13 04:07:00,857 [INFO] Step[50/4329]: training loss : 0.8757259047031403 TRAIN  loss dict:  {'classification_loss': 0.8757259047031403}
2025-01-13 04:07:12,415 [INFO] Step[100/4329]: training loss : 0.8699209988117218 TRAIN  loss dict:  {'classification_loss': 0.8699209988117218}
2025-01-13 04:07:24,021 [INFO] Step[150/4329]: training loss : 0.8715828669071197 TRAIN  loss dict:  {'classification_loss': 0.8715828669071197}
2025-01-13 04:07:35,657 [INFO] Step[200/4329]: training loss : 0.8768508303165435 TRAIN  loss dict:  {'classification_loss': 0.8768508303165435}
2025-01-13 04:07:47,300 [INFO] Step[250/4329]: training loss : 0.8772040712833404 TRAIN  loss dict:  {'classification_loss': 0.8772040712833404}
2025-01-13 04:07:58,941 [INFO] Step[300/4329]: training loss : 0.8910397505760193 TRAIN  loss dict:  {'classification_loss': 0.8910397505760193}
2025-01-13 04:08:10,589 [INFO] Step[350/4329]: training loss : 0.8757009947299957 TRAIN  loss dict:  {'classification_loss': 0.8757009947299957}
2025-01-13 04:08:22,253 [INFO] Step[400/4329]: training loss : 0.8844793379306793 TRAIN  loss dict:  {'classification_loss': 0.8844793379306793}
2025-01-13 04:08:33,896 [INFO] Step[450/4329]: training loss : 0.8909279906749725 TRAIN  loss dict:  {'classification_loss': 0.8909279906749725}
2025-01-13 04:08:45,557 [INFO] Step[500/4329]: training loss : 0.8695599591732025 TRAIN  loss dict:  {'classification_loss': 0.8695599591732025}
2025-01-13 04:08:57,202 [INFO] Step[550/4329]: training loss : 0.8722099912166595 TRAIN  loss dict:  {'classification_loss': 0.8722099912166595}
2025-01-13 04:09:08,845 [INFO] Step[600/4329]: training loss : 0.8791528367996215 TRAIN  loss dict:  {'classification_loss': 0.8791528367996215}
2025-01-13 04:09:20,489 [INFO] Step[650/4329]: training loss : 0.8765105736255646 TRAIN  loss dict:  {'classification_loss': 0.8765105736255646}
2025-01-13 04:09:32,161 [INFO] Step[700/4329]: training loss : 0.8721869158744812 TRAIN  loss dict:  {'classification_loss': 0.8721869158744812}
2025-01-13 04:09:43,787 [INFO] Step[750/4329]: training loss : 0.8750668561458588 TRAIN  loss dict:  {'classification_loss': 0.8750668561458588}
2025-01-13 04:09:55,377 [INFO] Step[800/4329]: training loss : 0.8737658786773682 TRAIN  loss dict:  {'classification_loss': 0.8737658786773682}
2025-01-13 04:10:06,997 [INFO] Step[850/4329]: training loss : 0.8866545057296753 TRAIN  loss dict:  {'classification_loss': 0.8866545057296753}
2025-01-13 04:10:18,616 [INFO] Step[900/4329]: training loss : 0.8789483964443207 TRAIN  loss dict:  {'classification_loss': 0.8789483964443207}
2025-01-13 04:10:30,222 [INFO] Step[950/4329]: training loss : 0.8793955159187317 TRAIN  loss dict:  {'classification_loss': 0.8793955159187317}
2025-01-13 04:10:41,842 [INFO] Step[1000/4329]: training loss : 0.884456924200058 TRAIN  loss dict:  {'classification_loss': 0.884456924200058}
2025-01-13 04:10:53,515 [INFO] Step[1050/4329]: training loss : 0.8754108321666717 TRAIN  loss dict:  {'classification_loss': 0.8754108321666717}
2025-01-13 04:11:05,164 [INFO] Step[1100/4329]: training loss : 0.8732544326782227 TRAIN  loss dict:  {'classification_loss': 0.8732544326782227}
2025-01-13 04:11:16,762 [INFO] Step[1150/4329]: training loss : 0.891293556690216 TRAIN  loss dict:  {'classification_loss': 0.891293556690216}
2025-01-13 04:11:28,387 [INFO] Step[1200/4329]: training loss : 0.8759910213947296 TRAIN  loss dict:  {'classification_loss': 0.8759910213947296}
2025-01-13 04:11:40,028 [INFO] Step[1250/4329]: training loss : 0.8872571527957916 TRAIN  loss dict:  {'classification_loss': 0.8872571527957916}
2025-01-13 04:11:51,641 [INFO] Step[1300/4329]: training loss : 0.873175995349884 TRAIN  loss dict:  {'classification_loss': 0.873175995349884}
2025-01-13 04:12:03,308 [INFO] Step[1350/4329]: training loss : 0.874044930934906 TRAIN  loss dict:  {'classification_loss': 0.874044930934906}
2025-01-13 04:12:14,956 [INFO] Step[1400/4329]: training loss : 0.8856902778148651 TRAIN  loss dict:  {'classification_loss': 0.8856902778148651}
2025-01-13 04:12:26,531 [INFO] Step[1450/4329]: training loss : 0.8827994632720947 TRAIN  loss dict:  {'classification_loss': 0.8827994632720947}
2025-01-13 04:12:38,111 [INFO] Step[1500/4329]: training loss : 0.8776006782054901 TRAIN  loss dict:  {'classification_loss': 0.8776006782054901}
2025-01-13 04:12:49,952 [INFO] Step[1550/4329]: training loss : 0.8870307242870331 TRAIN  loss dict:  {'classification_loss': 0.8870307242870331}
2025-01-13 04:13:02,337 [INFO] Step[1600/4329]: training loss : 0.8946188127994538 TRAIN  loss dict:  {'classification_loss': 0.8946188127994538}
2025-01-13 04:13:14,583 [INFO] Step[1650/4329]: training loss : 0.9248527097702026 TRAIN  loss dict:  {'classification_loss': 0.9248527097702026}
2025-01-13 04:13:27,527 [INFO] Step[1700/4329]: training loss : 0.8986899745464325 TRAIN  loss dict:  {'classification_loss': 0.8986899745464325}
2025-01-13 04:13:40,782 [INFO] Step[1750/4329]: training loss : 0.8732960414886475 TRAIN  loss dict:  {'classification_loss': 0.8732960414886475}
2025-01-13 04:13:54,102 [INFO] Step[1800/4329]: training loss : 0.9260491955280304 TRAIN  loss dict:  {'classification_loss': 0.9260491955280304}
2025-01-13 04:14:05,976 [INFO] Step[1850/4329]: training loss : 0.8757610309123993 TRAIN  loss dict:  {'classification_loss': 0.8757610309123993}
2025-01-13 04:14:17,809 [INFO] Step[1900/4329]: training loss : 0.8732992851734162 TRAIN  loss dict:  {'classification_loss': 0.8732992851734162}
2025-01-13 04:14:29,436 [INFO] Step[1950/4329]: training loss : 0.8890091717243195 TRAIN  loss dict:  {'classification_loss': 0.8890091717243195}
2025-01-13 04:14:41,031 [INFO] Step[2000/4329]: training loss : 0.893226717710495 TRAIN  loss dict:  {'classification_loss': 0.893226717710495}
2025-01-13 04:14:52,651 [INFO] Step[2050/4329]: training loss : 0.87178626537323 TRAIN  loss dict:  {'classification_loss': 0.87178626537323}
2025-01-13 04:15:04,272 [INFO] Step[2100/4329]: training loss : 0.8794773828983307 TRAIN  loss dict:  {'classification_loss': 0.8794773828983307}
2025-01-13 04:15:15,920 [INFO] Step[2150/4329]: training loss : 0.877333813905716 TRAIN  loss dict:  {'classification_loss': 0.877333813905716}
2025-01-13 04:15:27,509 [INFO] Step[2200/4329]: training loss : 0.8808835721015931 TRAIN  loss dict:  {'classification_loss': 0.8808835721015931}
2025-01-13 04:15:39,153 [INFO] Step[2250/4329]: training loss : 0.8723484027385712 TRAIN  loss dict:  {'classification_loss': 0.8723484027385712}
2025-01-13 04:15:50,891 [INFO] Step[2300/4329]: training loss : 0.9104111766815186 TRAIN  loss dict:  {'classification_loss': 0.9104111766815186}
2025-01-13 04:16:02,552 [INFO] Step[2350/4329]: training loss : 0.8913584816455841 TRAIN  loss dict:  {'classification_loss': 0.8913584816455841}
2025-01-13 04:16:14,123 [INFO] Step[2400/4329]: training loss : 0.8807126939296722 TRAIN  loss dict:  {'classification_loss': 0.8807126939296722}
2025-01-13 04:16:25,750 [INFO] Step[2450/4329]: training loss : 0.8944871008396149 TRAIN  loss dict:  {'classification_loss': 0.8944871008396149}
2025-01-13 04:16:37,394 [INFO] Step[2500/4329]: training loss : 0.891072747707367 TRAIN  loss dict:  {'classification_loss': 0.891072747707367}
2025-01-13 04:16:49,014 [INFO] Step[2550/4329]: training loss : 0.8694343781471252 TRAIN  loss dict:  {'classification_loss': 0.8694343781471252}
2025-01-13 04:17:00,602 [INFO] Step[2600/4329]: training loss : 0.8784411323070526 TRAIN  loss dict:  {'classification_loss': 0.8784411323070526}
2025-01-13 04:17:12,196 [INFO] Step[2650/4329]: training loss : 0.8720482623577118 TRAIN  loss dict:  {'classification_loss': 0.8720482623577118}
2025-01-13 04:17:23,818 [INFO] Step[2700/4329]: training loss : 0.8761919462680816 TRAIN  loss dict:  {'classification_loss': 0.8761919462680816}
2025-01-13 04:17:35,448 [INFO] Step[2750/4329]: training loss : 0.8768085706233978 TRAIN  loss dict:  {'classification_loss': 0.8768085706233978}
2025-01-13 04:17:47,049 [INFO] Step[2800/4329]: training loss : 0.8763264203071595 TRAIN  loss dict:  {'classification_loss': 0.8763264203071595}
2025-01-13 04:17:58,679 [INFO] Step[2850/4329]: training loss : 0.8736162090301514 TRAIN  loss dict:  {'classification_loss': 0.8736162090301514}
2025-01-13 04:18:10,285 [INFO] Step[2900/4329]: training loss : 0.8737190127372741 TRAIN  loss dict:  {'classification_loss': 0.8737190127372741}
2025-01-13 04:18:21,954 [INFO] Step[2950/4329]: training loss : 0.8725347471237183 TRAIN  loss dict:  {'classification_loss': 0.8725347471237183}
2025-01-13 04:18:33,551 [INFO] Step[3000/4329]: training loss : 0.8767560589313507 TRAIN  loss dict:  {'classification_loss': 0.8767560589313507}
2025-01-13 04:18:45,181 [INFO] Step[3050/4329]: training loss : 0.8924059271812439 TRAIN  loss dict:  {'classification_loss': 0.8924059271812439}
2025-01-13 04:18:56,781 [INFO] Step[3100/4329]: training loss : 0.8713350915908813 TRAIN  loss dict:  {'classification_loss': 0.8713350915908813}
2025-01-13 04:19:08,386 [INFO] Step[3150/4329]: training loss : 0.8809598052501678 TRAIN  loss dict:  {'classification_loss': 0.8809598052501678}
2025-01-13 04:19:19,999 [INFO] Step[3200/4329]: training loss : 0.8706395161151886 TRAIN  loss dict:  {'classification_loss': 0.8706395161151886}
2025-01-13 04:19:31,609 [INFO] Step[3250/4329]: training loss : 0.8787534964084626 TRAIN  loss dict:  {'classification_loss': 0.8787534964084626}
2025-01-13 04:19:43,197 [INFO] Step[3300/4329]: training loss : 0.8716895020008087 TRAIN  loss dict:  {'classification_loss': 0.8716895020008087}
2025-01-13 04:19:54,867 [INFO] Step[3350/4329]: training loss : 0.8726876878738403 TRAIN  loss dict:  {'classification_loss': 0.8726876878738403}
2025-01-13 04:20:06,480 [INFO] Step[3400/4329]: training loss : 0.8695139074325562 TRAIN  loss dict:  {'classification_loss': 0.8695139074325562}
2025-01-13 04:20:18,117 [INFO] Step[3450/4329]: training loss : 0.8903344345092773 TRAIN  loss dict:  {'classification_loss': 0.8903344345092773}
2025-01-13 04:20:29,749 [INFO] Step[3500/4329]: training loss : 0.8935466849803925 TRAIN  loss dict:  {'classification_loss': 0.8935466849803925}
2025-01-13 04:20:41,417 [INFO] Step[3550/4329]: training loss : 0.9016783547401428 TRAIN  loss dict:  {'classification_loss': 0.9016783547401428}
2025-01-13 04:20:53,052 [INFO] Step[3600/4329]: training loss : 0.884957994222641 TRAIN  loss dict:  {'classification_loss': 0.884957994222641}
2025-01-13 04:21:04,691 [INFO] Step[3650/4329]: training loss : 0.8852842164039612 TRAIN  loss dict:  {'classification_loss': 0.8852842164039612}
2025-01-13 04:21:16,338 [INFO] Step[3700/4329]: training loss : 0.8805936419963837 TRAIN  loss dict:  {'classification_loss': 0.8805936419963837}
2025-01-13 04:21:27,946 [INFO] Step[3750/4329]: training loss : 0.8731209087371826 TRAIN  loss dict:  {'classification_loss': 0.8731209087371826}
2025-01-13 04:21:39,596 [INFO] Step[3800/4329]: training loss : 0.8764905178546906 TRAIN  loss dict:  {'classification_loss': 0.8764905178546906}
2025-01-13 04:21:51,232 [INFO] Step[3850/4329]: training loss : 0.8732836329936982 TRAIN  loss dict:  {'classification_loss': 0.8732836329936982}
2025-01-13 04:22:02,875 [INFO] Step[3900/4329]: training loss : 0.8730084908008575 TRAIN  loss dict:  {'classification_loss': 0.8730084908008575}
2025-01-13 04:22:14,544 [INFO] Step[3950/4329]: training loss : 0.8748041868209839 TRAIN  loss dict:  {'classification_loss': 0.8748041868209839}
2025-01-13 04:22:26,132 [INFO] Step[4000/4329]: training loss : 0.877593594789505 TRAIN  loss dict:  {'classification_loss': 0.877593594789505}
2025-01-13 04:22:37,744 [INFO] Step[4050/4329]: training loss : 0.8727747166156768 TRAIN  loss dict:  {'classification_loss': 0.8727747166156768}
2025-01-13 04:22:49,362 [INFO] Step[4100/4329]: training loss : 0.8720528113842011 TRAIN  loss dict:  {'classification_loss': 0.8720528113842011}
2025-01-13 04:23:00,973 [INFO] Step[4150/4329]: training loss : 0.8766959953308106 TRAIN  loss dict:  {'classification_loss': 0.8766959953308106}
2025-01-13 04:23:12,622 [INFO] Step[4200/4329]: training loss : 0.8762334871292115 TRAIN  loss dict:  {'classification_loss': 0.8762334871292115}
2025-01-13 04:23:24,201 [INFO] Step[4250/4329]: training loss : 0.886357616186142 TRAIN  loss dict:  {'classification_loss': 0.886357616186142}
2025-01-13 04:23:35,792 [INFO] Step[4300/4329]: training loss : 0.879757957458496 TRAIN  loss dict:  {'classification_loss': 0.879757957458496}
2025-01-13 04:25:32,128 [INFO] Label accuracies statistics:
2025-01-13 04:25:32,129 [INFO] {0: 0.4444444444444444, 1: 0.8888888888888888, 2: 0.5833333333333334, 3: 0.8333333333333334, 4: 0.25, 5: 0.9166666666666666, 6: 0.5, 7: 0.5, 8: 0.5833333333333334, 9: 0.75, 10: 1.0, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.5833333333333334, 14: 0.5833333333333334, 15: 0.7777777777777778, 16: 0.75, 17: 0.5833333333333334, 18: 0.6666666666666666, 19: 0.8333333333333334, 20: 0.5833333333333334, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.8333333333333334, 26: 0.75, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.6666666666666666, 32: 0.75, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 0.8333333333333334, 36: 0.5833333333333334, 37: 0.9166666666666666, 38: 1.0, 39: 1.0, 40: 0.9166666666666666, 41: 0.5, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.4166666666666667, 55: 0.75, 56: 0.8333333333333334, 57: 0.75, 58: 0.5833333333333334, 59: 0.5833333333333334, 60: 0.6666666666666666, 61: 1.0, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.9166666666666666, 68: 0.6666666666666666, 69: 0.6666666666666666, 70: 0.4166666666666667, 71: 0.4166666666666667, 72: 0.9166666666666666, 73: 0.8333333333333334, 74: 0.6666666666666666, 75: 1.0, 76: 0.5833333333333334, 77: 0.8333333333333334, 78: 0.9166666666666666, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.8333333333333334, 83: 0.6666666666666666, 84: 0.6666666666666666, 85: 0.75, 86: 0.75, 87: 0.9166666666666666, 88: 0.8333333333333334, 89: 0.6666666666666666, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.5833333333333334, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.8333333333333334, 101: 0.8333333333333334, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.4166666666666667, 114: 0.4166666666666667, 115: 0.9166666666666666, 116: 0.8333333333333334, 117: 0.9166666666666666, 118: 0.9166666666666666, 119: 0.75, 120: 0.6666666666666666, 121: 0.6666666666666666, 122: 0.8333333333333334, 123: 0.9166666666666666, 124: 0.9166666666666666, 125: 0.9166666666666666, 126: 0.8333333333333334, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.9166666666666666, 132: 0.5833333333333334, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.8333333333333334, 140: 1.0, 141: 0.8333333333333334, 142: 1.0, 143: 1.0, 144: 0.5833333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 1.0, 153: 0.75, 154: 0.9166666666666666, 155: 1.0, 156: 0.5833333333333334, 157: 0.8333333333333334, 158: 0.7777777777777778, 159: 1.0, 160: 0.4166666666666667, 161: 0.8333333333333334, 162: 0.9166666666666666, 163: 1.0, 164: 0.8333333333333334, 165: 0.75, 166: 0.75, 167: 0.9166666666666666, 168: 0.8333333333333334, 169: 1.0, 170: 1.0, 171: 0.75, 172: 1.0, 173: 0.9166666666666666, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 1.0, 177: 0.9166666666666666, 178: 1.0, 179: 0.4444444444444444, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.75, 183: 0.6666666666666666, 184: 0.75, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.8333333333333334, 189: 0.9166666666666666, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.9166666666666666, 194: 0.8333333333333334, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.5833333333333334}

2025-01-13 04:25:32,133 [INFO] [43] TRAIN  loss: 0.8808357630378518 acc: 0.9977668258124134
2025-01-13 04:25:32,134 [INFO] [43] TRAIN  loss dict: {'classification_loss': 0.8808357630378518}
2025-01-13 04:25:32,134 [INFO] [43] VALIDATION loss: 1.5857874290509657 VALIDATION acc: 0.8089225589225589
2025-01-13 04:25:32,134 [INFO] [43] VALIDATION loss dict: {'classification_loss': 1.5857874290509657}
2025-01-13 04:25:32,135 [INFO] 
2025-01-13 04:25:51,970 [INFO] Step[50/4329]: training loss : 0.8977699410915375 TRAIN  loss dict:  {'classification_loss': 0.8977699410915375}
2025-01-13 04:26:06,557 [INFO] Step[100/4329]: training loss : 0.877967426776886 TRAIN  loss dict:  {'classification_loss': 0.877967426776886}
2025-01-13 04:26:19,869 [INFO] Step[150/4329]: training loss : 0.8899345958232879 TRAIN  loss dict:  {'classification_loss': 0.8899345958232879}
2025-01-13 04:26:31,916 [INFO] Step[200/4329]: training loss : 0.87260284781456 TRAIN  loss dict:  {'classification_loss': 0.87260284781456}
2025-01-13 04:26:43,787 [INFO] Step[250/4329]: training loss : 0.8805944454669953 TRAIN  loss dict:  {'classification_loss': 0.8805944454669953}
2025-01-13 04:26:55,540 [INFO] Step[300/4329]: training loss : 0.8708762550354003 TRAIN  loss dict:  {'classification_loss': 0.8708762550354003}
2025-01-13 04:27:07,184 [INFO] Step[350/4329]: training loss : 0.884861695766449 TRAIN  loss dict:  {'classification_loss': 0.884861695766449}
2025-01-13 04:27:18,803 [INFO] Step[400/4329]: training loss : 0.9166837084293366 TRAIN  loss dict:  {'classification_loss': 0.9166837084293366}
2025-01-13 04:27:30,434 [INFO] Step[450/4329]: training loss : 0.8747491884231567 TRAIN  loss dict:  {'classification_loss': 0.8747491884231567}
2025-01-13 04:27:42,016 [INFO] Step[500/4329]: training loss : 0.8804017698764801 TRAIN  loss dict:  {'classification_loss': 0.8804017698764801}
2025-01-13 04:27:53,664 [INFO] Step[550/4329]: training loss : 0.9065086925029755 TRAIN  loss dict:  {'classification_loss': 0.9065086925029755}
2025-01-13 04:28:05,315 [INFO] Step[600/4329]: training loss : 0.8724636912345887 TRAIN  loss dict:  {'classification_loss': 0.8724636912345887}
2025-01-13 04:28:16,951 [INFO] Step[650/4329]: training loss : 0.8714991593360901 TRAIN  loss dict:  {'classification_loss': 0.8714991593360901}
2025-01-13 04:28:28,602 [INFO] Step[700/4329]: training loss : 0.8752729713916778 TRAIN  loss dict:  {'classification_loss': 0.8752729713916778}
2025-01-13 04:28:40,221 [INFO] Step[750/4329]: training loss : 0.893659245967865 TRAIN  loss dict:  {'classification_loss': 0.893659245967865}
2025-01-13 04:28:51,822 [INFO] Step[800/4329]: training loss : 0.874213764667511 TRAIN  loss dict:  {'classification_loss': 0.874213764667511}
2025-01-13 04:29:03,500 [INFO] Step[850/4329]: training loss : 0.8709250998497009 TRAIN  loss dict:  {'classification_loss': 0.8709250998497009}
2025-01-13 04:29:15,146 [INFO] Step[900/4329]: training loss : 0.8757768845558167 TRAIN  loss dict:  {'classification_loss': 0.8757768845558167}
2025-01-13 04:29:26,786 [INFO] Step[950/4329]: training loss : 0.903817652463913 TRAIN  loss dict:  {'classification_loss': 0.903817652463913}
2025-01-13 04:29:38,425 [INFO] Step[1000/4329]: training loss : 0.8734156060218811 TRAIN  loss dict:  {'classification_loss': 0.8734156060218811}
2025-01-13 04:29:50,022 [INFO] Step[1050/4329]: training loss : 0.8709346759319305 TRAIN  loss dict:  {'classification_loss': 0.8709346759319305}
2025-01-13 04:30:01,659 [INFO] Step[1100/4329]: training loss : 0.8774345016479492 TRAIN  loss dict:  {'classification_loss': 0.8774345016479492}
2025-01-13 04:30:13,325 [INFO] Step[1150/4329]: training loss : 0.8745293724536896 TRAIN  loss dict:  {'classification_loss': 0.8745293724536896}
2025-01-13 04:30:24,887 [INFO] Step[1200/4329]: training loss : 0.891006588935852 TRAIN  loss dict:  {'classification_loss': 0.891006588935852}
2025-01-13 04:30:36,496 [INFO] Step[1250/4329]: training loss : 0.8740699076652527 TRAIN  loss dict:  {'classification_loss': 0.8740699076652527}
2025-01-13 04:30:48,104 [INFO] Step[1300/4329]: training loss : 0.8715880334377288 TRAIN  loss dict:  {'classification_loss': 0.8715880334377288}
2025-01-13 04:30:59,734 [INFO] Step[1350/4329]: training loss : 0.8779855263233185 TRAIN  loss dict:  {'classification_loss': 0.8779855263233185}
2025-01-13 04:31:11,364 [INFO] Step[1400/4329]: training loss : 0.8811713564395904 TRAIN  loss dict:  {'classification_loss': 0.8811713564395904}
2025-01-13 04:31:22,987 [INFO] Step[1450/4329]: training loss : 0.8723642075061798 TRAIN  loss dict:  {'classification_loss': 0.8723642075061798}
2025-01-13 04:31:34,624 [INFO] Step[1500/4329]: training loss : 0.8768859803676605 TRAIN  loss dict:  {'classification_loss': 0.8768859803676605}
2025-01-13 04:31:46,234 [INFO] Step[1550/4329]: training loss : 0.8782169997692109 TRAIN  loss dict:  {'classification_loss': 0.8782169997692109}
2025-01-13 04:31:57,855 [INFO] Step[1600/4329]: training loss : 0.883128867149353 TRAIN  loss dict:  {'classification_loss': 0.883128867149353}
2025-01-13 04:32:09,479 [INFO] Step[1650/4329]: training loss : 0.8928705191612244 TRAIN  loss dict:  {'classification_loss': 0.8928705191612244}
2025-01-13 04:32:21,108 [INFO] Step[1700/4329]: training loss : 0.8776891732215881 TRAIN  loss dict:  {'classification_loss': 0.8776891732215881}
2025-01-13 04:32:32,723 [INFO] Step[1750/4329]: training loss : 0.8905929434299469 TRAIN  loss dict:  {'classification_loss': 0.8905929434299469}
2025-01-13 04:32:44,307 [INFO] Step[1800/4329]: training loss : 0.8778177928924561 TRAIN  loss dict:  {'classification_loss': 0.8778177928924561}
2025-01-13 04:32:55,912 [INFO] Step[1850/4329]: training loss : 0.8745106816291809 TRAIN  loss dict:  {'classification_loss': 0.8745106816291809}
2025-01-13 04:33:07,570 [INFO] Step[1900/4329]: training loss : 0.8701695239543915 TRAIN  loss dict:  {'classification_loss': 0.8701695239543915}
2025-01-13 04:33:19,221 [INFO] Step[1950/4329]: training loss : 0.8695991253852844 TRAIN  loss dict:  {'classification_loss': 0.8695991253852844}
2025-01-13 04:33:30,841 [INFO] Step[2000/4329]: training loss : 0.8808830118179322 TRAIN  loss dict:  {'classification_loss': 0.8808830118179322}
2025-01-13 04:33:42,484 [INFO] Step[2050/4329]: training loss : 0.8742845749855042 TRAIN  loss dict:  {'classification_loss': 0.8742845749855042}
2025-01-13 04:33:54,051 [INFO] Step[2100/4329]: training loss : 0.8724661827087402 TRAIN  loss dict:  {'classification_loss': 0.8724661827087402}
2025-01-13 04:34:05,628 [INFO] Step[2150/4329]: training loss : 0.8976416325569153 TRAIN  loss dict:  {'classification_loss': 0.8976416325569153}
2025-01-13 04:34:17,245 [INFO] Step[2200/4329]: training loss : 0.8692044425010681 TRAIN  loss dict:  {'classification_loss': 0.8692044425010681}
2025-01-13 04:34:28,860 [INFO] Step[2250/4329]: training loss : 0.8694483125209809 TRAIN  loss dict:  {'classification_loss': 0.8694483125209809}
2025-01-13 04:34:40,455 [INFO] Step[2300/4329]: training loss : 0.8706094312667847 TRAIN  loss dict:  {'classification_loss': 0.8706094312667847}
2025-01-13 04:34:52,091 [INFO] Step[2350/4329]: training loss : 0.878345947265625 TRAIN  loss dict:  {'classification_loss': 0.878345947265625}
2025-01-13 04:35:03,729 [INFO] Step[2400/4329]: training loss : 0.8861849558353424 TRAIN  loss dict:  {'classification_loss': 0.8861849558353424}
2025-01-13 04:35:15,374 [INFO] Step[2450/4329]: training loss : 0.8893194711208343 TRAIN  loss dict:  {'classification_loss': 0.8893194711208343}
2025-01-13 04:35:27,014 [INFO] Step[2500/4329]: training loss : 0.9040354430675507 TRAIN  loss dict:  {'classification_loss': 0.9040354430675507}
2025-01-13 04:35:38,650 [INFO] Step[2550/4329]: training loss : 0.8823182272911072 TRAIN  loss dict:  {'classification_loss': 0.8823182272911072}
2025-01-13 04:35:50,265 [INFO] Step[2600/4329]: training loss : 0.8759971261024475 TRAIN  loss dict:  {'classification_loss': 0.8759971261024475}
2025-01-13 04:36:01,897 [INFO] Step[2650/4329]: training loss : 0.8849095582962037 TRAIN  loss dict:  {'classification_loss': 0.8849095582962037}
2025-01-13 04:36:13,539 [INFO] Step[2700/4329]: training loss : 0.871363661289215 TRAIN  loss dict:  {'classification_loss': 0.871363661289215}
2025-01-13 04:36:25,156 [INFO] Step[2750/4329]: training loss : 0.8818837106227875 TRAIN  loss dict:  {'classification_loss': 0.8818837106227875}
2025-01-13 04:36:36,789 [INFO] Step[2800/4329]: training loss : 0.8742103946208953 TRAIN  loss dict:  {'classification_loss': 0.8742103946208953}
2025-01-13 04:36:48,431 [INFO] Step[2850/4329]: training loss : 0.8764964985847473 TRAIN  loss dict:  {'classification_loss': 0.8764964985847473}
2025-01-13 04:37:00,034 [INFO] Step[2900/4329]: training loss : 0.881288161277771 TRAIN  loss dict:  {'classification_loss': 0.881288161277771}
2025-01-13 04:37:11,652 [INFO] Step[2950/4329]: training loss : 0.8748804962635041 TRAIN  loss dict:  {'classification_loss': 0.8748804962635041}
2025-01-13 04:37:23,259 [INFO] Step[3000/4329]: training loss : 0.8773879647254944 TRAIN  loss dict:  {'classification_loss': 0.8773879647254944}
2025-01-13 04:37:34,948 [INFO] Step[3050/4329]: training loss : 0.8824813115596771 TRAIN  loss dict:  {'classification_loss': 0.8824813115596771}
2025-01-13 04:37:46,996 [INFO] Step[3100/4329]: training loss : 0.876028528213501 TRAIN  loss dict:  {'classification_loss': 0.876028528213501}
2025-01-13 04:37:59,245 [INFO] Step[3150/4329]: training loss : 0.8773516821861267 TRAIN  loss dict:  {'classification_loss': 0.8773516821861267}
2025-01-13 04:38:11,619 [INFO] Step[3200/4329]: training loss : 0.8787309420108795 TRAIN  loss dict:  {'classification_loss': 0.8787309420108795}
2025-01-13 04:38:24,565 [INFO] Step[3250/4329]: training loss : 0.8712322068214416 TRAIN  loss dict:  {'classification_loss': 0.8712322068214416}
2025-01-13 04:38:38,027 [INFO] Step[3300/4329]: training loss : 0.8776035118103027 TRAIN  loss dict:  {'classification_loss': 0.8776035118103027}
2025-01-13 04:38:50,023 [INFO] Step[3350/4329]: training loss : 0.8940237987041474 TRAIN  loss dict:  {'classification_loss': 0.8940237987041474}
2025-01-13 04:39:01,925 [INFO] Step[3400/4329]: training loss : 0.8874530029296875 TRAIN  loss dict:  {'classification_loss': 0.8874530029296875}
2025-01-13 04:39:13,687 [INFO] Step[3450/4329]: training loss : 0.8776874268054962 TRAIN  loss dict:  {'classification_loss': 0.8776874268054962}
2025-01-13 04:39:25,316 [INFO] Step[3500/4329]: training loss : 0.8841577768325806 TRAIN  loss dict:  {'classification_loss': 0.8841577768325806}
2025-01-13 04:39:36,924 [INFO] Step[3550/4329]: training loss : 0.8785021948814392 TRAIN  loss dict:  {'classification_loss': 0.8785021948814392}
2025-01-13 04:39:48,518 [INFO] Step[3600/4329]: training loss : 0.8843270778656006 TRAIN  loss dict:  {'classification_loss': 0.8843270778656006}
2025-01-13 04:40:00,183 [INFO] Step[3650/4329]: training loss : 0.8801706182956696 TRAIN  loss dict:  {'classification_loss': 0.8801706182956696}
2025-01-13 04:40:11,831 [INFO] Step[3700/4329]: training loss : 0.8798086035251618 TRAIN  loss dict:  {'classification_loss': 0.8798086035251618}
2025-01-13 04:40:23,468 [INFO] Step[3750/4329]: training loss : 0.882664852142334 TRAIN  loss dict:  {'classification_loss': 0.882664852142334}
2025-01-13 04:40:35,068 [INFO] Step[3800/4329]: training loss : 0.8754733109474182 TRAIN  loss dict:  {'classification_loss': 0.8754733109474182}
2025-01-13 04:40:46,685 [INFO] Step[3850/4329]: training loss : 0.8704035365581513 TRAIN  loss dict:  {'classification_loss': 0.8704035365581513}
2025-01-13 04:40:58,316 [INFO] Step[3900/4329]: training loss : 0.9223536550998688 TRAIN  loss dict:  {'classification_loss': 0.9223536550998688}
2025-01-13 04:41:09,909 [INFO] Step[3950/4329]: training loss : 0.8865652298927307 TRAIN  loss dict:  {'classification_loss': 0.8865652298927307}
2025-01-13 04:41:21,506 [INFO] Step[4000/4329]: training loss : 0.871948549747467 TRAIN  loss dict:  {'classification_loss': 0.871948549747467}
2025-01-13 04:41:33,141 [INFO] Step[4050/4329]: training loss : 0.904886108636856 TRAIN  loss dict:  {'classification_loss': 0.904886108636856}
2025-01-13 04:41:44,716 [INFO] Step[4100/4329]: training loss : 0.8848879241943359 TRAIN  loss dict:  {'classification_loss': 0.8848879241943359}
2025-01-13 04:41:56,289 [INFO] Step[4150/4329]: training loss : 0.871075096130371 TRAIN  loss dict:  {'classification_loss': 0.871075096130371}
2025-01-13 04:42:07,903 [INFO] Step[4200/4329]: training loss : 0.8794571793079377 TRAIN  loss dict:  {'classification_loss': 0.8794571793079377}
2025-01-13 04:42:19,504 [INFO] Step[4250/4329]: training loss : 0.8723095333576203 TRAIN  loss dict:  {'classification_loss': 0.8723095333576203}
2025-01-13 04:42:31,095 [INFO] Step[4300/4329]: training loss : 0.880038115978241 TRAIN  loss dict:  {'classification_loss': 0.880038115978241}
2025-01-13 04:44:29,554 [INFO] Label accuracies statistics:
2025-01-13 04:44:29,554 [INFO] {0: 0.5555555555555556, 1: 1.0, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.3333333333333333, 5: 0.9166666666666666, 6: 0.5, 7: 0.5833333333333334, 8: 0.5833333333333334, 9: 0.8333333333333334, 10: 1.0, 11: 1.0, 12: 0.4166666666666667, 13: 0.5833333333333334, 14: 0.75, 15: 0.6666666666666666, 16: 0.75, 17: 0.5833333333333334, 18: 0.5833333333333334, 19: 0.8333333333333334, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.6666666666666666, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.6666666666666666, 31: 0.75, 32: 0.6666666666666666, 33: 0.8333333333333334, 34: 0.9166666666666666, 35: 1.0, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 0.9166666666666666, 40: 1.0, 41: 0.4166666666666667, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.6666666666666666, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.6666666666666666, 54: 0.4166666666666667, 55: 0.75, 56: 0.8333333333333334, 57: 0.75, 58: 0.5833333333333334, 59: 0.8333333333333334, 60: 0.75, 61: 0.9166666666666666, 62: 0.75, 63: 0.4166666666666667, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.8333333333333334, 68: 0.75, 69: 0.6666666666666666, 70: 0.3333333333333333, 71: 0.5, 72: 0.9166666666666666, 73: 1.0, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 0.9166666666666666, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.8333333333333334, 84: 0.5, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.6666666666666666, 89: 0.5833333333333334, 90: 0.6666666666666666, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 0.9166666666666666, 96: 0.4166666666666667, 97: 0.75, 98: 0.8333333333333334, 99: 1.0, 100: 0.9166666666666666, 101: 0.9166666666666666, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.8333333333333334, 111: 1.0, 112: 0.8333333333333334, 113: 0.3333333333333333, 114: 0.5833333333333334, 115: 0.9166666666666666, 116: 0.8333333333333334, 117: 0.8333333333333334, 118: 1.0, 119: 0.9166666666666666, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 0.6666666666666666, 126: 0.8333333333333334, 127: 0.9166666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 1.0, 132: 0.8333333333333334, 133: 1.0, 134: 0.75, 135: 1.0, 136: 0.8333333333333334, 137: 0.9166666666666666, 138: 1.0, 139: 0.8333333333333334, 140: 0.9166666666666666, 141: 0.9166666666666666, 142: 0.9166666666666666, 143: 0.9166666666666666, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 0.9166666666666666, 156: 0.6666666666666666, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.16666666666666666, 161: 0.9166666666666666, 162: 1.0, 163: 0.9166666666666666, 164: 0.8333333333333334, 165: 0.6666666666666666, 166: 0.75, 167: 0.5833333333333334, 168: 0.9166666666666666, 169: 1.0, 170: 1.0, 171: 0.6666666666666666, 172: 1.0, 173: 0.8333333333333334, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 0.9166666666666666, 177: 0.75, 178: 0.9166666666666666, 179: 0.2222222222222222, 180: 0.9166666666666666, 181: 0.9166666666666666, 182: 0.5, 183: 0.9166666666666666, 184: 0.6666666666666666, 185: 1.0, 186: 0.6666666666666666, 187: 0.9166666666666666, 188: 0.75, 189: 0.9166666666666666, 190: 0.6666666666666666, 191: 0.4166666666666667, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.6666666666666666}

2025-01-13 04:44:29,556 [INFO] [44] TRAIN  loss: 0.8807857033974525 acc: 0.9969967657477283
2025-01-13 04:44:29,556 [INFO] [44] TRAIN  loss dict: {'classification_loss': 0.8807857033974525}
2025-01-13 04:44:29,556 [INFO] [44] VALIDATION loss: 1.6128899692887007 VALIDATION acc: 0.8080808080808081
2025-01-13 04:44:29,556 [INFO] [44] VALIDATION loss dict: {'classification_loss': 1.6128899692887007}
2025-01-13 04:44:29,556 [INFO] 
2025-01-13 04:44:46,613 [INFO] Step[50/4329]: training loss : 0.8744637084007263 TRAIN  loss dict:  {'classification_loss': 0.8744637084007263}
2025-01-13 04:44:58,154 [INFO] Step[100/4329]: training loss : 0.8843938827514648 TRAIN  loss dict:  {'classification_loss': 0.8843938827514648}
2025-01-13 04:45:09,759 [INFO] Step[150/4329]: training loss : 0.8866493439674378 TRAIN  loss dict:  {'classification_loss': 0.8866493439674378}
2025-01-13 04:45:21,369 [INFO] Step[200/4329]: training loss : 0.8719033861160278 TRAIN  loss dict:  {'classification_loss': 0.8719033861160278}
2025-01-13 04:45:32,975 [INFO] Step[250/4329]: training loss : 0.8717139375209808 TRAIN  loss dict:  {'classification_loss': 0.8717139375209808}
2025-01-13 04:45:44,563 [INFO] Step[300/4329]: training loss : 0.8925312793254853 TRAIN  loss dict:  {'classification_loss': 0.8925312793254853}
2025-01-13 04:45:56,219 [INFO] Step[350/4329]: training loss : 0.8738863480091095 TRAIN  loss dict:  {'classification_loss': 0.8738863480091095}
2025-01-13 04:46:07,830 [INFO] Step[400/4329]: training loss : 0.8747210144996643 TRAIN  loss dict:  {'classification_loss': 0.8747210144996643}
2025-01-13 04:46:19,497 [INFO] Step[450/4329]: training loss : 0.8740805327892304 TRAIN  loss dict:  {'classification_loss': 0.8740805327892304}
2025-01-13 04:46:31,121 [INFO] Step[500/4329]: training loss : 0.8781363010406494 TRAIN  loss dict:  {'classification_loss': 0.8781363010406494}
2025-01-13 04:46:42,752 [INFO] Step[550/4329]: training loss : 0.8708154892921448 TRAIN  loss dict:  {'classification_loss': 0.8708154892921448}
2025-01-13 04:46:54,393 [INFO] Step[600/4329]: training loss : 0.8877850210666657 TRAIN  loss dict:  {'classification_loss': 0.8877850210666657}
2025-01-13 04:47:06,037 [INFO] Step[650/4329]: training loss : 0.8894897186756134 TRAIN  loss dict:  {'classification_loss': 0.8894897186756134}
2025-01-13 04:47:17,654 [INFO] Step[700/4329]: training loss : 0.8728280127048492 TRAIN  loss dict:  {'classification_loss': 0.8728280127048492}
2025-01-13 04:47:29,353 [INFO] Step[750/4329]: training loss : 0.8696816956996918 TRAIN  loss dict:  {'classification_loss': 0.8696816956996918}
2025-01-13 04:47:40,989 [INFO] Step[800/4329]: training loss : 0.8792028594017028 TRAIN  loss dict:  {'classification_loss': 0.8792028594017028}
2025-01-13 04:47:52,625 [INFO] Step[850/4329]: training loss : 0.8772252345085144 TRAIN  loss dict:  {'classification_loss': 0.8772252345085144}
2025-01-13 04:48:04,239 [INFO] Step[900/4329]: training loss : 0.8879512560367584 TRAIN  loss dict:  {'classification_loss': 0.8879512560367584}
2025-01-13 04:48:15,863 [INFO] Step[950/4329]: training loss : 0.8883752655982972 TRAIN  loss dict:  {'classification_loss': 0.8883752655982972}
2025-01-13 04:48:27,493 [INFO] Step[1000/4329]: training loss : 0.87648428440094 TRAIN  loss dict:  {'classification_loss': 0.87648428440094}
2025-01-13 04:48:39,094 [INFO] Step[1050/4329]: training loss : 0.8702938401699066 TRAIN  loss dict:  {'classification_loss': 0.8702938401699066}
2025-01-13 04:48:50,741 [INFO] Step[1100/4329]: training loss : 0.8708329689502716 TRAIN  loss dict:  {'classification_loss': 0.8708329689502716}
2025-01-13 04:49:02,363 [INFO] Step[1150/4329]: training loss : 0.8770667457580567 TRAIN  loss dict:  {'classification_loss': 0.8770667457580567}
2025-01-13 04:49:13,997 [INFO] Step[1200/4329]: training loss : 0.8890407252311706 TRAIN  loss dict:  {'classification_loss': 0.8890407252311706}
2025-01-13 04:49:25,654 [INFO] Step[1250/4329]: training loss : 0.8721168923377991 TRAIN  loss dict:  {'classification_loss': 0.8721168923377991}
2025-01-13 04:49:37,264 [INFO] Step[1300/4329]: training loss : 0.877127970457077 TRAIN  loss dict:  {'classification_loss': 0.877127970457077}
2025-01-13 04:49:48,869 [INFO] Step[1350/4329]: training loss : 0.8808368217945098 TRAIN  loss dict:  {'classification_loss': 0.8808368217945098}
2025-01-13 04:50:00,507 [INFO] Step[1400/4329]: training loss : 0.877655838727951 TRAIN  loss dict:  {'classification_loss': 0.877655838727951}
2025-01-13 04:50:12,544 [INFO] Step[1450/4329]: training loss : 0.8760429620742798 TRAIN  loss dict:  {'classification_loss': 0.8760429620742798}
2025-01-13 04:50:24,754 [INFO] Step[1500/4329]: training loss : 0.8811058533191681 TRAIN  loss dict:  {'classification_loss': 0.8811058533191681}
2025-01-13 04:50:37,291 [INFO] Step[1550/4329]: training loss : 0.8766660594940185 TRAIN  loss dict:  {'classification_loss': 0.8766660594940185}
2025-01-13 04:50:51,834 [INFO] Step[1600/4329]: training loss : 0.8789907109737396 TRAIN  loss dict:  {'classification_loss': 0.8789907109737396}
2025-01-13 04:51:05,872 [INFO] Step[1650/4329]: training loss : 0.8731201934814453 TRAIN  loss dict:  {'classification_loss': 0.8731201934814453}
2025-01-13 04:51:17,792 [INFO] Step[1700/4329]: training loss : 0.8842654347419738 TRAIN  loss dict:  {'classification_loss': 0.8842654347419738}
2025-01-13 04:51:29,793 [INFO] Step[1750/4329]: training loss : 0.8827927458286285 TRAIN  loss dict:  {'classification_loss': 0.8827927458286285}
2025-01-13 04:51:41,402 [INFO] Step[1800/4329]: training loss : 0.8850637090206146 TRAIN  loss dict:  {'classification_loss': 0.8850637090206146}
2025-01-13 04:51:53,033 [INFO] Step[1850/4329]: training loss : 0.8884251832962036 TRAIN  loss dict:  {'classification_loss': 0.8884251832962036}
2025-01-13 04:52:04,658 [INFO] Step[1900/4329]: training loss : 0.8743272686004638 TRAIN  loss dict:  {'classification_loss': 0.8743272686004638}
2025-01-13 04:52:16,293 [INFO] Step[1950/4329]: training loss : 0.8788131046295166 TRAIN  loss dict:  {'classification_loss': 0.8788131046295166}
2025-01-13 04:52:27,929 [INFO] Step[2000/4329]: training loss : 0.8783960485458374 TRAIN  loss dict:  {'classification_loss': 0.8783960485458374}
2025-01-13 04:52:39,554 [INFO] Step[2050/4329]: training loss : 0.8734798896312713 TRAIN  loss dict:  {'classification_loss': 0.8734798896312713}
2025-01-13 04:52:51,179 [INFO] Step[2100/4329]: training loss : 0.8831792652606965 TRAIN  loss dict:  {'classification_loss': 0.8831792652606965}
2025-01-13 04:53:02,830 [INFO] Step[2150/4329]: training loss : 0.8740615892410278 TRAIN  loss dict:  {'classification_loss': 0.8740615892410278}
2025-01-13 04:53:14,459 [INFO] Step[2200/4329]: training loss : 0.8697847533226013 TRAIN  loss dict:  {'classification_loss': 0.8697847533226013}
2025-01-13 04:53:26,116 [INFO] Step[2250/4329]: training loss : 0.8709271109104156 TRAIN  loss dict:  {'classification_loss': 0.8709271109104156}
2025-01-13 04:53:37,723 [INFO] Step[2300/4329]: training loss : 0.8806971156597138 TRAIN  loss dict:  {'classification_loss': 0.8806971156597138}
2025-01-13 04:53:49,343 [INFO] Step[2350/4329]: training loss : 0.8859981191158295 TRAIN  loss dict:  {'classification_loss': 0.8859981191158295}
2025-01-13 04:54:00,972 [INFO] Step[2400/4329]: training loss : 0.8743317925930023 TRAIN  loss dict:  {'classification_loss': 0.8743317925930023}
2025-01-13 04:54:12,589 [INFO] Step[2450/4329]: training loss : 0.8727696335315704 TRAIN  loss dict:  {'classification_loss': 0.8727696335315704}
2025-01-13 04:54:24,215 [INFO] Step[2500/4329]: training loss : 0.9016505646705627 TRAIN  loss dict:  {'classification_loss': 0.9016505646705627}
2025-01-13 04:54:35,837 [INFO] Step[2550/4329]: training loss : 0.8768730735778809 TRAIN  loss dict:  {'classification_loss': 0.8768730735778809}
2025-01-13 04:54:47,458 [INFO] Step[2600/4329]: training loss : 0.8915654575824737 TRAIN  loss dict:  {'classification_loss': 0.8915654575824737}
2025-01-13 04:54:59,041 [INFO] Step[2650/4329]: training loss : 0.8734831178188324 TRAIN  loss dict:  {'classification_loss': 0.8734831178188324}
2025-01-13 04:55:10,648 [INFO] Step[2700/4329]: training loss : 0.8753434038162231 TRAIN  loss dict:  {'classification_loss': 0.8753434038162231}
2025-01-13 04:55:22,279 [INFO] Step[2750/4329]: training loss : 0.879615968465805 TRAIN  loss dict:  {'classification_loss': 0.879615968465805}
2025-01-13 04:55:33,872 [INFO] Step[2800/4329]: training loss : 0.8814496850967407 TRAIN  loss dict:  {'classification_loss': 0.8814496850967407}
2025-01-13 04:55:45,514 [INFO] Step[2850/4329]: training loss : 0.8762726616859436 TRAIN  loss dict:  {'classification_loss': 0.8762726616859436}
2025-01-13 04:55:57,164 [INFO] Step[2900/4329]: training loss : 0.8716343212127685 TRAIN  loss dict:  {'classification_loss': 0.8716343212127685}
2025-01-13 04:56:08,774 [INFO] Step[2950/4329]: training loss : 0.8724879729747772 TRAIN  loss dict:  {'classification_loss': 0.8724879729747772}
2025-01-13 04:56:20,407 [INFO] Step[3000/4329]: training loss : 0.9010019505023956 TRAIN  loss dict:  {'classification_loss': 0.9010019505023956}
2025-01-13 04:56:32,044 [INFO] Step[3050/4329]: training loss : 0.8805372333526611 TRAIN  loss dict:  {'classification_loss': 0.8805372333526611}
2025-01-13 04:56:43,694 [INFO] Step[3100/4329]: training loss : 0.8720212543010711 TRAIN  loss dict:  {'classification_loss': 0.8720212543010711}
2025-01-13 04:56:55,334 [INFO] Step[3150/4329]: training loss : 0.8858777856826783 TRAIN  loss dict:  {'classification_loss': 0.8858777856826783}
2025-01-13 04:57:06,985 [INFO] Step[3200/4329]: training loss : 0.8783088803291321 TRAIN  loss dict:  {'classification_loss': 0.8783088803291321}
2025-01-13 04:57:18,616 [INFO] Step[3250/4329]: training loss : 0.8813398337364197 TRAIN  loss dict:  {'classification_loss': 0.8813398337364197}
2025-01-13 04:57:30,271 [INFO] Step[3300/4329]: training loss : 0.8722826588153839 TRAIN  loss dict:  {'classification_loss': 0.8722826588153839}
2025-01-13 04:57:41,934 [INFO] Step[3350/4329]: training loss : 0.877441040277481 TRAIN  loss dict:  {'classification_loss': 0.877441040277481}
2025-01-13 04:57:53,579 [INFO] Step[3400/4329]: training loss : 0.8856522226333619 TRAIN  loss dict:  {'classification_loss': 0.8856522226333619}
2025-01-13 04:58:05,218 [INFO] Step[3450/4329]: training loss : 0.8885057377815246 TRAIN  loss dict:  {'classification_loss': 0.8885057377815246}
2025-01-13 04:58:16,847 [INFO] Step[3500/4329]: training loss : 0.876619679927826 TRAIN  loss dict:  {'classification_loss': 0.876619679927826}
2025-01-13 04:58:28,508 [INFO] Step[3550/4329]: training loss : 0.8818090462684631 TRAIN  loss dict:  {'classification_loss': 0.8818090462684631}
2025-01-13 04:58:40,165 [INFO] Step[3600/4329]: training loss : 0.8822007942199707 TRAIN  loss dict:  {'classification_loss': 0.8822007942199707}
2025-01-13 04:58:51,794 [INFO] Step[3650/4329]: training loss : 0.8756228625774384 TRAIN  loss dict:  {'classification_loss': 0.8756228625774384}
2025-01-13 04:59:03,421 [INFO] Step[3700/4329]: training loss : 0.8723894453048706 TRAIN  loss dict:  {'classification_loss': 0.8723894453048706}
2025-01-13 04:59:15,028 [INFO] Step[3750/4329]: training loss : 0.8793976616859436 TRAIN  loss dict:  {'classification_loss': 0.8793976616859436}
2025-01-13 04:59:26,661 [INFO] Step[3800/4329]: training loss : 0.8709268736839294 TRAIN  loss dict:  {'classification_loss': 0.8709268736839294}
2025-01-13 04:59:38,293 [INFO] Step[3850/4329]: training loss : 0.8732688236236572 TRAIN  loss dict:  {'classification_loss': 0.8732688236236572}
2025-01-13 04:59:49,903 [INFO] Step[3900/4329]: training loss : 0.8713212740421296 TRAIN  loss dict:  {'classification_loss': 0.8713212740421296}
2025-01-13 05:00:01,521 [INFO] Step[3950/4329]: training loss : 0.8696545839309693 TRAIN  loss dict:  {'classification_loss': 0.8696545839309693}
2025-01-13 05:00:13,128 [INFO] Step[4000/4329]: training loss : 0.8731761789321899 TRAIN  loss dict:  {'classification_loss': 0.8731761789321899}
2025-01-13 05:00:24,813 [INFO] Step[4050/4329]: training loss : 0.8686604118347168 TRAIN  loss dict:  {'classification_loss': 0.8686604118347168}
2025-01-13 05:00:36,448 [INFO] Step[4100/4329]: training loss : 0.8902598309516907 TRAIN  loss dict:  {'classification_loss': 0.8902598309516907}
2025-01-13 05:00:48,092 [INFO] Step[4150/4329]: training loss : 0.9066678595542907 TRAIN  loss dict:  {'classification_loss': 0.9066678595542907}
2025-01-13 05:00:59,707 [INFO] Step[4200/4329]: training loss : 0.9005442476272583 TRAIN  loss dict:  {'classification_loss': 0.9005442476272583}
2025-01-13 05:01:11,311 [INFO] Step[4250/4329]: training loss : 0.8740556704998016 TRAIN  loss dict:  {'classification_loss': 0.8740556704998016}
2025-01-13 05:01:22,940 [INFO] Step[4300/4329]: training loss : 0.874287645816803 TRAIN  loss dict:  {'classification_loss': 0.874287645816803}
2025-01-13 05:03:40,775 [INFO] Label accuracies statistics:
2025-01-13 05:03:40,776 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.5, 8: 0.4166666666666667, 9: 0.8333333333333334, 10: 1.0, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.5, 14: 0.5833333333333334, 15: 0.7777777777777778, 16: 0.75, 17: 0.6666666666666666, 18: 0.6666666666666666, 19: 0.75, 20: 0.5833333333333334, 21: 0.6666666666666666, 22: 0.75, 23: 0.8333333333333334, 24: 1.0, 25: 0.5833333333333334, 26: 0.75, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.8333333333333334, 32: 0.75, 33: 0.8333333333333334, 34: 0.8333333333333334, 35: 1.0, 36: 0.5833333333333334, 37: 0.9166666666666666, 38: 0.9166666666666666, 39: 1.0, 40: 0.8333333333333334, 41: 0.5, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.6666666666666666, 45: 0.5833333333333334, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5833333333333334, 54: 0.4166666666666667, 55: 0.6666666666666666, 56: 0.9166666666666666, 57: 0.75, 58: 0.6666666666666666, 59: 0.8333333333333334, 60: 0.75, 61: 0.9166666666666666, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.9166666666666666, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.4166666666666667, 72: 0.8333333333333334, 73: 0.9166666666666666, 74: 0.5833333333333334, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 0.9166666666666666, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.6666666666666666, 84: 0.75, 85: 0.75, 86: 0.5833333333333334, 87: 0.8333333333333334, 88: 0.5, 89: 0.6666666666666666, 90: 0.5833333333333334, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 1.0, 96: 0.5, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.9166666666666666, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 0.9166666666666666, 111: 1.0, 112: 1.0, 113: 0.3333333333333333, 114: 0.6666666666666666, 115: 0.9166666666666666, 116: 0.8333333333333334, 117: 0.9166666666666666, 118: 0.9166666666666666, 119: 0.9166666666666666, 120: 0.8333333333333334, 121: 0.6666666666666666, 122: 0.8333333333333334, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.8333333333333334, 127: 0.5833333333333334, 128: 1.0, 129: 1.0, 130: 0.8333333333333334, 131: 0.9166666666666666, 132: 0.5833333333333334, 133: 1.0, 134: 0.8333333333333334, 135: 1.0, 136: 0.9166666666666666, 137: 0.8333333333333334, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 1.0, 141: 0.8333333333333334, 142: 0.6666666666666666, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 0.9166666666666666, 156: 0.75, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.25, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.8333333333333334, 169: 0.9166666666666666, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.9166666666666666, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.8333333333333334, 178: 0.9166666666666666, 179: 0.0, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.6666666666666666, 183: 0.75, 184: 0.8333333333333334, 185: 1.0, 186: 0.75, 187: 0.9166666666666666, 188: 0.8333333333333334, 189: 1.0, 190: 0.6666666666666666, 191: 0.4166666666666667, 192: 1.0, 193: 0.9166666666666666, 194: 0.8333333333333334, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.6666666666666666}

2025-01-13 05:03:40,782 [INFO] [45] TRAIN  loss: 0.8791437345251637 acc: 0.9975358077930079
2025-01-13 05:03:40,782 [INFO] [45] TRAIN  loss dict: {'classification_loss': 0.8791437345251637}
2025-01-13 05:03:40,783 [INFO] [45] VALIDATION loss: 1.607287638265677 VALIDATION acc: 0.8055555555555556
2025-01-13 05:03:40,783 [INFO] [45] VALIDATION loss dict: {'classification_loss': 1.607287638265677}
2025-01-13 05:03:40,783 [INFO] 
2025-01-13 05:04:01,609 [INFO] Step[50/4329]: training loss : 0.8748725736141205 TRAIN  loss dict:  {'classification_loss': 0.8748725736141205}
2025-01-13 05:04:13,396 [INFO] Step[100/4329]: training loss : 0.8911294591426849 TRAIN  loss dict:  {'classification_loss': 0.8911294591426849}
2025-01-13 05:04:24,976 [INFO] Step[150/4329]: training loss : 0.8761679542064666 TRAIN  loss dict:  {'classification_loss': 0.8761679542064666}
2025-01-13 05:04:36,590 [INFO] Step[200/4329]: training loss : 0.8718005096912385 TRAIN  loss dict:  {'classification_loss': 0.8718005096912385}
2025-01-13 05:04:48,208 [INFO] Step[250/4329]: training loss : 0.870286602973938 TRAIN  loss dict:  {'classification_loss': 0.870286602973938}
2025-01-13 05:04:59,849 [INFO] Step[300/4329]: training loss : 0.8816136586666107 TRAIN  loss dict:  {'classification_loss': 0.8816136586666107}
2025-01-13 05:05:11,504 [INFO] Step[350/4329]: training loss : 0.8833676755428315 TRAIN  loss dict:  {'classification_loss': 0.8833676755428315}
2025-01-13 05:05:23,109 [INFO] Step[400/4329]: training loss : 0.8787367475032807 TRAIN  loss dict:  {'classification_loss': 0.8787367475032807}
2025-01-13 05:05:34,780 [INFO] Step[450/4329]: training loss : 0.8798441338539124 TRAIN  loss dict:  {'classification_loss': 0.8798441338539124}
2025-01-13 05:05:46,434 [INFO] Step[500/4329]: training loss : 0.8810579907894135 TRAIN  loss dict:  {'classification_loss': 0.8810579907894135}
2025-01-13 05:05:58,092 [INFO] Step[550/4329]: training loss : 0.8738755369186402 TRAIN  loss dict:  {'classification_loss': 0.8738755369186402}
2025-01-13 05:06:09,662 [INFO] Step[600/4329]: training loss : 0.876706634759903 TRAIN  loss dict:  {'classification_loss': 0.876706634759903}
2025-01-13 05:06:21,296 [INFO] Step[650/4329]: training loss : 0.8704137206077576 TRAIN  loss dict:  {'classification_loss': 0.8704137206077576}
2025-01-13 05:06:32,900 [INFO] Step[700/4329]: training loss : 0.8716573476791382 TRAIN  loss dict:  {'classification_loss': 0.8716573476791382}
2025-01-13 05:06:44,545 [INFO] Step[750/4329]: training loss : 0.8828119766712189 TRAIN  loss dict:  {'classification_loss': 0.8828119766712189}
2025-01-13 05:06:56,190 [INFO] Step[800/4329]: training loss : 0.8710923373699189 TRAIN  loss dict:  {'classification_loss': 0.8710923373699189}
2025-01-13 05:07:07,805 [INFO] Step[850/4329]: training loss : 0.8980780875682831 TRAIN  loss dict:  {'classification_loss': 0.8980780875682831}
2025-01-13 05:07:19,436 [INFO] Step[900/4329]: training loss : 0.8658269798755646 TRAIN  loss dict:  {'classification_loss': 0.8658269798755646}
2025-01-13 05:07:31,057 [INFO] Step[950/4329]: training loss : 0.8675432085990906 TRAIN  loss dict:  {'classification_loss': 0.8675432085990906}
2025-01-13 05:07:42,670 [INFO] Step[1000/4329]: training loss : 0.8767651927471161 TRAIN  loss dict:  {'classification_loss': 0.8767651927471161}
2025-01-13 05:07:54,298 [INFO] Step[1050/4329]: training loss : 0.8746192181110382 TRAIN  loss dict:  {'classification_loss': 0.8746192181110382}
2025-01-13 05:08:05,883 [INFO] Step[1100/4329]: training loss : 0.8906523656845092 TRAIN  loss dict:  {'classification_loss': 0.8906523656845092}
2025-01-13 05:08:17,526 [INFO] Step[1150/4329]: training loss : 0.8875752472877503 TRAIN  loss dict:  {'classification_loss': 0.8875752472877503}
2025-01-13 05:08:29,159 [INFO] Step[1200/4329]: training loss : 0.8847074162960052 TRAIN  loss dict:  {'classification_loss': 0.8847074162960052}
2025-01-13 05:08:40,788 [INFO] Step[1250/4329]: training loss : 0.8881874752044677 TRAIN  loss dict:  {'classification_loss': 0.8881874752044677}
2025-01-13 05:08:52,392 [INFO] Step[1300/4329]: training loss : 0.8850070071220398 TRAIN  loss dict:  {'classification_loss': 0.8850070071220398}
2025-01-13 05:09:04,015 [INFO] Step[1350/4329]: training loss : 0.8697242152690887 TRAIN  loss dict:  {'classification_loss': 0.8697242152690887}
2025-01-13 05:09:15,618 [INFO] Step[1400/4329]: training loss : 0.8709134244918824 TRAIN  loss dict:  {'classification_loss': 0.8709134244918824}
2025-01-13 05:09:27,258 [INFO] Step[1450/4329]: training loss : 0.8901825261116028 TRAIN  loss dict:  {'classification_loss': 0.8901825261116028}
2025-01-13 05:09:38,879 [INFO] Step[1500/4329]: training loss : 0.898493891954422 TRAIN  loss dict:  {'classification_loss': 0.898493891954422}
2025-01-13 05:09:50,511 [INFO] Step[1550/4329]: training loss : 0.8768489170074463 TRAIN  loss dict:  {'classification_loss': 0.8768489170074463}
2025-01-13 05:10:02,143 [INFO] Step[1600/4329]: training loss : 0.869829330444336 TRAIN  loss dict:  {'classification_loss': 0.869829330444336}
2025-01-13 05:10:13,804 [INFO] Step[1650/4329]: training loss : 0.8715236186981201 TRAIN  loss dict:  {'classification_loss': 0.8715236186981201}
2025-01-13 05:10:25,374 [INFO] Step[1700/4329]: training loss : 0.8735576105117798 TRAIN  loss dict:  {'classification_loss': 0.8735576105117798}
2025-01-13 05:10:36,937 [INFO] Step[1750/4329]: training loss : 0.8869517540931702 TRAIN  loss dict:  {'classification_loss': 0.8869517540931702}
2025-01-13 05:10:48,547 [INFO] Step[1800/4329]: training loss : 0.8791724026203156 TRAIN  loss dict:  {'classification_loss': 0.8791724026203156}
2025-01-13 05:11:00,171 [INFO] Step[1850/4329]: training loss : 0.8744157814979553 TRAIN  loss dict:  {'classification_loss': 0.8744157814979553}
2025-01-13 05:11:11,811 [INFO] Step[1900/4329]: training loss : 0.878962994813919 TRAIN  loss dict:  {'classification_loss': 0.878962994813919}
2025-01-13 05:11:23,421 [INFO] Step[1950/4329]: training loss : 0.8664322030544281 TRAIN  loss dict:  {'classification_loss': 0.8664322030544281}
2025-01-13 05:11:35,039 [INFO] Step[2000/4329]: training loss : 0.8771668422222137 TRAIN  loss dict:  {'classification_loss': 0.8771668422222137}
2025-01-13 05:11:46,689 [INFO] Step[2050/4329]: training loss : 0.8734525561332702 TRAIN  loss dict:  {'classification_loss': 0.8734525561332702}
2025-01-13 05:11:58,280 [INFO] Step[2100/4329]: training loss : 0.8882657277584076 TRAIN  loss dict:  {'classification_loss': 0.8882657277584076}
2025-01-13 05:12:09,910 [INFO] Step[2150/4329]: training loss : 0.8746101367473602 TRAIN  loss dict:  {'classification_loss': 0.8746101367473602}
2025-01-13 05:12:21,521 [INFO] Step[2200/4329]: training loss : 0.8728481411933899 TRAIN  loss dict:  {'classification_loss': 0.8728481411933899}
2025-01-13 05:12:33,173 [INFO] Step[2250/4329]: training loss : 0.8824449920654297 TRAIN  loss dict:  {'classification_loss': 0.8824449920654297}
2025-01-13 05:12:44,789 [INFO] Step[2300/4329]: training loss : 0.8869632756710053 TRAIN  loss dict:  {'classification_loss': 0.8869632756710053}
2025-01-13 05:12:56,418 [INFO] Step[2350/4329]: training loss : 0.8922760224342347 TRAIN  loss dict:  {'classification_loss': 0.8922760224342347}
2025-01-13 05:13:08,075 [INFO] Step[2400/4329]: training loss : 0.8767822682857513 TRAIN  loss dict:  {'classification_loss': 0.8767822682857513}
2025-01-13 05:13:19,704 [INFO] Step[2450/4329]: training loss : 0.8779045474529267 TRAIN  loss dict:  {'classification_loss': 0.8779045474529267}
2025-01-13 05:13:31,334 [INFO] Step[2500/4329]: training loss : 0.8716722786426544 TRAIN  loss dict:  {'classification_loss': 0.8716722786426544}
2025-01-13 05:13:42,991 [INFO] Step[2550/4329]: training loss : 0.8792322909832001 TRAIN  loss dict:  {'classification_loss': 0.8792322909832001}
2025-01-13 05:13:54,592 [INFO] Step[2600/4329]: training loss : 0.8826539289951324 TRAIN  loss dict:  {'classification_loss': 0.8826539289951324}
2025-01-13 05:14:06,241 [INFO] Step[2650/4329]: training loss : 0.8742016565799713 TRAIN  loss dict:  {'classification_loss': 0.8742016565799713}
2025-01-13 05:14:17,887 [INFO] Step[2700/4329]: training loss : 0.8767395389080047 TRAIN  loss dict:  {'classification_loss': 0.8767395389080047}
2025-01-13 05:14:29,543 [INFO] Step[2750/4329]: training loss : 0.8772016417980194 TRAIN  loss dict:  {'classification_loss': 0.8772016417980194}
2025-01-13 05:14:41,187 [INFO] Step[2800/4329]: training loss : 0.8878861999511719 TRAIN  loss dict:  {'classification_loss': 0.8878861999511719}
2025-01-13 05:14:52,796 [INFO] Step[2850/4329]: training loss : 0.8795883083343505 TRAIN  loss dict:  {'classification_loss': 0.8795883083343505}
2025-01-13 05:15:04,456 [INFO] Step[2900/4329]: training loss : 0.8720436859130859 TRAIN  loss dict:  {'classification_loss': 0.8720436859130859}
2025-01-13 05:15:16,685 [INFO] Step[2950/4329]: training loss : 0.8828460729122162 TRAIN  loss dict:  {'classification_loss': 0.8828460729122162}
2025-01-13 05:15:28,972 [INFO] Step[3000/4329]: training loss : 0.8774026584625244 TRAIN  loss dict:  {'classification_loss': 0.8774026584625244}
2025-01-13 05:15:41,877 [INFO] Step[3050/4329]: training loss : 0.8732677090168 TRAIN  loss dict:  {'classification_loss': 0.8732677090168}
2025-01-13 05:15:55,792 [INFO] Step[3100/4329]: training loss : 0.8762004041671753 TRAIN  loss dict:  {'classification_loss': 0.8762004041671753}
2025-01-13 05:16:10,600 [INFO] Step[3150/4329]: training loss : 0.8837112188339233 TRAIN  loss dict:  {'classification_loss': 0.8837112188339233}
2025-01-13 05:16:22,535 [INFO] Step[3200/4329]: training loss : 0.8743136239051819 TRAIN  loss dict:  {'classification_loss': 0.8743136239051819}
2025-01-13 05:16:34,462 [INFO] Step[3250/4329]: training loss : 0.8784139919281005 TRAIN  loss dict:  {'classification_loss': 0.8784139919281005}
2025-01-13 05:16:46,057 [INFO] Step[3300/4329]: training loss : 0.8821876204013824 TRAIN  loss dict:  {'classification_loss': 0.8821876204013824}
2025-01-13 05:16:57,660 [INFO] Step[3350/4329]: training loss : 0.8775505876541138 TRAIN  loss dict:  {'classification_loss': 0.8775505876541138}
2025-01-13 05:17:09,220 [INFO] Step[3400/4329]: training loss : 0.8826395392417907 TRAIN  loss dict:  {'classification_loss': 0.8826395392417907}
2025-01-13 05:17:20,841 [INFO] Step[3450/4329]: training loss : 0.8716721951961517 TRAIN  loss dict:  {'classification_loss': 0.8716721951961517}
2025-01-13 05:17:32,474 [INFO] Step[3500/4329]: training loss : 0.8744732284545899 TRAIN  loss dict:  {'classification_loss': 0.8744732284545899}
2025-01-13 05:17:44,141 [INFO] Step[3550/4329]: training loss : 0.878895993232727 TRAIN  loss dict:  {'classification_loss': 0.878895993232727}
2025-01-13 05:17:55,761 [INFO] Step[3600/4329]: training loss : 0.8886655580997467 TRAIN  loss dict:  {'classification_loss': 0.8886655580997467}
2025-01-13 05:18:07,366 [INFO] Step[3650/4329]: training loss : 0.8772349393367768 TRAIN  loss dict:  {'classification_loss': 0.8772349393367768}
2025-01-13 05:18:18,954 [INFO] Step[3700/4329]: training loss : 0.8772928714752197 TRAIN  loss dict:  {'classification_loss': 0.8772928714752197}
2025-01-13 05:18:30,580 [INFO] Step[3750/4329]: training loss : 0.8729283332824707 TRAIN  loss dict:  {'classification_loss': 0.8729283332824707}
2025-01-13 05:18:42,211 [INFO] Step[3800/4329]: training loss : 0.8717784559726716 TRAIN  loss dict:  {'classification_loss': 0.8717784559726716}
2025-01-13 05:18:53,840 [INFO] Step[3850/4329]: training loss : 0.8939558601379395 TRAIN  loss dict:  {'classification_loss': 0.8939558601379395}
2025-01-13 05:19:05,467 [INFO] Step[3900/4329]: training loss : 0.8943832969665527 TRAIN  loss dict:  {'classification_loss': 0.8943832969665527}
2025-01-13 05:19:17,064 [INFO] Step[3950/4329]: training loss : 0.87673499584198 TRAIN  loss dict:  {'classification_loss': 0.87673499584198}
2025-01-13 05:19:28,706 [INFO] Step[4000/4329]: training loss : 0.8832299673557281 TRAIN  loss dict:  {'classification_loss': 0.8832299673557281}
2025-01-13 05:19:40,390 [INFO] Step[4050/4329]: training loss : 0.8891004681587219 TRAIN  loss dict:  {'classification_loss': 0.8891004681587219}
2025-01-13 05:19:52,021 [INFO] Step[4100/4329]: training loss : 0.8753117525577545 TRAIN  loss dict:  {'classification_loss': 0.8753117525577545}
2025-01-13 05:20:03,660 [INFO] Step[4150/4329]: training loss : 0.8683021688461303 TRAIN  loss dict:  {'classification_loss': 0.8683021688461303}
2025-01-13 05:20:15,260 [INFO] Step[4200/4329]: training loss : 0.8739026892185211 TRAIN  loss dict:  {'classification_loss': 0.8739026892185211}
2025-01-13 05:20:26,867 [INFO] Step[4250/4329]: training loss : 0.8761870217323303 TRAIN  loss dict:  {'classification_loss': 0.8761870217323303}
2025-01-13 05:20:38,494 [INFO] Step[4300/4329]: training loss : 0.8775202178955078 TRAIN  loss dict:  {'classification_loss': 0.8775202178955078}
2025-01-13 05:22:37,246 [INFO] Label accuracies statistics:
2025-01-13 05:22:37,246 [INFO] {0: 0.6666666666666666, 1: 0.7777777777777778, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.3333333333333333, 5: 0.9166666666666666, 6: 0.5, 7: 0.5833333333333334, 8: 0.5, 9: 0.8333333333333334, 10: 1.0, 11: 0.9166666666666666, 12: 0.5, 13: 0.4166666666666667, 14: 0.75, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.5, 18: 0.4166666666666667, 19: 0.8333333333333334, 20: 0.6666666666666666, 21: 0.6666666666666666, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.8333333333333334, 26: 0.9166666666666666, 27: 0.5833333333333334, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.75, 32: 0.75, 33: 0.8333333333333334, 34: 1.0, 35: 0.9166666666666666, 36: 0.5, 37: 0.9166666666666666, 38: 1.0, 39: 1.0, 40: 0.9166666666666666, 41: 0.5833333333333334, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.6666666666666666, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.5833333333333334, 54: 0.5, 55: 0.6666666666666666, 56: 0.6666666666666666, 57: 0.75, 58: 0.5833333333333334, 59: 0.9166666666666666, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.9166666666666666, 68: 0.75, 69: 0.6666666666666666, 70: 0.4166666666666667, 71: 0.6666666666666666, 72: 0.9166666666666666, 73: 1.0, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 0.9166666666666666, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.6666666666666666, 84: 0.6666666666666666, 85: 0.8333333333333334, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.75, 89: 0.5833333333333334, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 0.9166666666666666, 96: 0.5833333333333334, 97: 0.5833333333333334, 98: 0.8333333333333334, 99: 1.0, 100: 0.75, 101: 1.0, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.6666666666666666, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 0.9166666666666666, 111: 1.0, 112: 0.9166666666666666, 113: 0.4166666666666667, 114: 0.5, 115: 1.0, 116: 0.8333333333333334, 117: 0.8333333333333334, 118: 1.0, 119: 0.75, 120: 0.6666666666666666, 121: 0.75, 122: 0.9166666666666666, 123: 0.9166666666666666, 124: 0.9166666666666666, 125: 0.9166666666666666, 126: 0.75, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.9166666666666666, 131: 0.9166666666666666, 132: 0.4166666666666667, 133: 1.0, 134: 0.8333333333333334, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 0.8333333333333334, 142: 0.8333333333333334, 143: 1.0, 144: 0.5833333333333334, 145: 1.0, 146: 1.0, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.9166666666666666, 158: 0.7777777777777778, 159: 1.0, 160: 0.25, 161: 0.9166666666666666, 162: 0.9166666666666666, 163: 1.0, 164: 0.9166666666666666, 165: 0.9166666666666666, 166: 0.6666666666666666, 167: 0.6666666666666666, 168: 0.9166666666666666, 169: 0.8333333333333334, 170: 1.0, 171: 0.75, 172: 1.0, 173: 0.8333333333333334, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.9166666666666666, 178: 0.9166666666666666, 179: 0.4444444444444444, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.4166666666666667, 183: 0.8333333333333334, 184: 0.75, 185: 1.0, 186: 0.9166666666666666, 187: 0.9166666666666666, 188: 0.5833333333333334, 189: 1.0, 190: 0.6666666666666666, 191: 0.5, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.6666666666666666}

2025-01-13 05:22:37,248 [INFO] [46] TRAIN  loss: 0.878870660712356 acc: 0.9973047897736024
2025-01-13 05:22:37,248 [INFO] [46] TRAIN  loss dict: {'classification_loss': 0.878870660712356}
2025-01-13 05:22:37,248 [INFO] [46] VALIDATION loss: 1.5922309627587146 VALIDATION acc: 0.8106060606060606
2025-01-13 05:22:37,248 [INFO] [46] VALIDATION loss dict: {'classification_loss': 1.5922309627587146}
2025-01-13 05:22:37,248 [INFO] 
2025-01-13 05:22:55,239 [INFO] Step[50/4329]: training loss : 0.8735532164573669 TRAIN  loss dict:  {'classification_loss': 0.8735532164573669}
2025-01-13 05:23:06,782 [INFO] Step[100/4329]: training loss : 0.8815378057956695 TRAIN  loss dict:  {'classification_loss': 0.8815378057956695}
2025-01-13 05:23:18,356 [INFO] Step[150/4329]: training loss : 0.8766107523441314 TRAIN  loss dict:  {'classification_loss': 0.8766107523441314}
2025-01-13 05:23:29,963 [INFO] Step[200/4329]: training loss : 0.8673878252506256 TRAIN  loss dict:  {'classification_loss': 0.8673878252506256}
2025-01-13 05:23:41,547 [INFO] Step[250/4329]: training loss : 0.8693605279922485 TRAIN  loss dict:  {'classification_loss': 0.8693605279922485}
2025-01-13 05:23:53,171 [INFO] Step[300/4329]: training loss : 0.8817560911178589 TRAIN  loss dict:  {'classification_loss': 0.8817560911178589}
2025-01-13 05:24:04,820 [INFO] Step[350/4329]: training loss : 0.873841826915741 TRAIN  loss dict:  {'classification_loss': 0.873841826915741}
2025-01-13 05:24:16,455 [INFO] Step[400/4329]: training loss : 0.8719790577888489 TRAIN  loss dict:  {'classification_loss': 0.8719790577888489}
2025-01-13 05:24:28,096 [INFO] Step[450/4329]: training loss : 0.8800632524490356 TRAIN  loss dict:  {'classification_loss': 0.8800632524490356}
2025-01-13 05:24:39,737 [INFO] Step[500/4329]: training loss : 0.881341655254364 TRAIN  loss dict:  {'classification_loss': 0.881341655254364}
2025-01-13 05:24:51,367 [INFO] Step[550/4329]: training loss : 0.8770714437961579 TRAIN  loss dict:  {'classification_loss': 0.8770714437961579}
2025-01-13 05:25:02,969 [INFO] Step[600/4329]: training loss : 0.8902301740646362 TRAIN  loss dict:  {'classification_loss': 0.8902301740646362}
2025-01-13 05:25:14,577 [INFO] Step[650/4329]: training loss : 0.8739313101768493 TRAIN  loss dict:  {'classification_loss': 0.8739313101768493}
2025-01-13 05:25:26,231 [INFO] Step[700/4329]: training loss : 0.8768658256530761 TRAIN  loss dict:  {'classification_loss': 0.8768658256530761}
2025-01-13 05:25:37,815 [INFO] Step[750/4329]: training loss : 0.8960460352897645 TRAIN  loss dict:  {'classification_loss': 0.8960460352897645}
2025-01-13 05:25:49,506 [INFO] Step[800/4329]: training loss : 0.8781424510478973 TRAIN  loss dict:  {'classification_loss': 0.8781424510478973}
2025-01-13 05:26:01,089 [INFO] Step[850/4329]: training loss : 0.8704292011260987 TRAIN  loss dict:  {'classification_loss': 0.8704292011260987}
2025-01-13 05:26:12,703 [INFO] Step[900/4329]: training loss : 0.8945024144649506 TRAIN  loss dict:  {'classification_loss': 0.8945024144649506}
2025-01-13 05:26:24,340 [INFO] Step[950/4329]: training loss : 0.8706058859825134 TRAIN  loss dict:  {'classification_loss': 0.8706058859825134}
2025-01-13 05:26:35,982 [INFO] Step[1000/4329]: training loss : 0.8732088589668274 TRAIN  loss dict:  {'classification_loss': 0.8732088589668274}
2025-01-13 05:26:47,596 [INFO] Step[1050/4329]: training loss : 0.8755419063568115 TRAIN  loss dict:  {'classification_loss': 0.8755419063568115}
2025-01-13 05:26:59,209 [INFO] Step[1100/4329]: training loss : 0.8699016070365906 TRAIN  loss dict:  {'classification_loss': 0.8699016070365906}
2025-01-13 05:27:10,865 [INFO] Step[1150/4329]: training loss : 0.8869607615470886 TRAIN  loss dict:  {'classification_loss': 0.8869607615470886}
2025-01-13 05:27:22,459 [INFO] Step[1200/4329]: training loss : 0.8762447667121888 TRAIN  loss dict:  {'classification_loss': 0.8762447667121888}
2025-01-13 05:27:34,278 [INFO] Step[1250/4329]: training loss : 0.8764024639129638 TRAIN  loss dict:  {'classification_loss': 0.8764024639129638}
2025-01-13 05:27:46,640 [INFO] Step[1300/4329]: training loss : 0.8814634537696838 TRAIN  loss dict:  {'classification_loss': 0.8814634537696838}
2025-01-13 05:27:58,943 [INFO] Step[1350/4329]: training loss : 0.8737125968933106 TRAIN  loss dict:  {'classification_loss': 0.8737125968933106}
2025-01-13 05:28:12,095 [INFO] Step[1400/4329]: training loss : 0.8705213785171508 TRAIN  loss dict:  {'classification_loss': 0.8705213785171508}
2025-01-13 05:28:25,330 [INFO] Step[1450/4329]: training loss : 0.8732744789123535 TRAIN  loss dict:  {'classification_loss': 0.8732744789123535}
2025-01-13 05:28:37,884 [INFO] Step[1500/4329]: training loss : 0.8833215034008026 TRAIN  loss dict:  {'classification_loss': 0.8833215034008026}
2025-01-13 05:28:49,717 [INFO] Step[1550/4329]: training loss : 0.8827008616924286 TRAIN  loss dict:  {'classification_loss': 0.8827008616924286}
2025-01-13 05:29:01,584 [INFO] Step[1600/4329]: training loss : 0.8756419217586517 TRAIN  loss dict:  {'classification_loss': 0.8756419217586517}
2025-01-13 05:29:13,225 [INFO] Step[1650/4329]: training loss : 0.8693402183055877 TRAIN  loss dict:  {'classification_loss': 0.8693402183055877}
2025-01-13 05:29:24,839 [INFO] Step[1700/4329]: training loss : 0.8696183657646179 TRAIN  loss dict:  {'classification_loss': 0.8696183657646179}
2025-01-13 05:29:36,466 [INFO] Step[1750/4329]: training loss : 0.8723472833633423 TRAIN  loss dict:  {'classification_loss': 0.8723472833633423}
2025-01-13 05:29:48,114 [INFO] Step[1800/4329]: training loss : 0.8711553275585174 TRAIN  loss dict:  {'classification_loss': 0.8711553275585174}
2025-01-13 05:29:59,716 [INFO] Step[1850/4329]: training loss : 0.86784707903862 TRAIN  loss dict:  {'classification_loss': 0.86784707903862}
2025-01-13 05:30:11,365 [INFO] Step[1900/4329]: training loss : 0.8729704773426056 TRAIN  loss dict:  {'classification_loss': 0.8729704773426056}
2025-01-13 05:30:22,990 [INFO] Step[1950/4329]: training loss : 0.8759541177749633 TRAIN  loss dict:  {'classification_loss': 0.8759541177749633}
2025-01-13 05:30:34,611 [INFO] Step[2000/4329]: training loss : 0.8714558613300324 TRAIN  loss dict:  {'classification_loss': 0.8714558613300324}
2025-01-13 05:30:46,243 [INFO] Step[2050/4329]: training loss : 0.8838713729381561 TRAIN  loss dict:  {'classification_loss': 0.8838713729381561}
2025-01-13 05:30:57,841 [INFO] Step[2100/4329]: training loss : 0.8674932241439819 TRAIN  loss dict:  {'classification_loss': 0.8674932241439819}
2025-01-13 05:31:09,480 [INFO] Step[2150/4329]: training loss : 0.8833110857009888 TRAIN  loss dict:  {'classification_loss': 0.8833110857009888}
2025-01-13 05:31:21,046 [INFO] Step[2200/4329]: training loss : 0.8731084752082825 TRAIN  loss dict:  {'classification_loss': 0.8731084752082825}
2025-01-13 05:31:32,724 [INFO] Step[2250/4329]: training loss : 0.8688202917575836 TRAIN  loss dict:  {'classification_loss': 0.8688202917575836}
2025-01-13 05:31:44,342 [INFO] Step[2300/4329]: training loss : 0.8687465083599091 TRAIN  loss dict:  {'classification_loss': 0.8687465083599091}
2025-01-13 05:31:55,963 [INFO] Step[2350/4329]: training loss : 0.8663662707805634 TRAIN  loss dict:  {'classification_loss': 0.8663662707805634}
2025-01-13 05:32:07,596 [INFO] Step[2400/4329]: training loss : 0.8704208707809449 TRAIN  loss dict:  {'classification_loss': 0.8704208707809449}
2025-01-13 05:32:19,245 [INFO] Step[2450/4329]: training loss : 0.8760113680362701 TRAIN  loss dict:  {'classification_loss': 0.8760113680362701}
2025-01-13 05:32:30,884 [INFO] Step[2500/4329]: training loss : 0.8679235208034516 TRAIN  loss dict:  {'classification_loss': 0.8679235208034516}
2025-01-13 05:32:42,544 [INFO] Step[2550/4329]: training loss : 0.8676797497272491 TRAIN  loss dict:  {'classification_loss': 0.8676797497272491}
2025-01-13 05:32:54,170 [INFO] Step[2600/4329]: training loss : 0.8740260326862335 TRAIN  loss dict:  {'classification_loss': 0.8740260326862335}
2025-01-13 05:33:05,803 [INFO] Step[2650/4329]: training loss : 0.8813943183422088 TRAIN  loss dict:  {'classification_loss': 0.8813943183422088}
2025-01-13 05:33:17,431 [INFO] Step[2700/4329]: training loss : 0.8814589214324952 TRAIN  loss dict:  {'classification_loss': 0.8814589214324952}
2025-01-13 05:33:29,084 [INFO] Step[2750/4329]: training loss : 0.8692804336547851 TRAIN  loss dict:  {'classification_loss': 0.8692804336547851}
2025-01-13 05:33:40,684 [INFO] Step[2800/4329]: training loss : 0.8905396986007691 TRAIN  loss dict:  {'classification_loss': 0.8905396986007691}
2025-01-13 05:33:52,308 [INFO] Step[2850/4329]: training loss : 0.8738115239143371 TRAIN  loss dict:  {'classification_loss': 0.8738115239143371}
2025-01-13 05:34:03,957 [INFO] Step[2900/4329]: training loss : 0.8796322047710419 TRAIN  loss dict:  {'classification_loss': 0.8796322047710419}
2025-01-13 05:34:15,604 [INFO] Step[2950/4329]: training loss : 0.8754926979541778 TRAIN  loss dict:  {'classification_loss': 0.8754926979541778}
2025-01-13 05:34:27,184 [INFO] Step[3000/4329]: training loss : 0.8711937427520752 TRAIN  loss dict:  {'classification_loss': 0.8711937427520752}
2025-01-13 05:34:38,776 [INFO] Step[3050/4329]: training loss : 0.8834633898735046 TRAIN  loss dict:  {'classification_loss': 0.8834633898735046}
2025-01-13 05:34:50,430 [INFO] Step[3100/4329]: training loss : 0.8772925138473511 TRAIN  loss dict:  {'classification_loss': 0.8772925138473511}
2025-01-13 05:35:02,072 [INFO] Step[3150/4329]: training loss : 0.8772204792499543 TRAIN  loss dict:  {'classification_loss': 0.8772204792499543}
2025-01-13 05:35:13,647 [INFO] Step[3200/4329]: training loss : 0.8746880686283112 TRAIN  loss dict:  {'classification_loss': 0.8746880686283112}
2025-01-13 05:35:25,253 [INFO] Step[3250/4329]: training loss : 0.8745282173156739 TRAIN  loss dict:  {'classification_loss': 0.8745282173156739}
2025-01-13 05:35:36,875 [INFO] Step[3300/4329]: training loss : 0.8777413618564606 TRAIN  loss dict:  {'classification_loss': 0.8777413618564606}
2025-01-13 05:35:48,538 [INFO] Step[3350/4329]: training loss : 0.8787021684646606 TRAIN  loss dict:  {'classification_loss': 0.8787021684646606}
2025-01-13 05:36:00,140 [INFO] Step[3400/4329]: training loss : 0.882552125453949 TRAIN  loss dict:  {'classification_loss': 0.882552125453949}
2025-01-13 05:36:11,791 [INFO] Step[3450/4329]: training loss : 0.8701931166648865 TRAIN  loss dict:  {'classification_loss': 0.8701931166648865}
2025-01-13 05:36:23,408 [INFO] Step[3500/4329]: training loss : 0.8729095208644867 TRAIN  loss dict:  {'classification_loss': 0.8729095208644867}
2025-01-13 05:36:35,010 [INFO] Step[3550/4329]: training loss : 0.872332684993744 TRAIN  loss dict:  {'classification_loss': 0.872332684993744}
2025-01-13 05:36:46,600 [INFO] Step[3600/4329]: training loss : 0.8696357429027557 TRAIN  loss dict:  {'classification_loss': 0.8696357429027557}
2025-01-13 05:36:58,230 [INFO] Step[3650/4329]: training loss : 0.8735880303382874 TRAIN  loss dict:  {'classification_loss': 0.8735880303382874}
2025-01-13 05:37:09,857 [INFO] Step[3700/4329]: training loss : 0.8932309794425964 TRAIN  loss dict:  {'classification_loss': 0.8932309794425964}
2025-01-13 05:37:21,493 [INFO] Step[3750/4329]: training loss : 0.8794176518917084 TRAIN  loss dict:  {'classification_loss': 0.8794176518917084}
2025-01-13 05:37:33,116 [INFO] Step[3800/4329]: training loss : 0.8722244262695312 TRAIN  loss dict:  {'classification_loss': 0.8722244262695312}
2025-01-13 05:37:44,760 [INFO] Step[3850/4329]: training loss : 0.8825808823108673 TRAIN  loss dict:  {'classification_loss': 0.8825808823108673}
2025-01-13 05:37:56,367 [INFO] Step[3900/4329]: training loss : 0.8708202135562897 TRAIN  loss dict:  {'classification_loss': 0.8708202135562897}
2025-01-13 05:38:07,990 [INFO] Step[3950/4329]: training loss : 0.8691634917259217 TRAIN  loss dict:  {'classification_loss': 0.8691634917259217}
2025-01-13 05:38:19,584 [INFO] Step[4000/4329]: training loss : 0.8799576306343079 TRAIN  loss dict:  {'classification_loss': 0.8799576306343079}
2025-01-13 05:38:31,229 [INFO] Step[4050/4329]: training loss : 0.8707447564601898 TRAIN  loss dict:  {'classification_loss': 0.8707447564601898}
2025-01-13 05:38:42,837 [INFO] Step[4100/4329]: training loss : 0.8738580513000488 TRAIN  loss dict:  {'classification_loss': 0.8738580513000488}
2025-01-13 05:38:54,495 [INFO] Step[4150/4329]: training loss : 0.8716395735740662 TRAIN  loss dict:  {'classification_loss': 0.8716395735740662}
2025-01-13 05:39:06,096 [INFO] Step[4200/4329]: training loss : 0.9054632103443145 TRAIN  loss dict:  {'classification_loss': 0.9054632103443145}
2025-01-13 05:39:17,728 [INFO] Step[4250/4329]: training loss : 0.8852554070949554 TRAIN  loss dict:  {'classification_loss': 0.8852554070949554}
2025-01-13 05:39:29,359 [INFO] Step[4300/4329]: training loss : 0.8835386824607849 TRAIN  loss dict:  {'classification_loss': 0.8835386824607849}
2025-01-13 05:41:59,307 [INFO] Label accuracies statistics:
2025-01-13 05:41:59,308 [INFO] {0: 0.4444444444444444, 1: 1.0, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.3333333333333333, 5: 0.9166666666666666, 6: 0.5833333333333334, 7: 0.5, 8: 0.4166666666666667, 9: 0.9166666666666666, 10: 1.0, 11: 0.9166666666666666, 12: 0.3333333333333333, 13: 0.5833333333333334, 14: 0.6666666666666666, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.5833333333333334, 18: 0.6666666666666666, 19: 0.8333333333333334, 20: 0.5, 21: 0.6666666666666666, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.9166666666666666, 27: 0.5833333333333334, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.75, 32: 0.6666666666666666, 33: 0.9166666666666666, 34: 1.0, 35: 1.0, 36: 0.5, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.8333333333333334, 41: 0.5, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.6666666666666666, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 0.9166666666666666, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.4166666666666667, 54: 0.5, 55: 0.6666666666666666, 56: 0.6666666666666666, 57: 0.75, 58: 0.5833333333333334, 59: 0.9166666666666666, 60: 0.5833333333333334, 61: 0.8333333333333334, 62: 0.6666666666666666, 63: 0.6666666666666666, 64: 0.9166666666666666, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.8333333333333334, 69: 0.5833333333333334, 70: 0.5833333333333334, 71: 0.5833333333333334, 72: 0.8333333333333334, 73: 0.8333333333333334, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.8333333333333334, 83: 0.6666666666666666, 84: 0.5833333333333334, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.75, 89: 0.6666666666666666, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.6666666666666666, 97: 0.5833333333333334, 98: 0.75, 99: 1.0, 100: 0.8333333333333334, 101: 1.0, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 0.9166666666666666, 106: 0.9166666666666666, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.8333333333333334, 111: 0.9166666666666666, 112: 1.0, 113: 0.3333333333333333, 114: 0.5833333333333334, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.8333333333333334, 120: 0.6666666666666666, 121: 0.9166666666666666, 122: 0.9166666666666666, 123: 0.8333333333333334, 124: 1.0, 125: 0.8333333333333334, 126: 0.8333333333333334, 127: 0.75, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.9166666666666666, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 1.0, 141: 0.8333333333333334, 142: 0.8333333333333334, 143: 1.0, 144: 0.75, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.5, 151: 0.8333333333333334, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.8333333333333334, 158: 0.7777777777777778, 159: 1.0, 160: 0.4166666666666667, 161: 0.8333333333333334, 162: 0.9166666666666666, 163: 0.8333333333333334, 164: 0.8333333333333334, 165: 0.75, 166: 0.8333333333333334, 167: 0.75, 168: 0.8333333333333334, 169: 0.9166666666666666, 170: 0.9166666666666666, 171: 0.5, 172: 1.0, 173: 0.9166666666666666, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 0.9166666666666666, 177: 0.75, 178: 0.9166666666666666, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.5833333333333334, 183: 0.75, 184: 0.6666666666666666, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.5, 189: 1.0, 190: 0.6666666666666666, 191: 0.4166666666666667, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.8333333333333334, 196: 1.0, 197: 0.75, 198: 0.75}

2025-01-13 05:41:59,311 [INFO] [47] TRAIN  loss: 0.8764116772605189 acc: 0.9982288618512244
2025-01-13 05:41:59,311 [INFO] [47] TRAIN  loss dict: {'classification_loss': 0.8764116772605189}
2025-01-13 05:41:59,311 [INFO] [47] VALIDATION loss: 1.6200806190720711 VALIDATION acc: 0.8063973063973064
2025-01-13 05:41:59,311 [INFO] [47] VALIDATION loss dict: {'classification_loss': 1.6200806190720711}
2025-01-13 05:41:59,312 [INFO] 
2025-01-13 05:42:16,530 [INFO] Step[50/4329]: training loss : 0.883408226966858 TRAIN  loss dict:  {'classification_loss': 0.883408226966858}
2025-01-13 05:42:28,135 [INFO] Step[100/4329]: training loss : 0.8711192739009858 TRAIN  loss dict:  {'classification_loss': 0.8711192739009858}
2025-01-13 05:42:39,771 [INFO] Step[150/4329]: training loss : 0.8862029707431793 TRAIN  loss dict:  {'classification_loss': 0.8862029707431793}
2025-01-13 05:42:51,376 [INFO] Step[200/4329]: training loss : 0.8747418749332428 TRAIN  loss dict:  {'classification_loss': 0.8747418749332428}
2025-01-13 05:43:02,968 [INFO] Step[250/4329]: training loss : 0.8756987094879151 TRAIN  loss dict:  {'classification_loss': 0.8756987094879151}
2025-01-13 05:43:14,557 [INFO] Step[300/4329]: training loss : 0.8749893462657928 TRAIN  loss dict:  {'classification_loss': 0.8749893462657928}
2025-01-13 05:43:26,190 [INFO] Step[350/4329]: training loss : 0.8816437494754791 TRAIN  loss dict:  {'classification_loss': 0.8816437494754791}
2025-01-13 05:43:37,837 [INFO] Step[400/4329]: training loss : 0.8747193658351898 TRAIN  loss dict:  {'classification_loss': 0.8747193658351898}
2025-01-13 05:43:49,488 [INFO] Step[450/4329]: training loss : 0.8721691071987152 TRAIN  loss dict:  {'classification_loss': 0.8721691071987152}
2025-01-13 05:44:01,085 [INFO] Step[500/4329]: training loss : 0.8712035119533539 TRAIN  loss dict:  {'classification_loss': 0.8712035119533539}
2025-01-13 05:44:12,711 [INFO] Step[550/4329]: training loss : 0.8877225112915039 TRAIN  loss dict:  {'classification_loss': 0.8877225112915039}
2025-01-13 05:44:24,326 [INFO] Step[600/4329]: training loss : 0.8737084341049194 TRAIN  loss dict:  {'classification_loss': 0.8737084341049194}
2025-01-13 05:44:36,029 [INFO] Step[650/4329]: training loss : 0.8695913779735566 TRAIN  loss dict:  {'classification_loss': 0.8695913779735566}
2025-01-13 05:44:47,673 [INFO] Step[700/4329]: training loss : 0.8829183053970336 TRAIN  loss dict:  {'classification_loss': 0.8829183053970336}
2025-01-13 05:44:59,271 [INFO] Step[750/4329]: training loss : 0.8821555280685425 TRAIN  loss dict:  {'classification_loss': 0.8821555280685425}
2025-01-13 05:45:10,888 [INFO] Step[800/4329]: training loss : 0.9022918701171875 TRAIN  loss dict:  {'classification_loss': 0.9022918701171875}
2025-01-13 05:45:22,500 [INFO] Step[850/4329]: training loss : 0.8701674795150757 TRAIN  loss dict:  {'classification_loss': 0.8701674795150757}
2025-01-13 05:45:34,133 [INFO] Step[900/4329]: training loss : 0.8731447005271912 TRAIN  loss dict:  {'classification_loss': 0.8731447005271912}
2025-01-13 05:45:45,744 [INFO] Step[950/4329]: training loss : 0.8781442224979401 TRAIN  loss dict:  {'classification_loss': 0.8781442224979401}
2025-01-13 05:45:57,364 [INFO] Step[1000/4329]: training loss : 0.8687269401550293 TRAIN  loss dict:  {'classification_loss': 0.8687269401550293}
2025-01-13 05:46:09,008 [INFO] Step[1050/4329]: training loss : 0.8812749683856964 TRAIN  loss dict:  {'classification_loss': 0.8812749683856964}
2025-01-13 05:46:20,592 [INFO] Step[1100/4329]: training loss : 0.8667255890369415 TRAIN  loss dict:  {'classification_loss': 0.8667255890369415}
2025-01-13 05:46:32,205 [INFO] Step[1150/4329]: training loss : 0.8749367928504944 TRAIN  loss dict:  {'classification_loss': 0.8749367928504944}
2025-01-13 05:46:43,800 [INFO] Step[1200/4329]: training loss : 0.876760779619217 TRAIN  loss dict:  {'classification_loss': 0.876760779619217}
2025-01-13 05:46:55,424 [INFO] Step[1250/4329]: training loss : 0.8746478140354157 TRAIN  loss dict:  {'classification_loss': 0.8746478140354157}
2025-01-13 05:47:07,082 [INFO] Step[1300/4329]: training loss : 0.8818082797527313 TRAIN  loss dict:  {'classification_loss': 0.8818082797527313}
2025-01-13 05:47:18,709 [INFO] Step[1350/4329]: training loss : 0.8724689018726349 TRAIN  loss dict:  {'classification_loss': 0.8724689018726349}
2025-01-13 05:47:30,351 [INFO] Step[1400/4329]: training loss : 0.8689282369613648 TRAIN  loss dict:  {'classification_loss': 0.8689282369613648}
2025-01-13 05:47:42,019 [INFO] Step[1450/4329]: training loss : 0.8810761857032776 TRAIN  loss dict:  {'classification_loss': 0.8810761857032776}
2025-01-13 05:47:53,612 [INFO] Step[1500/4329]: training loss : 0.8710063576698304 TRAIN  loss dict:  {'classification_loss': 0.8710063576698304}
2025-01-13 05:48:05,204 [INFO] Step[1550/4329]: training loss : 0.8950508272647858 TRAIN  loss dict:  {'classification_loss': 0.8950508272647858}
2025-01-13 05:48:16,804 [INFO] Step[1600/4329]: training loss : 0.8843716382980347 TRAIN  loss dict:  {'classification_loss': 0.8843716382980347}
2025-01-13 05:48:28,457 [INFO] Step[1650/4329]: training loss : 0.8686874425411224 TRAIN  loss dict:  {'classification_loss': 0.8686874425411224}
2025-01-13 05:48:40,066 [INFO] Step[1700/4329]: training loss : 0.8706914174556732 TRAIN  loss dict:  {'classification_loss': 0.8706914174556732}
2025-01-13 05:48:51,695 [INFO] Step[1750/4329]: training loss : 0.8702274608612061 TRAIN  loss dict:  {'classification_loss': 0.8702274608612061}
2025-01-13 05:49:03,315 [INFO] Step[1800/4329]: training loss : 0.8761401534080505 TRAIN  loss dict:  {'classification_loss': 0.8761401534080505}
2025-01-13 05:49:15,020 [INFO] Step[1850/4329]: training loss : 0.8696624457836151 TRAIN  loss dict:  {'classification_loss': 0.8696624457836151}
2025-01-13 05:49:26,654 [INFO] Step[1900/4329]: training loss : 0.884645426273346 TRAIN  loss dict:  {'classification_loss': 0.884645426273346}
2025-01-13 05:49:38,308 [INFO] Step[1950/4329]: training loss : 0.8696094429492951 TRAIN  loss dict:  {'classification_loss': 0.8696094429492951}
2025-01-13 05:49:49,919 [INFO] Step[2000/4329]: training loss : 0.876219574213028 TRAIN  loss dict:  {'classification_loss': 0.876219574213028}
2025-01-13 05:50:01,536 [INFO] Step[2050/4329]: training loss : 0.8767310392856598 TRAIN  loss dict:  {'classification_loss': 0.8767310392856598}
2025-01-13 05:50:13,129 [INFO] Step[2100/4329]: training loss : 0.8700286936759949 TRAIN  loss dict:  {'classification_loss': 0.8700286936759949}
2025-01-13 05:50:24,769 [INFO] Step[2150/4329]: training loss : 0.8695386719703674 TRAIN  loss dict:  {'classification_loss': 0.8695386719703674}
2025-01-13 05:50:36,365 [INFO] Step[2200/4329]: training loss : 0.8760544407367706 TRAIN  loss dict:  {'classification_loss': 0.8760544407367706}
2025-01-13 05:50:47,976 [INFO] Step[2250/4329]: training loss : 0.8741985964775085 TRAIN  loss dict:  {'classification_loss': 0.8741985964775085}
2025-01-13 05:50:59,574 [INFO] Step[2300/4329]: training loss : 0.8776165461540222 TRAIN  loss dict:  {'classification_loss': 0.8776165461540222}
2025-01-13 05:51:11,217 [INFO] Step[2350/4329]: training loss : 0.8682380867004394 TRAIN  loss dict:  {'classification_loss': 0.8682380867004394}
2025-01-13 05:51:22,822 [INFO] Step[2400/4329]: training loss : 0.8738387751579285 TRAIN  loss dict:  {'classification_loss': 0.8738387751579285}
2025-01-13 05:51:34,445 [INFO] Step[2450/4329]: training loss : 0.8738258612155915 TRAIN  loss dict:  {'classification_loss': 0.8738258612155915}
2025-01-13 05:51:46,047 [INFO] Step[2500/4329]: training loss : 0.8756555485725402 TRAIN  loss dict:  {'classification_loss': 0.8756555485725402}
2025-01-13 05:51:57,669 [INFO] Step[2550/4329]: training loss : 0.8693897974491119 TRAIN  loss dict:  {'classification_loss': 0.8693897974491119}
2025-01-13 05:52:09,260 [INFO] Step[2600/4329]: training loss : 0.8733333683013916 TRAIN  loss dict:  {'classification_loss': 0.8733333683013916}
2025-01-13 05:52:20,891 [INFO] Step[2650/4329]: training loss : 0.8741677498817444 TRAIN  loss dict:  {'classification_loss': 0.8741677498817444}
2025-01-13 05:52:32,667 [INFO] Step[2700/4329]: training loss : 0.868374855518341 TRAIN  loss dict:  {'classification_loss': 0.868374855518341}
2025-01-13 05:52:44,992 [INFO] Step[2750/4329]: training loss : 0.8685587978363037 TRAIN  loss dict:  {'classification_loss': 0.8685587978363037}
2025-01-13 05:52:57,159 [INFO] Step[2800/4329]: training loss : 0.8783892631530762 TRAIN  loss dict:  {'classification_loss': 0.8783892631530762}
2025-01-13 05:53:09,966 [INFO] Step[2850/4329]: training loss : 0.867317019701004 TRAIN  loss dict:  {'classification_loss': 0.867317019701004}
2025-01-13 05:53:22,840 [INFO] Step[2900/4329]: training loss : 0.8672076737880707 TRAIN  loss dict:  {'classification_loss': 0.8672076737880707}
2025-01-13 05:53:35,555 [INFO] Step[2950/4329]: training loss : 0.8695301926136016 TRAIN  loss dict:  {'classification_loss': 0.8695301926136016}
2025-01-13 05:53:47,495 [INFO] Step[3000/4329]: training loss : 0.8662442767620087 TRAIN  loss dict:  {'classification_loss': 0.8662442767620087}
2025-01-13 05:53:59,396 [INFO] Step[3050/4329]: training loss : 0.8802767932415009 TRAIN  loss dict:  {'classification_loss': 0.8802767932415009}
2025-01-13 05:54:11,052 [INFO] Step[3100/4329]: training loss : 0.8765086221694947 TRAIN  loss dict:  {'classification_loss': 0.8765086221694947}
2025-01-13 05:54:22,698 [INFO] Step[3150/4329]: training loss : 0.8759286916255951 TRAIN  loss dict:  {'classification_loss': 0.8759286916255951}
2025-01-13 05:54:34,286 [INFO] Step[3200/4329]: training loss : 0.8934442055225372 TRAIN  loss dict:  {'classification_loss': 0.8934442055225372}
2025-01-13 05:54:45,916 [INFO] Step[3250/4329]: training loss : 0.8743926215171814 TRAIN  loss dict:  {'classification_loss': 0.8743926215171814}
2025-01-13 05:54:57,519 [INFO] Step[3300/4329]: training loss : 0.8737126111984252 TRAIN  loss dict:  {'classification_loss': 0.8737126111984252}
2025-01-13 05:55:09,099 [INFO] Step[3350/4329]: training loss : 0.8717487990856171 TRAIN  loss dict:  {'classification_loss': 0.8717487990856171}
2025-01-13 05:55:20,724 [INFO] Step[3400/4329]: training loss : 0.877536712884903 TRAIN  loss dict:  {'classification_loss': 0.877536712884903}
2025-01-13 05:55:32,326 [INFO] Step[3450/4329]: training loss : 0.8703636300563812 TRAIN  loss dict:  {'classification_loss': 0.8703636300563812}
2025-01-13 05:55:43,974 [INFO] Step[3500/4329]: training loss : 0.8821416819095611 TRAIN  loss dict:  {'classification_loss': 0.8821416819095611}
2025-01-13 05:55:55,599 [INFO] Step[3550/4329]: training loss : 0.870300680398941 TRAIN  loss dict:  {'classification_loss': 0.870300680398941}
2025-01-13 05:56:07,265 [INFO] Step[3600/4329]: training loss : 0.8691692745685577 TRAIN  loss dict:  {'classification_loss': 0.8691692745685577}
2025-01-13 05:56:18,817 [INFO] Step[3650/4329]: training loss : 0.8714192593097687 TRAIN  loss dict:  {'classification_loss': 0.8714192593097687}
2025-01-13 05:56:30,457 [INFO] Step[3700/4329]: training loss : 0.8735966801643371 TRAIN  loss dict:  {'classification_loss': 0.8735966801643371}
2025-01-13 05:56:42,096 [INFO] Step[3750/4329]: training loss : 0.8715137815475464 TRAIN  loss dict:  {'classification_loss': 0.8715137815475464}
2025-01-13 05:56:53,671 [INFO] Step[3800/4329]: training loss : 0.8716691446304321 TRAIN  loss dict:  {'classification_loss': 0.8716691446304321}
2025-01-13 05:57:05,272 [INFO] Step[3850/4329]: training loss : 0.8786612749099731 TRAIN  loss dict:  {'classification_loss': 0.8786612749099731}
2025-01-13 05:57:16,876 [INFO] Step[3900/4329]: training loss : 0.8685620045661926 TRAIN  loss dict:  {'classification_loss': 0.8685620045661926}
2025-01-13 05:57:28,563 [INFO] Step[3950/4329]: training loss : 0.8675787663459777 TRAIN  loss dict:  {'classification_loss': 0.8675787663459777}
2025-01-13 05:57:40,197 [INFO] Step[4000/4329]: training loss : 0.8669661033153534 TRAIN  loss dict:  {'classification_loss': 0.8669661033153534}
2025-01-13 05:57:51,816 [INFO] Step[4050/4329]: training loss : 0.8873223876953125 TRAIN  loss dict:  {'classification_loss': 0.8873223876953125}
2025-01-13 05:58:03,420 [INFO] Step[4100/4329]: training loss : 0.8692456078529358 TRAIN  loss dict:  {'classification_loss': 0.8692456078529358}
2025-01-13 05:58:15,065 [INFO] Step[4150/4329]: training loss : 0.87994025349617 TRAIN  loss dict:  {'classification_loss': 0.87994025349617}
2025-01-13 05:58:26,646 [INFO] Step[4200/4329]: training loss : 0.8716096985340118 TRAIN  loss dict:  {'classification_loss': 0.8716096985340118}
2025-01-13 05:58:38,284 [INFO] Step[4250/4329]: training loss : 0.8970880150794983 TRAIN  loss dict:  {'classification_loss': 0.8970880150794983}
2025-01-13 05:58:49,881 [INFO] Step[4300/4329]: training loss : 0.8765462958812713 TRAIN  loss dict:  {'classification_loss': 0.8765462958812713}
2025-01-13 06:00:49,463 [INFO] Label accuracies statistics:
2025-01-13 06:00:49,463 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.25, 5: 0.9166666666666666, 6: 0.5, 7: 0.5, 8: 0.6666666666666666, 9: 0.9166666666666666, 10: 1.0, 11: 1.0, 12: 0.4166666666666667, 13: 0.5, 14: 0.6666666666666666, 15: 0.5555555555555556, 16: 0.5833333333333334, 17: 0.5, 18: 0.5, 19: 0.75, 20: 0.6666666666666666, 21: 0.75, 22: 0.6666666666666666, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.8333333333333334, 27: 0.75, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.6666666666666666, 32: 0.6666666666666666, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 1.0, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.8333333333333334, 41: 0.5833333333333334, 42: 0.8333333333333334, 43: 1.0, 44: 0.5833333333333334, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.9166666666666666, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.6666666666666666, 56: 0.8333333333333334, 57: 0.6666666666666666, 58: 0.5833333333333334, 59: 0.75, 60: 0.75, 61: 0.9166666666666666, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.9166666666666666, 68: 0.75, 69: 0.75, 70: 0.4166666666666667, 71: 0.5833333333333334, 72: 0.9166666666666666, 73: 0.8333333333333334, 74: 0.6666666666666666, 75: 1.0, 76: 0.5833333333333334, 77: 0.8333333333333334, 78: 1.0, 79: 0.5833333333333334, 80: 1.0, 81: 1.0, 82: 0.9166666666666666, 83: 0.6666666666666666, 84: 0.4166666666666667, 85: 0.75, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.6666666666666666, 89: 0.5833333333333334, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.5833333333333334, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.9166666666666666, 102: 0.9166666666666666, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.8333333333333334, 111: 1.0, 112: 0.8333333333333334, 113: 0.5, 114: 0.3333333333333333, 115: 1.0, 116: 0.8333333333333334, 117: 0.75, 118: 1.0, 119: 0.8333333333333334, 120: 0.6666666666666666, 121: 0.8333333333333334, 122: 0.9166666666666666, 123: 1.0, 124: 1.0, 125: 0.8333333333333334, 126: 0.8333333333333334, 127: 0.75, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.9166666666666666, 132: 0.3333333333333333, 133: 1.0, 134: 0.8333333333333334, 135: 0.9166666666666666, 136: 1.0, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 0.8333333333333334, 142: 0.75, 143: 1.0, 144: 0.8333333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.9166666666666666, 148: 0.75, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.8333333333333334, 158: 0.7777777777777778, 159: 1.0, 160: 0.3333333333333333, 161: 0.9166666666666666, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.9166666666666666, 169: 0.8333333333333334, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.9166666666666666, 178: 1.0, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.75, 183: 0.8333333333333334, 184: 0.75, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.5, 189: 1.0, 190: 0.6666666666666666, 191: 0.5, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.8333333333333334, 196: 0.8333333333333334, 197: 0.6666666666666666, 198: 0.8333333333333334}

2025-01-13 06:00:49,465 [INFO] [48] TRAIN  loss: 0.8752818673222631 acc: 0.9980748498382874
2025-01-13 06:00:49,465 [INFO] [48] TRAIN  loss dict: {'classification_loss': 0.8752818673222631}
2025-01-13 06:00:49,466 [INFO] [48] VALIDATION loss: 1.6068582330087218 VALIDATION acc: 0.8080808080808081
2025-01-13 06:00:49,466 [INFO] [48] VALIDATION loss dict: {'classification_loss': 1.6068582330087218}
2025-01-13 06:00:49,466 [INFO] 
2025-01-13 06:01:06,789 [INFO] Step[50/4329]: training loss : 0.8703122735023499 TRAIN  loss dict:  {'classification_loss': 0.8703122735023499}
2025-01-13 06:01:18,315 [INFO] Step[100/4329]: training loss : 0.8786152017116546 TRAIN  loss dict:  {'classification_loss': 0.8786152017116546}
2025-01-13 06:01:29,949 [INFO] Step[150/4329]: training loss : 0.8812329244613647 TRAIN  loss dict:  {'classification_loss': 0.8812329244613647}
2025-01-13 06:01:41,569 [INFO] Step[200/4329]: training loss : 0.8755772066116333 TRAIN  loss dict:  {'classification_loss': 0.8755772066116333}
2025-01-13 06:01:53,191 [INFO] Step[250/4329]: training loss : 0.8765648186206818 TRAIN  loss dict:  {'classification_loss': 0.8765648186206818}
2025-01-13 06:02:04,803 [INFO] Step[300/4329]: training loss : 0.8812247538566589 TRAIN  loss dict:  {'classification_loss': 0.8812247538566589}
2025-01-13 06:02:16,440 [INFO] Step[350/4329]: training loss : 0.8667188179492951 TRAIN  loss dict:  {'classification_loss': 0.8667188179492951}
2025-01-13 06:02:28,037 [INFO] Step[400/4329]: training loss : 0.8768847608566284 TRAIN  loss dict:  {'classification_loss': 0.8768847608566284}
2025-01-13 06:02:39,649 [INFO] Step[450/4329]: training loss : 0.865565356016159 TRAIN  loss dict:  {'classification_loss': 0.865565356016159}
2025-01-13 06:02:51,274 [INFO] Step[500/4329]: training loss : 0.8667915964126587 TRAIN  loss dict:  {'classification_loss': 0.8667915964126587}
2025-01-13 06:03:02,944 [INFO] Step[550/4329]: training loss : 0.8687124121189117 TRAIN  loss dict:  {'classification_loss': 0.8687124121189117}
2025-01-13 06:03:14,550 [INFO] Step[600/4329]: training loss : 0.8746967554092407 TRAIN  loss dict:  {'classification_loss': 0.8746967554092407}
2025-01-13 06:03:26,237 [INFO] Step[650/4329]: training loss : 0.8739625132083892 TRAIN  loss dict:  {'classification_loss': 0.8739625132083892}
2025-01-13 06:03:37,854 [INFO] Step[700/4329]: training loss : 0.8691092586517334 TRAIN  loss dict:  {'classification_loss': 0.8691092586517334}
2025-01-13 06:03:49,489 [INFO] Step[750/4329]: training loss : 0.8670529186725616 TRAIN  loss dict:  {'classification_loss': 0.8670529186725616}
2025-01-13 06:04:01,085 [INFO] Step[800/4329]: training loss : 0.8733528101444245 TRAIN  loss dict:  {'classification_loss': 0.8733528101444245}
2025-01-13 06:04:12,717 [INFO] Step[850/4329]: training loss : 0.8862173926830291 TRAIN  loss dict:  {'classification_loss': 0.8862173926830291}
2025-01-13 06:04:24,363 [INFO] Step[900/4329]: training loss : 0.8782754611968994 TRAIN  loss dict:  {'classification_loss': 0.8782754611968994}
2025-01-13 06:04:36,001 [INFO] Step[950/4329]: training loss : 0.8665531706809998 TRAIN  loss dict:  {'classification_loss': 0.8665531706809998}
2025-01-13 06:04:47,576 [INFO] Step[1000/4329]: training loss : 0.8694800758361816 TRAIN  loss dict:  {'classification_loss': 0.8694800758361816}
2025-01-13 06:04:59,426 [INFO] Step[1050/4329]: training loss : 0.8752688765525818 TRAIN  loss dict:  {'classification_loss': 0.8752688765525818}
2025-01-13 06:05:11,810 [INFO] Step[1100/4329]: training loss : 0.8674916064739228 TRAIN  loss dict:  {'classification_loss': 0.8674916064739228}
2025-01-13 06:05:24,104 [INFO] Step[1150/4329]: training loss : 0.868313775062561 TRAIN  loss dict:  {'classification_loss': 0.868313775062561}
2025-01-13 06:05:37,315 [INFO] Step[1200/4329]: training loss : 0.8713037145137786 TRAIN  loss dict:  {'classification_loss': 0.8713037145137786}
2025-01-13 06:05:51,020 [INFO] Step[1250/4329]: training loss : 0.8685345351696014 TRAIN  loss dict:  {'classification_loss': 0.8685345351696014}
2025-01-13 06:06:03,353 [INFO] Step[1300/4329]: training loss : 0.8979788160324097 TRAIN  loss dict:  {'classification_loss': 0.8979788160324097}
2025-01-13 06:06:15,208 [INFO] Step[1350/4329]: training loss : 0.8693691158294677 TRAIN  loss dict:  {'classification_loss': 0.8693691158294677}
2025-01-13 06:06:27,110 [INFO] Step[1400/4329]: training loss : 0.8723615741729737 TRAIN  loss dict:  {'classification_loss': 0.8723615741729737}
2025-01-13 06:06:38,786 [INFO] Step[1450/4329]: training loss : 0.8686098325252533 TRAIN  loss dict:  {'classification_loss': 0.8686098325252533}
2025-01-13 06:06:50,444 [INFO] Step[1500/4329]: training loss : 0.882578797340393 TRAIN  loss dict:  {'classification_loss': 0.882578797340393}
2025-01-13 06:07:02,115 [INFO] Step[1550/4329]: training loss : 0.871004341840744 TRAIN  loss dict:  {'classification_loss': 0.871004341840744}
2025-01-13 06:07:13,756 [INFO] Step[1600/4329]: training loss : 0.8667881941795349 TRAIN  loss dict:  {'classification_loss': 0.8667881941795349}
2025-01-13 06:07:25,413 [INFO] Step[1650/4329]: training loss : 0.8645531392097473 TRAIN  loss dict:  {'classification_loss': 0.8645531392097473}
2025-01-13 06:07:37,059 [INFO] Step[1700/4329]: training loss : 0.8700151872634888 TRAIN  loss dict:  {'classification_loss': 0.8700151872634888}
2025-01-13 06:07:48,661 [INFO] Step[1750/4329]: training loss : 0.8780255234241485 TRAIN  loss dict:  {'classification_loss': 0.8780255234241485}
2025-01-13 06:08:00,284 [INFO] Step[1800/4329]: training loss : 0.8726716327667237 TRAIN  loss dict:  {'classification_loss': 0.8726716327667237}
2025-01-13 06:08:11,940 [INFO] Step[1850/4329]: training loss : 0.8814335179328918 TRAIN  loss dict:  {'classification_loss': 0.8814335179328918}
2025-01-13 06:08:23,560 [INFO] Step[1900/4329]: training loss : 0.8736288964748382 TRAIN  loss dict:  {'classification_loss': 0.8736288964748382}
2025-01-13 06:08:35,156 [INFO] Step[1950/4329]: training loss : 0.8685815811157227 TRAIN  loss dict:  {'classification_loss': 0.8685815811157227}
2025-01-13 06:08:46,764 [INFO] Step[2000/4329]: training loss : 0.8738422703742981 TRAIN  loss dict:  {'classification_loss': 0.8738422703742981}
2025-01-13 06:08:58,446 [INFO] Step[2050/4329]: training loss : 0.8838504993915558 TRAIN  loss dict:  {'classification_loss': 0.8838504993915558}
2025-01-13 06:09:10,056 [INFO] Step[2100/4329]: training loss : 0.8828138577938079 TRAIN  loss dict:  {'classification_loss': 0.8828138577938079}
2025-01-13 06:09:21,731 [INFO] Step[2150/4329]: training loss : 0.8737083995342254 TRAIN  loss dict:  {'classification_loss': 0.8737083995342254}
2025-01-13 06:09:33,351 [INFO] Step[2200/4329]: training loss : 0.8947460877895356 TRAIN  loss dict:  {'classification_loss': 0.8947460877895356}
2025-01-13 06:09:44,973 [INFO] Step[2250/4329]: training loss : 0.8805422425270081 TRAIN  loss dict:  {'classification_loss': 0.8805422425270081}
2025-01-13 06:09:56,581 [INFO] Step[2300/4329]: training loss : 0.8748485577106476 TRAIN  loss dict:  {'classification_loss': 0.8748485577106476}
2025-01-13 06:10:08,241 [INFO] Step[2350/4329]: training loss : 0.8764469802379609 TRAIN  loss dict:  {'classification_loss': 0.8764469802379609}
2025-01-13 06:10:19,863 [INFO] Step[2400/4329]: training loss : 0.885528894662857 TRAIN  loss dict:  {'classification_loss': 0.885528894662857}
2025-01-13 06:10:31,473 [INFO] Step[2450/4329]: training loss : 0.8844051373004913 TRAIN  loss dict:  {'classification_loss': 0.8844051373004913}
2025-01-13 06:10:43,069 [INFO] Step[2500/4329]: training loss : 0.865079036951065 TRAIN  loss dict:  {'classification_loss': 0.865079036951065}
2025-01-13 06:10:54,729 [INFO] Step[2550/4329]: training loss : 0.8911204302310943 TRAIN  loss dict:  {'classification_loss': 0.8911204302310943}
2025-01-13 06:11:06,307 [INFO] Step[2600/4329]: training loss : 0.8706869518756867 TRAIN  loss dict:  {'classification_loss': 0.8706869518756867}
2025-01-13 06:11:17,912 [INFO] Step[2650/4329]: training loss : 0.8737808203697205 TRAIN  loss dict:  {'classification_loss': 0.8737808203697205}
2025-01-13 06:11:29,543 [INFO] Step[2700/4329]: training loss : 0.8788741517066956 TRAIN  loss dict:  {'classification_loss': 0.8788741517066956}
2025-01-13 06:11:41,160 [INFO] Step[2750/4329]: training loss : 0.874801231622696 TRAIN  loss dict:  {'classification_loss': 0.874801231622696}
2025-01-13 06:11:52,804 [INFO] Step[2800/4329]: training loss : 0.8980484962463379 TRAIN  loss dict:  {'classification_loss': 0.8980484962463379}
2025-01-13 06:12:04,434 [INFO] Step[2850/4329]: training loss : 0.8684849882125855 TRAIN  loss dict:  {'classification_loss': 0.8684849882125855}
2025-01-13 06:12:16,034 [INFO] Step[2900/4329]: training loss : 0.8716879677772522 TRAIN  loss dict:  {'classification_loss': 0.8716879677772522}
2025-01-13 06:12:27,708 [INFO] Step[2950/4329]: training loss : 0.8669323813915253 TRAIN  loss dict:  {'classification_loss': 0.8669323813915253}
2025-01-13 06:12:39,354 [INFO] Step[3000/4329]: training loss : 0.8725955080986023 TRAIN  loss dict:  {'classification_loss': 0.8725955080986023}
2025-01-13 06:12:50,972 [INFO] Step[3050/4329]: training loss : 0.8908134293556214 TRAIN  loss dict:  {'classification_loss': 0.8908134293556214}
2025-01-13 06:13:02,623 [INFO] Step[3100/4329]: training loss : 0.8679262483119965 TRAIN  loss dict:  {'classification_loss': 0.8679262483119965}
2025-01-13 06:13:14,252 [INFO] Step[3150/4329]: training loss : 0.8755822968482971 TRAIN  loss dict:  {'classification_loss': 0.8755822968482971}
2025-01-13 06:13:25,849 [INFO] Step[3200/4329]: training loss : 0.880449150800705 TRAIN  loss dict:  {'classification_loss': 0.880449150800705}
2025-01-13 06:13:37,443 [INFO] Step[3250/4329]: training loss : 0.874415032863617 TRAIN  loss dict:  {'classification_loss': 0.874415032863617}
2025-01-13 06:13:49,075 [INFO] Step[3300/4329]: training loss : 0.8694008338451386 TRAIN  loss dict:  {'classification_loss': 0.8694008338451386}
2025-01-13 06:14:00,690 [INFO] Step[3350/4329]: training loss : 0.8810895848274231 TRAIN  loss dict:  {'classification_loss': 0.8810895848274231}
2025-01-13 06:14:12,298 [INFO] Step[3400/4329]: training loss : 0.8780242466926574 TRAIN  loss dict:  {'classification_loss': 0.8780242466926574}
2025-01-13 06:14:23,937 [INFO] Step[3450/4329]: training loss : 0.8663059365749359 TRAIN  loss dict:  {'classification_loss': 0.8663059365749359}
2025-01-13 06:14:35,542 [INFO] Step[3500/4329]: training loss : 0.875569874048233 TRAIN  loss dict:  {'classification_loss': 0.875569874048233}
2025-01-13 06:14:47,129 [INFO] Step[3550/4329]: training loss : 0.8797303938865662 TRAIN  loss dict:  {'classification_loss': 0.8797303938865662}
2025-01-13 06:14:58,799 [INFO] Step[3600/4329]: training loss : 0.876485960483551 TRAIN  loss dict:  {'classification_loss': 0.876485960483551}
2025-01-13 06:15:10,410 [INFO] Step[3650/4329]: training loss : 0.8675701677799225 TRAIN  loss dict:  {'classification_loss': 0.8675701677799225}
2025-01-13 06:15:22,032 [INFO] Step[3700/4329]: training loss : 0.8791596555709839 TRAIN  loss dict:  {'classification_loss': 0.8791596555709839}
2025-01-13 06:15:33,670 [INFO] Step[3750/4329]: training loss : 0.8717743217945099 TRAIN  loss dict:  {'classification_loss': 0.8717743217945099}
2025-01-13 06:15:45,298 [INFO] Step[3800/4329]: training loss : 0.8933017265796661 TRAIN  loss dict:  {'classification_loss': 0.8933017265796661}
2025-01-13 06:15:56,925 [INFO] Step[3850/4329]: training loss : 0.8783474087715148 TRAIN  loss dict:  {'classification_loss': 0.8783474087715148}
2025-01-13 06:16:08,528 [INFO] Step[3900/4329]: training loss : 0.8708495843410492 TRAIN  loss dict:  {'classification_loss': 0.8708495843410492}
2025-01-13 06:16:20,180 [INFO] Step[3950/4329]: training loss : 0.8717680537700653 TRAIN  loss dict:  {'classification_loss': 0.8717680537700653}
2025-01-13 06:16:31,743 [INFO] Step[4000/4329]: training loss : 0.8700949215888977 TRAIN  loss dict:  {'classification_loss': 0.8700949215888977}
2025-01-13 06:16:43,409 [INFO] Step[4050/4329]: training loss : 0.8731513166427612 TRAIN  loss dict:  {'classification_loss': 0.8731513166427612}
2025-01-13 06:16:55,041 [INFO] Step[4100/4329]: training loss : 0.8760754358768463 TRAIN  loss dict:  {'classification_loss': 0.8760754358768463}
2025-01-13 06:17:06,714 [INFO] Step[4150/4329]: training loss : 0.8910673975944519 TRAIN  loss dict:  {'classification_loss': 0.8910673975944519}
2025-01-13 06:17:18,548 [INFO] Step[4200/4329]: training loss : 0.875420206785202 TRAIN  loss dict:  {'classification_loss': 0.875420206785202}
2025-01-13 06:17:30,932 [INFO] Step[4250/4329]: training loss : 0.874901089668274 TRAIN  loss dict:  {'classification_loss': 0.874901089668274}
2025-01-13 06:17:43,138 [INFO] Step[4300/4329]: training loss : 0.8691547000408173 TRAIN  loss dict:  {'classification_loss': 0.8691547000408173}
2025-01-13 06:20:01,059 [INFO] Label accuracies statistics:
2025-01-13 06:20:01,059 [INFO] {0: 0.5555555555555556, 1: 0.7777777777777778, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.9166666666666666, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.9166666666666666, 10: 1.0, 11: 1.0, 12: 0.4166666666666667, 13: 0.5833333333333334, 14: 0.75, 15: 0.7777777777777778, 16: 0.75, 17: 0.5833333333333334, 18: 0.6666666666666666, 19: 0.75, 20: 0.5833333333333334, 21: 0.6666666666666666, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.8333333333333334, 26: 0.8333333333333334, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.5833333333333334, 31: 0.9166666666666666, 32: 0.75, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 1.0, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.9166666666666666, 41: 0.5, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.5833333333333334, 45: 0.5833333333333334, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.8333333333333334, 57: 0.6666666666666666, 58: 0.5833333333333334, 59: 0.9166666666666666, 60: 0.8333333333333334, 61: 0.9166666666666666, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.9166666666666666, 68: 0.5833333333333334, 69: 0.6666666666666666, 70: 0.4166666666666667, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.6666666666666666, 78: 0.9166666666666666, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.8333333333333334, 83: 0.5833333333333334, 84: 0.6666666666666666, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.75, 89: 0.4166666666666667, 90: 0.4166666666666667, 91: 0.9166666666666666, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 0.9166666666666666, 96: 0.5833333333333334, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.9166666666666666, 101: 1.0, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 0.9166666666666666, 106: 0.9166666666666666, 107: 0.6666666666666666, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 1.0, 111: 1.0, 112: 0.8333333333333334, 113: 0.5833333333333334, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.8333333333333334, 120: 0.6666666666666666, 121: 0.8333333333333334, 122: 0.9166666666666666, 123: 0.9166666666666666, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.6666666666666666, 128: 0.9166666666666666, 129: 0.9166666666666666, 130: 0.75, 131: 0.9166666666666666, 132: 0.5, 133: 1.0, 134: 0.6666666666666666, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 0.9166666666666666, 141: 0.9166666666666666, 142: 0.9166666666666666, 143: 1.0, 144: 0.75, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.4166666666666667, 151: 0.9166666666666666, 152: 0.9166666666666666, 153: 0.8333333333333334, 154: 1.0, 155: 0.9166666666666666, 156: 0.75, 157: 0.9166666666666666, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.8333333333333334, 162: 1.0, 163: 0.9166666666666666, 164: 0.8333333333333334, 165: 0.75, 166: 0.8333333333333334, 167: 0.8333333333333334, 168: 0.8333333333333334, 169: 0.9166666666666666, 170: 0.9166666666666666, 171: 0.5, 172: 1.0, 173: 0.9166666666666666, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.5, 183: 0.8333333333333334, 184: 0.75, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.6666666666666666, 191: 0.3333333333333333, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.9166666666666666, 198: 0.75}

2025-01-13 06:20:01,981 [INFO] [49] TRAIN  loss: 0.8753807750550119 acc: 0.9978438318188819
2025-01-13 06:20:01,981 [INFO] [49] TRAIN  loss dict: {'classification_loss': 0.8753807750550119}
2025-01-13 06:20:01,982 [INFO] [49] VALIDATION loss: 1.590850294990973 VALIDATION acc: 0.8169191919191919
2025-01-13 06:20:01,982 [INFO] [49] VALIDATION loss dict: {'classification_loss': 1.590850294990973}
2025-01-13 06:20:01,982 [INFO] 
2025-01-13 06:20:19,859 [INFO] Step[50/4329]: training loss : 0.8696791672706604 TRAIN  loss dict:  {'classification_loss': 0.8696791672706604}
2025-01-13 06:20:31,445 [INFO] Step[100/4329]: training loss : 0.8777518963813782 TRAIN  loss dict:  {'classification_loss': 0.8777518963813782}
2025-01-13 06:20:43,063 [INFO] Step[150/4329]: training loss : 0.8781810927391053 TRAIN  loss dict:  {'classification_loss': 0.8781810927391053}
2025-01-13 06:20:54,643 [INFO] Step[200/4329]: training loss : 0.8704992008209228 TRAIN  loss dict:  {'classification_loss': 0.8704992008209228}
2025-01-13 06:21:06,282 [INFO] Step[250/4329]: training loss : 0.8708248376846314 TRAIN  loss dict:  {'classification_loss': 0.8708248376846314}
2025-01-13 06:21:17,895 [INFO] Step[300/4329]: training loss : 0.868543643951416 TRAIN  loss dict:  {'classification_loss': 0.868543643951416}
2025-01-13 06:21:29,563 [INFO] Step[350/4329]: training loss : 0.8721559822559357 TRAIN  loss dict:  {'classification_loss': 0.8721559822559357}
2025-01-13 06:21:41,175 [INFO] Step[400/4329]: training loss : 0.8699232828617096 TRAIN  loss dict:  {'classification_loss': 0.8699232828617096}
2025-01-13 06:21:52,788 [INFO] Step[450/4329]: training loss : 0.8838880789279938 TRAIN  loss dict:  {'classification_loss': 0.8838880789279938}
2025-01-13 06:22:04,420 [INFO] Step[500/4329]: training loss : 0.8665372920036316 TRAIN  loss dict:  {'classification_loss': 0.8665372920036316}
2025-01-13 06:22:16,087 [INFO] Step[550/4329]: training loss : 0.8765751481056213 TRAIN  loss dict:  {'classification_loss': 0.8765751481056213}
2025-01-13 06:22:27,739 [INFO] Step[600/4329]: training loss : 0.8670356345176696 TRAIN  loss dict:  {'classification_loss': 0.8670356345176696}
2025-01-13 06:22:39,368 [INFO] Step[650/4329]: training loss : 0.8787575089931488 TRAIN  loss dict:  {'classification_loss': 0.8787575089931488}
2025-01-13 06:22:50,996 [INFO] Step[700/4329]: training loss : 0.8680271303653717 TRAIN  loss dict:  {'classification_loss': 0.8680271303653717}
2025-01-13 06:23:02,608 [INFO] Step[750/4329]: training loss : 0.865457626581192 TRAIN  loss dict:  {'classification_loss': 0.865457626581192}
2025-01-13 06:23:14,236 [INFO] Step[800/4329]: training loss : 0.8707895171642304 TRAIN  loss dict:  {'classification_loss': 0.8707895171642304}
2025-01-13 06:23:25,852 [INFO] Step[850/4329]: training loss : 0.8661821842193603 TRAIN  loss dict:  {'classification_loss': 0.8661821842193603}
2025-01-13 06:23:37,460 [INFO] Step[900/4329]: training loss : 0.8682039666175843 TRAIN  loss dict:  {'classification_loss': 0.8682039666175843}
2025-01-13 06:23:49,105 [INFO] Step[950/4329]: training loss : 0.8747671949863434 TRAIN  loss dict:  {'classification_loss': 0.8747671949863434}
2025-01-13 06:24:00,723 [INFO] Step[1000/4329]: training loss : 0.8654274141788483 TRAIN  loss dict:  {'classification_loss': 0.8654274141788483}
2025-01-13 06:24:12,345 [INFO] Step[1050/4329]: training loss : 0.8839020609855652 TRAIN  loss dict:  {'classification_loss': 0.8839020609855652}
2025-01-13 06:24:24,001 [INFO] Step[1100/4329]: training loss : 0.873851146697998 TRAIN  loss dict:  {'classification_loss': 0.873851146697998}
2025-01-13 06:24:35,623 [INFO] Step[1150/4329]: training loss : 0.8696622264385223 TRAIN  loss dict:  {'classification_loss': 0.8696622264385223}
2025-01-13 06:24:47,253 [INFO] Step[1200/4329]: training loss : 0.8741876161098481 TRAIN  loss dict:  {'classification_loss': 0.8741876161098481}
2025-01-13 06:24:58,912 [INFO] Step[1250/4329]: training loss : 0.8677376818656921 TRAIN  loss dict:  {'classification_loss': 0.8677376818656921}
2025-01-13 06:25:10,500 [INFO] Step[1300/4329]: training loss : 0.8760089230537415 TRAIN  loss dict:  {'classification_loss': 0.8760089230537415}
2025-01-13 06:25:22,166 [INFO] Step[1350/4329]: training loss : 0.8710496926307678 TRAIN  loss dict:  {'classification_loss': 0.8710496926307678}
2025-01-13 06:25:33,822 [INFO] Step[1400/4329]: training loss : 0.8771071410179139 TRAIN  loss dict:  {'classification_loss': 0.8771071410179139}
2025-01-13 06:25:45,451 [INFO] Step[1450/4329]: training loss : 0.8727983891963959 TRAIN  loss dict:  {'classification_loss': 0.8727983891963959}
2025-01-13 06:25:57,044 [INFO] Step[1500/4329]: training loss : 0.8896132862567901 TRAIN  loss dict:  {'classification_loss': 0.8896132862567901}
2025-01-13 06:26:08,671 [INFO] Step[1550/4329]: training loss : 0.8708460366725922 TRAIN  loss dict:  {'classification_loss': 0.8708460366725922}
2025-01-13 06:26:20,319 [INFO] Step[1600/4329]: training loss : 0.876674929857254 TRAIN  loss dict:  {'classification_loss': 0.876674929857254}
2025-01-13 06:26:31,977 [INFO] Step[1650/4329]: training loss : 0.8696592330932618 TRAIN  loss dict:  {'classification_loss': 0.8696592330932618}
2025-01-13 06:26:43,575 [INFO] Step[1700/4329]: training loss : 0.8713697338104248 TRAIN  loss dict:  {'classification_loss': 0.8713697338104248}
2025-01-13 06:26:55,216 [INFO] Step[1750/4329]: training loss : 0.8659918534755707 TRAIN  loss dict:  {'classification_loss': 0.8659918534755707}
2025-01-13 06:27:06,847 [INFO] Step[1800/4329]: training loss : 0.8821892952919006 TRAIN  loss dict:  {'classification_loss': 0.8821892952919006}
2025-01-13 06:27:18,455 [INFO] Step[1850/4329]: training loss : 0.8671811759471894 TRAIN  loss dict:  {'classification_loss': 0.8671811759471894}
2025-01-13 06:27:30,084 [INFO] Step[1900/4329]: training loss : 0.8731026995182037 TRAIN  loss dict:  {'classification_loss': 0.8731026995182037}
2025-01-13 06:27:41,699 [INFO] Step[1950/4329]: training loss : 0.8700949096679688 TRAIN  loss dict:  {'classification_loss': 0.8700949096679688}
2025-01-13 06:27:53,321 [INFO] Step[2000/4329]: training loss : 0.8777792704105377 TRAIN  loss dict:  {'classification_loss': 0.8777792704105377}
2025-01-13 06:28:04,941 [INFO] Step[2050/4329]: training loss : 0.8683976244926452 TRAIN  loss dict:  {'classification_loss': 0.8683976244926452}
2025-01-13 06:28:16,543 [INFO] Step[2100/4329]: training loss : 0.8677198302745819 TRAIN  loss dict:  {'classification_loss': 0.8677198302745819}
2025-01-13 06:28:28,147 [INFO] Step[2150/4329]: training loss : 0.8766006302833557 TRAIN  loss dict:  {'classification_loss': 0.8766006302833557}
2025-01-13 06:28:39,770 [INFO] Step[2200/4329]: training loss : 0.8699890565872193 TRAIN  loss dict:  {'classification_loss': 0.8699890565872193}
2025-01-13 06:28:51,403 [INFO] Step[2250/4329]: training loss : 0.8674875390529633 TRAIN  loss dict:  {'classification_loss': 0.8674875390529633}
2025-01-13 06:29:03,018 [INFO] Step[2300/4329]: training loss : 0.8738512063026428 TRAIN  loss dict:  {'classification_loss': 0.8738512063026428}
2025-01-13 06:29:14,643 [INFO] Step[2350/4329]: training loss : 0.8773670959472656 TRAIN  loss dict:  {'classification_loss': 0.8773670959472656}
2025-01-13 06:29:26,275 [INFO] Step[2400/4329]: training loss : 0.8715328097343444 TRAIN  loss dict:  {'classification_loss': 0.8715328097343444}
2025-01-13 06:29:37,903 [INFO] Step[2450/4329]: training loss : 0.8706901407241822 TRAIN  loss dict:  {'classification_loss': 0.8706901407241822}
2025-01-13 06:29:49,836 [INFO] Step[2500/4329]: training loss : 0.8671233320236206 TRAIN  loss dict:  {'classification_loss': 0.8671233320236206}
2025-01-13 06:30:02,178 [INFO] Step[2550/4329]: training loss : 0.8737914824485778 TRAIN  loss dict:  {'classification_loss': 0.8737914824485778}
2025-01-13 06:30:14,529 [INFO] Step[2600/4329]: training loss : 0.8799847149848938 TRAIN  loss dict:  {'classification_loss': 0.8799847149848938}
2025-01-13 06:30:27,746 [INFO] Step[2650/4329]: training loss : 0.8769381332397461 TRAIN  loss dict:  {'classification_loss': 0.8769381332397461}
2025-01-13 06:30:41,097 [INFO] Step[2700/4329]: training loss : 0.8806624507904053 TRAIN  loss dict:  {'classification_loss': 0.8806624507904053}
2025-01-13 06:30:53,151 [INFO] Step[2750/4329]: training loss : 0.8698495507240296 TRAIN  loss dict:  {'classification_loss': 0.8698495507240296}
2025-01-13 06:31:04,974 [INFO] Step[2800/4329]: training loss : 0.8835173034667969 TRAIN  loss dict:  {'classification_loss': 0.8835173034667969}
2025-01-13 06:31:16,755 [INFO] Step[2850/4329]: training loss : 0.8721324515342712 TRAIN  loss dict:  {'classification_loss': 0.8721324515342712}
2025-01-13 06:31:28,342 [INFO] Step[2900/4329]: training loss : 0.9303598988056183 TRAIN  loss dict:  {'classification_loss': 0.9303598988056183}
2025-01-13 06:31:40,007 [INFO] Step[2950/4329]: training loss : 0.8710052728652954 TRAIN  loss dict:  {'classification_loss': 0.8710052728652954}
2025-01-13 06:31:51,634 [INFO] Step[3000/4329]: training loss : 0.8918970549106597 TRAIN  loss dict:  {'classification_loss': 0.8918970549106597}
2025-01-13 06:32:03,225 [INFO] Step[3050/4329]: training loss : 0.9007720756530762 TRAIN  loss dict:  {'classification_loss': 0.9007720756530762}
2025-01-13 06:32:14,835 [INFO] Step[3100/4329]: training loss : 0.87081787109375 TRAIN  loss dict:  {'classification_loss': 0.87081787109375}
2025-01-13 06:32:26,463 [INFO] Step[3150/4329]: training loss : 0.8807495546340942 TRAIN  loss dict:  {'classification_loss': 0.8807495546340942}
2025-01-13 06:32:38,064 [INFO] Step[3200/4329]: training loss : 0.8712188589572907 TRAIN  loss dict:  {'classification_loss': 0.8712188589572907}
2025-01-13 06:32:49,692 [INFO] Step[3250/4329]: training loss : 0.8785299623012542 TRAIN  loss dict:  {'classification_loss': 0.8785299623012542}
2025-01-13 06:33:01,329 [INFO] Step[3300/4329]: training loss : 0.8727579879760742 TRAIN  loss dict:  {'classification_loss': 0.8727579879760742}
2025-01-13 06:33:12,970 [INFO] Step[3350/4329]: training loss : 0.8716483104228974 TRAIN  loss dict:  {'classification_loss': 0.8716483104228974}
2025-01-13 06:33:24,550 [INFO] Step[3400/4329]: training loss : 0.8824214231967926 TRAIN  loss dict:  {'classification_loss': 0.8824214231967926}
2025-01-13 06:33:36,204 [INFO] Step[3450/4329]: training loss : 0.8707936763763428 TRAIN  loss dict:  {'classification_loss': 0.8707936763763428}
2025-01-13 06:33:47,818 [INFO] Step[3500/4329]: training loss : 0.907287106513977 TRAIN  loss dict:  {'classification_loss': 0.907287106513977}
2025-01-13 06:33:59,461 [INFO] Step[3550/4329]: training loss : 0.8781561315059662 TRAIN  loss dict:  {'classification_loss': 0.8781561315059662}
2025-01-13 06:34:11,029 [INFO] Step[3600/4329]: training loss : 0.8847312664985657 TRAIN  loss dict:  {'classification_loss': 0.8847312664985657}
2025-01-13 06:34:22,626 [INFO] Step[3650/4329]: training loss : 0.8695871591567993 TRAIN  loss dict:  {'classification_loss': 0.8695871591567993}
2025-01-13 06:34:34,293 [INFO] Step[3700/4329]: training loss : 0.8859255468845367 TRAIN  loss dict:  {'classification_loss': 0.8859255468845367}
2025-01-13 06:34:45,855 [INFO] Step[3750/4329]: training loss : 0.8833553922176361 TRAIN  loss dict:  {'classification_loss': 0.8833553922176361}
2025-01-13 06:34:57,444 [INFO] Step[3800/4329]: training loss : 0.8795577788352966 TRAIN  loss dict:  {'classification_loss': 0.8795577788352966}
2025-01-13 06:35:09,044 [INFO] Step[3850/4329]: training loss : 0.8702284646034241 TRAIN  loss dict:  {'classification_loss': 0.8702284646034241}
2025-01-13 06:35:20,667 [INFO] Step[3900/4329]: training loss : 0.8783085191249848 TRAIN  loss dict:  {'classification_loss': 0.8783085191249848}
2025-01-13 06:35:32,246 [INFO] Step[3950/4329]: training loss : 0.8766070520877838 TRAIN  loss dict:  {'classification_loss': 0.8766070520877838}
2025-01-13 06:35:43,821 [INFO] Step[4000/4329]: training loss : 0.8774223709106446 TRAIN  loss dict:  {'classification_loss': 0.8774223709106446}
2025-01-13 06:35:55,402 [INFO] Step[4050/4329]: training loss : 0.869121425151825 TRAIN  loss dict:  {'classification_loss': 0.869121425151825}
2025-01-13 06:36:06,996 [INFO] Step[4100/4329]: training loss : 0.8862650310993194 TRAIN  loss dict:  {'classification_loss': 0.8862650310993194}
2025-01-13 06:36:18,565 [INFO] Step[4150/4329]: training loss : 0.8666895270347595 TRAIN  loss dict:  {'classification_loss': 0.8666895270347595}
2025-01-13 06:36:30,169 [INFO] Step[4200/4329]: training loss : 0.8895141577720642 TRAIN  loss dict:  {'classification_loss': 0.8895141577720642}
2025-01-13 06:36:41,768 [INFO] Step[4250/4329]: training loss : 0.8718544101715088 TRAIN  loss dict:  {'classification_loss': 0.8718544101715088}
2025-01-13 06:36:53,355 [INFO] Step[4300/4329]: training loss : 0.8843794393539429 TRAIN  loss dict:  {'classification_loss': 0.8843794393539429}
2025-01-13 06:38:51,757 [INFO] Label accuracies statistics:
2025-01-13 06:38:51,757 [INFO] {0: 0.5555555555555556, 1: 1.0, 2: 0.5833333333333334, 3: 0.8333333333333334, 4: 0.25, 5: 0.8333333333333334, 6: 0.5, 7: 0.5, 8: 0.5, 9: 0.9166666666666666, 10: 1.0, 11: 1.0, 12: 0.4166666666666667, 13: 0.5833333333333334, 14: 0.75, 15: 0.6666666666666666, 16: 0.5833333333333334, 17: 0.5833333333333334, 18: 0.6666666666666666, 19: 0.8333333333333334, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.8333333333333334, 27: 0.75, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.75, 32: 0.75, 33: 0.9166666666666666, 34: 0.8333333333333334, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 0.9166666666666666, 38: 0.9166666666666666, 39: 0.9166666666666666, 40: 0.8333333333333334, 41: 0.5, 42: 0.9166666666666666, 43: 0.8333333333333334, 44: 0.6666666666666666, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.9166666666666666, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.4166666666666667, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5833333333333334, 59: 0.9166666666666666, 60: 0.5833333333333334, 61: 0.9166666666666666, 62: 0.6666666666666666, 63: 0.5, 64: 0.9166666666666666, 65: 1.0, 66: 0.6666666666666666, 67: 0.8333333333333334, 68: 0.75, 69: 0.6666666666666666, 70: 0.5833333333333334, 71: 0.5833333333333334, 72: 0.8333333333333334, 73: 0.9166666666666666, 74: 0.75, 75: 0.9166666666666666, 76: 0.75, 77: 0.75, 78: 0.9166666666666666, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5833333333333334, 85: 0.8333333333333334, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.8333333333333334, 89: 0.6666666666666666, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 0.9166666666666666, 96: 0.6666666666666666, 97: 0.5, 98: 0.75, 99: 0.9333333333333333, 100: 0.8333333333333334, 101: 0.9166666666666666, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 0.9166666666666666, 106: 1.0, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 0.9166666666666666, 111: 0.9166666666666666, 112: 0.9166666666666666, 113: 0.4166666666666667, 114: 0.6666666666666666, 115: 1.0, 116: 0.9166666666666666, 117: 0.8333333333333334, 118: 1.0, 119: 0.6666666666666666, 120: 0.75, 121: 0.9166666666666666, 122: 0.9166666666666666, 123: 1.0, 124: 0.9166666666666666, 125: 0.75, 126: 0.9166666666666666, 127: 0.5, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.9166666666666666, 132: 0.6666666666666666, 133: 1.0, 134: 0.8333333333333334, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 0.8333333333333334, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.8333333333333334, 145: 0.9166666666666666, 146: 0.9166666666666666, 147: 0.75, 148: 0.8333333333333334, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 0.9166666666666666, 153: 0.75, 154: 1.0, 155: 0.9166666666666666, 156: 0.6666666666666666, 157: 0.9166666666666666, 158: 0.7777777777777778, 159: 1.0, 160: 0.5833333333333334, 161: 0.9166666666666666, 162: 0.9166666666666666, 163: 1.0, 164: 0.8333333333333334, 165: 0.8333333333333334, 166: 0.6666666666666666, 167: 0.8333333333333334, 168: 0.9166666666666666, 169: 0.8333333333333334, 170: 0.9166666666666666, 171: 0.4166666666666667, 172: 1.0, 173: 0.9166666666666666, 174: 0.9166666666666666, 175: 0.75, 176: 1.0, 177: 0.8333333333333334, 178: 0.9166666666666666, 179: 0.2222222222222222, 180: 0.9166666666666666, 181: 0.8333333333333334, 182: 0.75, 183: 0.6666666666666666, 184: 0.6666666666666666, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.75, 189: 0.8333333333333334, 190: 0.6666666666666666, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.6666666666666666, 196: 0.9166666666666666, 197: 0.75, 198: 0.75}

2025-01-13 06:38:51,759 [INFO] [50] TRAIN  loss: 0.8757043507446673 acc: 0.9984598798706299
2025-01-13 06:38:51,759 [INFO] [50] TRAIN  loss dict: {'classification_loss': 0.8757043507446673}
2025-01-13 06:38:51,759 [INFO] [50] VALIDATION loss: 1.6054734235460109 VALIDATION acc: 0.8051346801346801
2025-01-13 06:38:51,759 [INFO] [50] VALIDATION loss dict: {'classification_loss': 1.6054734235460109}
2025-01-13 06:38:51,759 [INFO] 
2025-01-13 06:39:09,034 [INFO] Step[50/4329]: training loss : 0.8734801399707794 TRAIN  loss dict:  {'classification_loss': 0.8734801399707794}
2025-01-13 06:39:20,582 [INFO] Step[100/4329]: training loss : 0.8687452614307404 TRAIN  loss dict:  {'classification_loss': 0.8687452614307404}
2025-01-13 06:39:32,210 [INFO] Step[150/4329]: training loss : 0.8677485227584839 TRAIN  loss dict:  {'classification_loss': 0.8677485227584839}
2025-01-13 06:39:43,880 [INFO] Step[200/4329]: training loss : 0.8742295467853546 TRAIN  loss dict:  {'classification_loss': 0.8742295467853546}
2025-01-13 06:39:55,484 [INFO] Step[250/4329]: training loss : 0.8717568290233612 TRAIN  loss dict:  {'classification_loss': 0.8717568290233612}
2025-01-13 06:40:07,073 [INFO] Step[300/4329]: training loss : 0.8671840512752533 TRAIN  loss dict:  {'classification_loss': 0.8671840512752533}
2025-01-13 06:40:18,748 [INFO] Step[350/4329]: training loss : 0.8885712778568268 TRAIN  loss dict:  {'classification_loss': 0.8885712778568268}
2025-01-13 06:40:30,417 [INFO] Step[400/4329]: training loss : 0.8774615871906281 TRAIN  loss dict:  {'classification_loss': 0.8774615871906281}
2025-01-13 06:40:42,051 [INFO] Step[450/4329]: training loss : 0.8661324262619019 TRAIN  loss dict:  {'classification_loss': 0.8661324262619019}
2025-01-13 06:40:53,680 [INFO] Step[500/4329]: training loss : 0.8690112853050231 TRAIN  loss dict:  {'classification_loss': 0.8690112853050231}
2025-01-13 06:41:05,294 [INFO] Step[550/4329]: training loss : 0.8703975689411163 TRAIN  loss dict:  {'classification_loss': 0.8703975689411163}
2025-01-13 06:41:16,880 [INFO] Step[600/4329]: training loss : 0.8668195843696594 TRAIN  loss dict:  {'classification_loss': 0.8668195843696594}
2025-01-13 06:41:28,536 [INFO] Step[650/4329]: training loss : 0.8664608526229859 TRAIN  loss dict:  {'classification_loss': 0.8664608526229859}
2025-01-13 06:41:40,146 [INFO] Step[700/4329]: training loss : 0.8688977587223053 TRAIN  loss dict:  {'classification_loss': 0.8688977587223053}
2025-01-13 06:41:51,813 [INFO] Step[750/4329]: training loss : 0.8696658396720887 TRAIN  loss dict:  {'classification_loss': 0.8696658396720887}
2025-01-13 06:42:03,476 [INFO] Step[800/4329]: training loss : 0.8754176616668701 TRAIN  loss dict:  {'classification_loss': 0.8754176616668701}
2025-01-13 06:42:15,600 [INFO] Step[850/4329]: training loss : 0.868217304944992 TRAIN  loss dict:  {'classification_loss': 0.868217304944992}
2025-01-13 06:42:27,730 [INFO] Step[900/4329]: training loss : 0.8632025742530822 TRAIN  loss dict:  {'classification_loss': 0.8632025742530822}
2025-01-13 06:42:40,204 [INFO] Step[950/4329]: training loss : 0.884838443994522 TRAIN  loss dict:  {'classification_loss': 0.884838443994522}
2025-01-13 06:42:53,430 [INFO] Step[1000/4329]: training loss : 0.8815103936195373 TRAIN  loss dict:  {'classification_loss': 0.8815103936195373}
2025-01-13 06:43:06,575 [INFO] Step[1050/4329]: training loss : 0.8700735759735108 TRAIN  loss dict:  {'classification_loss': 0.8700735759735108}
2025-01-13 06:43:18,520 [INFO] Step[1100/4329]: training loss : 0.8693606877326965 TRAIN  loss dict:  {'classification_loss': 0.8693606877326965}
2025-01-13 06:43:30,363 [INFO] Step[1150/4329]: training loss : 0.8651638793945312 TRAIN  loss dict:  {'classification_loss': 0.8651638793945312}
2025-01-13 06:43:42,084 [INFO] Step[1200/4329]: training loss : 0.8711538088321685 TRAIN  loss dict:  {'classification_loss': 0.8711538088321685}
2025-01-13 06:43:53,681 [INFO] Step[1250/4329]: training loss : 0.8906111598014832 TRAIN  loss dict:  {'classification_loss': 0.8906111598014832}
2025-01-13 06:44:05,293 [INFO] Step[1300/4329]: training loss : 0.8705428874492646 TRAIN  loss dict:  {'classification_loss': 0.8705428874492646}
2025-01-13 06:44:16,880 [INFO] Step[1350/4329]: training loss : 0.8682600879669189 TRAIN  loss dict:  {'classification_loss': 0.8682600879669189}
2025-01-13 06:44:28,558 [INFO] Step[1400/4329]: training loss : 0.8705102169513702 TRAIN  loss dict:  {'classification_loss': 0.8705102169513702}
2025-01-13 06:44:40,120 [INFO] Step[1450/4329]: training loss : 0.8675133800506591 TRAIN  loss dict:  {'classification_loss': 0.8675133800506591}
2025-01-13 06:44:51,753 [INFO] Step[1500/4329]: training loss : 0.8661639070510865 TRAIN  loss dict:  {'classification_loss': 0.8661639070510865}
2025-01-13 06:45:03,347 [INFO] Step[1550/4329]: training loss : 0.8688759779930115 TRAIN  loss dict:  {'classification_loss': 0.8688759779930115}
2025-01-13 06:45:14,964 [INFO] Step[1600/4329]: training loss : 0.8664446783065796 TRAIN  loss dict:  {'classification_loss': 0.8664446783065796}
2025-01-13 06:45:26,547 [INFO] Step[1650/4329]: training loss : 0.8742868363857269 TRAIN  loss dict:  {'classification_loss': 0.8742868363857269}
2025-01-13 06:45:38,119 [INFO] Step[1700/4329]: training loss : 0.866148784160614 TRAIN  loss dict:  {'classification_loss': 0.866148784160614}
2025-01-13 06:45:49,741 [INFO] Step[1750/4329]: training loss : 0.8677974569797516 TRAIN  loss dict:  {'classification_loss': 0.8677974569797516}
2025-01-13 06:46:01,344 [INFO] Step[1800/4329]: training loss : 0.8713887798786163 TRAIN  loss dict:  {'classification_loss': 0.8713887798786163}
2025-01-13 06:46:12,969 [INFO] Step[1850/4329]: training loss : 0.8640961635112763 TRAIN  loss dict:  {'classification_loss': 0.8640961635112763}
2025-01-13 06:46:24,536 [INFO] Step[1900/4329]: training loss : 0.8632487404346466 TRAIN  loss dict:  {'classification_loss': 0.8632487404346466}
2025-01-13 06:46:36,144 [INFO] Step[1950/4329]: training loss : 0.873533765077591 TRAIN  loss dict:  {'classification_loss': 0.873533765077591}
2025-01-13 06:46:47,730 [INFO] Step[2000/4329]: training loss : 0.905321147441864 TRAIN  loss dict:  {'classification_loss': 0.905321147441864}
2025-01-13 06:46:59,311 [INFO] Step[2050/4329]: training loss : 0.8697889637947083 TRAIN  loss dict:  {'classification_loss': 0.8697889637947083}
2025-01-13 06:47:10,888 [INFO] Step[2100/4329]: training loss : 0.869728821516037 TRAIN  loss dict:  {'classification_loss': 0.869728821516037}
2025-01-13 06:47:22,485 [INFO] Step[2150/4329]: training loss : 0.885453634262085 TRAIN  loss dict:  {'classification_loss': 0.885453634262085}
2025-01-13 06:47:34,075 [INFO] Step[2200/4329]: training loss : 0.8696791172027588 TRAIN  loss dict:  {'classification_loss': 0.8696791172027588}
2025-01-13 06:47:45,660 [INFO] Step[2250/4329]: training loss : 0.8653762876987457 TRAIN  loss dict:  {'classification_loss': 0.8653762876987457}
2025-01-13 06:47:57,257 [INFO] Step[2300/4329]: training loss : 0.874069641828537 TRAIN  loss dict:  {'classification_loss': 0.874069641828537}
2025-01-13 06:48:08,885 [INFO] Step[2350/4329]: training loss : 0.877680321931839 TRAIN  loss dict:  {'classification_loss': 0.877680321931839}
2025-01-13 06:48:20,507 [INFO] Step[2400/4329]: training loss : 0.866963176727295 TRAIN  loss dict:  {'classification_loss': 0.866963176727295}
2025-01-13 06:48:32,102 [INFO] Step[2450/4329]: training loss : 0.8828966891765595 TRAIN  loss dict:  {'classification_loss': 0.8828966891765595}
2025-01-13 06:48:43,656 [INFO] Step[2500/4329]: training loss : 0.876322512626648 TRAIN  loss dict:  {'classification_loss': 0.876322512626648}
2025-01-13 06:48:55,311 [INFO] Step[2550/4329]: training loss : 0.8675301849842072 TRAIN  loss dict:  {'classification_loss': 0.8675301849842072}
2025-01-13 06:49:06,945 [INFO] Step[2600/4329]: training loss : 0.870290060043335 TRAIN  loss dict:  {'classification_loss': 0.870290060043335}
2025-01-13 06:49:18,567 [INFO] Step[2650/4329]: training loss : 0.8812121260166168 TRAIN  loss dict:  {'classification_loss': 0.8812121260166168}
2025-01-13 06:49:30,190 [INFO] Step[2700/4329]: training loss : 0.8655987632274628 TRAIN  loss dict:  {'classification_loss': 0.8655987632274628}
2025-01-13 06:49:41,856 [INFO] Step[2750/4329]: training loss : 0.8651299464702606 TRAIN  loss dict:  {'classification_loss': 0.8651299464702606}
2025-01-13 06:49:53,425 [INFO] Step[2800/4329]: training loss : 0.8682192945480347 TRAIN  loss dict:  {'classification_loss': 0.8682192945480347}
2025-01-13 06:50:05,061 [INFO] Step[2850/4329]: training loss : 0.8645006942749024 TRAIN  loss dict:  {'classification_loss': 0.8645006942749024}
2025-01-13 06:50:16,649 [INFO] Step[2900/4329]: training loss : 0.8665584123134613 TRAIN  loss dict:  {'classification_loss': 0.8665584123134613}
2025-01-13 06:50:28,290 [INFO] Step[2950/4329]: training loss : 0.8697135663032531 TRAIN  loss dict:  {'classification_loss': 0.8697135663032531}
2025-01-13 06:50:39,902 [INFO] Step[3000/4329]: training loss : 0.8710496306419373 TRAIN  loss dict:  {'classification_loss': 0.8710496306419373}
2025-01-13 06:50:51,515 [INFO] Step[3050/4329]: training loss : 0.8659010720252991 TRAIN  loss dict:  {'classification_loss': 0.8659010720252991}
2025-01-13 06:51:03,119 [INFO] Step[3100/4329]: training loss : 0.8693418657779693 TRAIN  loss dict:  {'classification_loss': 0.8693418657779693}
2025-01-13 06:51:14,781 [INFO] Step[3150/4329]: training loss : 0.8707985293865204 TRAIN  loss dict:  {'classification_loss': 0.8707985293865204}
2025-01-13 06:51:26,358 [INFO] Step[3200/4329]: training loss : 0.8864344072341919 TRAIN  loss dict:  {'classification_loss': 0.8864344072341919}
2025-01-13 06:51:37,930 [INFO] Step[3250/4329]: training loss : 0.8673630309104919 TRAIN  loss dict:  {'classification_loss': 0.8673630309104919}
2025-01-13 06:51:49,511 [INFO] Step[3300/4329]: training loss : 0.8840532219409942 TRAIN  loss dict:  {'classification_loss': 0.8840532219409942}
2025-01-13 06:52:01,096 [INFO] Step[3350/4329]: training loss : 0.8639980471134185 TRAIN  loss dict:  {'classification_loss': 0.8639980471134185}
2025-01-13 06:52:12,734 [INFO] Step[3400/4329]: training loss : 0.8654318642616272 TRAIN  loss dict:  {'classification_loss': 0.8654318642616272}
2025-01-13 06:52:24,330 [INFO] Step[3450/4329]: training loss : 0.8636629211902619 TRAIN  loss dict:  {'classification_loss': 0.8636629211902619}
2025-01-13 06:52:35,931 [INFO] Step[3500/4329]: training loss : 0.8847512173652649 TRAIN  loss dict:  {'classification_loss': 0.8847512173652649}
2025-01-13 06:52:47,609 [INFO] Step[3550/4329]: training loss : 0.8705810940265656 TRAIN  loss dict:  {'classification_loss': 0.8705810940265656}
2025-01-13 06:52:59,252 [INFO] Step[3600/4329]: training loss : 0.8693963766098023 TRAIN  loss dict:  {'classification_loss': 0.8693963766098023}
2025-01-13 06:53:10,853 [INFO] Step[3650/4329]: training loss : 0.883976663351059 TRAIN  loss dict:  {'classification_loss': 0.883976663351059}
2025-01-13 06:53:22,467 [INFO] Step[3700/4329]: training loss : 0.866189022064209 TRAIN  loss dict:  {'classification_loss': 0.866189022064209}
2025-01-13 06:53:34,080 [INFO] Step[3750/4329]: training loss : 0.870705612897873 TRAIN  loss dict:  {'classification_loss': 0.870705612897873}
2025-01-13 06:53:45,675 [INFO] Step[3800/4329]: training loss : 0.865879008769989 TRAIN  loss dict:  {'classification_loss': 0.865879008769989}
2025-01-13 06:53:57,288 [INFO] Step[3850/4329]: training loss : 0.8700442397594452 TRAIN  loss dict:  {'classification_loss': 0.8700442397594452}
2025-01-13 06:54:08,920 [INFO] Step[3900/4329]: training loss : 0.876553189754486 TRAIN  loss dict:  {'classification_loss': 0.876553189754486}
2025-01-13 06:54:20,663 [INFO] Step[3950/4329]: training loss : 0.8651920509338379 TRAIN  loss dict:  {'classification_loss': 0.8651920509338379}
2025-01-13 06:54:32,803 [INFO] Step[4000/4329]: training loss : 0.8653805494308472 TRAIN  loss dict:  {'classification_loss': 0.8653805494308472}
2025-01-13 06:54:44,993 [INFO] Step[4050/4329]: training loss : 0.8672089385986328 TRAIN  loss dict:  {'classification_loss': 0.8672089385986328}
2025-01-13 06:54:57,611 [INFO] Step[4100/4329]: training loss : 0.8731422865390778 TRAIN  loss dict:  {'classification_loss': 0.8731422865390778}
2025-01-13 06:55:11,011 [INFO] Step[4150/4329]: training loss : 0.8702192258834839 TRAIN  loss dict:  {'classification_loss': 0.8702192258834839}
2025-01-13 06:55:24,170 [INFO] Step[4200/4329]: training loss : 0.8643139183521271 TRAIN  loss dict:  {'classification_loss': 0.8643139183521271}
2025-01-13 06:55:36,071 [INFO] Step[4250/4329]: training loss : 0.8657506573200225 TRAIN  loss dict:  {'classification_loss': 0.8657506573200225}
2025-01-13 06:55:48,012 [INFO] Step[4300/4329]: training loss : 0.8688659763336182 TRAIN  loss dict:  {'classification_loss': 0.8688659763336182}
2025-01-13 06:57:46,593 [INFO] Label accuracies statistics:
2025-01-13 06:57:46,593 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.5, 8: 0.5833333333333334, 9: 0.8333333333333334, 10: 1.0, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.5, 14: 0.75, 15: 0.5555555555555556, 16: 0.5833333333333334, 17: 0.6666666666666666, 18: 0.6666666666666666, 19: 0.6666666666666666, 20: 0.5, 21: 0.6666666666666666, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.8333333333333334, 26: 0.9166666666666666, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.6666666666666666, 31: 0.8333333333333334, 32: 0.6666666666666666, 33: 0.8333333333333334, 34: 1.0, 35: 1.0, 36: 0.5, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.8333333333333334, 43: 0.8333333333333334, 44: 0.6666666666666666, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.6666666666666666, 54: 0.5, 55: 0.6666666666666666, 56: 0.75, 57: 0.6666666666666666, 58: 0.5833333333333334, 59: 0.8333333333333334, 60: 0.75, 61: 0.9166666666666666, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.9166666666666666, 68: 0.6666666666666666, 69: 0.8333333333333334, 70: 0.4166666666666667, 71: 0.5833333333333334, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.5833333333333334, 77: 0.8333333333333334, 78: 1.0, 79: 0.8333333333333334, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.6666666666666666, 84: 0.5, 85: 0.6666666666666666, 86: 0.5833333333333334, 87: 0.9166666666666666, 88: 0.6666666666666666, 89: 0.6666666666666666, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.5833333333333334, 97: 0.75, 98: 0.75, 99: 0.9333333333333333, 100: 0.9166666666666666, 101: 1.0, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 0.8333333333333334, 107: 0.6666666666666666, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 1.0, 111: 1.0, 112: 0.9166666666666666, 113: 0.5, 114: 0.5833333333333334, 115: 1.0, 116: 0.75, 117: 0.8333333333333334, 118: 1.0, 119: 0.9166666666666666, 120: 0.9166666666666666, 121: 0.9166666666666666, 122: 0.9166666666666666, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 1.0, 132: 0.6666666666666666, 133: 1.0, 134: 0.75, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 0.9166666666666666, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.4166666666666667, 151: 0.9166666666666666, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.3333333333333333, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.8333333333333334, 166: 0.75, 167: 0.75, 168: 0.9166666666666666, 169: 0.9166666666666666, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.9166666666666666, 174: 1.0, 175: 0.9166666666666666, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.9166666666666666, 181: 0.8333333333333334, 182: 0.5833333333333334, 183: 0.8333333333333334, 184: 0.75, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.3333333333333333, 189: 1.0, 190: 0.5833333333333334, 191: 0.6666666666666666, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.75}

2025-01-13 06:57:48,426 [INFO] [51] TRAIN  loss: 0.8714499131832973 acc: 0.9986908978900354
2025-01-13 06:57:48,426 [INFO] [51] TRAIN  loss dict: {'classification_loss': 0.8714499131832973}
2025-01-13 06:57:48,426 [INFO] [51] VALIDATION loss: 1.5720319169187786 VALIDATION acc: 0.8181818181818182
2025-01-13 06:57:48,427 [INFO] [51] VALIDATION loss dict: {'classification_loss': 1.5720319169187786}
2025-01-13 06:57:48,427 [INFO] 
2025-01-13 06:58:05,677 [INFO] Step[50/4329]: training loss : 0.8665406703948975 TRAIN  loss dict:  {'classification_loss': 0.8665406703948975}
2025-01-13 06:58:17,215 [INFO] Step[100/4329]: training loss : 0.8677393007278442 TRAIN  loss dict:  {'classification_loss': 0.8677393007278442}
2025-01-13 06:58:28,826 [INFO] Step[150/4329]: training loss : 0.8684415769577026 TRAIN  loss dict:  {'classification_loss': 0.8684415769577026}
2025-01-13 06:58:40,390 [INFO] Step[200/4329]: training loss : 0.8784494173526763 TRAIN  loss dict:  {'classification_loss': 0.8784494173526763}
2025-01-13 06:58:52,017 [INFO] Step[250/4329]: training loss : 0.8651879692077636 TRAIN  loss dict:  {'classification_loss': 0.8651879692077636}
2025-01-13 06:59:03,639 [INFO] Step[300/4329]: training loss : 0.8711356413364411 TRAIN  loss dict:  {'classification_loss': 0.8711356413364411}
2025-01-13 06:59:15,278 [INFO] Step[350/4329]: training loss : 0.8663783597946167 TRAIN  loss dict:  {'classification_loss': 0.8663783597946167}
2025-01-13 06:59:26,952 [INFO] Step[400/4329]: training loss : 0.8648047959804535 TRAIN  loss dict:  {'classification_loss': 0.8648047959804535}
2025-01-13 06:59:38,607 [INFO] Step[450/4329]: training loss : 0.8639202105998993 TRAIN  loss dict:  {'classification_loss': 0.8639202105998993}
2025-01-13 06:59:50,288 [INFO] Step[500/4329]: training loss : 0.8637434959411621 TRAIN  loss dict:  {'classification_loss': 0.8637434959411621}
2025-01-13 07:00:01,933 [INFO] Step[550/4329]: training loss : 0.8996234703063964 TRAIN  loss dict:  {'classification_loss': 0.8996234703063964}
2025-01-13 07:00:13,556 [INFO] Step[600/4329]: training loss : 0.863559113740921 TRAIN  loss dict:  {'classification_loss': 0.863559113740921}
2025-01-13 07:00:25,189 [INFO] Step[650/4329]: training loss : 0.8718228602409362 TRAIN  loss dict:  {'classification_loss': 0.8718228602409362}
2025-01-13 07:00:36,799 [INFO] Step[700/4329]: training loss : 0.8661963784694672 TRAIN  loss dict:  {'classification_loss': 0.8661963784694672}
2025-01-13 07:00:48,491 [INFO] Step[750/4329]: training loss : 0.8670599341392518 TRAIN  loss dict:  {'classification_loss': 0.8670599341392518}
2025-01-13 07:01:00,114 [INFO] Step[800/4329]: training loss : 0.8680353140830994 TRAIN  loss dict:  {'classification_loss': 0.8680353140830994}
2025-01-13 07:01:11,752 [INFO] Step[850/4329]: training loss : 0.8696798813343048 TRAIN  loss dict:  {'classification_loss': 0.8696798813343048}
2025-01-13 07:01:23,383 [INFO] Step[900/4329]: training loss : 0.8683322286605835 TRAIN  loss dict:  {'classification_loss': 0.8683322286605835}
2025-01-13 07:01:34,998 [INFO] Step[950/4329]: training loss : 0.8920148730278015 TRAIN  loss dict:  {'classification_loss': 0.8920148730278015}
2025-01-13 07:01:46,648 [INFO] Step[1000/4329]: training loss : 0.8653360295295716 TRAIN  loss dict:  {'classification_loss': 0.8653360295295716}
2025-01-13 07:01:58,263 [INFO] Step[1050/4329]: training loss : 0.8664835751056671 TRAIN  loss dict:  {'classification_loss': 0.8664835751056671}
2025-01-13 07:02:09,840 [INFO] Step[1100/4329]: training loss : 0.9055228757858277 TRAIN  loss dict:  {'classification_loss': 0.9055228757858277}
2025-01-13 07:02:21,461 [INFO] Step[1150/4329]: training loss : 0.871138390302658 TRAIN  loss dict:  {'classification_loss': 0.871138390302658}
2025-01-13 07:02:33,031 [INFO] Step[1200/4329]: training loss : 0.8777790451049805 TRAIN  loss dict:  {'classification_loss': 0.8777790451049805}
2025-01-13 07:02:44,641 [INFO] Step[1250/4329]: training loss : 0.8710856378078461 TRAIN  loss dict:  {'classification_loss': 0.8710856378078461}
2025-01-13 07:02:56,222 [INFO] Step[1300/4329]: training loss : 0.8691847491264343 TRAIN  loss dict:  {'classification_loss': 0.8691847491264343}
2025-01-13 07:03:07,882 [INFO] Step[1350/4329]: training loss : 0.8674380993843078 TRAIN  loss dict:  {'classification_loss': 0.8674380993843078}
2025-01-13 07:03:19,507 [INFO] Step[1400/4329]: training loss : 0.864045979976654 TRAIN  loss dict:  {'classification_loss': 0.864045979976654}
2025-01-13 07:03:31,127 [INFO] Step[1450/4329]: training loss : 0.8689715230464935 TRAIN  loss dict:  {'classification_loss': 0.8689715230464935}
2025-01-13 07:03:42,727 [INFO] Step[1500/4329]: training loss : 0.8682563281059266 TRAIN  loss dict:  {'classification_loss': 0.8682563281059266}
2025-01-13 07:03:54,332 [INFO] Step[1550/4329]: training loss : 0.8764848363399506 TRAIN  loss dict:  {'classification_loss': 0.8764848363399506}
2025-01-13 07:04:05,980 [INFO] Step[1600/4329]: training loss : 0.8761985695362091 TRAIN  loss dict:  {'classification_loss': 0.8761985695362091}
2025-01-13 07:04:17,626 [INFO] Step[1650/4329]: training loss : 0.872515070438385 TRAIN  loss dict:  {'classification_loss': 0.872515070438385}
2025-01-13 07:04:29,236 [INFO] Step[1700/4329]: training loss : 0.8640080964565278 TRAIN  loss dict:  {'classification_loss': 0.8640080964565278}
2025-01-13 07:04:40,876 [INFO] Step[1750/4329]: training loss : 0.8658106029033661 TRAIN  loss dict:  {'classification_loss': 0.8658106029033661}
2025-01-13 07:04:52,498 [INFO] Step[1800/4329]: training loss : 0.864586318731308 TRAIN  loss dict:  {'classification_loss': 0.864586318731308}
2025-01-13 07:05:04,132 [INFO] Step[1850/4329]: training loss : 0.8662286281585694 TRAIN  loss dict:  {'classification_loss': 0.8662286281585694}
2025-01-13 07:05:15,703 [INFO] Step[1900/4329]: training loss : 0.8669880878925323 TRAIN  loss dict:  {'classification_loss': 0.8669880878925323}
2025-01-13 07:05:27,338 [INFO] Step[1950/4329]: training loss : 0.8613795959949493 TRAIN  loss dict:  {'classification_loss': 0.8613795959949493}
2025-01-13 07:05:38,893 [INFO] Step[2000/4329]: training loss : 0.888275533914566 TRAIN  loss dict:  {'classification_loss': 0.888275533914566}
2025-01-13 07:05:50,487 [INFO] Step[2050/4329]: training loss : 0.8640259242057801 TRAIN  loss dict:  {'classification_loss': 0.8640259242057801}
2025-01-13 07:06:02,088 [INFO] Step[2100/4329]: training loss : 0.8734105825424194 TRAIN  loss dict:  {'classification_loss': 0.8734105825424194}
2025-01-13 07:06:13,749 [INFO] Step[2150/4329]: training loss : 0.8635070455074311 TRAIN  loss dict:  {'classification_loss': 0.8635070455074311}
2025-01-13 07:06:25,392 [INFO] Step[2200/4329]: training loss : 0.8646196699142457 TRAIN  loss dict:  {'classification_loss': 0.8646196699142457}
2025-01-13 07:06:37,029 [INFO] Step[2250/4329]: training loss : 0.8662703943252563 TRAIN  loss dict:  {'classification_loss': 0.8662703943252563}
2025-01-13 07:06:48,778 [INFO] Step[2300/4329]: training loss : 0.868841426372528 TRAIN  loss dict:  {'classification_loss': 0.868841426372528}
2025-01-13 07:07:01,204 [INFO] Step[2350/4329]: training loss : 0.8663632929325104 TRAIN  loss dict:  {'classification_loss': 0.8663632929325104}
2025-01-13 07:07:13,352 [INFO] Step[2400/4329]: training loss : 0.8656808757781982 TRAIN  loss dict:  {'classification_loss': 0.8656808757781982}
2025-01-13 07:07:26,000 [INFO] Step[2450/4329]: training loss : 0.8808879017829895 TRAIN  loss dict:  {'classification_loss': 0.8808879017829895}
2025-01-13 07:07:38,901 [INFO] Step[2500/4329]: training loss : 0.8668802440166473 TRAIN  loss dict:  {'classification_loss': 0.8668802440166473}
2025-01-13 07:07:51,217 [INFO] Step[2550/4329]: training loss : 0.8680588364601135 TRAIN  loss dict:  {'classification_loss': 0.8680588364601135}
2025-01-13 07:08:03,120 [INFO] Step[2600/4329]: training loss : 0.8621797299385071 TRAIN  loss dict:  {'classification_loss': 0.8621797299385071}
2025-01-13 07:08:14,987 [INFO] Step[2650/4329]: training loss : 0.8837843823432923 TRAIN  loss dict:  {'classification_loss': 0.8837843823432923}
2025-01-13 07:08:26,617 [INFO] Step[2700/4329]: training loss : 0.86870063662529 TRAIN  loss dict:  {'classification_loss': 0.86870063662529}
2025-01-13 07:08:38,248 [INFO] Step[2750/4329]: training loss : 0.864512791633606 TRAIN  loss dict:  {'classification_loss': 0.864512791633606}
2025-01-13 07:08:49,885 [INFO] Step[2800/4329]: training loss : 0.8672150194644928 TRAIN  loss dict:  {'classification_loss': 0.8672150194644928}
2025-01-13 07:09:01,523 [INFO] Step[2850/4329]: training loss : 0.8704775297641754 TRAIN  loss dict:  {'classification_loss': 0.8704775297641754}
2025-01-13 07:09:13,169 [INFO] Step[2900/4329]: training loss : 0.8725087893009186 TRAIN  loss dict:  {'classification_loss': 0.8725087893009186}
2025-01-13 07:09:24,779 [INFO] Step[2950/4329]: training loss : 0.8700990569591522 TRAIN  loss dict:  {'classification_loss': 0.8700990569591522}
2025-01-13 07:09:36,380 [INFO] Step[3000/4329]: training loss : 0.8667460060119629 TRAIN  loss dict:  {'classification_loss': 0.8667460060119629}
2025-01-13 07:09:47,996 [INFO] Step[3050/4329]: training loss : 0.8681007325649261 TRAIN  loss dict:  {'classification_loss': 0.8681007325649261}
2025-01-13 07:09:59,641 [INFO] Step[3100/4329]: training loss : 0.8817811429500579 TRAIN  loss dict:  {'classification_loss': 0.8817811429500579}
2025-01-13 07:10:11,298 [INFO] Step[3150/4329]: training loss : 0.8660596966743469 TRAIN  loss dict:  {'classification_loss': 0.8660596966743469}
2025-01-13 07:10:22,912 [INFO] Step[3200/4329]: training loss : 0.8695979702472687 TRAIN  loss dict:  {'classification_loss': 0.8695979702472687}
2025-01-13 07:10:34,530 [INFO] Step[3250/4329]: training loss : 0.8680895149707795 TRAIN  loss dict:  {'classification_loss': 0.8680895149707795}
2025-01-13 07:10:46,100 [INFO] Step[3300/4329]: training loss : 0.8687973916530609 TRAIN  loss dict:  {'classification_loss': 0.8687973916530609}
2025-01-13 07:10:57,745 [INFO] Step[3350/4329]: training loss : 0.8650509130954742 TRAIN  loss dict:  {'classification_loss': 0.8650509130954742}
2025-01-13 07:11:09,335 [INFO] Step[3400/4329]: training loss : 0.8662941539287567 TRAIN  loss dict:  {'classification_loss': 0.8662941539287567}
2025-01-13 07:11:20,961 [INFO] Step[3450/4329]: training loss : 0.8668481409549713 TRAIN  loss dict:  {'classification_loss': 0.8668481409549713}
2025-01-13 07:11:32,596 [INFO] Step[3500/4329]: training loss : 0.8661592161655426 TRAIN  loss dict:  {'classification_loss': 0.8661592161655426}
2025-01-13 07:11:44,237 [INFO] Step[3550/4329]: training loss : 0.8661983621120453 TRAIN  loss dict:  {'classification_loss': 0.8661983621120453}
2025-01-13 07:11:55,872 [INFO] Step[3600/4329]: training loss : 0.8761540949344635 TRAIN  loss dict:  {'classification_loss': 0.8761540949344635}
2025-01-13 07:12:07,497 [INFO] Step[3650/4329]: training loss : 0.8674008119106292 TRAIN  loss dict:  {'classification_loss': 0.8674008119106292}
2025-01-13 07:12:19,104 [INFO] Step[3700/4329]: training loss : 0.8698596727848052 TRAIN  loss dict:  {'classification_loss': 0.8698596727848052}
2025-01-13 07:12:30,739 [INFO] Step[3750/4329]: training loss : 0.8862037026882171 TRAIN  loss dict:  {'classification_loss': 0.8862037026882171}
2025-01-13 07:12:42,313 [INFO] Step[3800/4329]: training loss : 0.8807645905017852 TRAIN  loss dict:  {'classification_loss': 0.8807645905017852}
2025-01-13 07:12:53,905 [INFO] Step[3850/4329]: training loss : 0.8882904756069183 TRAIN  loss dict:  {'classification_loss': 0.8882904756069183}
2025-01-13 07:13:05,458 [INFO] Step[3900/4329]: training loss : 0.8796603977680206 TRAIN  loss dict:  {'classification_loss': 0.8796603977680206}
2025-01-13 07:13:17,099 [INFO] Step[3950/4329]: training loss : 0.8783710706233978 TRAIN  loss dict:  {'classification_loss': 0.8783710706233978}
2025-01-13 07:13:28,735 [INFO] Step[4000/4329]: training loss : 0.8635900175571442 TRAIN  loss dict:  {'classification_loss': 0.8635900175571442}
2025-01-13 07:13:40,357 [INFO] Step[4050/4329]: training loss : 0.8778518629074097 TRAIN  loss dict:  {'classification_loss': 0.8778518629074097}
2025-01-13 07:13:51,983 [INFO] Step[4100/4329]: training loss : 0.8770806658267974 TRAIN  loss dict:  {'classification_loss': 0.8770806658267974}
2025-01-13 07:14:03,638 [INFO] Step[4150/4329]: training loss : 0.8704065442085266 TRAIN  loss dict:  {'classification_loss': 0.8704065442085266}
2025-01-13 07:14:15,265 [INFO] Step[4200/4329]: training loss : 0.8642064106464385 TRAIN  loss dict:  {'classification_loss': 0.8642064106464385}
2025-01-13 07:14:26,896 [INFO] Step[4250/4329]: training loss : 0.8699867641925811 TRAIN  loss dict:  {'classification_loss': 0.8699867641925811}
2025-01-13 07:14:38,502 [INFO] Step[4300/4329]: training loss : 0.8685697364807129 TRAIN  loss dict:  {'classification_loss': 0.8685697364807129}
2025-01-13 07:16:37,432 [INFO] Label accuracies statistics:
2025-01-13 07:16:37,432 [INFO] {0: 0.5555555555555556, 1: 1.0, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5, 7: 0.5833333333333334, 8: 0.6666666666666666, 9: 0.75, 10: 1.0, 11: 0.8333333333333334, 12: 0.4166666666666667, 13: 0.5, 14: 0.75, 15: 0.7777777777777778, 16: 0.75, 17: 0.6666666666666666, 18: 0.6666666666666666, 19: 0.8333333333333334, 20: 0.6666666666666666, 21: 0.6666666666666666, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.8333333333333334, 26: 0.8333333333333334, 27: 0.75, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.9166666666666666, 32: 0.75, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.9166666666666666, 41: 0.4166666666666667, 42: 0.8333333333333334, 43: 0.8333333333333334, 44: 0.6666666666666666, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.75, 51: 0.6666666666666666, 52: 1.0, 53: 0.75, 54: 0.3333333333333333, 55: 0.6666666666666666, 56: 0.6666666666666666, 57: 0.75, 58: 0.5833333333333334, 59: 0.8333333333333334, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.75, 69: 0.6666666666666666, 70: 0.5833333333333334, 71: 0.5, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 0.9166666666666666, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.5833333333333334, 87: 0.9166666666666666, 88: 0.6666666666666666, 89: 0.5833333333333334, 90: 0.9166666666666666, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.5833333333333334, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.9166666666666666, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 0.9166666666666666, 106: 1.0, 107: 0.4166666666666667, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 1.0, 111: 0.9166666666666666, 112: 0.9166666666666666, 113: 0.4166666666666667, 114: 0.5833333333333334, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.8333333333333334, 120: 0.8333333333333334, 121: 0.8333333333333334, 122: 0.9166666666666666, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.9166666666666666, 127: 0.75, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.9166666666666666, 132: 0.4166666666666667, 133: 1.0, 134: 0.75, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 0.9166666666666666, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 0.9166666666666666, 153: 0.8333333333333334, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.25, 161: 0.8333333333333334, 162: 1.0, 163: 0.9166666666666666, 164: 0.75, 165: 0.8333333333333334, 166: 0.75, 167: 0.75, 168: 0.9166666666666666, 169: 0.9166666666666666, 170: 0.9166666666666666, 171: 0.5, 172: 1.0, 173: 0.9166666666666666, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.75, 178: 0.9166666666666666, 179: 0.0, 180: 0.8333333333333334, 181: 0.6666666666666666, 182: 0.5, 183: 0.8333333333333334, 184: 0.75, 185: 1.0, 186: 0.8333333333333334, 187: 0.9166666666666666, 188: 0.75, 189: 1.0, 190: 0.5833333333333334, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.75, 198: 0.6666666666666666}

2025-01-13 07:16:37,434 [INFO] [52] TRAIN  loss: 0.8707643556082654 acc: 0.9983828738641614
2025-01-13 07:16:37,435 [INFO] [52] TRAIN  loss dict: {'classification_loss': 0.8707643556082654}
2025-01-13 07:16:37,435 [INFO] [52] VALIDATION loss: 1.598664898688745 VALIDATION acc: 0.8106060606060606
2025-01-13 07:16:37,435 [INFO] [52] VALIDATION loss dict: {'classification_loss': 1.598664898688745}
2025-01-13 07:16:37,435 [INFO] 
2025-01-13 07:16:54,518 [INFO] Step[50/4329]: training loss : 0.8683177483081818 TRAIN  loss dict:  {'classification_loss': 0.8683177483081818}
2025-01-13 07:17:06,106 [INFO] Step[100/4329]: training loss : 0.8632487463951111 TRAIN  loss dict:  {'classification_loss': 0.8632487463951111}
2025-01-13 07:17:17,750 [INFO] Step[150/4329]: training loss : 0.8715339243412018 TRAIN  loss dict:  {'classification_loss': 0.8715339243412018}
2025-01-13 07:17:29,394 [INFO] Step[200/4329]: training loss : 0.8635283803939819 TRAIN  loss dict:  {'classification_loss': 0.8635283803939819}
2025-01-13 07:17:41,058 [INFO] Step[250/4329]: training loss : 0.8772516810894012 TRAIN  loss dict:  {'classification_loss': 0.8772516810894012}
2025-01-13 07:17:52,712 [INFO] Step[300/4329]: training loss : 0.8627218341827393 TRAIN  loss dict:  {'classification_loss': 0.8627218341827393}
2025-01-13 07:18:04,390 [INFO] Step[350/4329]: training loss : 0.864493441581726 TRAIN  loss dict:  {'classification_loss': 0.864493441581726}
2025-01-13 07:18:16,057 [INFO] Step[400/4329]: training loss : 0.8712040543556213 TRAIN  loss dict:  {'classification_loss': 0.8712040543556213}
2025-01-13 07:18:27,728 [INFO] Step[450/4329]: training loss : 0.8644800543785095 TRAIN  loss dict:  {'classification_loss': 0.8644800543785095}
2025-01-13 07:18:39,394 [INFO] Step[500/4329]: training loss : 0.8652296996116638 TRAIN  loss dict:  {'classification_loss': 0.8652296996116638}
2025-01-13 07:18:51,061 [INFO] Step[550/4329]: training loss : 0.8679945242404937 TRAIN  loss dict:  {'classification_loss': 0.8679945242404937}
2025-01-13 07:19:02,689 [INFO] Step[600/4329]: training loss : 0.8766264128684997 TRAIN  loss dict:  {'classification_loss': 0.8766264128684997}
2025-01-13 07:19:14,683 [INFO] Step[650/4329]: training loss : 0.8633697974681854 TRAIN  loss dict:  {'classification_loss': 0.8633697974681854}
2025-01-13 07:19:28,141 [INFO] Step[700/4329]: training loss : 0.863888931274414 TRAIN  loss dict:  {'classification_loss': 0.863888931274414}
2025-01-13 07:19:40,697 [INFO] Step[750/4329]: training loss : 0.8737059187889099 TRAIN  loss dict:  {'classification_loss': 0.8737059187889099}
2025-01-13 07:19:55,000 [INFO] Step[800/4329]: training loss : 0.8646164870262146 TRAIN  loss dict:  {'classification_loss': 0.8646164870262146}
2025-01-13 07:20:08,117 [INFO] Step[850/4329]: training loss : 0.8721365678310394 TRAIN  loss dict:  {'classification_loss': 0.8721365678310394}
2025-01-13 07:20:20,037 [INFO] Step[900/4329]: training loss : 0.8666990578174592 TRAIN  loss dict:  {'classification_loss': 0.8666990578174592}
2025-01-13 07:20:31,928 [INFO] Step[950/4329]: training loss : 0.8692871761322022 TRAIN  loss dict:  {'classification_loss': 0.8692871761322022}
2025-01-13 07:20:43,531 [INFO] Step[1000/4329]: training loss : 0.8683639299869538 TRAIN  loss dict:  {'classification_loss': 0.8683639299869538}
2025-01-13 07:20:55,143 [INFO] Step[1050/4329]: training loss : 0.866949223279953 TRAIN  loss dict:  {'classification_loss': 0.866949223279953}
2025-01-13 07:21:06,711 [INFO] Step[1100/4329]: training loss : 0.869128087759018 TRAIN  loss dict:  {'classification_loss': 0.869128087759018}
2025-01-13 07:21:18,374 [INFO] Step[1150/4329]: training loss : 0.8731831455230713 TRAIN  loss dict:  {'classification_loss': 0.8731831455230713}
2025-01-13 07:21:29,968 [INFO] Step[1200/4329]: training loss : 0.8652719688415528 TRAIN  loss dict:  {'classification_loss': 0.8652719688415528}
2025-01-13 07:21:41,580 [INFO] Step[1250/4329]: training loss : 0.8741828370094299 TRAIN  loss dict:  {'classification_loss': 0.8741828370094299}
2025-01-13 07:21:53,184 [INFO] Step[1300/4329]: training loss : 0.8820272254943847 TRAIN  loss dict:  {'classification_loss': 0.8820272254943847}
2025-01-13 07:22:04,802 [INFO] Step[1350/4329]: training loss : 0.8684478271007537 TRAIN  loss dict:  {'classification_loss': 0.8684478271007537}
2025-01-13 07:22:16,427 [INFO] Step[1400/4329]: training loss : 0.8646596133708954 TRAIN  loss dict:  {'classification_loss': 0.8646596133708954}
2025-01-13 07:22:28,087 [INFO] Step[1450/4329]: training loss : 0.8721454620361329 TRAIN  loss dict:  {'classification_loss': 0.8721454620361329}
2025-01-13 07:22:39,671 [INFO] Step[1500/4329]: training loss : 0.8833051109313965 TRAIN  loss dict:  {'classification_loss': 0.8833051109313965}
2025-01-13 07:22:51,306 [INFO] Step[1550/4329]: training loss : 0.867102119922638 TRAIN  loss dict:  {'classification_loss': 0.867102119922638}
2025-01-13 07:23:02,874 [INFO] Step[1600/4329]: training loss : 0.8658416318893433 TRAIN  loss dict:  {'classification_loss': 0.8658416318893433}
2025-01-13 07:23:14,463 [INFO] Step[1650/4329]: training loss : 0.871254277229309 TRAIN  loss dict:  {'classification_loss': 0.871254277229309}
2025-01-13 07:23:26,069 [INFO] Step[1700/4329]: training loss : 0.8731724345684051 TRAIN  loss dict:  {'classification_loss': 0.8731724345684051}
2025-01-13 07:23:37,685 [INFO] Step[1750/4329]: training loss : 0.8642438983917237 TRAIN  loss dict:  {'classification_loss': 0.8642438983917237}
2025-01-13 07:23:49,320 [INFO] Step[1800/4329]: training loss : 0.8853229260444642 TRAIN  loss dict:  {'classification_loss': 0.8853229260444642}
2025-01-13 07:24:00,941 [INFO] Step[1850/4329]: training loss : 0.8725708425045013 TRAIN  loss dict:  {'classification_loss': 0.8725708425045013}
2025-01-13 07:24:12,548 [INFO] Step[1900/4329]: training loss : 0.8668839752674102 TRAIN  loss dict:  {'classification_loss': 0.8668839752674102}
2025-01-13 07:24:24,127 [INFO] Step[1950/4329]: training loss : 0.8719529843330384 TRAIN  loss dict:  {'classification_loss': 0.8719529843330384}
2025-01-13 07:24:35,747 [INFO] Step[2000/4329]: training loss : 0.8657373869419098 TRAIN  loss dict:  {'classification_loss': 0.8657373869419098}
2025-01-13 07:24:47,363 [INFO] Step[2050/4329]: training loss : 0.8641839373111725 TRAIN  loss dict:  {'classification_loss': 0.8641839373111725}
2025-01-13 07:24:58,960 [INFO] Step[2100/4329]: training loss : 0.8647007834911347 TRAIN  loss dict:  {'classification_loss': 0.8647007834911347}
2025-01-13 07:25:10,578 [INFO] Step[2150/4329]: training loss : 0.8663114428520202 TRAIN  loss dict:  {'classification_loss': 0.8663114428520202}
2025-01-13 07:25:22,169 [INFO] Step[2200/4329]: training loss : 0.8672310864925384 TRAIN  loss dict:  {'classification_loss': 0.8672310864925384}
2025-01-13 07:25:33,789 [INFO] Step[2250/4329]: training loss : 0.8659620010852813 TRAIN  loss dict:  {'classification_loss': 0.8659620010852813}
2025-01-13 07:25:45,389 [INFO] Step[2300/4329]: training loss : 0.8661112082004547 TRAIN  loss dict:  {'classification_loss': 0.8661112082004547}
2025-01-13 07:25:56,982 [INFO] Step[2350/4329]: training loss : 0.8637873184680939 TRAIN  loss dict:  {'classification_loss': 0.8637873184680939}
2025-01-13 07:26:08,572 [INFO] Step[2400/4329]: training loss : 0.8626060163974762 TRAIN  loss dict:  {'classification_loss': 0.8626060163974762}
2025-01-13 07:26:20,170 [INFO] Step[2450/4329]: training loss : 0.8675990617275238 TRAIN  loss dict:  {'classification_loss': 0.8675990617275238}
2025-01-13 07:26:31,787 [INFO] Step[2500/4329]: training loss : 0.8774152946472168 TRAIN  loss dict:  {'classification_loss': 0.8774152946472168}
2025-01-13 07:26:43,415 [INFO] Step[2550/4329]: training loss : 0.8824367368221283 TRAIN  loss dict:  {'classification_loss': 0.8824367368221283}
2025-01-13 07:26:54,965 [INFO] Step[2600/4329]: training loss : 0.8718291151523591 TRAIN  loss dict:  {'classification_loss': 0.8718291151523591}
2025-01-13 07:27:06,557 [INFO] Step[2650/4329]: training loss : 0.8628706920146942 TRAIN  loss dict:  {'classification_loss': 0.8628706920146942}
2025-01-13 07:27:18,139 [INFO] Step[2700/4329]: training loss : 0.8710733842849732 TRAIN  loss dict:  {'classification_loss': 0.8710733842849732}
2025-01-13 07:27:29,756 [INFO] Step[2750/4329]: training loss : 0.8659216916561127 TRAIN  loss dict:  {'classification_loss': 0.8659216916561127}
2025-01-13 07:27:41,394 [INFO] Step[2800/4329]: training loss : 0.9020785045623779 TRAIN  loss dict:  {'classification_loss': 0.9020785045623779}
2025-01-13 07:27:53,038 [INFO] Step[2850/4329]: training loss : 0.8648989772796631 TRAIN  loss dict:  {'classification_loss': 0.8648989772796631}
2025-01-13 07:28:04,639 [INFO] Step[2900/4329]: training loss : 0.865632152557373 TRAIN  loss dict:  {'classification_loss': 0.865632152557373}
2025-01-13 07:28:16,280 [INFO] Step[2950/4329]: training loss : 0.8662896490097046 TRAIN  loss dict:  {'classification_loss': 0.8662896490097046}
2025-01-13 07:28:27,859 [INFO] Step[3000/4329]: training loss : 0.8701653802394866 TRAIN  loss dict:  {'classification_loss': 0.8701653802394866}
2025-01-13 07:28:39,473 [INFO] Step[3050/4329]: training loss : 0.8668677723407745 TRAIN  loss dict:  {'classification_loss': 0.8668677723407745}
2025-01-13 07:28:51,047 [INFO] Step[3100/4329]: training loss : 0.871128534078598 TRAIN  loss dict:  {'classification_loss': 0.871128534078598}
2025-01-13 07:29:02,670 [INFO] Step[3150/4329]: training loss : 0.8660014665126801 TRAIN  loss dict:  {'classification_loss': 0.8660014665126801}
2025-01-13 07:29:14,326 [INFO] Step[3200/4329]: training loss : 0.8638157021999359 TRAIN  loss dict:  {'classification_loss': 0.8638157021999359}
2025-01-13 07:29:25,956 [INFO] Step[3250/4329]: training loss : 0.8953854775428772 TRAIN  loss dict:  {'classification_loss': 0.8953854775428772}
2025-01-13 07:29:37,568 [INFO] Step[3300/4329]: training loss : 0.8655576634407044 TRAIN  loss dict:  {'classification_loss': 0.8655576634407044}
2025-01-13 07:29:49,188 [INFO] Step[3350/4329]: training loss : 0.8676049637794495 TRAIN  loss dict:  {'classification_loss': 0.8676049637794495}
2025-01-13 07:30:00,820 [INFO] Step[3400/4329]: training loss : 0.8723930668830872 TRAIN  loss dict:  {'classification_loss': 0.8723930668830872}
2025-01-13 07:30:12,450 [INFO] Step[3450/4329]: training loss : 0.8927960121631622 TRAIN  loss dict:  {'classification_loss': 0.8927960121631622}
2025-01-13 07:30:24,039 [INFO] Step[3500/4329]: training loss : 0.8717385649681091 TRAIN  loss dict:  {'classification_loss': 0.8717385649681091}
2025-01-13 07:30:35,687 [INFO] Step[3550/4329]: training loss : 0.8665118396282196 TRAIN  loss dict:  {'classification_loss': 0.8665118396282196}
2025-01-13 07:30:47,284 [INFO] Step[3600/4329]: training loss : 0.8872375524044037 TRAIN  loss dict:  {'classification_loss': 0.8872375524044037}
2025-01-13 07:30:58,943 [INFO] Step[3650/4329]: training loss : 0.881379736661911 TRAIN  loss dict:  {'classification_loss': 0.881379736661911}
2025-01-13 07:31:10,573 [INFO] Step[3700/4329]: training loss : 0.8708450675010682 TRAIN  loss dict:  {'classification_loss': 0.8708450675010682}
2025-01-13 07:31:22,288 [INFO] Step[3750/4329]: training loss : 0.8682623279094696 TRAIN  loss dict:  {'classification_loss': 0.8682623279094696}
2025-01-13 07:31:34,433 [INFO] Step[3800/4329]: training loss : 0.8718063962459565 TRAIN  loss dict:  {'classification_loss': 0.8718063962459565}
2025-01-13 07:31:46,649 [INFO] Step[3850/4329]: training loss : 0.8688417398929595 TRAIN  loss dict:  {'classification_loss': 0.8688417398929595}
2025-01-13 07:31:59,283 [INFO] Step[3900/4329]: training loss : 0.8656890761852264 TRAIN  loss dict:  {'classification_loss': 0.8656890761852264}
2025-01-13 07:32:12,673 [INFO] Step[3950/4329]: training loss : 0.8752952229976654 TRAIN  loss dict:  {'classification_loss': 0.8752952229976654}
2025-01-13 07:32:26,890 [INFO] Step[4000/4329]: training loss : 0.8641752445697785 TRAIN  loss dict:  {'classification_loss': 0.8641752445697785}
2025-01-13 07:32:38,805 [INFO] Step[4050/4329]: training loss : 0.8640010035037995 TRAIN  loss dict:  {'classification_loss': 0.8640010035037995}
2025-01-13 07:32:50,744 [INFO] Step[4100/4329]: training loss : 0.8713598418235778 TRAIN  loss dict:  {'classification_loss': 0.8713598418235778}
2025-01-13 07:33:02,393 [INFO] Step[4150/4329]: training loss : 0.8656001043319702 TRAIN  loss dict:  {'classification_loss': 0.8656001043319702}
2025-01-13 07:33:14,025 [INFO] Step[4200/4329]: training loss : 0.878044822216034 TRAIN  loss dict:  {'classification_loss': 0.878044822216034}
2025-01-13 07:33:25,632 [INFO] Step[4250/4329]: training loss : 0.8632071042060852 TRAIN  loss dict:  {'classification_loss': 0.8632071042060852}
2025-01-13 07:33:37,272 [INFO] Step[4300/4329]: training loss : 0.8796416342258453 TRAIN  loss dict:  {'classification_loss': 0.8796416342258453}
2025-01-13 07:35:36,251 [INFO] Label accuracies statistics:
2025-01-13 07:35:36,251 [INFO] {0: 0.5555555555555556, 1: 1.0, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.9166666666666666, 6: 0.5833333333333334, 7: 0.5, 8: 0.75, 9: 0.8333333333333334, 10: 1.0, 11: 1.0, 12: 0.4166666666666667, 13: 0.5, 14: 0.6666666666666666, 15: 0.7777777777777778, 16: 0.5833333333333334, 17: 0.5, 18: 0.5833333333333334, 19: 0.8333333333333334, 20: 0.75, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.8333333333333334, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.75, 32: 0.75, 33: 0.8333333333333334, 34: 0.9166666666666666, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.9166666666666666, 41: 0.5833333333333334, 42: 0.75, 43: 0.8333333333333334, 44: 0.5833333333333334, 45: 0.5833333333333334, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 0.9166666666666666, 53: 0.5833333333333334, 54: 0.5, 55: 0.6666666666666666, 56: 0.6666666666666666, 57: 0.75, 58: 0.5833333333333334, 59: 0.9166666666666666, 60: 0.6666666666666666, 61: 1.0, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.6666666666666666, 69: 0.6666666666666666, 70: 0.5, 71: 0.4166666666666667, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.8333333333333334, 78: 1.0, 79: 0.8333333333333334, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5833333333333334, 84: 0.5833333333333334, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.75, 89: 0.6666666666666666, 90: 0.8333333333333334, 91: 0.9166666666666666, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 0.9166666666666666, 96: 0.6666666666666666, 97: 0.6666666666666666, 98: 0.75, 99: 1.0, 100: 0.9166666666666666, 101: 1.0, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 0.9166666666666666, 106: 1.0, 107: 0.4166666666666667, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 1.0, 111: 1.0, 112: 0.9166666666666666, 113: 0.5833333333333334, 114: 0.4166666666666667, 115: 1.0, 116: 0.75, 117: 0.8333333333333334, 118: 1.0, 119: 0.75, 120: 0.9166666666666666, 121: 0.9166666666666666, 122: 0.9166666666666666, 123: 1.0, 124: 0.9166666666666666, 125: 0.9166666666666666, 126: 0.9166666666666666, 127: 0.8333333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.9166666666666666, 132: 0.4166666666666667, 133: 1.0, 134: 0.75, 135: 0.9166666666666666, 136: 0.8333333333333334, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 0.9166666666666666, 142: 0.8333333333333334, 143: 1.0, 144: 0.75, 145: 0.9166666666666666, 146: 1.0, 147: 0.9166666666666666, 148: 0.6666666666666666, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.9166666666666666, 156: 0.75, 157: 0.9166666666666666, 158: 0.7777777777777778, 159: 1.0, 160: 0.4166666666666667, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.9166666666666666, 166: 0.8333333333333334, 167: 0.75, 168: 0.9166666666666666, 169: 0.9166666666666666, 170: 1.0, 171: 0.6666666666666666, 172: 1.0, 173: 0.9166666666666666, 174: 0.9166666666666666, 175: 1.0, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.1111111111111111, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.6666666666666666, 183: 0.8333333333333334, 184: 0.75, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.75, 189: 0.9166666666666666, 190: 0.6666666666666666, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 1.0, 197: 0.8333333333333334, 198: 0.75}

2025-01-13 07:35:37,180 [INFO] [53] TRAIN  loss: 0.8703087715745715 acc: 0.9983058678576929
2025-01-13 07:35:37,180 [INFO] [53] TRAIN  loss dict: {'classification_loss': 0.8703087715745715}
2025-01-13 07:35:37,180 [INFO] [53] VALIDATION loss: 1.5640622194517741 VALIDATION acc: 0.8173400673400674
2025-01-13 07:35:37,180 [INFO] [53] VALIDATION loss dict: {'classification_loss': 1.5640622194517741}
2025-01-13 07:35:37,180 [INFO] 
2025-01-13 07:35:54,352 [INFO] Step[50/4329]: training loss : 0.8686467480659484 TRAIN  loss dict:  {'classification_loss': 0.8686467480659484}
2025-01-13 07:36:05,932 [INFO] Step[100/4329]: training loss : 0.8629591989517212 TRAIN  loss dict:  {'classification_loss': 0.8629591989517212}
2025-01-13 07:36:17,548 [INFO] Step[150/4329]: training loss : 0.8643571591377258 TRAIN  loss dict:  {'classification_loss': 0.8643571591377258}
2025-01-13 07:36:29,145 [INFO] Step[200/4329]: training loss : 0.890442658662796 TRAIN  loss dict:  {'classification_loss': 0.890442658662796}
2025-01-13 07:36:40,758 [INFO] Step[250/4329]: training loss : 0.8698130702972412 TRAIN  loss dict:  {'classification_loss': 0.8698130702972412}
2025-01-13 07:36:52,341 [INFO] Step[300/4329]: training loss : 0.8648611962795257 TRAIN  loss dict:  {'classification_loss': 0.8648611962795257}
2025-01-13 07:37:03,978 [INFO] Step[350/4329]: training loss : 0.9000733149051666 TRAIN  loss dict:  {'classification_loss': 0.9000733149051666}
2025-01-13 07:37:15,578 [INFO] Step[400/4329]: training loss : 0.867087140083313 TRAIN  loss dict:  {'classification_loss': 0.867087140083313}
2025-01-13 07:37:27,179 [INFO] Step[450/4329]: training loss : 0.8694854319095612 TRAIN  loss dict:  {'classification_loss': 0.8694854319095612}
2025-01-13 07:37:38,824 [INFO] Step[500/4329]: training loss : 0.8750081586837769 TRAIN  loss dict:  {'classification_loss': 0.8750081586837769}
2025-01-13 07:37:50,520 [INFO] Step[550/4329]: training loss : 0.8698345470428467 TRAIN  loss dict:  {'classification_loss': 0.8698345470428467}
2025-01-13 07:38:02,128 [INFO] Step[600/4329]: training loss : 0.8616973066329956 TRAIN  loss dict:  {'classification_loss': 0.8616973066329956}
2025-01-13 07:38:13,780 [INFO] Step[650/4329]: training loss : 0.866026314496994 TRAIN  loss dict:  {'classification_loss': 0.866026314496994}
2025-01-13 07:38:25,399 [INFO] Step[700/4329]: training loss : 0.8666521489620209 TRAIN  loss dict:  {'classification_loss': 0.8666521489620209}
2025-01-13 07:38:37,047 [INFO] Step[750/4329]: training loss : 0.8660307061672211 TRAIN  loss dict:  {'classification_loss': 0.8660307061672211}
2025-01-13 07:38:48,660 [INFO] Step[800/4329]: training loss : 0.8684798777103424 TRAIN  loss dict:  {'classification_loss': 0.8684798777103424}
2025-01-13 07:39:00,281 [INFO] Step[850/4329]: training loss : 0.8668717384338379 TRAIN  loss dict:  {'classification_loss': 0.8668717384338379}
2025-01-13 07:39:11,897 [INFO] Step[900/4329]: training loss : 0.8659544444084167 TRAIN  loss dict:  {'classification_loss': 0.8659544444084167}
2025-01-13 07:39:23,522 [INFO] Step[950/4329]: training loss : 0.8764637291431427 TRAIN  loss dict:  {'classification_loss': 0.8764637291431427}
2025-01-13 07:39:35,186 [INFO] Step[1000/4329]: training loss : 0.8641492176055908 TRAIN  loss dict:  {'classification_loss': 0.8641492176055908}
2025-01-13 07:39:46,858 [INFO] Step[1050/4329]: training loss : 0.8683989012241363 TRAIN  loss dict:  {'classification_loss': 0.8683989012241363}
2025-01-13 07:39:58,473 [INFO] Step[1100/4329]: training loss : 0.8670069062709809 TRAIN  loss dict:  {'classification_loss': 0.8670069062709809}
2025-01-13 07:40:10,112 [INFO] Step[1150/4329]: training loss : 0.873633793592453 TRAIN  loss dict:  {'classification_loss': 0.873633793592453}
2025-01-13 07:40:21,773 [INFO] Step[1200/4329]: training loss : 0.8667419195175171 TRAIN  loss dict:  {'classification_loss': 0.8667419195175171}
2025-01-13 07:40:33,438 [INFO] Step[1250/4329]: training loss : 0.8655930244922638 TRAIN  loss dict:  {'classification_loss': 0.8655930244922638}
2025-01-13 07:40:45,069 [INFO] Step[1300/4329]: training loss : 0.8625911605358124 TRAIN  loss dict:  {'classification_loss': 0.8625911605358124}
2025-01-13 07:40:56,753 [INFO] Step[1350/4329]: training loss : 0.8677922070026398 TRAIN  loss dict:  {'classification_loss': 0.8677922070026398}
2025-01-13 07:41:08,357 [INFO] Step[1400/4329]: training loss : 0.864058940410614 TRAIN  loss dict:  {'classification_loss': 0.864058940410614}
2025-01-13 07:41:19,977 [INFO] Step[1450/4329]: training loss : 0.8665216112136841 TRAIN  loss dict:  {'classification_loss': 0.8665216112136841}
2025-01-13 07:41:31,568 [INFO] Step[1500/4329]: training loss : 0.8631186723709107 TRAIN  loss dict:  {'classification_loss': 0.8631186723709107}
2025-01-13 07:41:43,199 [INFO] Step[1550/4329]: training loss : 0.874350494146347 TRAIN  loss dict:  {'classification_loss': 0.874350494146347}
2025-01-13 07:41:54,847 [INFO] Step[1600/4329]: training loss : 0.9285016989707947 TRAIN  loss dict:  {'classification_loss': 0.9285016989707947}
2025-01-13 07:42:06,507 [INFO] Step[1650/4329]: training loss : 0.8677017748355865 TRAIN  loss dict:  {'classification_loss': 0.8677017748355865}
2025-01-13 07:42:18,111 [INFO] Step[1700/4329]: training loss : 0.8741254794597626 TRAIN  loss dict:  {'classification_loss': 0.8741254794597626}
2025-01-13 07:42:29,739 [INFO] Step[1750/4329]: training loss : 0.8672442758083343 TRAIN  loss dict:  {'classification_loss': 0.8672442758083343}
2025-01-13 07:42:41,369 [INFO] Step[1800/4329]: training loss : 0.8662617230415344 TRAIN  loss dict:  {'classification_loss': 0.8662617230415344}
2025-01-13 07:42:52,991 [INFO] Step[1850/4329]: training loss : 0.8733865463733673 TRAIN  loss dict:  {'classification_loss': 0.8733865463733673}
2025-01-13 07:43:04,604 [INFO] Step[1900/4329]: training loss : 0.8785891437530517 TRAIN  loss dict:  {'classification_loss': 0.8785891437530517}
2025-01-13 07:43:16,249 [INFO] Step[1950/4329]: training loss : 0.885846301317215 TRAIN  loss dict:  {'classification_loss': 0.885846301317215}
2025-01-13 07:43:27,840 [INFO] Step[2000/4329]: training loss : 0.8684519457817078 TRAIN  loss dict:  {'classification_loss': 0.8684519457817078}
2025-01-13 07:43:39,483 [INFO] Step[2050/4329]: training loss : 0.8696819138526917 TRAIN  loss dict:  {'classification_loss': 0.8696819138526917}
2025-01-13 07:43:51,407 [INFO] Step[2100/4329]: training loss : 0.8659572696685791 TRAIN  loss dict:  {'classification_loss': 0.8659572696685791}
2025-01-13 07:44:03,797 [INFO] Step[2150/4329]: training loss : 0.8641013872623443 TRAIN  loss dict:  {'classification_loss': 0.8641013872623443}
2025-01-13 07:44:16,078 [INFO] Step[2200/4329]: training loss : 0.8794202852249146 TRAIN  loss dict:  {'classification_loss': 0.8794202852249146}
2025-01-13 07:44:29,615 [INFO] Step[2250/4329]: training loss : 0.8767291712760925 TRAIN  loss dict:  {'classification_loss': 0.8767291712760925}
2025-01-13 07:44:43,227 [INFO] Step[2300/4329]: training loss : 0.8713651847839355 TRAIN  loss dict:  {'classification_loss': 0.8713651847839355}
2025-01-13 07:44:55,346 [INFO] Step[2350/4329]: training loss : 0.8663574099540711 TRAIN  loss dict:  {'classification_loss': 0.8663574099540711}
2025-01-13 07:45:07,246 [INFO] Step[2400/4329]: training loss : 0.8630154263973236 TRAIN  loss dict:  {'classification_loss': 0.8630154263973236}
2025-01-13 07:45:19,031 [INFO] Step[2450/4329]: training loss : 0.8678354573249817 TRAIN  loss dict:  {'classification_loss': 0.8678354573249817}
2025-01-13 07:45:30,659 [INFO] Step[2500/4329]: training loss : 0.8663486933708191 TRAIN  loss dict:  {'classification_loss': 0.8663486933708191}
2025-01-13 07:45:42,279 [INFO] Step[2550/4329]: training loss : 0.8695612859725952 TRAIN  loss dict:  {'classification_loss': 0.8695612859725952}
2025-01-13 07:45:53,897 [INFO] Step[2600/4329]: training loss : 0.8668419873714447 TRAIN  loss dict:  {'classification_loss': 0.8668419873714447}
2025-01-13 07:46:05,530 [INFO] Step[2650/4329]: training loss : 0.8663590204715729 TRAIN  loss dict:  {'classification_loss': 0.8663590204715729}
2025-01-13 07:46:17,122 [INFO] Step[2700/4329]: training loss : 0.892087243795395 TRAIN  loss dict:  {'classification_loss': 0.892087243795395}
2025-01-13 07:46:28,765 [INFO] Step[2750/4329]: training loss : 0.869321837425232 TRAIN  loss dict:  {'classification_loss': 0.869321837425232}
2025-01-13 07:46:40,385 [INFO] Step[2800/4329]: training loss : 0.8720123016834259 TRAIN  loss dict:  {'classification_loss': 0.8720123016834259}
2025-01-13 07:46:51,993 [INFO] Step[2850/4329]: training loss : 0.8765252184867859 TRAIN  loss dict:  {'classification_loss': 0.8765252184867859}
2025-01-13 07:47:03,613 [INFO] Step[2900/4329]: training loss : 0.876639928817749 TRAIN  loss dict:  {'classification_loss': 0.876639928817749}
2025-01-13 07:47:15,249 [INFO] Step[2950/4329]: training loss : 0.8701760911941528 TRAIN  loss dict:  {'classification_loss': 0.8701760911941528}
2025-01-13 07:47:26,858 [INFO] Step[3000/4329]: training loss : 0.8695788931846619 TRAIN  loss dict:  {'classification_loss': 0.8695788931846619}
2025-01-13 07:47:38,506 [INFO] Step[3050/4329]: training loss : 0.8644775187969208 TRAIN  loss dict:  {'classification_loss': 0.8644775187969208}
2025-01-13 07:47:50,121 [INFO] Step[3100/4329]: training loss : 0.8742921805381775 TRAIN  loss dict:  {'classification_loss': 0.8742921805381775}
2025-01-13 07:48:01,751 [INFO] Step[3150/4329]: training loss : 0.8647104632854462 TRAIN  loss dict:  {'classification_loss': 0.8647104632854462}
2025-01-13 07:48:13,348 [INFO] Step[3200/4329]: training loss : 0.8641301333904267 TRAIN  loss dict:  {'classification_loss': 0.8641301333904267}
2025-01-13 07:48:24,985 [INFO] Step[3250/4329]: training loss : 0.868577311038971 TRAIN  loss dict:  {'classification_loss': 0.868577311038971}
2025-01-13 07:48:36,591 [INFO] Step[3300/4329]: training loss : 0.8676303255558014 TRAIN  loss dict:  {'classification_loss': 0.8676303255558014}
2025-01-13 07:48:48,191 [INFO] Step[3350/4329]: training loss : 0.8664092898368836 TRAIN  loss dict:  {'classification_loss': 0.8664092898368836}
2025-01-13 07:48:59,819 [INFO] Step[3400/4329]: training loss : 0.863389847278595 TRAIN  loss dict:  {'classification_loss': 0.863389847278595}
2025-01-13 07:49:11,420 [INFO] Step[3450/4329]: training loss : 0.8844981443881988 TRAIN  loss dict:  {'classification_loss': 0.8844981443881988}
2025-01-13 07:49:23,057 [INFO] Step[3500/4329]: training loss : 0.866927582025528 TRAIN  loss dict:  {'classification_loss': 0.866927582025528}
2025-01-13 07:49:34,711 [INFO] Step[3550/4329]: training loss : 0.8643201315402984 TRAIN  loss dict:  {'classification_loss': 0.8643201315402984}
2025-01-13 07:49:46,333 [INFO] Step[3600/4329]: training loss : 0.8692326772212983 TRAIN  loss dict:  {'classification_loss': 0.8692326772212983}
2025-01-13 07:49:57,924 [INFO] Step[3650/4329]: training loss : 0.8674758839607238 TRAIN  loss dict:  {'classification_loss': 0.8674758839607238}
2025-01-13 07:50:09,516 [INFO] Step[3700/4329]: training loss : 0.8747234165668487 TRAIN  loss dict:  {'classification_loss': 0.8747234165668487}
2025-01-13 07:50:21,121 [INFO] Step[3750/4329]: training loss : 0.8661793684959411 TRAIN  loss dict:  {'classification_loss': 0.8661793684959411}
2025-01-13 07:50:32,728 [INFO] Step[3800/4329]: training loss : 0.8632568752765656 TRAIN  loss dict:  {'classification_loss': 0.8632568752765656}
2025-01-13 07:50:44,323 [INFO] Step[3850/4329]: training loss : 0.8684427440166473 TRAIN  loss dict:  {'classification_loss': 0.8684427440166473}
2025-01-13 07:50:55,913 [INFO] Step[3900/4329]: training loss : 0.8650846397876739 TRAIN  loss dict:  {'classification_loss': 0.8650846397876739}
2025-01-13 07:51:07,582 [INFO] Step[3950/4329]: training loss : 0.8642984294891357 TRAIN  loss dict:  {'classification_loss': 0.8642984294891357}
2025-01-13 07:51:19,195 [INFO] Step[4000/4329]: training loss : 0.8615399396419525 TRAIN  loss dict:  {'classification_loss': 0.8615399396419525}
2025-01-13 07:51:30,825 [INFO] Step[4050/4329]: training loss : 0.8625347948074341 TRAIN  loss dict:  {'classification_loss': 0.8625347948074341}
2025-01-13 07:51:42,438 [INFO] Step[4100/4329]: training loss : 0.8674798309803009 TRAIN  loss dict:  {'classification_loss': 0.8674798309803009}
2025-01-13 07:51:54,087 [INFO] Step[4150/4329]: training loss : 0.8709889912605285 TRAIN  loss dict:  {'classification_loss': 0.8709889912605285}
2025-01-13 07:52:05,689 [INFO] Step[4200/4329]: training loss : 0.8727285265922546 TRAIN  loss dict:  {'classification_loss': 0.8727285265922546}
2025-01-13 07:52:17,283 [INFO] Step[4250/4329]: training loss : 0.8633109021186829 TRAIN  loss dict:  {'classification_loss': 0.8633109021186829}
2025-01-13 07:52:28,870 [INFO] Step[4300/4329]: training loss : 0.8662464559078217 TRAIN  loss dict:  {'classification_loss': 0.8662464559078217}
2025-01-13 07:54:28,383 [INFO] Label accuracies statistics:
2025-01-13 07:54:28,383 [INFO] {0: 0.5555555555555556, 1: 1.0, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.75, 8: 0.6666666666666666, 9: 0.9166666666666666, 10: 1.0, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.4166666666666667, 14: 0.75, 15: 0.7777777777777778, 16: 0.5833333333333334, 17: 0.5833333333333334, 18: 0.5833333333333334, 19: 0.75, 20: 0.5833333333333334, 21: 0.75, 22: 0.75, 23: 0.9166666666666666, 24: 1.0, 25: 0.8333333333333334, 26: 0.8333333333333334, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.6666666666666666, 31: 0.8333333333333334, 32: 0.75, 33: 0.9166666666666666, 34: 0.8333333333333334, 35: 1.0, 36: 0.5833333333333334, 37: 1.0, 38: 0.9166666666666666, 39: 1.0, 40: 0.8333333333333334, 41: 0.4166666666666667, 42: 0.9166666666666666, 43: 0.8333333333333334, 44: 0.6666666666666666, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.8333333333333334, 51: 0.75, 52: 1.0, 53: 0.5833333333333334, 54: 0.6666666666666666, 55: 0.6666666666666666, 56: 0.8333333333333334, 57: 0.75, 58: 0.5833333333333334, 59: 0.9166666666666666, 60: 0.6666666666666666, 61: 1.0, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.9166666666666666, 73: 1.0, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.8333333333333334, 83: 0.5833333333333334, 84: 0.5, 85: 0.8333333333333334, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.6666666666666666, 89: 0.5, 90: 0.9166666666666666, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 1.0, 96: 0.5833333333333334, 97: 0.6666666666666666, 98: 0.75, 99: 1.0, 100: 0.8333333333333334, 101: 1.0, 102: 0.9166666666666666, 103: 0.8333333333333334, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.9166666666666666, 111: 1.0, 112: 0.9166666666666666, 113: 0.6666666666666666, 114: 0.3333333333333333, 115: 1.0, 116: 0.8333333333333334, 117: 0.75, 118: 1.0, 119: 0.8333333333333334, 120: 0.75, 121: 0.8333333333333334, 122: 0.9166666666666666, 123: 1.0, 124: 1.0, 125: 0.75, 126: 0.9166666666666666, 127: 0.75, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.8333333333333334, 132: 0.5833333333333334, 133: 1.0, 134: 0.9166666666666666, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 1.0, 139: 0.8333333333333334, 140: 1.0, 141: 0.9166666666666666, 142: 0.8333333333333334, 143: 1.0, 144: 0.5, 145: 0.9166666666666666, 146: 1.0, 147: 0.9166666666666666, 148: 0.9166666666666666, 149: 1.0, 150: 0.5, 151: 0.8333333333333334, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.6666666666666666, 158: 0.7777777777777778, 159: 1.0, 160: 0.25, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.75, 166: 0.8333333333333334, 167: 0.75, 168: 0.8333333333333334, 169: 0.9166666666666666, 170: 0.9166666666666666, 171: 0.5, 172: 1.0, 173: 0.8333333333333334, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.8333333333333334, 178: 1.0, 179: 0.2222222222222222, 180: 0.9166666666666666, 181: 0.9166666666666666, 182: 0.5, 183: 0.9166666666666666, 184: 0.8333333333333334, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.75, 189: 0.9166666666666666, 190: 0.5833333333333334, 191: 0.4166666666666667, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 1.0, 196: 0.9166666666666666, 197: 0.9166666666666666, 198: 0.6666666666666666}

2025-01-13 07:54:28,385 [INFO] [54] TRAIN  loss: 0.8700825257399364 acc: 0.998613891883567
2025-01-13 07:54:28,385 [INFO] [54] TRAIN  loss dict: {'classification_loss': 0.8700825257399364}
2025-01-13 07:54:28,385 [INFO] [54] VALIDATION loss: 1.5775645063682036 VALIDATION acc: 0.8181818181818182
2025-01-13 07:54:28,385 [INFO] [54] VALIDATION loss dict: {'classification_loss': 1.5775645063682036}
2025-01-13 07:54:28,386 [INFO] 
2025-01-13 07:54:45,589 [INFO] Step[50/4329]: training loss : 0.8659461641311645 TRAIN  loss dict:  {'classification_loss': 0.8659461641311645}
2025-01-13 07:54:57,155 [INFO] Step[100/4329]: training loss : 0.8715590596199035 TRAIN  loss dict:  {'classification_loss': 0.8715590596199035}
2025-01-13 07:55:08,785 [INFO] Step[150/4329]: training loss : 0.8658418393135071 TRAIN  loss dict:  {'classification_loss': 0.8658418393135071}
2025-01-13 07:55:20,363 [INFO] Step[200/4329]: training loss : 0.8656806719303131 TRAIN  loss dict:  {'classification_loss': 0.8656806719303131}
2025-01-13 07:55:32,007 [INFO] Step[250/4329]: training loss : 0.8612852573394776 TRAIN  loss dict:  {'classification_loss': 0.8612852573394776}
2025-01-13 07:55:43,675 [INFO] Step[300/4329]: training loss : 0.8664573574066162 TRAIN  loss dict:  {'classification_loss': 0.8664573574066162}
2025-01-13 07:55:55,383 [INFO] Step[350/4329]: training loss : 0.8662991225719452 TRAIN  loss dict:  {'classification_loss': 0.8662991225719452}
2025-01-13 07:56:07,122 [INFO] Step[400/4329]: training loss : 0.86585165143013 TRAIN  loss dict:  {'classification_loss': 0.86585165143013}
2025-01-13 07:56:19,294 [INFO] Step[450/4329]: training loss : 0.8710960614681243 TRAIN  loss dict:  {'classification_loss': 0.8710960614681243}
2025-01-13 07:56:31,521 [INFO] Step[500/4329]: training loss : 0.8673358094692231 TRAIN  loss dict:  {'classification_loss': 0.8673358094692231}
2025-01-13 07:56:44,119 [INFO] Step[550/4329]: training loss : 0.8745020365715027 TRAIN  loss dict:  {'classification_loss': 0.8745020365715027}
2025-01-13 07:56:59,357 [INFO] Step[600/4329]: training loss : 0.8632444500923157 TRAIN  loss dict:  {'classification_loss': 0.8632444500923157}
2025-01-13 07:57:12,201 [INFO] Step[650/4329]: training loss : 0.8925973045825958 TRAIN  loss dict:  {'classification_loss': 0.8925973045825958}
2025-01-13 07:57:24,091 [INFO] Step[700/4329]: training loss : 0.865541684627533 TRAIN  loss dict:  {'classification_loss': 0.865541684627533}
2025-01-13 07:57:35,983 [INFO] Step[750/4329]: training loss : 0.8693829727172852 TRAIN  loss dict:  {'classification_loss': 0.8693829727172852}
2025-01-13 07:57:47,568 [INFO] Step[800/4329]: training loss : 0.8641642379760742 TRAIN  loss dict:  {'classification_loss': 0.8641642379760742}
2025-01-13 07:57:59,211 [INFO] Step[850/4329]: training loss : 0.864838217496872 TRAIN  loss dict:  {'classification_loss': 0.864838217496872}
2025-01-13 07:58:10,842 [INFO] Step[900/4329]: training loss : 0.8666359484195709 TRAIN  loss dict:  {'classification_loss': 0.8666359484195709}
2025-01-13 07:58:22,479 [INFO] Step[950/4329]: training loss : 0.8624447607994079 TRAIN  loss dict:  {'classification_loss': 0.8624447607994079}
2025-01-13 07:58:34,107 [INFO] Step[1000/4329]: training loss : 0.8711632752418518 TRAIN  loss dict:  {'classification_loss': 0.8711632752418518}
2025-01-13 07:58:45,759 [INFO] Step[1050/4329]: training loss : 0.8690484929084777 TRAIN  loss dict:  {'classification_loss': 0.8690484929084777}
2025-01-13 07:58:57,351 [INFO] Step[1100/4329]: training loss : 0.8639784467220306 TRAIN  loss dict:  {'classification_loss': 0.8639784467220306}
2025-01-13 07:59:09,024 [INFO] Step[1150/4329]: training loss : 0.8688517606258392 TRAIN  loss dict:  {'classification_loss': 0.8688517606258392}
2025-01-13 07:59:20,631 [INFO] Step[1200/4329]: training loss : 0.8647706687450409 TRAIN  loss dict:  {'classification_loss': 0.8647706687450409}
2025-01-13 07:59:32,284 [INFO] Step[1250/4329]: training loss : 0.8704128706455231 TRAIN  loss dict:  {'classification_loss': 0.8704128706455231}
2025-01-13 07:59:43,866 [INFO] Step[1300/4329]: training loss : 0.8626780712604523 TRAIN  loss dict:  {'classification_loss': 0.8626780712604523}
2025-01-13 07:59:55,479 [INFO] Step[1350/4329]: training loss : 0.8685770845413208 TRAIN  loss dict:  {'classification_loss': 0.8685770845413208}
2025-01-13 08:00:07,071 [INFO] Step[1400/4329]: training loss : 0.8677365779876709 TRAIN  loss dict:  {'classification_loss': 0.8677365779876709}
2025-01-13 08:00:18,698 [INFO] Step[1450/4329]: training loss : 0.8681129610538483 TRAIN  loss dict:  {'classification_loss': 0.8681129610538483}
2025-01-13 08:00:30,333 [INFO] Step[1500/4329]: training loss : 0.8843743824958801 TRAIN  loss dict:  {'classification_loss': 0.8843743824958801}
2025-01-13 08:00:41,940 [INFO] Step[1550/4329]: training loss : 0.8803626155853271 TRAIN  loss dict:  {'classification_loss': 0.8803626155853271}
2025-01-13 08:00:53,555 [INFO] Step[1600/4329]: training loss : 0.8681164455413818 TRAIN  loss dict:  {'classification_loss': 0.8681164455413818}
2025-01-13 08:01:05,231 [INFO] Step[1650/4329]: training loss : 0.8644252514839172 TRAIN  loss dict:  {'classification_loss': 0.8644252514839172}
2025-01-13 08:01:16,866 [INFO] Step[1700/4329]: training loss : 0.8719544982910157 TRAIN  loss dict:  {'classification_loss': 0.8719544982910157}
2025-01-13 08:01:28,501 [INFO] Step[1750/4329]: training loss : 0.8772972571849823 TRAIN  loss dict:  {'classification_loss': 0.8772972571849823}
2025-01-13 08:01:40,112 [INFO] Step[1800/4329]: training loss : 0.8653664696216583 TRAIN  loss dict:  {'classification_loss': 0.8653664696216583}
2025-01-13 08:01:51,760 [INFO] Step[1850/4329]: training loss : 0.8687964618206024 TRAIN  loss dict:  {'classification_loss': 0.8687964618206024}
2025-01-13 08:02:03,366 [INFO] Step[1900/4329]: training loss : 0.8655132663249969 TRAIN  loss dict:  {'classification_loss': 0.8655132663249969}
2025-01-13 08:02:15,024 [INFO] Step[1950/4329]: training loss : 0.8666750621795655 TRAIN  loss dict:  {'classification_loss': 0.8666750621795655}
2025-01-13 08:02:26,618 [INFO] Step[2000/4329]: training loss : 0.8629190981388092 TRAIN  loss dict:  {'classification_loss': 0.8629190981388092}
2025-01-13 08:02:38,250 [INFO] Step[2050/4329]: training loss : 0.8728284347057342 TRAIN  loss dict:  {'classification_loss': 0.8728284347057342}
2025-01-13 08:02:49,880 [INFO] Step[2100/4329]: training loss : 0.8695300090312957 TRAIN  loss dict:  {'classification_loss': 0.8695300090312957}
2025-01-13 08:03:01,453 [INFO] Step[2150/4329]: training loss : 0.8668799376487732 TRAIN  loss dict:  {'classification_loss': 0.8668799376487732}
2025-01-13 08:03:13,074 [INFO] Step[2200/4329]: training loss : 0.8621630907058716 TRAIN  loss dict:  {'classification_loss': 0.8621630907058716}
2025-01-13 08:03:24,709 [INFO] Step[2250/4329]: training loss : 0.8642839550971985 TRAIN  loss dict:  {'classification_loss': 0.8642839550971985}
2025-01-13 08:03:36,332 [INFO] Step[2300/4329]: training loss : 0.8755410969257355 TRAIN  loss dict:  {'classification_loss': 0.8755410969257355}
2025-01-13 08:03:47,929 [INFO] Step[2350/4329]: training loss : 0.875206698179245 TRAIN  loss dict:  {'classification_loss': 0.875206698179245}
2025-01-13 08:03:59,520 [INFO] Step[2400/4329]: training loss : 0.8721396708488465 TRAIN  loss dict:  {'classification_loss': 0.8721396708488465}
2025-01-13 08:04:11,119 [INFO] Step[2450/4329]: training loss : 0.8645253884792328 TRAIN  loss dict:  {'classification_loss': 0.8645253884792328}
2025-01-13 08:04:22,747 [INFO] Step[2500/4329]: training loss : 0.8673892486095428 TRAIN  loss dict:  {'classification_loss': 0.8673892486095428}
2025-01-13 08:04:34,387 [INFO] Step[2550/4329]: training loss : 0.8766111648082733 TRAIN  loss dict:  {'classification_loss': 0.8766111648082733}
2025-01-13 08:04:45,979 [INFO] Step[2600/4329]: training loss : 0.8716562867164612 TRAIN  loss dict:  {'classification_loss': 0.8716562867164612}
2025-01-13 08:04:57,611 [INFO] Step[2650/4329]: training loss : 0.8747237145900726 TRAIN  loss dict:  {'classification_loss': 0.8747237145900726}
2025-01-13 08:05:09,263 [INFO] Step[2700/4329]: training loss : 0.8662289321422577 TRAIN  loss dict:  {'classification_loss': 0.8662289321422577}
2025-01-13 08:05:21,042 [INFO] Step[2750/4329]: training loss : 0.8673281419277191 TRAIN  loss dict:  {'classification_loss': 0.8673281419277191}
2025-01-13 08:05:32,631 [INFO] Step[2800/4329]: training loss : 0.8663833320140839 TRAIN  loss dict:  {'classification_loss': 0.8663833320140839}
2025-01-13 08:05:44,319 [INFO] Step[2850/4329]: training loss : 0.8657225847244263 TRAIN  loss dict:  {'classification_loss': 0.8657225847244263}
2025-01-13 08:05:55,969 [INFO] Step[2900/4329]: training loss : 0.8820404589176178 TRAIN  loss dict:  {'classification_loss': 0.8820404589176178}
2025-01-13 08:06:07,607 [INFO] Step[2950/4329]: training loss : 0.8885149562358856 TRAIN  loss dict:  {'classification_loss': 0.8885149562358856}
2025-01-13 08:06:19,214 [INFO] Step[3000/4329]: training loss : 0.8698666357994079 TRAIN  loss dict:  {'classification_loss': 0.8698666357994079}
2025-01-13 08:06:30,844 [INFO] Step[3050/4329]: training loss : 0.8688545179367065 TRAIN  loss dict:  {'classification_loss': 0.8688545179367065}
2025-01-13 08:06:42,451 [INFO] Step[3100/4329]: training loss : 0.8648037099838257 TRAIN  loss dict:  {'classification_loss': 0.8648037099838257}
2025-01-13 08:06:54,065 [INFO] Step[3150/4329]: training loss : 0.8633783280849456 TRAIN  loss dict:  {'classification_loss': 0.8633783280849456}
2025-01-13 08:07:05,676 [INFO] Step[3200/4329]: training loss : 0.8685672533512115 TRAIN  loss dict:  {'classification_loss': 0.8685672533512115}
2025-01-13 08:07:17,291 [INFO] Step[3250/4329]: training loss : 0.8806653463840485 TRAIN  loss dict:  {'classification_loss': 0.8806653463840485}
2025-01-13 08:07:28,894 [INFO] Step[3300/4329]: training loss : 0.8650237166881561 TRAIN  loss dict:  {'classification_loss': 0.8650237166881561}
2025-01-13 08:07:40,517 [INFO] Step[3350/4329]: training loss : 0.8668552923202515 TRAIN  loss dict:  {'classification_loss': 0.8668552923202515}
2025-01-13 08:07:52,158 [INFO] Step[3400/4329]: training loss : 0.8649159145355224 TRAIN  loss dict:  {'classification_loss': 0.8649159145355224}
2025-01-13 08:08:03,811 [INFO] Step[3450/4329]: training loss : 0.8777338933944702 TRAIN  loss dict:  {'classification_loss': 0.8777338933944702}
2025-01-13 08:08:15,428 [INFO] Step[3500/4329]: training loss : 0.8688714706897736 TRAIN  loss dict:  {'classification_loss': 0.8688714706897736}
2025-01-13 08:08:27,232 [INFO] Step[3550/4329]: training loss : 0.8651413691043853 TRAIN  loss dict:  {'classification_loss': 0.8651413691043853}
2025-01-13 08:08:39,472 [INFO] Step[3600/4329]: training loss : 0.8655562841892243 TRAIN  loss dict:  {'classification_loss': 0.8655562841892243}
2025-01-13 08:08:51,681 [INFO] Step[3650/4329]: training loss : 0.8616742539405823 TRAIN  loss dict:  {'classification_loss': 0.8616742539405823}
2025-01-13 08:09:04,697 [INFO] Step[3700/4329]: training loss : 0.8840659427642822 TRAIN  loss dict:  {'classification_loss': 0.8840659427642822}
2025-01-13 08:09:17,985 [INFO] Step[3750/4329]: training loss : 0.872626975774765 TRAIN  loss dict:  {'classification_loss': 0.872626975774765}
2025-01-13 08:09:30,470 [INFO] Step[3800/4329]: training loss : 0.8817011797428131 TRAIN  loss dict:  {'classification_loss': 0.8817011797428131}
2025-01-13 08:09:42,412 [INFO] Step[3850/4329]: training loss : 0.8695128881931304 TRAIN  loss dict:  {'classification_loss': 0.8695128881931304}
2025-01-13 08:09:54,253 [INFO] Step[3900/4329]: training loss : 0.870457694530487 TRAIN  loss dict:  {'classification_loss': 0.870457694530487}
2025-01-13 08:10:05,869 [INFO] Step[3950/4329]: training loss : 0.878070969581604 TRAIN  loss dict:  {'classification_loss': 0.878070969581604}
2025-01-13 08:10:17,499 [INFO] Step[4000/4329]: training loss : 0.8684077346324921 TRAIN  loss dict:  {'classification_loss': 0.8684077346324921}
2025-01-13 08:10:29,139 [INFO] Step[4050/4329]: training loss : 0.8648909318447113 TRAIN  loss dict:  {'classification_loss': 0.8648909318447113}
2025-01-13 08:10:40,732 [INFO] Step[4100/4329]: training loss : 0.8714122867584229 TRAIN  loss dict:  {'classification_loss': 0.8714122867584229}
2025-01-13 08:10:52,382 [INFO] Step[4150/4329]: training loss : 0.8637995219230652 TRAIN  loss dict:  {'classification_loss': 0.8637995219230652}
2025-01-13 08:11:04,011 [INFO] Step[4200/4329]: training loss : 0.8666006338596344 TRAIN  loss dict:  {'classification_loss': 0.8666006338596344}
2025-01-13 08:11:15,591 [INFO] Step[4250/4329]: training loss : 0.8632417845726014 TRAIN  loss dict:  {'classification_loss': 0.8632417845726014}
2025-01-13 08:11:27,212 [INFO] Step[4300/4329]: training loss : 0.8679032516479492 TRAIN  loss dict:  {'classification_loss': 0.8679032516479492}
2025-01-13 08:13:25,501 [INFO] Label accuracies statistics:
2025-01-13 08:13:25,501 [INFO] {0: 0.7777777777777778, 1: 0.8888888888888888, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.3333333333333333, 5: 0.9166666666666666, 6: 0.6666666666666666, 7: 0.5833333333333334, 8: 0.6666666666666666, 9: 0.9166666666666666, 10: 1.0, 11: 1.0, 12: 0.4166666666666667, 13: 0.5, 14: 0.6666666666666666, 15: 0.7777777777777778, 16: 0.6666666666666666, 17: 0.5833333333333334, 18: 0.5833333333333334, 19: 0.8333333333333334, 20: 0.5833333333333334, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.8333333333333334, 26: 0.9166666666666666, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.9166666666666666, 32: 0.75, 33: 0.9166666666666666, 34: 0.8333333333333334, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.8333333333333334, 41: 0.4166666666666667, 42: 0.9166666666666666, 43: 0.8333333333333334, 44: 0.5, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.4166666666666667, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5833333333333334, 59: 0.8333333333333334, 60: 0.75, 61: 0.9166666666666666, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.4166666666666667, 72: 0.8333333333333334, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 1.0, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.6666666666666666, 84: 0.5, 85: 0.8333333333333334, 86: 0.5833333333333334, 87: 0.8333333333333334, 88: 0.6666666666666666, 89: 0.5833333333333334, 90: 0.8333333333333334, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 1.0, 96: 0.5833333333333334, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.6666666666666666, 101: 1.0, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.8333333333333334, 111: 1.0, 112: 0.9166666666666666, 113: 0.6666666666666666, 114: 0.5, 115: 0.8333333333333334, 116: 0.6666666666666666, 117: 0.75, 118: 1.0, 119: 0.8333333333333334, 120: 0.75, 121: 0.9166666666666666, 122: 0.75, 123: 0.8333333333333334, 124: 0.9166666666666666, 125: 0.8333333333333334, 126: 0.9166666666666666, 127: 0.5833333333333334, 128: 1.0, 129: 0.8333333333333334, 130: 0.5, 131: 0.8333333333333334, 132: 0.4166666666666667, 133: 1.0, 134: 0.9166666666666666, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.8333333333333334, 140: 0.9166666666666666, 141: 1.0, 142: 0.6666666666666666, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.9166666666666666, 148: 0.6666666666666666, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.25, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.8333333333333334, 166: 0.75, 167: 0.75, 168: 0.9166666666666666, 169: 1.0, 170: 1.0, 171: 0.75, 172: 1.0, 173: 0.9166666666666666, 174: 1.0, 175: 1.0, 176: 1.0, 177: 0.8333333333333334, 178: 0.9166666666666666, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.5833333333333334, 183: 0.8333333333333334, 184: 0.8333333333333334, 185: 0.9166666666666666, 186: 0.75, 187: 1.0, 188: 0.8333333333333334, 189: 1.0, 190: 0.5833333333333334, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 1.0, 196: 0.9166666666666666, 197: 0.9166666666666666, 198: 0.5833333333333334}

2025-01-13 08:13:25,504 [INFO] [55] TRAIN  loss: 0.8693760248633834 acc: 0.9984598798706299
2025-01-13 08:13:25,504 [INFO] [55] TRAIN  loss dict: {'classification_loss': 0.8693760248633834}
2025-01-13 08:13:25,504 [INFO] [55] VALIDATION loss: 1.5846300079967037 VALIDATION acc: 0.8122895622895623
2025-01-13 08:13:25,504 [INFO] [55] VALIDATION loss dict: {'classification_loss': 1.5846300079967037}
2025-01-13 08:13:25,504 [INFO] 
2025-01-13 08:13:42,774 [INFO] Step[50/4329]: training loss : 0.865083738565445 TRAIN  loss dict:  {'classification_loss': 0.865083738565445}
2025-01-13 08:13:54,335 [INFO] Step[100/4329]: training loss : 0.8643338561058045 TRAIN  loss dict:  {'classification_loss': 0.8643338561058045}
2025-01-13 08:14:05,983 [INFO] Step[150/4329]: training loss : 0.8825423359870911 TRAIN  loss dict:  {'classification_loss': 0.8825423359870911}
2025-01-13 08:14:17,573 [INFO] Step[200/4329]: training loss : 0.8670032525062561 TRAIN  loss dict:  {'classification_loss': 0.8670032525062561}
2025-01-13 08:14:29,226 [INFO] Step[250/4329]: training loss : 0.8711233234405518 TRAIN  loss dict:  {'classification_loss': 0.8711233234405518}
2025-01-13 08:14:40,875 [INFO] Step[300/4329]: training loss : 0.8673240816593171 TRAIN  loss dict:  {'classification_loss': 0.8673240816593171}
2025-01-13 08:14:52,571 [INFO] Step[350/4329]: training loss : 0.8892757296562195 TRAIN  loss dict:  {'classification_loss': 0.8892757296562195}
2025-01-13 08:15:04,213 [INFO] Step[400/4329]: training loss : 0.8639972817897796 TRAIN  loss dict:  {'classification_loss': 0.8639972817897796}
2025-01-13 08:15:15,853 [INFO] Step[450/4329]: training loss : 0.8686935436725617 TRAIN  loss dict:  {'classification_loss': 0.8686935436725617}
2025-01-13 08:15:27,457 [INFO] Step[500/4329]: training loss : 0.8657826995849609 TRAIN  loss dict:  {'classification_loss': 0.8657826995849609}
2025-01-13 08:15:39,103 [INFO] Step[550/4329]: training loss : 0.8671376919746399 TRAIN  loss dict:  {'classification_loss': 0.8671376919746399}
2025-01-13 08:15:50,744 [INFO] Step[600/4329]: training loss : 0.8665084397792816 TRAIN  loss dict:  {'classification_loss': 0.8665084397792816}
2025-01-13 08:16:02,400 [INFO] Step[650/4329]: training loss : 0.8701579332351684 TRAIN  loss dict:  {'classification_loss': 0.8701579332351684}
2025-01-13 08:16:14,019 [INFO] Step[700/4329]: training loss : 0.8658921205997467 TRAIN  loss dict:  {'classification_loss': 0.8658921205997467}
2025-01-13 08:16:25,689 [INFO] Step[750/4329]: training loss : 0.8724568855762481 TRAIN  loss dict:  {'classification_loss': 0.8724568855762481}
2025-01-13 08:16:37,363 [INFO] Step[800/4329]: training loss : 0.8746012735366822 TRAIN  loss dict:  {'classification_loss': 0.8746012735366822}
2025-01-13 08:16:49,007 [INFO] Step[850/4329]: training loss : 0.8632534062862396 TRAIN  loss dict:  {'classification_loss': 0.8632534062862396}
2025-01-13 08:17:00,651 [INFO] Step[900/4329]: training loss : 0.8663484466075897 TRAIN  loss dict:  {'classification_loss': 0.8663484466075897}
2025-01-13 08:17:12,351 [INFO] Step[950/4329]: training loss : 0.8643262481689453 TRAIN  loss dict:  {'classification_loss': 0.8643262481689453}
2025-01-13 08:17:24,016 [INFO] Step[1000/4329]: training loss : 0.862488579750061 TRAIN  loss dict:  {'classification_loss': 0.862488579750061}
2025-01-13 08:17:35,636 [INFO] Step[1050/4329]: training loss : 0.8740091776847839 TRAIN  loss dict:  {'classification_loss': 0.8740091776847839}
2025-01-13 08:17:47,262 [INFO] Step[1100/4329]: training loss : 0.8675580954551697 TRAIN  loss dict:  {'classification_loss': 0.8675580954551697}
2025-01-13 08:17:58,962 [INFO] Step[1150/4329]: training loss : 0.8687881672382355 TRAIN  loss dict:  {'classification_loss': 0.8687881672382355}
2025-01-13 08:18:10,623 [INFO] Step[1200/4329]: training loss : 0.8633483958244323 TRAIN  loss dict:  {'classification_loss': 0.8633483958244323}
2025-01-13 08:18:22,315 [INFO] Step[1250/4329]: training loss : 0.8687968409061432 TRAIN  loss dict:  {'classification_loss': 0.8687968409061432}
2025-01-13 08:18:33,947 [INFO] Step[1300/4329]: training loss : 0.869133368730545 TRAIN  loss dict:  {'classification_loss': 0.869133368730545}
2025-01-13 08:18:45,608 [INFO] Step[1350/4329]: training loss : 0.8892716014385224 TRAIN  loss dict:  {'classification_loss': 0.8892716014385224}
2025-01-13 08:18:57,250 [INFO] Step[1400/4329]: training loss : 0.8635335922241211 TRAIN  loss dict:  {'classification_loss': 0.8635335922241211}
2025-01-13 08:19:08,898 [INFO] Step[1450/4329]: training loss : 0.8749069368839264 TRAIN  loss dict:  {'classification_loss': 0.8749069368839264}
2025-01-13 08:19:20,554 [INFO] Step[1500/4329]: training loss : 0.8653283393383027 TRAIN  loss dict:  {'classification_loss': 0.8653283393383027}
2025-01-13 08:19:32,202 [INFO] Step[1550/4329]: training loss : 0.8701967895030975 TRAIN  loss dict:  {'classification_loss': 0.8701967895030975}
2025-01-13 08:19:43,878 [INFO] Step[1600/4329]: training loss : 0.8659582006931305 TRAIN  loss dict:  {'classification_loss': 0.8659582006931305}
2025-01-13 08:19:55,503 [INFO] Step[1650/4329]: training loss : 0.8732879137992859 TRAIN  loss dict:  {'classification_loss': 0.8732879137992859}
2025-01-13 08:20:07,173 [INFO] Step[1700/4329]: training loss : 0.8639366996288299 TRAIN  loss dict:  {'classification_loss': 0.8639366996288299}
2025-01-13 08:20:18,822 [INFO] Step[1750/4329]: training loss : 0.8627133440971374 TRAIN  loss dict:  {'classification_loss': 0.8627133440971374}
2025-01-13 08:20:30,462 [INFO] Step[1800/4329]: training loss : 0.8672109937667847 TRAIN  loss dict:  {'classification_loss': 0.8672109937667847}
2025-01-13 08:20:42,150 [INFO] Step[1850/4329]: training loss : 0.861102843284607 TRAIN  loss dict:  {'classification_loss': 0.861102843284607}
2025-01-13 08:20:54,080 [INFO] Step[1900/4329]: training loss : 0.8635462999343873 TRAIN  loss dict:  {'classification_loss': 0.8635462999343873}
2025-01-13 08:21:06,591 [INFO] Step[1950/4329]: training loss : 0.8618276059627533 TRAIN  loss dict:  {'classification_loss': 0.8618276059627533}
2025-01-13 08:21:18,889 [INFO] Step[2000/4329]: training loss : 0.8620192444324494 TRAIN  loss dict:  {'classification_loss': 0.8620192444324494}
2025-01-13 08:21:32,125 [INFO] Step[2050/4329]: training loss : 0.8631269121170044 TRAIN  loss dict:  {'classification_loss': 0.8631269121170044}
2025-01-13 08:21:45,435 [INFO] Step[2100/4329]: training loss : 0.8625969636440277 TRAIN  loss dict:  {'classification_loss': 0.8625969636440277}
2025-01-13 08:21:57,741 [INFO] Step[2150/4329]: training loss : 0.8614763438701629 TRAIN  loss dict:  {'classification_loss': 0.8614763438701629}
2025-01-13 08:22:09,628 [INFO] Step[2200/4329]: training loss : 0.8673438274860382 TRAIN  loss dict:  {'classification_loss': 0.8673438274860382}
2025-01-13 08:22:21,535 [INFO] Step[2250/4329]: training loss : 0.8797312259674073 TRAIN  loss dict:  {'classification_loss': 0.8797312259674073}
2025-01-13 08:22:33,157 [INFO] Step[2300/4329]: training loss : 0.864977753162384 TRAIN  loss dict:  {'classification_loss': 0.864977753162384}
2025-01-13 08:22:44,818 [INFO] Step[2350/4329]: training loss : 0.8635664534568787 TRAIN  loss dict:  {'classification_loss': 0.8635664534568787}
2025-01-13 08:22:56,456 [INFO] Step[2400/4329]: training loss : 0.8638642072677613 TRAIN  loss dict:  {'classification_loss': 0.8638642072677613}
2025-01-13 08:23:08,131 [INFO] Step[2450/4329]: training loss : 0.8629994070529938 TRAIN  loss dict:  {'classification_loss': 0.8629994070529938}
2025-01-13 08:23:19,860 [INFO] Step[2500/4329]: training loss : 0.86140589594841 TRAIN  loss dict:  {'classification_loss': 0.86140589594841}
2025-01-13 08:23:31,549 [INFO] Step[2550/4329]: training loss : 0.869130220413208 TRAIN  loss dict:  {'classification_loss': 0.869130220413208}
2025-01-13 08:23:43,194 [INFO] Step[2600/4329]: training loss : 0.8626236283779144 TRAIN  loss dict:  {'classification_loss': 0.8626236283779144}
2025-01-13 08:23:54,871 [INFO] Step[2650/4329]: training loss : 0.863596293926239 TRAIN  loss dict:  {'classification_loss': 0.863596293926239}
2025-01-13 08:24:06,513 [INFO] Step[2700/4329]: training loss : 0.8623621010780335 TRAIN  loss dict:  {'classification_loss': 0.8623621010780335}
2025-01-13 08:24:18,128 [INFO] Step[2750/4329]: training loss : 0.866087040901184 TRAIN  loss dict:  {'classification_loss': 0.866087040901184}
2025-01-13 08:24:29,773 [INFO] Step[2800/4329]: training loss : 0.871511904001236 TRAIN  loss dict:  {'classification_loss': 0.871511904001236}
2025-01-13 08:24:41,432 [INFO] Step[2850/4329]: training loss : 0.8621348309516906 TRAIN  loss dict:  {'classification_loss': 0.8621348309516906}
2025-01-13 08:24:53,057 [INFO] Step[2900/4329]: training loss : 0.8633503711223602 TRAIN  loss dict:  {'classification_loss': 0.8633503711223602}
2025-01-13 08:25:04,738 [INFO] Step[2950/4329]: training loss : 0.8634639537334442 TRAIN  loss dict:  {'classification_loss': 0.8634639537334442}
2025-01-13 08:25:16,386 [INFO] Step[3000/4329]: training loss : 0.871184846162796 TRAIN  loss dict:  {'classification_loss': 0.871184846162796}
2025-01-13 08:25:28,051 [INFO] Step[3050/4329]: training loss : 0.8690759909152984 TRAIN  loss dict:  {'classification_loss': 0.8690759909152984}
2025-01-13 08:25:39,740 [INFO] Step[3100/4329]: training loss : 0.8662834715843201 TRAIN  loss dict:  {'classification_loss': 0.8662834715843201}
2025-01-13 08:25:51,388 [INFO] Step[3150/4329]: training loss : 0.865076893568039 TRAIN  loss dict:  {'classification_loss': 0.865076893568039}
2025-01-13 08:26:03,041 [INFO] Step[3200/4329]: training loss : 0.8651157343387603 TRAIN  loss dict:  {'classification_loss': 0.8651157343387603}
2025-01-13 08:26:14,772 [INFO] Step[3250/4329]: training loss : 0.8694204437732697 TRAIN  loss dict:  {'classification_loss': 0.8694204437732697}
2025-01-13 08:26:26,430 [INFO] Step[3300/4329]: training loss : 0.8662563490867615 TRAIN  loss dict:  {'classification_loss': 0.8662563490867615}
2025-01-13 08:26:38,084 [INFO] Step[3350/4329]: training loss : 0.8624818336963653 TRAIN  loss dict:  {'classification_loss': 0.8624818336963653}
2025-01-13 08:26:49,767 [INFO] Step[3400/4329]: training loss : 0.8616055989265442 TRAIN  loss dict:  {'classification_loss': 0.8616055989265442}
2025-01-13 08:27:01,405 [INFO] Step[3450/4329]: training loss : 0.8644675946235657 TRAIN  loss dict:  {'classification_loss': 0.8644675946235657}
2025-01-13 08:27:13,068 [INFO] Step[3500/4329]: training loss : 0.8641321468353271 TRAIN  loss dict:  {'classification_loss': 0.8641321468353271}
2025-01-13 08:27:24,739 [INFO] Step[3550/4329]: training loss : 0.8654909014701844 TRAIN  loss dict:  {'classification_loss': 0.8654909014701844}
2025-01-13 08:27:36,397 [INFO] Step[3600/4329]: training loss : 0.8753515326976776 TRAIN  loss dict:  {'classification_loss': 0.8753515326976776}
2025-01-13 08:27:48,113 [INFO] Step[3650/4329]: training loss : 0.8762285315990448 TRAIN  loss dict:  {'classification_loss': 0.8762285315990448}
2025-01-13 08:27:59,733 [INFO] Step[3700/4329]: training loss : 0.8625905501842499 TRAIN  loss dict:  {'classification_loss': 0.8625905501842499}
2025-01-13 08:28:11,355 [INFO] Step[3750/4329]: training loss : 0.8650934565067291 TRAIN  loss dict:  {'classification_loss': 0.8650934565067291}
2025-01-13 08:28:22,989 [INFO] Step[3800/4329]: training loss : 0.8662981331348419 TRAIN  loss dict:  {'classification_loss': 0.8662981331348419}
2025-01-13 08:28:34,637 [INFO] Step[3850/4329]: training loss : 0.8847039437294006 TRAIN  loss dict:  {'classification_loss': 0.8847039437294006}
2025-01-13 08:28:46,327 [INFO] Step[3900/4329]: training loss : 0.8635065543651581 TRAIN  loss dict:  {'classification_loss': 0.8635065543651581}
2025-01-13 08:28:58,050 [INFO] Step[3950/4329]: training loss : 0.8744259417057038 TRAIN  loss dict:  {'classification_loss': 0.8744259417057038}
2025-01-13 08:29:09,693 [INFO] Step[4000/4329]: training loss : 0.8632083785533905 TRAIN  loss dict:  {'classification_loss': 0.8632083785533905}
2025-01-13 08:29:21,383 [INFO] Step[4050/4329]: training loss : 0.8679534280300141 TRAIN  loss dict:  {'classification_loss': 0.8679534280300141}
2025-01-13 08:29:33,085 [INFO] Step[4100/4329]: training loss : 0.869745455980301 TRAIN  loss dict:  {'classification_loss': 0.869745455980301}
2025-01-13 08:29:44,707 [INFO] Step[4150/4329]: training loss : 0.863835312128067 TRAIN  loss dict:  {'classification_loss': 0.863835312128067}
2025-01-13 08:29:56,286 [INFO] Step[4200/4329]: training loss : 0.868593658208847 TRAIN  loss dict:  {'classification_loss': 0.868593658208847}
2025-01-13 08:30:07,911 [INFO] Step[4250/4329]: training loss : 0.8671560192108154 TRAIN  loss dict:  {'classification_loss': 0.8671560192108154}
2025-01-13 08:30:19,589 [INFO] Step[4300/4329]: training loss : 0.8639394807815551 TRAIN  loss dict:  {'classification_loss': 0.8639394807815551}
2025-01-13 08:32:19,233 [INFO] Label accuracies statistics:
2025-01-13 08:32:19,233 [INFO] {0: 0.7777777777777778, 1: 0.8888888888888888, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.3333333333333333, 5: 0.9166666666666666, 6: 0.5833333333333334, 7: 0.5833333333333334, 8: 0.6666666666666666, 9: 0.9166666666666666, 10: 1.0, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.5, 14: 0.6666666666666666, 15: 0.7777777777777778, 16: 0.5833333333333334, 17: 0.6666666666666666, 18: 0.6666666666666666, 19: 0.8333333333333334, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.9166666666666666, 24: 0.9166666666666666, 25: 0.9166666666666666, 26: 0.9166666666666666, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.5833333333333334, 31: 0.8333333333333334, 32: 0.75, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 0.9166666666666666, 40: 1.0, 41: 0.5, 42: 0.9166666666666666, 43: 0.8333333333333334, 44: 0.6666666666666666, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.4166666666666667, 54: 0.3333333333333333, 55: 0.6666666666666666, 56: 0.75, 57: 0.75, 58: 0.5833333333333334, 59: 0.9166666666666666, 60: 0.6666666666666666, 61: 1.0, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.5833333333333334, 67: 1.0, 68: 0.75, 69: 0.6666666666666666, 70: 0.5833333333333334, 71: 0.4166666666666667, 72: 0.8333333333333334, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.5, 77: 0.75, 78: 0.9166666666666666, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.5, 89: 0.6666666666666666, 90: 0.5833333333333334, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 1.0, 96: 0.5, 97: 0.5833333333333334, 98: 0.75, 99: 1.0, 100: 0.8333333333333334, 101: 0.8333333333333334, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 1.0, 111: 0.9166666666666666, 112: 0.9166666666666666, 113: 0.4166666666666667, 114: 0.5, 115: 0.9166666666666666, 116: 0.75, 117: 0.8333333333333334, 118: 1.0, 119: 0.75, 120: 0.75, 121: 0.9166666666666666, 122: 0.9166666666666666, 123: 0.9166666666666666, 124: 0.9166666666666666, 125: 0.75, 126: 0.9166666666666666, 127: 0.5833333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.9166666666666666, 132: 0.5, 133: 1.0, 134: 0.6666666666666666, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 0.9166666666666666, 141: 0.9166666666666666, 142: 0.5833333333333334, 143: 1.0, 144: 0.8333333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.9166666666666666, 148: 0.75, 149: 1.0, 150: 0.5, 151: 0.9166666666666666, 152: 0.9166666666666666, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.8333333333333334, 158: 0.7777777777777778, 159: 1.0, 160: 0.16666666666666666, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.75, 166: 0.75, 167: 0.5833333333333334, 168: 0.9166666666666666, 169: 0.9166666666666666, 170: 0.9166666666666666, 171: 0.4166666666666667, 172: 1.0, 173: 0.8333333333333334, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.5, 183: 0.8333333333333334, 184: 0.6666666666666666, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5833333333333334, 189: 0.9166666666666666, 190: 0.5833333333333334, 191: 0.5, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.5833333333333334, 198: 0.5833333333333334}

2025-01-13 08:32:19,235 [INFO] [56] TRAIN  loss: 0.8673449968818044 acc: 0.9987679038965039
2025-01-13 08:32:19,235 [INFO] [56] TRAIN  loss dict: {'classification_loss': 0.8673449968818044}
2025-01-13 08:32:19,236 [INFO] [56] VALIDATION loss: 1.6341124875376922 VALIDATION acc: 0.7988215488215489
2025-01-13 08:32:19,236 [INFO] [56] VALIDATION loss dict: {'classification_loss': 1.6341124875376922}
2025-01-13 08:32:19,236 [INFO] 
2025-01-13 08:32:36,214 [INFO] Step[50/4329]: training loss : 0.8625433027744294 TRAIN  loss dict:  {'classification_loss': 0.8625433027744294}
2025-01-13 08:32:47,786 [INFO] Step[100/4329]: training loss : 0.8656563997268677 TRAIN  loss dict:  {'classification_loss': 0.8656563997268677}
2025-01-13 08:32:59,369 [INFO] Step[150/4329]: training loss : 0.8665356683731079 TRAIN  loss dict:  {'classification_loss': 0.8665356683731079}
2025-01-13 08:33:11,066 [INFO] Step[200/4329]: training loss : 0.8633396208286286 TRAIN  loss dict:  {'classification_loss': 0.8633396208286286}
2025-01-13 08:33:23,251 [INFO] Step[250/4329]: training loss : 0.8707757759094238 TRAIN  loss dict:  {'classification_loss': 0.8707757759094238}
2025-01-13 08:33:35,380 [INFO] Step[300/4329]: training loss : 0.8645822560787201 TRAIN  loss dict:  {'classification_loss': 0.8645822560787201}
2025-01-13 08:33:47,963 [INFO] Step[350/4329]: training loss : 0.8853124642372131 TRAIN  loss dict:  {'classification_loss': 0.8853124642372131}
2025-01-13 08:34:04,356 [INFO] Step[400/4329]: training loss : 0.8839810800552368 TRAIN  loss dict:  {'classification_loss': 0.8839810800552368}
2025-01-13 08:34:18,253 [INFO] Step[450/4329]: training loss : 0.8685996377468109 TRAIN  loss dict:  {'classification_loss': 0.8685996377468109}
2025-01-13 08:34:30,155 [INFO] Step[500/4329]: training loss : 0.8682811081409454 TRAIN  loss dict:  {'classification_loss': 0.8682811081409454}
2025-01-13 08:34:41,971 [INFO] Step[550/4329]: training loss : 0.865946592092514 TRAIN  loss dict:  {'classification_loss': 0.865946592092514}
2025-01-13 08:34:53,607 [INFO] Step[600/4329]: training loss : 0.8625578486919403 TRAIN  loss dict:  {'classification_loss': 0.8625578486919403}
2025-01-13 08:35:05,236 [INFO] Step[650/4329]: training loss : 0.866073077917099 TRAIN  loss dict:  {'classification_loss': 0.866073077917099}
2025-01-13 08:35:16,857 [INFO] Step[700/4329]: training loss : 0.8840698754787445 TRAIN  loss dict:  {'classification_loss': 0.8840698754787445}
2025-01-13 08:35:28,528 [INFO] Step[750/4329]: training loss : 0.8646281385421752 TRAIN  loss dict:  {'classification_loss': 0.8646281385421752}
2025-01-13 08:35:40,142 [INFO] Step[800/4329]: training loss : 0.8634568989276886 TRAIN  loss dict:  {'classification_loss': 0.8634568989276886}
2025-01-13 08:35:51,803 [INFO] Step[850/4329]: training loss : 0.859905903339386 TRAIN  loss dict:  {'classification_loss': 0.859905903339386}
2025-01-13 08:36:03,475 [INFO] Step[900/4329]: training loss : 0.8639705264568329 TRAIN  loss dict:  {'classification_loss': 0.8639705264568329}
2025-01-13 08:36:15,177 [INFO] Step[950/4329]: training loss : 0.8647776174545289 TRAIN  loss dict:  {'classification_loss': 0.8647776174545289}
2025-01-13 08:36:26,822 [INFO] Step[1000/4329]: training loss : 0.8651917123794556 TRAIN  loss dict:  {'classification_loss': 0.8651917123794556}
2025-01-13 08:36:38,448 [INFO] Step[1050/4329]: training loss : 0.8640227568149567 TRAIN  loss dict:  {'classification_loss': 0.8640227568149567}
2025-01-13 08:36:50,077 [INFO] Step[1100/4329]: training loss : 0.8681752598285675 TRAIN  loss dict:  {'classification_loss': 0.8681752598285675}
2025-01-13 08:37:01,707 [INFO] Step[1150/4329]: training loss : 0.8643750834465027 TRAIN  loss dict:  {'classification_loss': 0.8643750834465027}
2025-01-13 08:37:13,350 [INFO] Step[1200/4329]: training loss : 0.8667539846897125 TRAIN  loss dict:  {'classification_loss': 0.8667539846897125}
2025-01-13 08:37:24,952 [INFO] Step[1250/4329]: training loss : 0.8630695450305939 TRAIN  loss dict:  {'classification_loss': 0.8630695450305939}
2025-01-13 08:37:36,585 [INFO] Step[1300/4329]: training loss : 0.894299556016922 TRAIN  loss dict:  {'classification_loss': 0.894299556016922}
2025-01-13 08:37:48,181 [INFO] Step[1350/4329]: training loss : 0.8613412582874298 TRAIN  loss dict:  {'classification_loss': 0.8613412582874298}
2025-01-13 08:37:59,809 [INFO] Step[1400/4329]: training loss : 0.8656168735027313 TRAIN  loss dict:  {'classification_loss': 0.8656168735027313}
2025-01-13 08:38:11,414 [INFO] Step[1450/4329]: training loss : 0.8624982190132141 TRAIN  loss dict:  {'classification_loss': 0.8624982190132141}
2025-01-13 08:38:22,996 [INFO] Step[1500/4329]: training loss : 0.8649214506149292 TRAIN  loss dict:  {'classification_loss': 0.8649214506149292}
2025-01-13 08:38:34,614 [INFO] Step[1550/4329]: training loss : 0.8668613362312317 TRAIN  loss dict:  {'classification_loss': 0.8668613362312317}
2025-01-13 08:38:46,252 [INFO] Step[1600/4329]: training loss : 0.8646673142910004 TRAIN  loss dict:  {'classification_loss': 0.8646673142910004}
2025-01-13 08:38:57,850 [INFO] Step[1650/4329]: training loss : 0.8745300352573395 TRAIN  loss dict:  {'classification_loss': 0.8745300352573395}
2025-01-13 08:39:09,501 [INFO] Step[1700/4329]: training loss : 0.8645123445987701 TRAIN  loss dict:  {'classification_loss': 0.8645123445987701}
2025-01-13 08:39:21,178 [INFO] Step[1750/4329]: training loss : 0.8806832814216614 TRAIN  loss dict:  {'classification_loss': 0.8806832814216614}
2025-01-13 08:39:32,785 [INFO] Step[1800/4329]: training loss : 0.8756505680084229 TRAIN  loss dict:  {'classification_loss': 0.8756505680084229}
2025-01-13 08:39:44,432 [INFO] Step[1850/4329]: training loss : 0.8644198131561279 TRAIN  loss dict:  {'classification_loss': 0.8644198131561279}
2025-01-13 08:39:56,066 [INFO] Step[1900/4329]: training loss : 0.8656960749626159 TRAIN  loss dict:  {'classification_loss': 0.8656960749626159}
2025-01-13 08:40:07,702 [INFO] Step[1950/4329]: training loss : 0.8634801650047302 TRAIN  loss dict:  {'classification_loss': 0.8634801650047302}
2025-01-13 08:40:19,289 [INFO] Step[2000/4329]: training loss : 0.8754230940341949 TRAIN  loss dict:  {'classification_loss': 0.8754230940341949}
2025-01-13 08:40:30,954 [INFO] Step[2050/4329]: training loss : 0.8649527168273926 TRAIN  loss dict:  {'classification_loss': 0.8649527168273926}
2025-01-13 08:40:42,554 [INFO] Step[2100/4329]: training loss : 0.8643424546718598 TRAIN  loss dict:  {'classification_loss': 0.8643424546718598}
2025-01-13 08:40:54,172 [INFO] Step[2150/4329]: training loss : 0.8634955656528472 TRAIN  loss dict:  {'classification_loss': 0.8634955656528472}
2025-01-13 08:41:05,777 [INFO] Step[2200/4329]: training loss : 0.8688943016529084 TRAIN  loss dict:  {'classification_loss': 0.8688943016529084}
2025-01-13 08:41:17,429 [INFO] Step[2250/4329]: training loss : 0.864778311252594 TRAIN  loss dict:  {'classification_loss': 0.864778311252594}
2025-01-13 08:41:29,023 [INFO] Step[2300/4329]: training loss : 0.8775042378902436 TRAIN  loss dict:  {'classification_loss': 0.8775042378902436}
2025-01-13 08:41:40,635 [INFO] Step[2350/4329]: training loss : 0.8694698512554169 TRAIN  loss dict:  {'classification_loss': 0.8694698512554169}
2025-01-13 08:41:52,194 [INFO] Step[2400/4329]: training loss : 0.863464560508728 TRAIN  loss dict:  {'classification_loss': 0.863464560508728}
2025-01-13 08:42:03,801 [INFO] Step[2450/4329]: training loss : 0.8723770129680634 TRAIN  loss dict:  {'classification_loss': 0.8723770129680634}
2025-01-13 08:42:15,423 [INFO] Step[2500/4329]: training loss : 0.8650560569763184 TRAIN  loss dict:  {'classification_loss': 0.8650560569763184}
2025-01-13 08:42:27,054 [INFO] Step[2550/4329]: training loss : 0.8754352593421936 TRAIN  loss dict:  {'classification_loss': 0.8754352593421936}
2025-01-13 08:42:38,624 [INFO] Step[2600/4329]: training loss : 0.8633975636959076 TRAIN  loss dict:  {'classification_loss': 0.8633975636959076}
2025-01-13 08:42:50,261 [INFO] Step[2650/4329]: training loss : 0.8702405524253846 TRAIN  loss dict:  {'classification_loss': 0.8702405524253846}
2025-01-13 08:43:01,867 [INFO] Step[2700/4329]: training loss : 0.8608657598495484 TRAIN  loss dict:  {'classification_loss': 0.8608657598495484}
2025-01-13 08:43:13,519 [INFO] Step[2750/4329]: training loss : 0.8632801115512848 TRAIN  loss dict:  {'classification_loss': 0.8632801115512848}
2025-01-13 08:43:25,137 [INFO] Step[2800/4329]: training loss : 0.87073655128479 TRAIN  loss dict:  {'classification_loss': 0.87073655128479}
2025-01-13 08:43:36,765 [INFO] Step[2850/4329]: training loss : 0.8713826727867127 TRAIN  loss dict:  {'classification_loss': 0.8713826727867127}
2025-01-13 08:43:48,392 [INFO] Step[2900/4329]: training loss : 0.8660397291183471 TRAIN  loss dict:  {'classification_loss': 0.8660397291183471}
2025-01-13 08:44:00,025 [INFO] Step[2950/4329]: training loss : 0.8648086678981781 TRAIN  loss dict:  {'classification_loss': 0.8648086678981781}
2025-01-13 08:44:11,629 [INFO] Step[3000/4329]: training loss : 0.8647623682022094 TRAIN  loss dict:  {'classification_loss': 0.8647623682022094}
2025-01-13 08:44:23,296 [INFO] Step[3050/4329]: training loss : 0.865089271068573 TRAIN  loss dict:  {'classification_loss': 0.865089271068573}
2025-01-13 08:44:34,895 [INFO] Step[3100/4329]: training loss : 0.8644176971912384 TRAIN  loss dict:  {'classification_loss': 0.8644176971912384}
2025-01-13 08:44:46,475 [INFO] Step[3150/4329]: training loss : 0.8897046160697937 TRAIN  loss dict:  {'classification_loss': 0.8897046160697937}
2025-01-13 08:44:58,069 [INFO] Step[3200/4329]: training loss : 0.863311595916748 TRAIN  loss dict:  {'classification_loss': 0.863311595916748}
2025-01-13 08:45:09,704 [INFO] Step[3250/4329]: training loss : 0.8668311357498169 TRAIN  loss dict:  {'classification_loss': 0.8668311357498169}
2025-01-13 08:45:21,357 [INFO] Step[3300/4329]: training loss : 0.8662536180019379 TRAIN  loss dict:  {'classification_loss': 0.8662536180019379}
2025-01-13 08:45:33,258 [INFO] Step[3350/4329]: training loss : 0.8640829682350158 TRAIN  loss dict:  {'classification_loss': 0.8640829682350158}
2025-01-13 08:45:45,589 [INFO] Step[3400/4329]: training loss : 0.8721895933151245 TRAIN  loss dict:  {'classification_loss': 0.8721895933151245}
2025-01-13 08:45:57,895 [INFO] Step[3450/4329]: training loss : 0.8630857610702515 TRAIN  loss dict:  {'classification_loss': 0.8630857610702515}
2025-01-13 08:46:11,042 [INFO] Step[3500/4329]: training loss : 0.8679740118980408 TRAIN  loss dict:  {'classification_loss': 0.8679740118980408}
2025-01-13 08:46:28,407 [INFO] Step[3550/4329]: training loss : 0.8728209686279297 TRAIN  loss dict:  {'classification_loss': 0.8728209686279297}
2025-01-13 08:46:40,267 [INFO] Step[3600/4329]: training loss : 0.8627638673782348 TRAIN  loss dict:  {'classification_loss': 0.8627638673782348}
2025-01-13 08:46:52,168 [INFO] Step[3650/4329]: training loss : 0.8647659492492675 TRAIN  loss dict:  {'classification_loss': 0.8647659492492675}
2025-01-13 08:47:03,781 [INFO] Step[3700/4329]: training loss : 0.8730083847045899 TRAIN  loss dict:  {'classification_loss': 0.8730083847045899}
2025-01-13 08:47:15,419 [INFO] Step[3750/4329]: training loss : 0.8712002921104431 TRAIN  loss dict:  {'classification_loss': 0.8712002921104431}
2025-01-13 08:47:27,072 [INFO] Step[3800/4329]: training loss : 0.8712997972965241 TRAIN  loss dict:  {'classification_loss': 0.8712997972965241}
2025-01-13 08:47:38,701 [INFO] Step[3850/4329]: training loss : 0.8668259954452515 TRAIN  loss dict:  {'classification_loss': 0.8668259954452515}
2025-01-13 08:47:50,337 [INFO] Step[3900/4329]: training loss : 0.8642082262039185 TRAIN  loss dict:  {'classification_loss': 0.8642082262039185}
2025-01-13 08:48:01,944 [INFO] Step[3950/4329]: training loss : 0.8621356308460235 TRAIN  loss dict:  {'classification_loss': 0.8621356308460235}
2025-01-13 08:48:13,580 [INFO] Step[4000/4329]: training loss : 0.8664168071746826 TRAIN  loss dict:  {'classification_loss': 0.8664168071746826}
2025-01-13 08:48:25,219 [INFO] Step[4050/4329]: training loss : 0.8656150162220001 TRAIN  loss dict:  {'classification_loss': 0.8656150162220001}
2025-01-13 08:48:36,781 [INFO] Step[4100/4329]: training loss : 0.8658702218532562 TRAIN  loss dict:  {'classification_loss': 0.8658702218532562}
2025-01-13 08:48:48,392 [INFO] Step[4150/4329]: training loss : 0.8646874368190766 TRAIN  loss dict:  {'classification_loss': 0.8646874368190766}
2025-01-13 08:49:00,023 [INFO] Step[4200/4329]: training loss : 0.8881596934795379 TRAIN  loss dict:  {'classification_loss': 0.8881596934795379}
2025-01-13 08:49:11,664 [INFO] Step[4250/4329]: training loss : 0.8686783325672149 TRAIN  loss dict:  {'classification_loss': 0.8686783325672149}
2025-01-13 08:49:23,361 [INFO] Step[4300/4329]: training loss : 0.8766941821575165 TRAIN  loss dict:  {'classification_loss': 0.8766941821575165}
2025-01-13 08:51:21,686 [INFO] Label accuracies statistics:
2025-01-13 08:51:21,686 [INFO] {0: 0.8888888888888888, 1: 1.0, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.3333333333333333, 5: 0.9166666666666666, 6: 0.5, 7: 0.5833333333333334, 8: 0.6666666666666666, 9: 1.0, 10: 1.0, 11: 0.9166666666666666, 12: 0.5, 13: 0.5833333333333334, 14: 0.75, 15: 0.7777777777777778, 16: 0.5, 17: 0.6666666666666666, 18: 0.5, 19: 0.5833333333333334, 20: 0.5833333333333334, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.8333333333333334, 26: 0.8333333333333334, 27: 0.5833333333333334, 28: 0.8333333333333334, 29: 1.0, 30: 0.6666666666666666, 31: 0.9166666666666666, 32: 0.75, 33: 0.9166666666666666, 34: 0.8333333333333334, 35: 0.8333333333333334, 36: 0.5833333333333334, 37: 0.9166666666666666, 38: 1.0, 39: 1.0, 40: 0.8333333333333334, 41: 0.4166666666666667, 42: 0.8333333333333334, 43: 0.9166666666666666, 44: 0.75, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.75, 51: 0.8333333333333334, 52: 0.9166666666666666, 53: 0.5, 54: 0.3333333333333333, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5833333333333334, 59: 1.0, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.9166666666666666, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.8333333333333334, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.5833333333333334, 77: 0.8333333333333334, 78: 1.0, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.9166666666666666, 83: 0.6666666666666666, 84: 0.6666666666666666, 85: 0.6666666666666666, 86: 0.5833333333333334, 87: 0.9166666666666666, 88: 0.75, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 1.0, 96: 0.4166666666666667, 97: 0.6666666666666666, 98: 0.8333333333333334, 99: 1.0, 100: 0.9166666666666666, 101: 1.0, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.5, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.8333333333333334, 111: 1.0, 112: 0.9166666666666666, 113: 0.75, 114: 0.4166666666666667, 115: 1.0, 116: 0.8333333333333334, 117: 0.8333333333333334, 118: 1.0, 119: 0.8333333333333334, 120: 0.75, 121: 0.8333333333333334, 122: 0.9166666666666666, 123: 1.0, 124: 0.9166666666666666, 125: 1.0, 126: 1.0, 127: 0.8333333333333334, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.9166666666666666, 132: 0.5, 133: 1.0, 134: 0.6666666666666666, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 1.0, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 0.8333333333333334, 143: 1.0, 144: 0.75, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.4166666666666667, 151: 0.9166666666666666, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.5, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.9166666666666666, 166: 0.8333333333333334, 167: 0.75, 168: 0.9166666666666666, 169: 1.0, 170: 1.0, 171: 0.5833333333333334, 172: 1.0, 173: 0.75, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.9166666666666666, 181: 0.9166666666666666, 182: 0.6666666666666666, 183: 0.8333333333333334, 184: 0.75, 185: 0.9166666666666666, 186: 0.8333333333333334, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.4166666666666667, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.8333333333333334, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.75, 198: 0.8333333333333334}

2025-01-13 08:51:22,599 [INFO] [57] TRAIN  loss: 0.8681503124147839 acc: 0.9984598798706299
2025-01-13 08:51:22,599 [INFO] [57] TRAIN  loss dict: {'classification_loss': 0.8681503124147839}
2025-01-13 08:51:22,600 [INFO] [57] VALIDATION loss: 1.5804737390141295 VALIDATION acc: 0.8202861952861953
2025-01-13 08:51:22,600 [INFO] [57] VALIDATION loss dict: {'classification_loss': 1.5804737390141295}
2025-01-13 08:51:22,600 [INFO] 
2025-01-13 08:51:39,938 [INFO] Step[50/4329]: training loss : 0.8680269658565521 TRAIN  loss dict:  {'classification_loss': 0.8680269658565521}
2025-01-13 08:51:51,485 [INFO] Step[100/4329]: training loss : 0.8882115292549133 TRAIN  loss dict:  {'classification_loss': 0.8882115292549133}
2025-01-13 08:52:03,093 [INFO] Step[150/4329]: training loss : 0.8779285454750061 TRAIN  loss dict:  {'classification_loss': 0.8779285454750061}
2025-01-13 08:52:14,703 [INFO] Step[200/4329]: training loss : 0.8617280519008637 TRAIN  loss dict:  {'classification_loss': 0.8617280519008637}
2025-01-13 08:52:26,309 [INFO] Step[250/4329]: training loss : 0.863504102230072 TRAIN  loss dict:  {'classification_loss': 0.863504102230072}
2025-01-13 08:52:37,931 [INFO] Step[300/4329]: training loss : 0.8608248460292817 TRAIN  loss dict:  {'classification_loss': 0.8608248460292817}
2025-01-13 08:52:49,602 [INFO] Step[350/4329]: training loss : 0.8723678874969483 TRAIN  loss dict:  {'classification_loss': 0.8723678874969483}
2025-01-13 08:53:01,253 [INFO] Step[400/4329]: training loss : 0.8629541885852814 TRAIN  loss dict:  {'classification_loss': 0.8629541885852814}
2025-01-13 08:53:12,860 [INFO] Step[450/4329]: training loss : 0.88976318359375 TRAIN  loss dict:  {'classification_loss': 0.88976318359375}
2025-01-13 08:53:24,452 [INFO] Step[500/4329]: training loss : 0.8738690745830536 TRAIN  loss dict:  {'classification_loss': 0.8738690745830536}
2025-01-13 08:53:36,134 [INFO] Step[550/4329]: training loss : 0.8849352741241455 TRAIN  loss dict:  {'classification_loss': 0.8849352741241455}
2025-01-13 08:53:47,773 [INFO] Step[600/4329]: training loss : 0.8646736705303192 TRAIN  loss dict:  {'classification_loss': 0.8646736705303192}
2025-01-13 08:53:59,463 [INFO] Step[650/4329]: training loss : 0.8691857099533081 TRAIN  loss dict:  {'classification_loss': 0.8691857099533081}
2025-01-13 08:54:11,077 [INFO] Step[700/4329]: training loss : 0.8636325442790985 TRAIN  loss dict:  {'classification_loss': 0.8636325442790985}
2025-01-13 08:54:22,705 [INFO] Step[750/4329]: training loss : 0.877771077156067 TRAIN  loss dict:  {'classification_loss': 0.877771077156067}
2025-01-13 08:54:34,355 [INFO] Step[800/4329]: training loss : 0.8673571050167084 TRAIN  loss dict:  {'classification_loss': 0.8673571050167084}
2025-01-13 08:54:46,019 [INFO] Step[850/4329]: training loss : 0.8661545383930206 TRAIN  loss dict:  {'classification_loss': 0.8661545383930206}
2025-01-13 08:54:57,625 [INFO] Step[900/4329]: training loss : 0.8686086010932922 TRAIN  loss dict:  {'classification_loss': 0.8686086010932922}
2025-01-13 08:55:09,262 [INFO] Step[950/4329]: training loss : 0.8670605778694153 TRAIN  loss dict:  {'classification_loss': 0.8670605778694153}
2025-01-13 08:55:20,897 [INFO] Step[1000/4329]: training loss : 0.8645861780643463 TRAIN  loss dict:  {'classification_loss': 0.8645861780643463}
2025-01-13 08:55:32,535 [INFO] Step[1050/4329]: training loss : 0.8658722937107086 TRAIN  loss dict:  {'classification_loss': 0.8658722937107086}
2025-01-13 08:55:44,124 [INFO] Step[1100/4329]: training loss : 0.874562350511551 TRAIN  loss dict:  {'classification_loss': 0.874562350511551}
2025-01-13 08:55:55,791 [INFO] Step[1150/4329]: training loss : 0.8646467602252961 TRAIN  loss dict:  {'classification_loss': 0.8646467602252961}
2025-01-13 08:56:07,396 [INFO] Step[1200/4329]: training loss : 0.8622534060478211 TRAIN  loss dict:  {'classification_loss': 0.8622534060478211}
2025-01-13 08:56:19,047 [INFO] Step[1250/4329]: training loss : 0.8628959810733795 TRAIN  loss dict:  {'classification_loss': 0.8628959810733795}
2025-01-13 08:56:30,660 [INFO] Step[1300/4329]: training loss : 0.8697575652599334 TRAIN  loss dict:  {'classification_loss': 0.8697575652599334}
2025-01-13 08:56:42,292 [INFO] Step[1350/4329]: training loss : 0.8794050979614257 TRAIN  loss dict:  {'classification_loss': 0.8794050979614257}
2025-01-13 08:56:53,899 [INFO] Step[1400/4329]: training loss : 0.8634685468673706 TRAIN  loss dict:  {'classification_loss': 0.8634685468673706}
2025-01-13 08:57:05,564 [INFO] Step[1450/4329]: training loss : 0.8676375913619995 TRAIN  loss dict:  {'classification_loss': 0.8676375913619995}
2025-01-13 08:57:17,209 [INFO] Step[1500/4329]: training loss : 0.8642283976078033 TRAIN  loss dict:  {'classification_loss': 0.8642283976078033}
2025-01-13 08:57:28,822 [INFO] Step[1550/4329]: training loss : 0.8724936056137085 TRAIN  loss dict:  {'classification_loss': 0.8724936056137085}
2025-01-13 08:57:40,437 [INFO] Step[1600/4329]: training loss : 0.8624178647994996 TRAIN  loss dict:  {'classification_loss': 0.8624178647994996}
2025-01-13 08:57:52,226 [INFO] Step[1650/4329]: training loss : 0.8723963868618011 TRAIN  loss dict:  {'classification_loss': 0.8723963868618011}
2025-01-13 08:58:04,631 [INFO] Step[1700/4329]: training loss : 0.8639036619663238 TRAIN  loss dict:  {'classification_loss': 0.8639036619663238}
2025-01-13 08:58:16,860 [INFO] Step[1750/4329]: training loss : 0.8647399318218231 TRAIN  loss dict:  {'classification_loss': 0.8647399318218231}
2025-01-13 08:58:29,889 [INFO] Step[1800/4329]: training loss : 0.8702825367450714 TRAIN  loss dict:  {'classification_loss': 0.8702825367450714}
2025-01-13 08:58:43,395 [INFO] Step[1850/4329]: training loss : 0.8692877912521362 TRAIN  loss dict:  {'classification_loss': 0.8692877912521362}
2025-01-13 08:58:57,333 [INFO] Step[1900/4329]: training loss : 0.8800702822208405 TRAIN  loss dict:  {'classification_loss': 0.8800702822208405}
2025-01-13 08:59:09,196 [INFO] Step[1950/4329]: training loss : 0.8625608885288238 TRAIN  loss dict:  {'classification_loss': 0.8625608885288238}
2025-01-13 08:59:21,028 [INFO] Step[2000/4329]: training loss : 0.8658927965164185 TRAIN  loss dict:  {'classification_loss': 0.8658927965164185}
2025-01-13 08:59:32,668 [INFO] Step[2050/4329]: training loss : 0.862181100845337 TRAIN  loss dict:  {'classification_loss': 0.862181100845337}
2025-01-13 08:59:44,306 [INFO] Step[2100/4329]: training loss : 0.864116758108139 TRAIN  loss dict:  {'classification_loss': 0.864116758108139}
2025-01-13 08:59:55,980 [INFO] Step[2150/4329]: training loss : 0.879306218624115 TRAIN  loss dict:  {'classification_loss': 0.879306218624115}
2025-01-13 09:00:07,678 [INFO] Step[2200/4329]: training loss : 0.8665048038959503 TRAIN  loss dict:  {'classification_loss': 0.8665048038959503}
2025-01-13 09:00:19,343 [INFO] Step[2250/4329]: training loss : 0.8618599355220795 TRAIN  loss dict:  {'classification_loss': 0.8618599355220795}
2025-01-13 09:00:31,017 [INFO] Step[2300/4329]: training loss : 0.868963918685913 TRAIN  loss dict:  {'classification_loss': 0.868963918685913}
2025-01-13 09:00:42,655 [INFO] Step[2350/4329]: training loss : 0.864584903717041 TRAIN  loss dict:  {'classification_loss': 0.864584903717041}
2025-01-13 09:00:54,290 [INFO] Step[2400/4329]: training loss : 0.8673339176177979 TRAIN  loss dict:  {'classification_loss': 0.8673339176177979}
2025-01-13 09:01:05,946 [INFO] Step[2450/4329]: training loss : 0.8696050214767456 TRAIN  loss dict:  {'classification_loss': 0.8696050214767456}
2025-01-13 09:01:17,564 [INFO] Step[2500/4329]: training loss : 0.8665668582916259 TRAIN  loss dict:  {'classification_loss': 0.8665668582916259}
2025-01-13 09:01:29,184 [INFO] Step[2550/4329]: training loss : 0.8623812222480773 TRAIN  loss dict:  {'classification_loss': 0.8623812222480773}
2025-01-13 09:01:40,844 [INFO] Step[2600/4329]: training loss : 0.8619775295257568 TRAIN  loss dict:  {'classification_loss': 0.8619775295257568}
2025-01-13 09:01:52,515 [INFO] Step[2650/4329]: training loss : 0.8697285509109497 TRAIN  loss dict:  {'classification_loss': 0.8697285509109497}
2025-01-13 09:02:04,085 [INFO] Step[2700/4329]: training loss : 0.8630028605461121 TRAIN  loss dict:  {'classification_loss': 0.8630028605461121}
2025-01-13 09:02:15,685 [INFO] Step[2750/4329]: training loss : 0.866207058429718 TRAIN  loss dict:  {'classification_loss': 0.866207058429718}
2025-01-13 09:02:27,268 [INFO] Step[2800/4329]: training loss : 0.8654003179073334 TRAIN  loss dict:  {'classification_loss': 0.8654003179073334}
2025-01-13 09:02:38,866 [INFO] Step[2850/4329]: training loss : 0.86246741771698 TRAIN  loss dict:  {'classification_loss': 0.86246741771698}
2025-01-13 09:02:50,478 [INFO] Step[2900/4329]: training loss : 0.8650082564353943 TRAIN  loss dict:  {'classification_loss': 0.8650082564353943}
2025-01-13 09:03:02,114 [INFO] Step[2950/4329]: training loss : 0.8624369049072266 TRAIN  loss dict:  {'classification_loss': 0.8624369049072266}
2025-01-13 09:03:13,724 [INFO] Step[3000/4329]: training loss : 0.8756827664375305 TRAIN  loss dict:  {'classification_loss': 0.8756827664375305}
2025-01-13 09:03:25,370 [INFO] Step[3050/4329]: training loss : 0.8824845600128174 TRAIN  loss dict:  {'classification_loss': 0.8824845600128174}
2025-01-13 09:03:37,020 [INFO] Step[3100/4329]: training loss : 0.8617282545566559 TRAIN  loss dict:  {'classification_loss': 0.8617282545566559}
2025-01-13 09:03:48,667 [INFO] Step[3150/4329]: training loss : 0.8671173548698425 TRAIN  loss dict:  {'classification_loss': 0.8671173548698425}
2025-01-13 09:04:00,295 [INFO] Step[3200/4329]: training loss : 0.8645517873764038 TRAIN  loss dict:  {'classification_loss': 0.8645517873764038}
2025-01-13 09:04:11,952 [INFO] Step[3250/4329]: training loss : 0.8674325239658356 TRAIN  loss dict:  {'classification_loss': 0.8674325239658356}
2025-01-13 09:04:23,519 [INFO] Step[3300/4329]: training loss : 0.8633359396457672 TRAIN  loss dict:  {'classification_loss': 0.8633359396457672}
2025-01-13 09:04:35,141 [INFO] Step[3350/4329]: training loss : 0.8626407194137573 TRAIN  loss dict:  {'classification_loss': 0.8626407194137573}
2025-01-13 09:04:46,792 [INFO] Step[3400/4329]: training loss : 0.8787293612957001 TRAIN  loss dict:  {'classification_loss': 0.8787293612957001}
2025-01-13 09:04:58,446 [INFO] Step[3450/4329]: training loss : 0.8739972746372223 TRAIN  loss dict:  {'classification_loss': 0.8739972746372223}
2025-01-13 09:05:10,054 [INFO] Step[3500/4329]: training loss : 0.8641930615901947 TRAIN  loss dict:  {'classification_loss': 0.8641930615901947}
2025-01-13 09:05:21,719 [INFO] Step[3550/4329]: training loss : 0.8780625140666962 TRAIN  loss dict:  {'classification_loss': 0.8780625140666962}
2025-01-13 09:05:33,326 [INFO] Step[3600/4329]: training loss : 0.8635457944869995 TRAIN  loss dict:  {'classification_loss': 0.8635457944869995}
2025-01-13 09:05:44,985 [INFO] Step[3650/4329]: training loss : 0.8629523265361786 TRAIN  loss dict:  {'classification_loss': 0.8629523265361786}
2025-01-13 09:05:56,630 [INFO] Step[3700/4329]: training loss : 0.8639930760860444 TRAIN  loss dict:  {'classification_loss': 0.8639930760860444}
2025-01-13 09:06:08,276 [INFO] Step[3750/4329]: training loss : 0.8744409394264221 TRAIN  loss dict:  {'classification_loss': 0.8744409394264221}
2025-01-13 09:06:19,882 [INFO] Step[3800/4329]: training loss : 0.8667566990852356 TRAIN  loss dict:  {'classification_loss': 0.8667566990852356}
2025-01-13 09:06:31,477 [INFO] Step[3850/4329]: training loss : 0.8648644626140595 TRAIN  loss dict:  {'classification_loss': 0.8648644626140595}
2025-01-13 09:06:43,123 [INFO] Step[3900/4329]: training loss : 0.8655278837680817 TRAIN  loss dict:  {'classification_loss': 0.8655278837680817}
2025-01-13 09:06:54,772 [INFO] Step[3950/4329]: training loss : 0.8673401093482971 TRAIN  loss dict:  {'classification_loss': 0.8673401093482971}
2025-01-13 09:07:06,405 [INFO] Step[4000/4329]: training loss : 0.8728661906719207 TRAIN  loss dict:  {'classification_loss': 0.8728661906719207}
2025-01-13 09:07:18,011 [INFO] Step[4050/4329]: training loss : 0.8661062228679657 TRAIN  loss dict:  {'classification_loss': 0.8661062228679657}
2025-01-13 09:07:29,669 [INFO] Step[4100/4329]: training loss : 0.8669571566581726 TRAIN  loss dict:  {'classification_loss': 0.8669571566581726}
2025-01-13 09:07:41,291 [INFO] Step[4150/4329]: training loss : 0.9006967389583588 TRAIN  loss dict:  {'classification_loss': 0.9006967389583588}
2025-01-13 09:07:52,912 [INFO] Step[4200/4329]: training loss : 0.8646830630302429 TRAIN  loss dict:  {'classification_loss': 0.8646830630302429}
2025-01-13 09:08:04,567 [INFO] Step[4250/4329]: training loss : 0.8634579479694366 TRAIN  loss dict:  {'classification_loss': 0.8634579479694366}
2025-01-13 09:08:16,209 [INFO] Step[4300/4329]: training loss : 0.8626269280910492 TRAIN  loss dict:  {'classification_loss': 0.8626269280910492}
2025-01-13 09:10:13,521 [INFO] Label accuracies statistics:
2025-01-13 09:10:13,521 [INFO] {0: 0.8888888888888888, 1: 0.8888888888888888, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.3333333333333333, 5: 0.9166666666666666, 6: 0.5833333333333334, 7: 0.5, 8: 0.5833333333333334, 9: 0.9166666666666666, 10: 1.0, 11: 1.0, 12: 0.4166666666666667, 13: 0.5, 14: 0.75, 15: 0.7777777777777778, 16: 0.5833333333333334, 17: 0.25, 18: 0.6666666666666666, 19: 0.8333333333333334, 20: 0.75, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 1.0, 24: 0.9166666666666666, 25: 0.9166666666666666, 26: 0.8333333333333334, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.5833333333333334, 31: 0.8333333333333334, 32: 0.6666666666666666, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 0.8333333333333334, 38: 0.9166666666666666, 39: 0.9166666666666666, 40: 0.8333333333333334, 41: 0.4166666666666667, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.5833333333333334, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.8333333333333334, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5833333333333334, 59: 0.8333333333333334, 60: 0.8333333333333334, 61: 0.9166666666666666, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.8333333333333334, 68: 0.75, 69: 0.75, 70: 0.3333333333333333, 71: 0.5833333333333334, 72: 0.8333333333333334, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.8333333333333334, 78: 0.9166666666666666, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.6666666666666666, 83: 0.5833333333333334, 84: 0.5833333333333334, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.6666666666666666, 89: 0.75, 90: 0.8333333333333334, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 1.0, 96: 0.4166666666666667, 97: 0.75, 98: 0.9166666666666666, 99: 1.0, 100: 0.9166666666666666, 101: 1.0, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 0.9166666666666666, 106: 1.0, 107: 0.5, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 1.0, 111: 1.0, 112: 0.8333333333333334, 113: 0.5, 114: 0.5, 115: 0.9166666666666666, 116: 0.8333333333333334, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.8333333333333334, 121: 0.8333333333333334, 122: 0.9166666666666666, 123: 1.0, 124: 0.9166666666666666, 125: 0.8333333333333334, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.8333333333333334, 132: 0.5833333333333334, 133: 1.0, 134: 0.8333333333333334, 135: 1.0, 136: 0.8333333333333334, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 0.8333333333333334, 143: 1.0, 144: 0.75, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 0.9166666666666666, 153: 0.75, 154: 1.0, 155: 0.9166666666666666, 156: 0.75, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.5, 161: 0.9166666666666666, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.75, 166: 0.75, 167: 0.6666666666666666, 168: 0.9166666666666666, 169: 0.9166666666666666, 170: 0.9166666666666666, 171: 0.3333333333333333, 172: 1.0, 173: 0.9166666666666666, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 1.0, 177: 0.8333333333333334, 178: 1.0, 179: 0.3333333333333333, 180: 0.9166666666666666, 181: 0.9166666666666666, 182: 0.6666666666666666, 183: 0.8333333333333334, 184: 0.9166666666666666, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.5833333333333334, 189: 0.9166666666666666, 190: 0.6666666666666666, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.8333333333333334, 197: 0.8333333333333334, 198: 0.6666666666666666}

2025-01-13 09:10:13,525 [INFO] [58] TRAIN  loss: 0.8684509016674973 acc: 0.9986908978900354
2025-01-13 09:10:13,526 [INFO] [58] TRAIN  loss dict: {'classification_loss': 0.8684509016674973}
2025-01-13 09:10:13,526 [INFO] [58] VALIDATION loss: 1.5968918708538768 VALIDATION acc: 0.813973063973064
2025-01-13 09:10:13,526 [INFO] [58] VALIDATION loss dict: {'classification_loss': 1.5968918708538768}
2025-01-13 09:10:13,526 [INFO] 
2025-01-13 09:10:32,766 [INFO] Step[50/4329]: training loss : 0.8634527564048767 TRAIN  loss dict:  {'classification_loss': 0.8634527564048767}
2025-01-13 09:10:44,999 [INFO] Step[100/4329]: training loss : 0.8652685618400574 TRAIN  loss dict:  {'classification_loss': 0.8652685618400574}
2025-01-13 09:10:58,182 [INFO] Step[150/4329]: training loss : 0.8613432335853577 TRAIN  loss dict:  {'classification_loss': 0.8613432335853577}
2025-01-13 09:11:11,788 [INFO] Step[200/4329]: training loss : 0.8622257888317109 TRAIN  loss dict:  {'classification_loss': 0.8622257888317109}
2025-01-13 09:11:24,057 [INFO] Step[250/4329]: training loss : 0.8628244602680206 TRAIN  loss dict:  {'classification_loss': 0.8628244602680206}
2025-01-13 09:11:35,975 [INFO] Step[300/4329]: training loss : 0.8650523459911347 TRAIN  loss dict:  {'classification_loss': 0.8650523459911347}
2025-01-13 09:11:47,827 [INFO] Step[350/4329]: training loss : 0.8634580349922181 TRAIN  loss dict:  {'classification_loss': 0.8634580349922181}
2025-01-13 09:11:59,412 [INFO] Step[400/4329]: training loss : 0.862405288219452 TRAIN  loss dict:  {'classification_loss': 0.862405288219452}
2025-01-13 09:12:11,048 [INFO] Step[450/4329]: training loss : 0.8633426487445831 TRAIN  loss dict:  {'classification_loss': 0.8633426487445831}
2025-01-13 09:12:22,722 [INFO] Step[500/4329]: training loss : 0.8631592082977295 TRAIN  loss dict:  {'classification_loss': 0.8631592082977295}
2025-01-13 09:12:34,376 [INFO] Step[550/4329]: training loss : 0.8646696615219116 TRAIN  loss dict:  {'classification_loss': 0.8646696615219116}
2025-01-13 09:12:46,040 [INFO] Step[600/4329]: training loss : 0.8661895751953125 TRAIN  loss dict:  {'classification_loss': 0.8661895751953125}
2025-01-13 09:12:57,675 [INFO] Step[650/4329]: training loss : 0.8616684067249298 TRAIN  loss dict:  {'classification_loss': 0.8616684067249298}
2025-01-13 09:13:09,289 [INFO] Step[700/4329]: training loss : 0.8657726478576661 TRAIN  loss dict:  {'classification_loss': 0.8657726478576661}
2025-01-13 09:13:20,958 [INFO] Step[750/4329]: training loss : 0.8654615616798401 TRAIN  loss dict:  {'classification_loss': 0.8654615616798401}
2025-01-13 09:13:32,600 [INFO] Step[800/4329]: training loss : 0.8668462193012237 TRAIN  loss dict:  {'classification_loss': 0.8668462193012237}
2025-01-13 09:13:44,240 [INFO] Step[850/4329]: training loss : 0.8677343273162842 TRAIN  loss dict:  {'classification_loss': 0.8677343273162842}
2025-01-13 09:13:55,903 [INFO] Step[900/4329]: training loss : 0.8690375542640686 TRAIN  loss dict:  {'classification_loss': 0.8690375542640686}
2025-01-13 09:14:07,533 [INFO] Step[950/4329]: training loss : 0.8829843509197235 TRAIN  loss dict:  {'classification_loss': 0.8829843509197235}
2025-01-13 09:14:19,190 [INFO] Step[1000/4329]: training loss : 0.8600562369823456 TRAIN  loss dict:  {'classification_loss': 0.8600562369823456}
2025-01-13 09:14:30,845 [INFO] Step[1050/4329]: training loss : 0.862062611579895 TRAIN  loss dict:  {'classification_loss': 0.862062611579895}
2025-01-13 09:14:42,457 [INFO] Step[1100/4329]: training loss : 0.8671355617046356 TRAIN  loss dict:  {'classification_loss': 0.8671355617046356}
2025-01-13 09:14:54,078 [INFO] Step[1150/4329]: training loss : 0.8702602159976959 TRAIN  loss dict:  {'classification_loss': 0.8702602159976959}
2025-01-13 09:15:05,714 [INFO] Step[1200/4329]: training loss : 0.8637573802471161 TRAIN  loss dict:  {'classification_loss': 0.8637573802471161}
2025-01-13 09:15:17,327 [INFO] Step[1250/4329]: training loss : 0.8798688066005707 TRAIN  loss dict:  {'classification_loss': 0.8798688066005707}
2025-01-13 09:15:29,003 [INFO] Step[1300/4329]: training loss : 0.8710834980010986 TRAIN  loss dict:  {'classification_loss': 0.8710834980010986}
2025-01-13 09:15:40,610 [INFO] Step[1350/4329]: training loss : 0.8619433116912841 TRAIN  loss dict:  {'classification_loss': 0.8619433116912841}
2025-01-13 09:15:52,252 [INFO] Step[1400/4329]: training loss : 0.8777478659152984 TRAIN  loss dict:  {'classification_loss': 0.8777478659152984}
2025-01-13 09:16:03,853 [INFO] Step[1450/4329]: training loss : 0.8613973557949066 TRAIN  loss dict:  {'classification_loss': 0.8613973557949066}
2025-01-13 09:16:15,453 [INFO] Step[1500/4329]: training loss : 0.8827029621601105 TRAIN  loss dict:  {'classification_loss': 0.8827029621601105}
2025-01-13 09:16:27,100 [INFO] Step[1550/4329]: training loss : 0.8648900973796845 TRAIN  loss dict:  {'classification_loss': 0.8648900973796845}
2025-01-13 09:16:38,733 [INFO] Step[1600/4329]: training loss : 0.8639630544185638 TRAIN  loss dict:  {'classification_loss': 0.8639630544185638}
2025-01-13 09:16:50,377 [INFO] Step[1650/4329]: training loss : 0.8632007408142089 TRAIN  loss dict:  {'classification_loss': 0.8632007408142089}
2025-01-13 09:17:01,973 [INFO] Step[1700/4329]: training loss : 0.8631861555576325 TRAIN  loss dict:  {'classification_loss': 0.8631861555576325}
2025-01-13 09:17:13,613 [INFO] Step[1750/4329]: training loss : 0.8647136187553406 TRAIN  loss dict:  {'classification_loss': 0.8647136187553406}
2025-01-13 09:17:25,234 [INFO] Step[1800/4329]: training loss : 0.8661630165576935 TRAIN  loss dict:  {'classification_loss': 0.8661630165576935}
2025-01-13 09:17:36,885 [INFO] Step[1850/4329]: training loss : 0.8638969612121582 TRAIN  loss dict:  {'classification_loss': 0.8638969612121582}
2025-01-13 09:17:48,528 [INFO] Step[1900/4329]: training loss : 0.9123437082767487 TRAIN  loss dict:  {'classification_loss': 0.9123437082767487}
2025-01-13 09:18:00,160 [INFO] Step[1950/4329]: training loss : 0.8647511875629426 TRAIN  loss dict:  {'classification_loss': 0.8647511875629426}
2025-01-13 09:18:11,786 [INFO] Step[2000/4329]: training loss : 0.8621471345424652 TRAIN  loss dict:  {'classification_loss': 0.8621471345424652}
2025-01-13 09:18:23,428 [INFO] Step[2050/4329]: training loss : 0.8667710268497467 TRAIN  loss dict:  {'classification_loss': 0.8667710268497467}
2025-01-13 09:18:35,050 [INFO] Step[2100/4329]: training loss : 0.8633026731014252 TRAIN  loss dict:  {'classification_loss': 0.8633026731014252}
2025-01-13 09:18:46,681 [INFO] Step[2150/4329]: training loss : 0.8645240247249604 TRAIN  loss dict:  {'classification_loss': 0.8645240247249604}
2025-01-13 09:18:58,283 [INFO] Step[2200/4329]: training loss : 0.8628793275356292 TRAIN  loss dict:  {'classification_loss': 0.8628793275356292}
2025-01-13 09:19:09,977 [INFO] Step[2250/4329]: training loss : 0.8680148553848267 TRAIN  loss dict:  {'classification_loss': 0.8680148553848267}
2025-01-13 09:19:21,603 [INFO] Step[2300/4329]: training loss : 0.8658654141426086 TRAIN  loss dict:  {'classification_loss': 0.8658654141426086}
2025-01-13 09:19:33,281 [INFO] Step[2350/4329]: training loss : 0.8702759683132172 TRAIN  loss dict:  {'classification_loss': 0.8702759683132172}
2025-01-13 09:19:44,930 [INFO] Step[2400/4329]: training loss : 0.8675241398811341 TRAIN  loss dict:  {'classification_loss': 0.8675241398811341}
2025-01-13 09:19:56,634 [INFO] Step[2450/4329]: training loss : 0.8677085852622985 TRAIN  loss dict:  {'classification_loss': 0.8677085852622985}
2025-01-13 09:20:08,281 [INFO] Step[2500/4329]: training loss : 0.8644796621799469 TRAIN  loss dict:  {'classification_loss': 0.8644796621799469}
2025-01-13 09:20:19,858 [INFO] Step[2550/4329]: training loss : 0.8682289361953736 TRAIN  loss dict:  {'classification_loss': 0.8682289361953736}
2025-01-13 09:20:31,487 [INFO] Step[2600/4329]: training loss : 0.8614933240413666 TRAIN  loss dict:  {'classification_loss': 0.8614933240413666}
2025-01-13 09:20:43,130 [INFO] Step[2650/4329]: training loss : 0.8659910941123963 TRAIN  loss dict:  {'classification_loss': 0.8659910941123963}
2025-01-13 09:20:54,782 [INFO] Step[2700/4329]: training loss : 0.8623370063304902 TRAIN  loss dict:  {'classification_loss': 0.8623370063304902}
2025-01-13 09:21:06,457 [INFO] Step[2750/4329]: training loss : 0.8660099470615387 TRAIN  loss dict:  {'classification_loss': 0.8660099470615387}
2025-01-13 09:21:18,066 [INFO] Step[2800/4329]: training loss : 0.8629962885379792 TRAIN  loss dict:  {'classification_loss': 0.8629962885379792}
2025-01-13 09:21:29,638 [INFO] Step[2850/4329]: training loss : 0.8655945682525634 TRAIN  loss dict:  {'classification_loss': 0.8655945682525634}
2025-01-13 09:21:41,276 [INFO] Step[2900/4329]: training loss : 0.8651476466655731 TRAIN  loss dict:  {'classification_loss': 0.8651476466655731}
2025-01-13 09:21:52,914 [INFO] Step[2950/4329]: training loss : 0.8655524659156799 TRAIN  loss dict:  {'classification_loss': 0.8655524659156799}
2025-01-13 09:22:04,584 [INFO] Step[3000/4329]: training loss : 0.8630798184871673 TRAIN  loss dict:  {'classification_loss': 0.8630798184871673}
2025-01-13 09:22:16,227 [INFO] Step[3050/4329]: training loss : 0.8648868715763092 TRAIN  loss dict:  {'classification_loss': 0.8648868715763092}
2025-01-13 09:22:27,821 [INFO] Step[3100/4329]: training loss : 0.8631950843334198 TRAIN  loss dict:  {'classification_loss': 0.8631950843334198}
2025-01-13 09:22:39,793 [INFO] Step[3150/4329]: training loss : 0.8642885768413544 TRAIN  loss dict:  {'classification_loss': 0.8642885768413544}
2025-01-13 09:22:52,085 [INFO] Step[3200/4329]: training loss : 0.8737869799137116 TRAIN  loss dict:  {'classification_loss': 0.8737869799137116}
2025-01-13 09:23:04,427 [INFO] Step[3250/4329]: training loss : 0.8647691690921784 TRAIN  loss dict:  {'classification_loss': 0.8647691690921784}
2025-01-13 09:23:17,847 [INFO] Step[3300/4329]: training loss : 0.8627671325206756 TRAIN  loss dict:  {'classification_loss': 0.8627671325206756}
2025-01-13 09:23:33,555 [INFO] Step[3350/4329]: training loss : 0.8625796413421631 TRAIN  loss dict:  {'classification_loss': 0.8625796413421631}
2025-01-13 09:23:45,566 [INFO] Step[3400/4329]: training loss : 0.8702951908111572 TRAIN  loss dict:  {'classification_loss': 0.8702951908111572}
2025-01-13 09:23:57,487 [INFO] Step[3450/4329]: training loss : 0.866430025100708 TRAIN  loss dict:  {'classification_loss': 0.866430025100708}
2025-01-13 09:24:09,129 [INFO] Step[3500/4329]: training loss : 0.8687607312202453 TRAIN  loss dict:  {'classification_loss': 0.8687607312202453}
2025-01-13 09:24:20,769 [INFO] Step[3550/4329]: training loss : 0.8659194397926331 TRAIN  loss dict:  {'classification_loss': 0.8659194397926331}
2025-01-13 09:24:32,393 [INFO] Step[3600/4329]: training loss : 0.8713079285621643 TRAIN  loss dict:  {'classification_loss': 0.8713079285621643}
2025-01-13 09:24:44,016 [INFO] Step[3650/4329]: training loss : 0.8639213514328002 TRAIN  loss dict:  {'classification_loss': 0.8639213514328002}
2025-01-13 09:24:55,622 [INFO] Step[3700/4329]: training loss : 0.8839847886562348 TRAIN  loss dict:  {'classification_loss': 0.8839847886562348}
2025-01-13 09:25:07,233 [INFO] Step[3750/4329]: training loss : 0.8734378933906555 TRAIN  loss dict:  {'classification_loss': 0.8734378933906555}
2025-01-13 09:25:18,883 [INFO] Step[3800/4329]: training loss : 0.8621150970458984 TRAIN  loss dict:  {'classification_loss': 0.8621150970458984}
2025-01-13 09:25:30,506 [INFO] Step[3850/4329]: training loss : 0.8733735752105712 TRAIN  loss dict:  {'classification_loss': 0.8733735752105712}
2025-01-13 09:25:42,130 [INFO] Step[3900/4329]: training loss : 0.8630213177204132 TRAIN  loss dict:  {'classification_loss': 0.8630213177204132}
2025-01-13 09:25:53,790 [INFO] Step[3950/4329]: training loss : 0.8623767757415771 TRAIN  loss dict:  {'classification_loss': 0.8623767757415771}
2025-01-13 09:26:05,419 [INFO] Step[4000/4329]: training loss : 0.870404281616211 TRAIN  loss dict:  {'classification_loss': 0.870404281616211}
2025-01-13 09:26:17,085 [INFO] Step[4050/4329]: training loss : 0.8689107382297516 TRAIN  loss dict:  {'classification_loss': 0.8689107382297516}
2025-01-13 09:26:28,682 [INFO] Step[4100/4329]: training loss : 0.8654788374900818 TRAIN  loss dict:  {'classification_loss': 0.8654788374900818}
2025-01-13 09:26:40,293 [INFO] Step[4150/4329]: training loss : 0.8675973343849183 TRAIN  loss dict:  {'classification_loss': 0.8675973343849183}
2025-01-13 09:26:51,940 [INFO] Step[4200/4329]: training loss : 0.8765603435039521 TRAIN  loss dict:  {'classification_loss': 0.8765603435039521}
2025-01-13 09:27:03,604 [INFO] Step[4250/4329]: training loss : 0.8711830985546112 TRAIN  loss dict:  {'classification_loss': 0.8711830985546112}
2025-01-13 09:27:15,236 [INFO] Step[4300/4329]: training loss : 0.8624327969551087 TRAIN  loss dict:  {'classification_loss': 0.8624327969551087}
2025-01-13 09:29:14,577 [INFO] Label accuracies statistics:
2025-01-13 09:29:14,577 [INFO] {0: 0.8888888888888888, 1: 0.8888888888888888, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.9166666666666666, 6: 0.5833333333333334, 7: 0.5, 8: 0.4166666666666667, 9: 1.0, 10: 1.0, 11: 0.9166666666666666, 12: 0.5833333333333334, 13: 0.4166666666666667, 14: 0.6666666666666666, 15: 0.6666666666666666, 16: 0.75, 17: 0.5833333333333334, 18: 0.5, 19: 0.8333333333333334, 20: 0.5, 21: 0.75, 22: 0.6666666666666666, 23: 1.0, 24: 0.9166666666666666, 25: 0.6666666666666666, 26: 0.75, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.6666666666666666, 31: 0.6666666666666666, 32: 0.75, 33: 0.9166666666666666, 34: 1.0, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 0.8333333333333334, 38: 1.0, 39: 0.9166666666666666, 40: 0.8333333333333334, 41: 0.5, 42: 0.9166666666666666, 43: 1.0, 44: 0.6666666666666666, 45: 0.5833333333333334, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.8333333333333334, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.3333333333333333, 55: 0.6666666666666666, 56: 0.75, 57: 0.75, 58: 0.5833333333333334, 59: 0.6666666666666666, 60: 0.5833333333333334, 61: 1.0, 62: 0.75, 63: 0.5833333333333334, 64: 0.9166666666666666, 65: 1.0, 66: 0.6666666666666666, 67: 0.9166666666666666, 68: 0.5833333333333334, 69: 0.6666666666666666, 70: 0.5, 71: 0.6666666666666666, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.5833333333333334, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.6666666666666666, 84: 0.4166666666666667, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.75, 89: 0.6666666666666666, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 1.0, 96: 0.4166666666666667, 97: 0.75, 98: 0.8333333333333334, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 0.9166666666666666, 106: 1.0, 107: 0.75, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.9166666666666666, 111: 1.0, 112: 0.9166666666666666, 113: 0.5, 114: 0.4166666666666667, 115: 1.0, 116: 0.9166666666666666, 117: 0.8333333333333334, 118: 1.0, 119: 0.75, 120: 0.9166666666666666, 121: 0.8333333333333334, 122: 0.8333333333333334, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.6666666666666666, 131: 0.9166666666666666, 132: 0.4166666666666667, 133: 1.0, 134: 0.9166666666666666, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 0.8333333333333334, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.9166666666666666, 148: 0.75, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 0.9166666666666666, 153: 0.9166666666666666, 154: 1.0, 155: 0.9166666666666666, 156: 0.75, 157: 0.8333333333333334, 158: 0.6666666666666666, 159: 1.0, 160: 0.3333333333333333, 161: 0.75, 162: 0.9166666666666666, 163: 1.0, 164: 0.8333333333333334, 165: 0.8333333333333334, 166: 0.8333333333333334, 167: 0.6666666666666666, 168: 0.9166666666666666, 169: 0.9166666666666666, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.2222222222222222, 180: 0.9166666666666666, 181: 0.9166666666666666, 182: 0.6666666666666666, 183: 0.8333333333333334, 184: 0.8333333333333334, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5833333333333334, 189: 0.75, 190: 0.5833333333333334, 191: 0.3333333333333333, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.6666666666666666, 196: 0.9166666666666666, 197: 0.75, 198: 0.75}

2025-01-13 09:29:14,580 [INFO] [59] TRAIN  loss: 0.8669605144702086 acc: 0.9986908978900354
2025-01-13 09:29:14,580 [INFO] [59] TRAIN  loss dict: {'classification_loss': 0.8669605144702086}
2025-01-13 09:29:14,580 [INFO] [59] VALIDATION loss: 1.5972675106140097 VALIDATION acc: 0.803030303030303
2025-01-13 09:29:14,580 [INFO] [59] VALIDATION loss dict: {'classification_loss': 1.5972675106140097}
2025-01-13 09:29:14,580 [INFO] 
2025-01-13 09:29:32,265 [INFO] Step[50/4329]: training loss : 0.867236671447754 TRAIN  loss dict:  {'classification_loss': 0.867236671447754}
2025-01-13 09:29:43,841 [INFO] Step[100/4329]: training loss : 0.86572150349617 TRAIN  loss dict:  {'classification_loss': 0.86572150349617}
2025-01-13 09:29:55,435 [INFO] Step[150/4329]: training loss : 0.8717503154277801 TRAIN  loss dict:  {'classification_loss': 0.8717503154277801}
2025-01-13 09:30:07,040 [INFO] Step[200/4329]: training loss : 0.86183114528656 TRAIN  loss dict:  {'classification_loss': 0.86183114528656}
2025-01-13 09:30:18,680 [INFO] Step[250/4329]: training loss : 0.8712328088283539 TRAIN  loss dict:  {'classification_loss': 0.8712328088283539}
2025-01-13 09:30:30,333 [INFO] Step[300/4329]: training loss : 0.8711710286140442 TRAIN  loss dict:  {'classification_loss': 0.8711710286140442}
2025-01-13 09:30:41,961 [INFO] Step[350/4329]: training loss : 0.8768614435195923 TRAIN  loss dict:  {'classification_loss': 0.8768614435195923}
2025-01-13 09:30:53,622 [INFO] Step[400/4329]: training loss : 0.8650291538238526 TRAIN  loss dict:  {'classification_loss': 0.8650291538238526}
2025-01-13 09:31:05,270 [INFO] Step[450/4329]: training loss : 0.8756582319736481 TRAIN  loss dict:  {'classification_loss': 0.8756582319736481}
2025-01-13 09:31:16,937 [INFO] Step[500/4329]: training loss : 0.8727485525608063 TRAIN  loss dict:  {'classification_loss': 0.8727485525608063}
2025-01-13 09:31:28,608 [INFO] Step[550/4329]: training loss : 0.8618798625469207 TRAIN  loss dict:  {'classification_loss': 0.8618798625469207}
2025-01-13 09:31:40,268 [INFO] Step[600/4329]: training loss : 0.8625379371643066 TRAIN  loss dict:  {'classification_loss': 0.8625379371643066}
2025-01-13 09:31:51,950 [INFO] Step[650/4329]: training loss : 0.865934693813324 TRAIN  loss dict:  {'classification_loss': 0.865934693813324}
2025-01-13 09:32:03,595 [INFO] Step[700/4329]: training loss : 0.8647614789009094 TRAIN  loss dict:  {'classification_loss': 0.8647614789009094}
2025-01-13 09:32:15,217 [INFO] Step[750/4329]: training loss : 0.8664496517181397 TRAIN  loss dict:  {'classification_loss': 0.8664496517181397}
2025-01-13 09:32:26,887 [INFO] Step[800/4329]: training loss : 0.8728982090950013 TRAIN  loss dict:  {'classification_loss': 0.8728982090950013}
2025-01-13 09:32:38,516 [INFO] Step[850/4329]: training loss : 0.8637043023109436 TRAIN  loss dict:  {'classification_loss': 0.8637043023109436}
2025-01-13 09:32:50,151 [INFO] Step[900/4329]: training loss : 0.8649523198604584 TRAIN  loss dict:  {'classification_loss': 0.8649523198604584}
2025-01-13 09:33:01,785 [INFO] Step[950/4329]: training loss : 0.8636435222625732 TRAIN  loss dict:  {'classification_loss': 0.8636435222625732}
2025-01-13 09:33:13,439 [INFO] Step[1000/4329]: training loss : 0.8633696448802948 TRAIN  loss dict:  {'classification_loss': 0.8633696448802948}
2025-01-13 09:33:25,083 [INFO] Step[1050/4329]: training loss : 0.8621031677722931 TRAIN  loss dict:  {'classification_loss': 0.8621031677722931}
2025-01-13 09:33:36,736 [INFO] Step[1100/4329]: training loss : 0.8629638075828552 TRAIN  loss dict:  {'classification_loss': 0.8629638075828552}
2025-01-13 09:33:48,376 [INFO] Step[1150/4329]: training loss : 0.8635447931289673 TRAIN  loss dict:  {'classification_loss': 0.8635447931289673}
2025-01-13 09:33:59,963 [INFO] Step[1200/4329]: training loss : 0.877420037984848 TRAIN  loss dict:  {'classification_loss': 0.877420037984848}
2025-01-13 09:34:11,592 [INFO] Step[1250/4329]: training loss : 0.8656964302062988 TRAIN  loss dict:  {'classification_loss': 0.8656964302062988}
2025-01-13 09:34:23,204 [INFO] Step[1300/4329]: training loss : 0.864403692483902 TRAIN  loss dict:  {'classification_loss': 0.864403692483902}
2025-01-13 09:34:34,832 [INFO] Step[1350/4329]: training loss : 0.8915233290195466 TRAIN  loss dict:  {'classification_loss': 0.8915233290195466}
2025-01-13 09:34:46,454 [INFO] Step[1400/4329]: training loss : 0.8713334977626801 TRAIN  loss dict:  {'classification_loss': 0.8713334977626801}
2025-01-13 09:34:58,255 [INFO] Step[1450/4329]: training loss : 0.8764972233772278 TRAIN  loss dict:  {'classification_loss': 0.8764972233772278}
2025-01-13 09:35:10,666 [INFO] Step[1500/4329]: training loss : 0.866398788690567 TRAIN  loss dict:  {'classification_loss': 0.866398788690567}
2025-01-13 09:35:22,972 [INFO] Step[1550/4329]: training loss : 0.8656491065025329 TRAIN  loss dict:  {'classification_loss': 0.8656491065025329}
2025-01-13 09:35:36,215 [INFO] Step[1600/4329]: training loss : 0.8653303134441376 TRAIN  loss dict:  {'classification_loss': 0.8653303134441376}
2025-01-13 09:35:49,431 [INFO] Step[1650/4329]: training loss : 0.873643741607666 TRAIN  loss dict:  {'classification_loss': 0.873643741607666}
2025-01-13 09:36:02,695 [INFO] Step[1700/4329]: training loss : 0.862186632156372 TRAIN  loss dict:  {'classification_loss': 0.862186632156372}
2025-01-13 09:36:14,588 [INFO] Step[1750/4329]: training loss : 0.8639823389053345 TRAIN  loss dict:  {'classification_loss': 0.8639823389053345}
2025-01-13 09:36:26,410 [INFO] Step[1800/4329]: training loss : 0.8683087468147278 TRAIN  loss dict:  {'classification_loss': 0.8683087468147278}
2025-01-13 09:36:38,104 [INFO] Step[1850/4329]: training loss : 0.8693426251411438 TRAIN  loss dict:  {'classification_loss': 0.8693426251411438}
2025-01-13 09:36:49,709 [INFO] Step[1900/4329]: training loss : 0.8625569844245911 TRAIN  loss dict:  {'classification_loss': 0.8625569844245911}
2025-01-13 09:37:01,337 [INFO] Step[1950/4329]: training loss : 0.8617833828926087 TRAIN  loss dict:  {'classification_loss': 0.8617833828926087}
2025-01-13 09:37:12,960 [INFO] Step[2000/4329]: training loss : 0.8636604225635529 TRAIN  loss dict:  {'classification_loss': 0.8636604225635529}
2025-01-13 09:37:24,573 [INFO] Step[2050/4329]: training loss : 0.8754048788547516 TRAIN  loss dict:  {'classification_loss': 0.8754048788547516}
2025-01-13 09:37:36,212 [INFO] Step[2100/4329]: training loss : 0.8633708894252777 TRAIN  loss dict:  {'classification_loss': 0.8633708894252777}
2025-01-13 09:37:47,837 [INFO] Step[2150/4329]: training loss : 0.8776833939552308 TRAIN  loss dict:  {'classification_loss': 0.8776833939552308}
2025-01-13 09:37:59,462 [INFO] Step[2200/4329]: training loss : 0.8856155979633331 TRAIN  loss dict:  {'classification_loss': 0.8856155979633331}
2025-01-13 09:38:11,093 [INFO] Step[2250/4329]: training loss : 0.8674134826660156 TRAIN  loss dict:  {'classification_loss': 0.8674134826660156}
2025-01-13 09:38:22,742 [INFO] Step[2300/4329]: training loss : 0.8611444437503815 TRAIN  loss dict:  {'classification_loss': 0.8611444437503815}
2025-01-13 09:38:34,385 [INFO] Step[2350/4329]: training loss : 0.8625764048099518 TRAIN  loss dict:  {'classification_loss': 0.8625764048099518}
2025-01-13 09:38:45,986 [INFO] Step[2400/4329]: training loss : 0.8626784634590149 TRAIN  loss dict:  {'classification_loss': 0.8626784634590149}
2025-01-13 09:38:57,640 [INFO] Step[2450/4329]: training loss : 0.8604392623901367 TRAIN  loss dict:  {'classification_loss': 0.8604392623901367}
2025-01-13 09:39:09,308 [INFO] Step[2500/4329]: training loss : 0.8697323262691498 TRAIN  loss dict:  {'classification_loss': 0.8697323262691498}
2025-01-13 09:39:20,974 [INFO] Step[2550/4329]: training loss : 0.8699375140666962 TRAIN  loss dict:  {'classification_loss': 0.8699375140666962}
2025-01-13 09:39:32,571 [INFO] Step[2600/4329]: training loss : 0.8639119493961335 TRAIN  loss dict:  {'classification_loss': 0.8639119493961335}
2025-01-13 09:39:44,200 [INFO] Step[2650/4329]: training loss : 0.8633636164665223 TRAIN  loss dict:  {'classification_loss': 0.8633636164665223}
2025-01-13 09:39:55,848 [INFO] Step[2700/4329]: training loss : 0.8635885536670684 TRAIN  loss dict:  {'classification_loss': 0.8635885536670684}
2025-01-13 09:40:07,471 [INFO] Step[2750/4329]: training loss : 0.864397622346878 TRAIN  loss dict:  {'classification_loss': 0.864397622346878}
2025-01-13 09:40:19,103 [INFO] Step[2800/4329]: training loss : 0.8639394891262054 TRAIN  loss dict:  {'classification_loss': 0.8639394891262054}
2025-01-13 09:40:30,747 [INFO] Step[2850/4329]: training loss : 0.8650386810302735 TRAIN  loss dict:  {'classification_loss': 0.8650386810302735}
2025-01-13 09:40:42,359 [INFO] Step[2900/4329]: training loss : 0.86346440076828 TRAIN  loss dict:  {'classification_loss': 0.86346440076828}
2025-01-13 09:40:53,987 [INFO] Step[2950/4329]: training loss : 0.8894165968894958 TRAIN  loss dict:  {'classification_loss': 0.8894165968894958}
2025-01-13 09:41:05,619 [INFO] Step[3000/4329]: training loss : 0.8623838949203492 TRAIN  loss dict:  {'classification_loss': 0.8623838949203492}
2025-01-13 09:41:17,253 [INFO] Step[3050/4329]: training loss : 0.862723593711853 TRAIN  loss dict:  {'classification_loss': 0.862723593711853}
2025-01-13 09:41:28,863 [INFO] Step[3100/4329]: training loss : 0.8618960392475128 TRAIN  loss dict:  {'classification_loss': 0.8618960392475128}
2025-01-13 09:41:40,514 [INFO] Step[3150/4329]: training loss : 0.8712791013717651 TRAIN  loss dict:  {'classification_loss': 0.8712791013717651}
2025-01-13 09:41:52,155 [INFO] Step[3200/4329]: training loss : 0.8836695241928101 TRAIN  loss dict:  {'classification_loss': 0.8836695241928101}
2025-01-13 09:42:03,810 [INFO] Step[3250/4329]: training loss : 0.866005380153656 TRAIN  loss dict:  {'classification_loss': 0.866005380153656}
2025-01-13 09:42:15,435 [INFO] Step[3300/4329]: training loss : 0.8613772928714752 TRAIN  loss dict:  {'classification_loss': 0.8613772928714752}
2025-01-13 09:42:27,055 [INFO] Step[3350/4329]: training loss : 0.8712178480625152 TRAIN  loss dict:  {'classification_loss': 0.8712178480625152}
2025-01-13 09:42:38,708 [INFO] Step[3400/4329]: training loss : 0.8655210173130036 TRAIN  loss dict:  {'classification_loss': 0.8655210173130036}
2025-01-13 09:42:50,363 [INFO] Step[3450/4329]: training loss : 0.8622708344459533 TRAIN  loss dict:  {'classification_loss': 0.8622708344459533}
2025-01-13 09:43:01,964 [INFO] Step[3500/4329]: training loss : 0.8639518404006958 TRAIN  loss dict:  {'classification_loss': 0.8639518404006958}
2025-01-13 09:43:13,633 [INFO] Step[3550/4329]: training loss : 0.8800008630752564 TRAIN  loss dict:  {'classification_loss': 0.8800008630752564}
2025-01-13 09:43:25,235 [INFO] Step[3600/4329]: training loss : 0.8646459126472473 TRAIN  loss dict:  {'classification_loss': 0.8646459126472473}
2025-01-13 09:43:36,859 [INFO] Step[3650/4329]: training loss : 0.8631010091304779 TRAIN  loss dict:  {'classification_loss': 0.8631010091304779}
2025-01-13 09:43:48,474 [INFO] Step[3700/4329]: training loss : 0.8640226101875306 TRAIN  loss dict:  {'classification_loss': 0.8640226101875306}
2025-01-13 09:44:00,092 [INFO] Step[3750/4329]: training loss : 0.8634280037879943 TRAIN  loss dict:  {'classification_loss': 0.8634280037879943}
2025-01-13 09:44:11,703 [INFO] Step[3800/4329]: training loss : 0.8616194891929626 TRAIN  loss dict:  {'classification_loss': 0.8616194891929626}
2025-01-13 09:44:23,420 [INFO] Step[3850/4329]: training loss : 0.8629995942115783 TRAIN  loss dict:  {'classification_loss': 0.8629995942115783}
2025-01-13 09:44:35,022 [INFO] Step[3900/4329]: training loss : 0.8617686355113983 TRAIN  loss dict:  {'classification_loss': 0.8617686355113983}
2025-01-13 09:44:46,663 [INFO] Step[3950/4329]: training loss : 0.8674489557743073 TRAIN  loss dict:  {'classification_loss': 0.8674489557743073}
2025-01-13 09:44:58,273 [INFO] Step[4000/4329]: training loss : 0.8944588875770569 TRAIN  loss dict:  {'classification_loss': 0.8944588875770569}
2025-01-13 09:45:09,900 [INFO] Step[4050/4329]: training loss : 0.8626738142967224 TRAIN  loss dict:  {'classification_loss': 0.8626738142967224}
2025-01-13 09:45:21,508 [INFO] Step[4100/4329]: training loss : 0.8621358597278594 TRAIN  loss dict:  {'classification_loss': 0.8621358597278594}
2025-01-13 09:45:33,148 [INFO] Step[4150/4329]: training loss : 0.8646227061748505 TRAIN  loss dict:  {'classification_loss': 0.8646227061748505}
2025-01-13 09:45:44,764 [INFO] Step[4200/4329]: training loss : 0.8701146936416626 TRAIN  loss dict:  {'classification_loss': 0.8701146936416626}
2025-01-13 09:45:56,425 [INFO] Step[4250/4329]: training loss : 0.8600094735622406 TRAIN  loss dict:  {'classification_loss': 0.8600094735622406}
2025-01-13 09:46:08,039 [INFO] Step[4300/4329]: training loss : 0.8654411816596985 TRAIN  loss dict:  {'classification_loss': 0.8654411816596985}
2025-01-13 09:48:21,355 [INFO] Label accuracies statistics:
2025-01-13 09:48:21,356 [INFO] {0: 0.8888888888888888, 1: 1.0, 2: 0.6666666666666666, 3: 0.75, 4: 0.4166666666666667, 5: 0.9166666666666666, 6: 0.5833333333333334, 7: 0.5833333333333334, 8: 0.6666666666666666, 9: 0.9166666666666666, 10: 1.0, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.5, 14: 0.75, 15: 0.7777777777777778, 16: 0.6666666666666666, 17: 0.5833333333333334, 18: 0.5, 19: 0.8333333333333334, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.9166666666666666, 24: 0.9166666666666666, 25: 0.6666666666666666, 26: 0.6666666666666666, 27: 0.6666666666666666, 28: 0.8333333333333334, 29: 1.0, 30: 0.6666666666666666, 31: 0.6666666666666666, 32: 0.6666666666666666, 33: 0.9166666666666666, 34: 0.8333333333333334, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 0.9166666666666666, 40: 0.75, 41: 0.5833333333333334, 42: 0.75, 43: 0.8333333333333334, 44: 0.3333333333333333, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.8333333333333334, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.6666666666666666, 56: 0.9166666666666666, 57: 0.75, 58: 0.5, 59: 0.9166666666666666, 60: 0.75, 61: 0.8333333333333334, 62: 0.75, 63: 0.5, 64: 0.9166666666666666, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.5, 69: 0.5833333333333334, 70: 0.4166666666666667, 71: 0.5, 72: 0.75, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.8333333333333334, 78: 1.0, 79: 0.4166666666666667, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5833333333333334, 84: 0.5, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 0.9166666666666666, 92: 0.9166666666666666, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.5833333333333334, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.8333333333333334, 101: 0.9166666666666666, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 0.9166666666666666, 106: 1.0, 107: 0.5, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.9166666666666666, 111: 1.0, 112: 0.8333333333333334, 113: 0.5833333333333334, 114: 0.5, 115: 1.0, 116: 0.8333333333333334, 117: 0.75, 118: 1.0, 119: 0.8333333333333334, 120: 0.75, 121: 0.8333333333333334, 122: 0.9166666666666666, 123: 1.0, 124: 1.0, 125: 0.9166666666666666, 126: 0.9166666666666666, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.8333333333333334, 132: 0.3333333333333333, 133: 1.0, 134: 0.8333333333333334, 135: 1.0, 136: 0.8333333333333334, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.8333333333333334, 140: 0.8333333333333334, 141: 1.0, 142: 0.8333333333333334, 143: 1.0, 144: 0.75, 145: 0.9166666666666666, 146: 1.0, 147: 0.9166666666666666, 148: 0.6666666666666666, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 0.8333333333333334, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.25, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.9166666666666666, 169: 0.9166666666666666, 170: 1.0, 171: 0.4166666666666667, 172: 1.0, 173: 0.8333333333333334, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.8333333333333334, 178: 1.0, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.75, 183: 0.8333333333333334, 184: 0.75, 185: 1.0, 186: 0.75, 187: 0.9166666666666666, 188: 0.4166666666666667, 189: 0.9166666666666666, 190: 0.6666666666666666, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 1.0, 197: 0.8333333333333334, 198: 0.6666666666666666}

2025-01-13 09:48:21,363 [INFO] [60] TRAIN  loss: 0.8675983742165163 acc: 0.9982288618512244
2025-01-13 09:48:21,363 [INFO] [60] TRAIN  loss dict: {'classification_loss': 0.8675983742165163}
2025-01-13 09:48:21,364 [INFO] [60] VALIDATION loss: 1.6455052580797311 VALIDATION acc: 0.7992424242424242
2025-01-13 09:48:21,364 [INFO] [60] VALIDATION loss dict: {'classification_loss': 1.6455052580797311}
2025-01-13 09:48:21,364 [INFO] 
2025-01-13 09:48:46,688 [INFO] Step[50/4329]: training loss : 0.8681039202213288 TRAIN  loss dict:  {'classification_loss': 0.8681039202213288}
2025-01-13 09:48:58,492 [INFO] Step[100/4329]: training loss : 0.8625341248512268 TRAIN  loss dict:  {'classification_loss': 0.8625341248512268}
2025-01-13 09:49:10,206 [INFO] Step[150/4329]: training loss : 0.8616511690616607 TRAIN  loss dict:  {'classification_loss': 0.8616511690616607}
2025-01-13 09:49:21,863 [INFO] Step[200/4329]: training loss : 0.8608393740653991 TRAIN  loss dict:  {'classification_loss': 0.8608393740653991}
2025-01-13 09:49:33,532 [INFO] Step[250/4329]: training loss : 0.8650825905799866 TRAIN  loss dict:  {'classification_loss': 0.8650825905799866}
2025-01-13 09:49:45,165 [INFO] Step[300/4329]: training loss : 0.8609171986579895 TRAIN  loss dict:  {'classification_loss': 0.8609171986579895}
2025-01-13 09:49:56,790 [INFO] Step[350/4329]: training loss : 0.8658961606025696 TRAIN  loss dict:  {'classification_loss': 0.8658961606025696}
2025-01-13 09:50:08,441 [INFO] Step[400/4329]: training loss : 0.8673445737361908 TRAIN  loss dict:  {'classification_loss': 0.8673445737361908}
2025-01-13 09:50:20,073 [INFO] Step[450/4329]: training loss : 0.8757516658306121 TRAIN  loss dict:  {'classification_loss': 0.8757516658306121}
2025-01-13 09:50:31,733 [INFO] Step[500/4329]: training loss : 0.8717470228672027 TRAIN  loss dict:  {'classification_loss': 0.8717470228672027}
2025-01-13 09:50:43,380 [INFO] Step[550/4329]: training loss : 0.8636307835578918 TRAIN  loss dict:  {'classification_loss': 0.8636307835578918}
2025-01-13 09:50:55,026 [INFO] Step[600/4329]: training loss : 0.8598812580108642 TRAIN  loss dict:  {'classification_loss': 0.8598812580108642}
2025-01-13 09:51:06,643 [INFO] Step[650/4329]: training loss : 0.8599041438102722 TRAIN  loss dict:  {'classification_loss': 0.8599041438102722}
2025-01-13 09:51:18,233 [INFO] Step[700/4329]: training loss : 0.8626955533027649 TRAIN  loss dict:  {'classification_loss': 0.8626955533027649}
2025-01-13 09:51:29,842 [INFO] Step[750/4329]: training loss : 0.8614238655567169 TRAIN  loss dict:  {'classification_loss': 0.8614238655567169}
2025-01-13 09:51:41,430 [INFO] Step[800/4329]: training loss : 0.8622521197795868 TRAIN  loss dict:  {'classification_loss': 0.8622521197795868}
2025-01-13 09:51:53,081 [INFO] Step[850/4329]: training loss : 0.8616179931163788 TRAIN  loss dict:  {'classification_loss': 0.8616179931163788}
2025-01-13 09:52:04,681 [INFO] Step[900/4329]: training loss : 0.8644097530841828 TRAIN  loss dict:  {'classification_loss': 0.8644097530841828}
2025-01-13 09:52:16,346 [INFO] Step[950/4329]: training loss : 0.8651748847961426 TRAIN  loss dict:  {'classification_loss': 0.8651748847961426}
2025-01-13 09:52:27,969 [INFO] Step[1000/4329]: training loss : 0.8635338878631592 TRAIN  loss dict:  {'classification_loss': 0.8635338878631592}
2025-01-13 09:52:39,634 [INFO] Step[1050/4329]: training loss : 0.8629922878742218 TRAIN  loss dict:  {'classification_loss': 0.8629922878742218}
2025-01-13 09:52:51,265 [INFO] Step[1100/4329]: training loss : 0.8618425726890564 TRAIN  loss dict:  {'classification_loss': 0.8618425726890564}
2025-01-13 09:53:02,919 [INFO] Step[1150/4329]: training loss : 0.8595752549171448 TRAIN  loss dict:  {'classification_loss': 0.8595752549171448}
2025-01-13 09:53:14,584 [INFO] Step[1200/4329]: training loss : 0.861142064332962 TRAIN  loss dict:  {'classification_loss': 0.861142064332962}
2025-01-13 09:53:26,238 [INFO] Step[1250/4329]: training loss : 0.861828064918518 TRAIN  loss dict:  {'classification_loss': 0.861828064918518}
2025-01-13 09:53:37,896 [INFO] Step[1300/4329]: training loss : 0.8612413465976715 TRAIN  loss dict:  {'classification_loss': 0.8612413465976715}
2025-01-13 09:53:49,508 [INFO] Step[1350/4329]: training loss : 0.8630298209190369 TRAIN  loss dict:  {'classification_loss': 0.8630298209190369}
2025-01-13 09:54:01,177 [INFO] Step[1400/4329]: training loss : 0.87224867105484 TRAIN  loss dict:  {'classification_loss': 0.87224867105484}
2025-01-13 09:54:12,844 [INFO] Step[1450/4329]: training loss : 0.8610974562168121 TRAIN  loss dict:  {'classification_loss': 0.8610974562168121}
2025-01-13 09:54:24,470 [INFO] Step[1500/4329]: training loss : 0.8617758643627167 TRAIN  loss dict:  {'classification_loss': 0.8617758643627167}
2025-01-13 09:54:36,107 [INFO] Step[1550/4329]: training loss : 0.8631174826622009 TRAIN  loss dict:  {'classification_loss': 0.8631174826622009}
2025-01-13 09:54:47,733 [INFO] Step[1600/4329]: training loss : 0.8594985044002533 TRAIN  loss dict:  {'classification_loss': 0.8594985044002533}
2025-01-13 09:54:59,319 [INFO] Step[1650/4329]: training loss : 0.8786576998233795 TRAIN  loss dict:  {'classification_loss': 0.8786576998233795}
2025-01-13 09:55:10,957 [INFO] Step[1700/4329]: training loss : 0.8596854937076569 TRAIN  loss dict:  {'classification_loss': 0.8596854937076569}
2025-01-13 09:55:22,587 [INFO] Step[1750/4329]: training loss : 0.8622289705276489 TRAIN  loss dict:  {'classification_loss': 0.8622289705276489}
2025-01-13 09:55:34,231 [INFO] Step[1800/4329]: training loss : 0.8612495791912079 TRAIN  loss dict:  {'classification_loss': 0.8612495791912079}
2025-01-13 09:55:45,881 [INFO] Step[1850/4329]: training loss : 0.8641940355300903 TRAIN  loss dict:  {'classification_loss': 0.8641940355300903}
2025-01-13 09:55:57,528 [INFO] Step[1900/4329]: training loss : 0.8692588710784912 TRAIN  loss dict:  {'classification_loss': 0.8692588710784912}
2025-01-13 09:56:09,108 [INFO] Step[1950/4329]: training loss : 0.8722240614891053 TRAIN  loss dict:  {'classification_loss': 0.8722240614891053}
2025-01-13 09:56:20,739 [INFO] Step[2000/4329]: training loss : 0.8613401675224304 TRAIN  loss dict:  {'classification_loss': 0.8613401675224304}
2025-01-13 09:56:32,388 [INFO] Step[2050/4329]: training loss : 0.8975180661678315 TRAIN  loss dict:  {'classification_loss': 0.8975180661678315}
2025-01-13 09:56:44,042 [INFO] Step[2100/4329]: training loss : 0.8615460693836212 TRAIN  loss dict:  {'classification_loss': 0.8615460693836212}
2025-01-13 09:56:55,717 [INFO] Step[2150/4329]: training loss : 0.8704736185073852 TRAIN  loss dict:  {'classification_loss': 0.8704736185073852}
2025-01-13 09:57:07,308 [INFO] Step[2200/4329]: training loss : 0.8619722950458527 TRAIN  loss dict:  {'classification_loss': 0.8619722950458527}
2025-01-13 09:57:18,949 [INFO] Step[2250/4329]: training loss : 0.8624430632591248 TRAIN  loss dict:  {'classification_loss': 0.8624430632591248}
2025-01-13 09:57:30,554 [INFO] Step[2300/4329]: training loss : 0.85983158826828 TRAIN  loss dict:  {'classification_loss': 0.85983158826828}
2025-01-13 09:57:42,184 [INFO] Step[2350/4329]: training loss : 0.8619338917732239 TRAIN  loss dict:  {'classification_loss': 0.8619338917732239}
2025-01-13 09:57:53,812 [INFO] Step[2400/4329]: training loss : 0.8616583609580993 TRAIN  loss dict:  {'classification_loss': 0.8616583609580993}
2025-01-13 09:58:05,487 [INFO] Step[2450/4329]: training loss : 0.8614219355583191 TRAIN  loss dict:  {'classification_loss': 0.8614219355583191}
2025-01-13 09:58:17,111 [INFO] Step[2500/4329]: training loss : 0.8644039690494537 TRAIN  loss dict:  {'classification_loss': 0.8644039690494537}
2025-01-13 09:58:28,740 [INFO] Step[2550/4329]: training loss : 0.8614923894405365 TRAIN  loss dict:  {'classification_loss': 0.8614923894405365}
2025-01-13 09:58:40,360 [INFO] Step[2600/4329]: training loss : 0.8698471868038178 TRAIN  loss dict:  {'classification_loss': 0.8698471868038178}
2025-01-13 09:58:52,006 [INFO] Step[2650/4329]: training loss : 0.8664046800136567 TRAIN  loss dict:  {'classification_loss': 0.8664046800136567}
2025-01-13 09:59:03,608 [INFO] Step[2700/4329]: training loss : 0.8605071401596069 TRAIN  loss dict:  {'classification_loss': 0.8605071401596069}
2025-01-13 09:59:15,235 [INFO] Step[2750/4329]: training loss : 0.8686576759815217 TRAIN  loss dict:  {'classification_loss': 0.8686576759815217}
2025-01-13 09:59:26,858 [INFO] Step[2800/4329]: training loss : 0.8627359139919281 TRAIN  loss dict:  {'classification_loss': 0.8627359139919281}
2025-01-13 09:59:38,494 [INFO] Step[2850/4329]: training loss : 0.8662502849102021 TRAIN  loss dict:  {'classification_loss': 0.8662502849102021}
2025-01-13 09:59:50,205 [INFO] Step[2900/4329]: training loss : 0.881670994758606 TRAIN  loss dict:  {'classification_loss': 0.881670994758606}
2025-01-13 10:00:02,397 [INFO] Step[2950/4329]: training loss : 0.8622697865962983 TRAIN  loss dict:  {'classification_loss': 0.8622697865962983}
2025-01-13 10:00:14,649 [INFO] Step[3000/4329]: training loss : 0.8642318749427795 TRAIN  loss dict:  {'classification_loss': 0.8642318749427795}
2025-01-13 10:00:27,389 [INFO] Step[3050/4329]: training loss : 0.8617088603973388 TRAIN  loss dict:  {'classification_loss': 0.8617088603973388}
2025-01-13 10:00:40,631 [INFO] Step[3100/4329]: training loss : 0.8616079401969909 TRAIN  loss dict:  {'classification_loss': 0.8616079401969909}
2025-01-13 10:00:53,741 [INFO] Step[3150/4329]: training loss : 0.8723822665214539 TRAIN  loss dict:  {'classification_loss': 0.8723822665214539}
2025-01-13 10:01:05,724 [INFO] Step[3200/4329]: training loss : 0.8608710038661956 TRAIN  loss dict:  {'classification_loss': 0.8608710038661956}
2025-01-13 10:01:17,674 [INFO] Step[3250/4329]: training loss : 0.8647038233280182 TRAIN  loss dict:  {'classification_loss': 0.8647038233280182}
2025-01-13 10:01:29,333 [INFO] Step[3300/4329]: training loss : 0.8600528562068939 TRAIN  loss dict:  {'classification_loss': 0.8600528562068939}
2025-01-13 10:01:40,985 [INFO] Step[3350/4329]: training loss : 0.861935887336731 TRAIN  loss dict:  {'classification_loss': 0.861935887336731}
2025-01-13 10:01:52,584 [INFO] Step[3400/4329]: training loss : 0.8658586323261261 TRAIN  loss dict:  {'classification_loss': 0.8658586323261261}
2025-01-13 10:02:04,171 [INFO] Step[3450/4329]: training loss : 0.8666599297523498 TRAIN  loss dict:  {'classification_loss': 0.8666599297523498}
2025-01-13 10:02:15,794 [INFO] Step[3500/4329]: training loss : 0.8605973720550537 TRAIN  loss dict:  {'classification_loss': 0.8605973720550537}
2025-01-13 10:02:27,433 [INFO] Step[3550/4329]: training loss : 0.866131740808487 TRAIN  loss dict:  {'classification_loss': 0.866131740808487}
2025-01-13 10:02:39,073 [INFO] Step[3600/4329]: training loss : 0.8757132375240326 TRAIN  loss dict:  {'classification_loss': 0.8757132375240326}
2025-01-13 10:02:50,676 [INFO] Step[3650/4329]: training loss : 0.8653845143318176 TRAIN  loss dict:  {'classification_loss': 0.8653845143318176}
2025-01-13 10:03:02,289 [INFO] Step[3700/4329]: training loss : 0.8660528361797333 TRAIN  loss dict:  {'classification_loss': 0.8660528361797333}
2025-01-13 10:03:14,034 [INFO] Step[3750/4329]: training loss : 0.8601198720932007 TRAIN  loss dict:  {'classification_loss': 0.8601198720932007}
2025-01-13 10:03:25,664 [INFO] Step[3800/4329]: training loss : 0.869743459224701 TRAIN  loss dict:  {'classification_loss': 0.869743459224701}
2025-01-13 10:03:37,323 [INFO] Step[3850/4329]: training loss : 0.867937445640564 TRAIN  loss dict:  {'classification_loss': 0.867937445640564}
2025-01-13 10:03:48,908 [INFO] Step[3900/4329]: training loss : 0.8619385433197021 TRAIN  loss dict:  {'classification_loss': 0.8619385433197021}
2025-01-13 10:04:00,568 [INFO] Step[3950/4329]: training loss : 0.8627659666538239 TRAIN  loss dict:  {'classification_loss': 0.8627659666538239}
2025-01-13 10:04:12,162 [INFO] Step[4000/4329]: training loss : 0.8635085391998291 TRAIN  loss dict:  {'classification_loss': 0.8635085391998291}
2025-01-13 10:04:23,770 [INFO] Step[4050/4329]: training loss : 0.860074405670166 TRAIN  loss dict:  {'classification_loss': 0.860074405670166}
2025-01-13 10:04:35,409 [INFO] Step[4100/4329]: training loss : 0.8605136787891388 TRAIN  loss dict:  {'classification_loss': 0.8605136787891388}
2025-01-13 10:04:47,032 [INFO] Step[4150/4329]: training loss : 0.8639426636695862 TRAIN  loss dict:  {'classification_loss': 0.8639426636695862}
2025-01-13 10:04:58,667 [INFO] Step[4200/4329]: training loss : 0.8676669728755951 TRAIN  loss dict:  {'classification_loss': 0.8676669728755951}
2025-01-13 10:05:10,276 [INFO] Step[4250/4329]: training loss : 0.8775831627845764 TRAIN  loss dict:  {'classification_loss': 0.8775831627845764}
2025-01-13 10:05:21,946 [INFO] Step[4300/4329]: training loss : 0.8736605072021484 TRAIN  loss dict:  {'classification_loss': 0.8736605072021484}
2025-01-13 10:07:20,838 [INFO] Label accuracies statistics:
2025-01-13 10:07:20,838 [INFO] {0: 0.8888888888888888, 1: 1.0, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.5, 8: 0.4166666666666667, 9: 1.0, 10: 1.0, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.5, 14: 0.75, 15: 0.7777777777777778, 16: 0.75, 17: 0.6666666666666666, 18: 0.5, 19: 0.8333333333333334, 20: 0.5833333333333334, 21: 0.5833333333333334, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.6666666666666666, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.5833333333333334, 31: 0.75, 32: 0.75, 33: 0.9166666666666666, 34: 1.0, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 0.9166666666666666, 38: 1.0, 39: 0.9166666666666666, 40: 0.8333333333333334, 41: 0.4166666666666667, 42: 1.0, 43: 0.8333333333333334, 44: 0.6666666666666666, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5833333333333334, 54: 0.5, 55: 0.6666666666666666, 56: 0.8333333333333334, 57: 0.75, 58: 0.5, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.75, 69: 0.5833333333333334, 70: 0.5833333333333334, 71: 0.5, 72: 0.9166666666666666, 73: 0.8333333333333334, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.8333333333333334, 78: 1.0, 79: 0.5833333333333334, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5833333333333334, 84: 0.6666666666666666, 85: 0.8333333333333334, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.8333333333333334, 89: 0.5, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.5, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.9166666666666666, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.5, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.5, 114: 0.5, 115: 0.9166666666666666, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.8333333333333334, 120: 0.75, 121: 0.8333333333333334, 122: 0.9166666666666666, 123: 1.0, 124: 1.0, 125: 0.9166666666666666, 126: 1.0, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.8333333333333334, 132: 0.25, 133: 1.0, 134: 0.75, 135: 1.0, 136: 0.8333333333333334, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 0.9166666666666666, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.5833333333333334, 151: 0.9166666666666666, 152: 0.8333333333333334, 153: 1.0, 154: 1.0, 155: 0.9166666666666666, 156: 0.75, 157: 0.6666666666666666, 158: 0.6666666666666666, 159: 1.0, 160: 0.3333333333333333, 161: 0.9166666666666666, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.75, 166: 0.8333333333333334, 167: 0.75, 168: 0.9166666666666666, 169: 0.9166666666666666, 170: 0.9166666666666666, 171: 0.6666666666666666, 172: 1.0, 173: 0.8333333333333334, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.8333333333333334, 178: 1.0, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 1.0, 182: 0.5833333333333334, 183: 0.9166666666666666, 184: 0.8333333333333334, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.6666666666666666, 189: 0.9166666666666666, 190: 0.6666666666666666, 191: 0.4166666666666667, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.6666666666666666}

2025-01-13 10:07:20,841 [INFO] [61] TRAIN  loss: 0.8650012912087144 acc: 0.999229939935315
2025-01-13 10:07:20,841 [INFO] [61] TRAIN  loss dict: {'classification_loss': 0.8650012912087144}
2025-01-13 10:07:20,841 [INFO] [61] VALIDATION loss: 1.59269323546176 VALIDATION acc: 0.8160774410774411
2025-01-13 10:07:20,841 [INFO] [61] VALIDATION loss dict: {'classification_loss': 1.59269323546176}
2025-01-13 10:07:20,841 [INFO] 
2025-01-13 10:07:38,256 [INFO] Step[50/4329]: training loss : 0.8646363627910614 TRAIN  loss dict:  {'classification_loss': 0.8646363627910614}
2025-01-13 10:07:49,788 [INFO] Step[100/4329]: training loss : 0.8614618515968323 TRAIN  loss dict:  {'classification_loss': 0.8614618515968323}
2025-01-13 10:08:01,371 [INFO] Step[150/4329]: training loss : 0.8652828776836395 TRAIN  loss dict:  {'classification_loss': 0.8652828776836395}
2025-01-13 10:08:12,975 [INFO] Step[200/4329]: training loss : 0.8598993837833404 TRAIN  loss dict:  {'classification_loss': 0.8598993837833404}
2025-01-13 10:08:24,633 [INFO] Step[250/4329]: training loss : 0.8605794882774354 TRAIN  loss dict:  {'classification_loss': 0.8605794882774354}
2025-01-13 10:08:36,225 [INFO] Step[300/4329]: training loss : 0.862270644903183 TRAIN  loss dict:  {'classification_loss': 0.862270644903183}
2025-01-13 10:08:47,883 [INFO] Step[350/4329]: training loss : 0.8804964685440063 TRAIN  loss dict:  {'classification_loss': 0.8804964685440063}
2025-01-13 10:08:59,526 [INFO] Step[400/4329]: training loss : 0.8633045303821564 TRAIN  loss dict:  {'classification_loss': 0.8633045303821564}
2025-01-13 10:09:11,152 [INFO] Step[450/4329]: training loss : 0.8714100039005279 TRAIN  loss dict:  {'classification_loss': 0.8714100039005279}
2025-01-13 10:09:22,771 [INFO] Step[500/4329]: training loss : 0.8609343647956849 TRAIN  loss dict:  {'classification_loss': 0.8609343647956849}
2025-01-13 10:09:34,358 [INFO] Step[550/4329]: training loss : 0.8587082576751709 TRAIN  loss dict:  {'classification_loss': 0.8587082576751709}
2025-01-13 10:09:46,016 [INFO] Step[600/4329]: training loss : 0.8618910741806031 TRAIN  loss dict:  {'classification_loss': 0.8618910741806031}
2025-01-13 10:09:57,701 [INFO] Step[650/4329]: training loss : 0.8623564732074738 TRAIN  loss dict:  {'classification_loss': 0.8623564732074738}
2025-01-13 10:10:09,306 [INFO] Step[700/4329]: training loss : 0.8594568228721619 TRAIN  loss dict:  {'classification_loss': 0.8594568228721619}
2025-01-13 10:10:20,939 [INFO] Step[750/4329]: training loss : 0.8621514809131622 TRAIN  loss dict:  {'classification_loss': 0.8621514809131622}
2025-01-13 10:10:32,554 [INFO] Step[800/4329]: training loss : 0.866058269739151 TRAIN  loss dict:  {'classification_loss': 0.866058269739151}
2025-01-13 10:10:44,207 [INFO] Step[850/4329]: training loss : 0.8619858133792877 TRAIN  loss dict:  {'classification_loss': 0.8619858133792877}
2025-01-13 10:10:55,825 [INFO] Step[900/4329]: training loss : 0.8679306101799011 TRAIN  loss dict:  {'classification_loss': 0.8679306101799011}
2025-01-13 10:11:07,449 [INFO] Step[950/4329]: training loss : 0.8659494626522064 TRAIN  loss dict:  {'classification_loss': 0.8659494626522064}
2025-01-13 10:11:19,067 [INFO] Step[1000/4329]: training loss : 0.8751944470405578 TRAIN  loss dict:  {'classification_loss': 0.8751944470405578}
2025-01-13 10:11:30,741 [INFO] Step[1050/4329]: training loss : 0.8622787034511566 TRAIN  loss dict:  {'classification_loss': 0.8622787034511566}
2025-01-13 10:11:42,341 [INFO] Step[1100/4329]: training loss : 0.860203902721405 TRAIN  loss dict:  {'classification_loss': 0.860203902721405}
2025-01-13 10:11:53,971 [INFO] Step[1150/4329]: training loss : 0.8621730923652648 TRAIN  loss dict:  {'classification_loss': 0.8621730923652648}
2025-01-13 10:12:05,603 [INFO] Step[1200/4329]: training loss : 0.8651489841938019 TRAIN  loss dict:  {'classification_loss': 0.8651489841938019}
2025-01-13 10:12:17,385 [INFO] Step[1250/4329]: training loss : 0.8585222554206848 TRAIN  loss dict:  {'classification_loss': 0.8585222554206848}
2025-01-13 10:12:29,612 [INFO] Step[1300/4329]: training loss : 0.8755512583255768 TRAIN  loss dict:  {'classification_loss': 0.8755512583255768}
2025-01-13 10:12:41,852 [INFO] Step[1350/4329]: training loss : 0.860720157623291 TRAIN  loss dict:  {'classification_loss': 0.860720157623291}
2025-01-13 10:12:55,039 [INFO] Step[1400/4329]: training loss : 0.8655931651592255 TRAIN  loss dict:  {'classification_loss': 0.8655931651592255}
2025-01-13 10:13:08,405 [INFO] Step[1450/4329]: training loss : 0.8614879119396209 TRAIN  loss dict:  {'classification_loss': 0.8614879119396209}
2025-01-13 10:13:21,013 [INFO] Step[1500/4329]: training loss : 0.8613239431381225 TRAIN  loss dict:  {'classification_loss': 0.8613239431381225}
2025-01-13 10:13:32,957 [INFO] Step[1550/4329]: training loss : 0.8603937327861786 TRAIN  loss dict:  {'classification_loss': 0.8603937327861786}
2025-01-13 10:13:44,889 [INFO] Step[1600/4329]: training loss : 0.8599907875061035 TRAIN  loss dict:  {'classification_loss': 0.8599907875061035}
2025-01-13 10:13:56,563 [INFO] Step[1650/4329]: training loss : 0.866995882987976 TRAIN  loss dict:  {'classification_loss': 0.866995882987976}
2025-01-13 10:14:08,199 [INFO] Step[1700/4329]: training loss : 0.8814750850200653 TRAIN  loss dict:  {'classification_loss': 0.8814750850200653}
2025-01-13 10:14:19,799 [INFO] Step[1750/4329]: training loss : 0.8604090559482575 TRAIN  loss dict:  {'classification_loss': 0.8604090559482575}
2025-01-13 10:14:31,385 [INFO] Step[1800/4329]: training loss : 0.8601297736167908 TRAIN  loss dict:  {'classification_loss': 0.8601297736167908}
2025-01-13 10:14:43,073 [INFO] Step[1850/4329]: training loss : 0.8605091798305512 TRAIN  loss dict:  {'classification_loss': 0.8605091798305512}
2025-01-13 10:14:54,708 [INFO] Step[1900/4329]: training loss : 0.8607323038578033 TRAIN  loss dict:  {'classification_loss': 0.8607323038578033}
2025-01-13 10:15:06,367 [INFO] Step[1950/4329]: training loss : 0.8711880028247834 TRAIN  loss dict:  {'classification_loss': 0.8711880028247834}
2025-01-13 10:15:17,978 [INFO] Step[2000/4329]: training loss : 0.8608576595783234 TRAIN  loss dict:  {'classification_loss': 0.8608576595783234}
2025-01-13 10:15:29,601 [INFO] Step[2050/4329]: training loss : 0.8647314786911011 TRAIN  loss dict:  {'classification_loss': 0.8647314786911011}
2025-01-13 10:15:41,208 [INFO] Step[2100/4329]: training loss : 0.8622446084022521 TRAIN  loss dict:  {'classification_loss': 0.8622446084022521}
2025-01-13 10:15:52,859 [INFO] Step[2150/4329]: training loss : 0.8628483211994171 TRAIN  loss dict:  {'classification_loss': 0.8628483211994171}
2025-01-13 10:16:04,453 [INFO] Step[2200/4329]: training loss : 0.8627805614471435 TRAIN  loss dict:  {'classification_loss': 0.8627805614471435}
2025-01-13 10:16:16,100 [INFO] Step[2250/4329]: training loss : 0.86535196185112 TRAIN  loss dict:  {'classification_loss': 0.86535196185112}
2025-01-13 10:16:27,746 [INFO] Step[2300/4329]: training loss : 0.8599628758430481 TRAIN  loss dict:  {'classification_loss': 0.8599628758430481}
2025-01-13 10:16:39,397 [INFO] Step[2350/4329]: training loss : 0.8609581637382507 TRAIN  loss dict:  {'classification_loss': 0.8609581637382507}
2025-01-13 10:16:50,987 [INFO] Step[2400/4329]: training loss : 0.8608581399917603 TRAIN  loss dict:  {'classification_loss': 0.8608581399917603}
2025-01-13 10:17:02,674 [INFO] Step[2450/4329]: training loss : 0.860354106426239 TRAIN  loss dict:  {'classification_loss': 0.860354106426239}
2025-01-13 10:17:14,323 [INFO] Step[2500/4329]: training loss : 0.8613501393795013 TRAIN  loss dict:  {'classification_loss': 0.8613501393795013}
2025-01-13 10:17:25,983 [INFO] Step[2550/4329]: training loss : 0.8620076131820679 TRAIN  loss dict:  {'classification_loss': 0.8620076131820679}
2025-01-13 10:17:37,650 [INFO] Step[2600/4329]: training loss : 0.863251576423645 TRAIN  loss dict:  {'classification_loss': 0.863251576423645}
2025-01-13 10:17:49,342 [INFO] Step[2650/4329]: training loss : 0.871651120185852 TRAIN  loss dict:  {'classification_loss': 0.871651120185852}
2025-01-13 10:18:00,955 [INFO] Step[2700/4329]: training loss : 0.8615297317504883 TRAIN  loss dict:  {'classification_loss': 0.8615297317504883}
2025-01-13 10:18:12,585 [INFO] Step[2750/4329]: training loss : 0.8609464514255524 TRAIN  loss dict:  {'classification_loss': 0.8609464514255524}
2025-01-13 10:18:24,163 [INFO] Step[2800/4329]: training loss : 0.8615953195095062 TRAIN  loss dict:  {'classification_loss': 0.8615953195095062}
2025-01-13 10:18:35,752 [INFO] Step[2850/4329]: training loss : 0.8638172614574432 TRAIN  loss dict:  {'classification_loss': 0.8638172614574432}
2025-01-13 10:18:47,343 [INFO] Step[2900/4329]: training loss : 0.8796085584163665 TRAIN  loss dict:  {'classification_loss': 0.8796085584163665}
2025-01-13 10:18:58,972 [INFO] Step[2950/4329]: training loss : 0.8675986516475678 TRAIN  loss dict:  {'classification_loss': 0.8675986516475678}
2025-01-13 10:19:10,590 [INFO] Step[3000/4329]: training loss : 0.860698504447937 TRAIN  loss dict:  {'classification_loss': 0.860698504447937}
2025-01-13 10:19:22,242 [INFO] Step[3050/4329]: training loss : 0.8679099941253662 TRAIN  loss dict:  {'classification_loss': 0.8679099941253662}
2025-01-13 10:19:33,877 [INFO] Step[3100/4329]: training loss : 0.8614043259620666 TRAIN  loss dict:  {'classification_loss': 0.8614043259620666}
2025-01-13 10:19:45,504 [INFO] Step[3150/4329]: training loss : 0.8711673712730408 TRAIN  loss dict:  {'classification_loss': 0.8711673712730408}
2025-01-13 10:19:57,146 [INFO] Step[3200/4329]: training loss : 0.8599078321456909 TRAIN  loss dict:  {'classification_loss': 0.8599078321456909}
2025-01-13 10:20:08,773 [INFO] Step[3250/4329]: training loss : 0.8622429656982422 TRAIN  loss dict:  {'classification_loss': 0.8622429656982422}
2025-01-13 10:20:20,396 [INFO] Step[3300/4329]: training loss : 0.8620188546180725 TRAIN  loss dict:  {'classification_loss': 0.8620188546180725}
2025-01-13 10:20:32,042 [INFO] Step[3350/4329]: training loss : 0.8609044885635376 TRAIN  loss dict:  {'classification_loss': 0.8609044885635376}
2025-01-13 10:20:43,660 [INFO] Step[3400/4329]: training loss : 0.8699250018596649 TRAIN  loss dict:  {'classification_loss': 0.8699250018596649}
2025-01-13 10:20:55,288 [INFO] Step[3450/4329]: training loss : 0.8605070650577545 TRAIN  loss dict:  {'classification_loss': 0.8605070650577545}
2025-01-13 10:21:06,949 [INFO] Step[3500/4329]: training loss : 0.8667815065383911 TRAIN  loss dict:  {'classification_loss': 0.8667815065383911}
2025-01-13 10:21:18,572 [INFO] Step[3550/4329]: training loss : 0.8664311289787292 TRAIN  loss dict:  {'classification_loss': 0.8664311289787292}
2025-01-13 10:21:30,230 [INFO] Step[3600/4329]: training loss : 0.8644503664970398 TRAIN  loss dict:  {'classification_loss': 0.8644503664970398}
2025-01-13 10:21:41,842 [INFO] Step[3650/4329]: training loss : 0.8606949973106385 TRAIN  loss dict:  {'classification_loss': 0.8606949973106385}
2025-01-13 10:21:53,478 [INFO] Step[3700/4329]: training loss : 0.8614240896701812 TRAIN  loss dict:  {'classification_loss': 0.8614240896701812}
2025-01-13 10:22:05,118 [INFO] Step[3750/4329]: training loss : 0.8633019959926606 TRAIN  loss dict:  {'classification_loss': 0.8633019959926606}
2025-01-13 10:22:16,705 [INFO] Step[3800/4329]: training loss : 0.8736873412132263 TRAIN  loss dict:  {'classification_loss': 0.8736873412132263}
2025-01-13 10:22:28,296 [INFO] Step[3850/4329]: training loss : 0.8617538666725159 TRAIN  loss dict:  {'classification_loss': 0.8617538666725159}
2025-01-13 10:22:39,891 [INFO] Step[3900/4329]: training loss : 0.8616078329086304 TRAIN  loss dict:  {'classification_loss': 0.8616078329086304}
2025-01-13 10:22:51,557 [INFO] Step[3950/4329]: training loss : 0.8685382306575775 TRAIN  loss dict:  {'classification_loss': 0.8685382306575775}
2025-01-13 10:23:03,188 [INFO] Step[4000/4329]: training loss : 0.8802697217464447 TRAIN  loss dict:  {'classification_loss': 0.8802697217464447}
2025-01-13 10:23:14,822 [INFO] Step[4050/4329]: training loss : 0.8868396925926209 TRAIN  loss dict:  {'classification_loss': 0.8868396925926209}
2025-01-13 10:23:26,417 [INFO] Step[4100/4329]: training loss : 0.8598086142539978 TRAIN  loss dict:  {'classification_loss': 0.8598086142539978}
2025-01-13 10:23:38,027 [INFO] Step[4150/4329]: training loss : 0.8624545514583588 TRAIN  loss dict:  {'classification_loss': 0.8624545514583588}
2025-01-13 10:23:49,670 [INFO] Step[4200/4329]: training loss : 0.8667331814765931 TRAIN  loss dict:  {'classification_loss': 0.8667331814765931}
2025-01-13 10:24:01,297 [INFO] Step[4250/4329]: training loss : 0.8613529241085053 TRAIN  loss dict:  {'classification_loss': 0.8613529241085053}
2025-01-13 10:24:12,906 [INFO] Step[4300/4329]: training loss : 0.8637887966632843 TRAIN  loss dict:  {'classification_loss': 0.8637887966632843}
2025-01-13 10:26:40,963 [INFO] Label accuracies statistics:
2025-01-13 10:26:40,963 [INFO] {0: 0.5555555555555556, 1: 0.8888888888888888, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.5833333333333334, 8: 0.9166666666666666, 9: 0.9166666666666666, 10: 1.0, 11: 0.8333333333333334, 12: 0.4166666666666667, 13: 0.5, 14: 0.75, 15: 0.6666666666666666, 16: 0.75, 17: 0.5833333333333334, 18: 0.5, 19: 0.75, 20: 0.6666666666666666, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.8333333333333334, 26: 0.9166666666666666, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.6666666666666666, 31: 0.8333333333333334, 32: 0.75, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 0.8333333333333334, 36: 0.5833333333333334, 37: 0.9166666666666666, 38: 0.9166666666666666, 39: 1.0, 40: 0.8333333333333334, 41: 0.4166666666666667, 42: 1.0, 43: 0.8333333333333334, 44: 0.5833333333333334, 45: 0.5833333333333334, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.8333333333333334, 51: 0.75, 52: 0.9166666666666666, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.9166666666666666, 57: 0.75, 58: 0.5, 59: 0.8333333333333334, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.6666666666666666, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.6666666666666666, 69: 0.6666666666666666, 70: 0.5, 71: 0.6666666666666666, 72: 1.0, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.8333333333333334, 78: 0.9166666666666666, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.8333333333333334, 83: 0.6666666666666666, 84: 0.5833333333333334, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.6666666666666666, 89: 0.5833333333333334, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.8333333333333334, 95: 1.0, 96: 0.5833333333333334, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.8333333333333334, 101: 1.0, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 1.0, 111: 1.0, 112: 0.9166666666666666, 113: 0.5833333333333334, 114: 0.4166666666666667, 115: 1.0, 116: 0.6666666666666666, 117: 0.75, 118: 1.0, 119: 0.8333333333333334, 120: 0.75, 121: 0.8333333333333334, 122: 0.8333333333333334, 123: 1.0, 124: 1.0, 125: 0.9166666666666666, 126: 1.0, 127: 0.8333333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.8333333333333334, 132: 0.75, 133: 1.0, 134: 0.6666666666666666, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 0.9166666666666666, 141: 1.0, 142: 0.8333333333333334, 143: 1.0, 144: 0.75, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.5833333333333334, 149: 1.0, 150: 0.5, 151: 0.8333333333333334, 152: 0.9166666666666666, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.5, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.8333333333333334, 166: 0.8333333333333334, 167: 0.5833333333333334, 168: 0.8333333333333334, 169: 0.9166666666666666, 170: 1.0, 171: 0.5833333333333334, 172: 1.0, 173: 0.8333333333333334, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.8333333333333334, 178: 1.0, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 1.0, 182: 0.6666666666666666, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.8333333333333334, 189: 0.9166666666666666, 190: 0.6666666666666666, 191: 0.4166666666666667, 192: 1.0, 193: 0.9166666666666666, 194: 0.75, 195: 0.9166666666666666, 196: 0.8333333333333334, 197: 0.8333333333333334, 198: 0.6666666666666666}

2025-01-13 10:26:41,912 [INFO] [62] TRAIN  loss: 0.8645062714532882 acc: 0.9988449099029725
2025-01-13 10:26:41,913 [INFO] [62] TRAIN  loss dict: {'classification_loss': 0.8645062714532882}
2025-01-13 10:26:41,913 [INFO] [62] VALIDATION loss: 1.5613046283974792 VALIDATION acc: 0.8202861952861953
2025-01-13 10:26:41,913 [INFO] [62] VALIDATION loss dict: {'classification_loss': 1.5613046283974792}
2025-01-13 10:26:41,913 [INFO] 
2025-01-13 10:26:59,734 [INFO] Step[50/4329]: training loss : 0.8642645585536957 TRAIN  loss dict:  {'classification_loss': 0.8642645585536957}
2025-01-13 10:27:11,349 [INFO] Step[100/4329]: training loss : 0.8608332347869873 TRAIN  loss dict:  {'classification_loss': 0.8608332347869873}
2025-01-13 10:27:22,936 [INFO] Step[150/4329]: training loss : 0.8939243721961975 TRAIN  loss dict:  {'classification_loss': 0.8939243721961975}
2025-01-13 10:27:34,589 [INFO] Step[200/4329]: training loss : 0.8642341065406799 TRAIN  loss dict:  {'classification_loss': 0.8642341065406799}
2025-01-13 10:27:46,201 [INFO] Step[250/4329]: training loss : 0.8649003267288208 TRAIN  loss dict:  {'classification_loss': 0.8649003267288208}
2025-01-13 10:27:57,825 [INFO] Step[300/4329]: training loss : 0.866609787940979 TRAIN  loss dict:  {'classification_loss': 0.866609787940979}
2025-01-13 10:28:09,448 [INFO] Step[350/4329]: training loss : 0.8623607003688812 TRAIN  loss dict:  {'classification_loss': 0.8623607003688812}
2025-01-13 10:28:21,090 [INFO] Step[400/4329]: training loss : 0.8641055989265441 TRAIN  loss dict:  {'classification_loss': 0.8641055989265441}
2025-01-13 10:28:32,703 [INFO] Step[450/4329]: training loss : 0.8646035516262054 TRAIN  loss dict:  {'classification_loss': 0.8646035516262054}
2025-01-13 10:28:44,356 [INFO] Step[500/4329]: training loss : 0.8620972692966461 TRAIN  loss dict:  {'classification_loss': 0.8620972692966461}
2025-01-13 10:28:55,984 [INFO] Step[550/4329]: training loss : 0.8630210876464843 TRAIN  loss dict:  {'classification_loss': 0.8630210876464843}
2025-01-13 10:29:07,641 [INFO] Step[600/4329]: training loss : 0.8602462315559387 TRAIN  loss dict:  {'classification_loss': 0.8602462315559387}
2025-01-13 10:29:19,314 [INFO] Step[650/4329]: training loss : 0.8614996004104615 TRAIN  loss dict:  {'classification_loss': 0.8614996004104615}
2025-01-13 10:29:30,961 [INFO] Step[700/4329]: training loss : 0.861210435628891 TRAIN  loss dict:  {'classification_loss': 0.861210435628891}
2025-01-13 10:29:42,640 [INFO] Step[750/4329]: training loss : 0.859746561050415 TRAIN  loss dict:  {'classification_loss': 0.859746561050415}
2025-01-13 10:29:54,274 [INFO] Step[800/4329]: training loss : 0.8714456808567047 TRAIN  loss dict:  {'classification_loss': 0.8714456808567047}
2025-01-13 10:30:05,892 [INFO] Step[850/4329]: training loss : 0.8685226929187775 TRAIN  loss dict:  {'classification_loss': 0.8685226929187775}
2025-01-13 10:30:17,552 [INFO] Step[900/4329]: training loss : 0.8681091427803039 TRAIN  loss dict:  {'classification_loss': 0.8681091427803039}
2025-01-13 10:30:29,220 [INFO] Step[950/4329]: training loss : 0.8692577159404755 TRAIN  loss dict:  {'classification_loss': 0.8692577159404755}
2025-01-13 10:30:40,864 [INFO] Step[1000/4329]: training loss : 0.8601667833328247 TRAIN  loss dict:  {'classification_loss': 0.8601667833328247}
2025-01-13 10:30:52,486 [INFO] Step[1050/4329]: training loss : 0.8619336974620819 TRAIN  loss dict:  {'classification_loss': 0.8619336974620819}
2025-01-13 10:31:04,135 [INFO] Step[1100/4329]: training loss : 0.8611439788341522 TRAIN  loss dict:  {'classification_loss': 0.8611439788341522}
2025-01-13 10:31:15,807 [INFO] Step[1150/4329]: training loss : 0.8601174867153167 TRAIN  loss dict:  {'classification_loss': 0.8601174867153167}
2025-01-13 10:31:27,386 [INFO] Step[1200/4329]: training loss : 0.8703159177303315 TRAIN  loss dict:  {'classification_loss': 0.8703159177303315}
2025-01-13 10:31:38,994 [INFO] Step[1250/4329]: training loss : 0.8610283315181733 TRAIN  loss dict:  {'classification_loss': 0.8610283315181733}
2025-01-13 10:31:50,657 [INFO] Step[1300/4329]: training loss : 0.8667325365543366 TRAIN  loss dict:  {'classification_loss': 0.8667325365543366}
2025-01-13 10:32:02,294 [INFO] Step[1350/4329]: training loss : 0.862123293876648 TRAIN  loss dict:  {'classification_loss': 0.862123293876648}
2025-01-13 10:32:13,880 [INFO] Step[1400/4329]: training loss : 0.8596094191074372 TRAIN  loss dict:  {'classification_loss': 0.8596094191074372}
2025-01-13 10:32:25,512 [INFO] Step[1450/4329]: training loss : 0.8698200690746307 TRAIN  loss dict:  {'classification_loss': 0.8698200690746307}
2025-01-13 10:32:37,119 [INFO] Step[1500/4329]: training loss : 0.8631433129310608 TRAIN  loss dict:  {'classification_loss': 0.8631433129310608}
2025-01-13 10:32:48,745 [INFO] Step[1550/4329]: training loss : 0.8601480233669281 TRAIN  loss dict:  {'classification_loss': 0.8601480233669281}
2025-01-13 10:33:00,356 [INFO] Step[1600/4329]: training loss : 0.8610195493698121 TRAIN  loss dict:  {'classification_loss': 0.8610195493698121}
2025-01-13 10:33:11,998 [INFO] Step[1650/4329]: training loss : 0.8605350041389466 TRAIN  loss dict:  {'classification_loss': 0.8605350041389466}
2025-01-13 10:33:23,634 [INFO] Step[1700/4329]: training loss : 0.8646240365505219 TRAIN  loss dict:  {'classification_loss': 0.8646240365505219}
2025-01-13 10:33:35,287 [INFO] Step[1750/4329]: training loss : 0.8650244116783142 TRAIN  loss dict:  {'classification_loss': 0.8650244116783142}
2025-01-13 10:33:46,880 [INFO] Step[1800/4329]: training loss : 0.8732349908351899 TRAIN  loss dict:  {'classification_loss': 0.8732349908351899}
2025-01-13 10:33:58,529 [INFO] Step[1850/4329]: training loss : 0.8591957426071167 TRAIN  loss dict:  {'classification_loss': 0.8591957426071167}
2025-01-13 10:34:10,160 [INFO] Step[1900/4329]: training loss : 0.8613130259513855 TRAIN  loss dict:  {'classification_loss': 0.8613130259513855}
2025-01-13 10:34:21,816 [INFO] Step[1950/4329]: training loss : 0.8607576179504395 TRAIN  loss dict:  {'classification_loss': 0.8607576179504395}
2025-01-13 10:34:33,419 [INFO] Step[2000/4329]: training loss : 0.8598202967643738 TRAIN  loss dict:  {'classification_loss': 0.8598202967643738}
2025-01-13 10:34:45,086 [INFO] Step[2050/4329]: training loss : 0.8595753276348114 TRAIN  loss dict:  {'classification_loss': 0.8595753276348114}
2025-01-13 10:34:56,704 [INFO] Step[2100/4329]: training loss : 0.863431031703949 TRAIN  loss dict:  {'classification_loss': 0.863431031703949}
2025-01-13 10:35:08,377 [INFO] Step[2150/4329]: training loss : 0.860616227388382 TRAIN  loss dict:  {'classification_loss': 0.860616227388382}
2025-01-13 10:35:20,023 [INFO] Step[2200/4329]: training loss : 0.8598661625385284 TRAIN  loss dict:  {'classification_loss': 0.8598661625385284}
2025-01-13 10:35:31,691 [INFO] Step[2250/4329]: training loss : 0.8636155569553375 TRAIN  loss dict:  {'classification_loss': 0.8636155569553375}
2025-01-13 10:35:43,330 [INFO] Step[2300/4329]: training loss : 0.8592627000808716 TRAIN  loss dict:  {'classification_loss': 0.8592627000808716}
2025-01-13 10:35:54,945 [INFO] Step[2350/4329]: training loss : 0.8633736324310303 TRAIN  loss dict:  {'classification_loss': 0.8633736324310303}
2025-01-13 10:36:06,609 [INFO] Step[2400/4329]: training loss : 0.8612616539001465 TRAIN  loss dict:  {'classification_loss': 0.8612616539001465}
2025-01-13 10:36:18,228 [INFO] Step[2450/4329]: training loss : 0.8713760602474213 TRAIN  loss dict:  {'classification_loss': 0.8713760602474213}
2025-01-13 10:36:29,865 [INFO] Step[2500/4329]: training loss : 0.8714941012859344 TRAIN  loss dict:  {'classification_loss': 0.8714941012859344}
2025-01-13 10:36:41,501 [INFO] Step[2550/4329]: training loss : 0.8626850771903992 TRAIN  loss dict:  {'classification_loss': 0.8626850771903992}
2025-01-13 10:36:53,156 [INFO] Step[2600/4329]: training loss : 0.8603264617919922 TRAIN  loss dict:  {'classification_loss': 0.8603264617919922}
2025-01-13 10:37:04,817 [INFO] Step[2650/4329]: training loss : 0.8594433808326721 TRAIN  loss dict:  {'classification_loss': 0.8594433808326721}
2025-01-13 10:37:16,456 [INFO] Step[2700/4329]: training loss : 0.8742930114269256 TRAIN  loss dict:  {'classification_loss': 0.8742930114269256}
2025-01-13 10:37:28,446 [INFO] Step[2750/4329]: training loss : 0.8639501702785491 TRAIN  loss dict:  {'classification_loss': 0.8639501702785491}
2025-01-13 10:37:40,835 [INFO] Step[2800/4329]: training loss : 0.8585521161556244 TRAIN  loss dict:  {'classification_loss': 0.8585521161556244}
2025-01-13 10:37:53,238 [INFO] Step[2850/4329]: training loss : 0.8607090842723847 TRAIN  loss dict:  {'classification_loss': 0.8607090842723847}
2025-01-13 10:38:06,638 [INFO] Step[2900/4329]: training loss : 0.8621526801586151 TRAIN  loss dict:  {'classification_loss': 0.8621526801586151}
2025-01-13 10:38:20,005 [INFO] Step[2950/4329]: training loss : 0.8613081538677215 TRAIN  loss dict:  {'classification_loss': 0.8613081538677215}
2025-01-13 10:38:32,073 [INFO] Step[3000/4329]: training loss : 0.8611394119262695 TRAIN  loss dict:  {'classification_loss': 0.8611394119262695}
2025-01-13 10:38:43,979 [INFO] Step[3050/4329]: training loss : 0.8606354928016663 TRAIN  loss dict:  {'classification_loss': 0.8606354928016663}
2025-01-13 10:38:55,741 [INFO] Step[3100/4329]: training loss : 0.8680807101726532 TRAIN  loss dict:  {'classification_loss': 0.8680807101726532}
2025-01-13 10:39:07,402 [INFO] Step[3150/4329]: training loss : 0.8607562899589538 TRAIN  loss dict:  {'classification_loss': 0.8607562899589538}
2025-01-13 10:39:19,051 [INFO] Step[3200/4329]: training loss : 0.8587066280841827 TRAIN  loss dict:  {'classification_loss': 0.8587066280841827}
2025-01-13 10:39:30,702 [INFO] Step[3250/4329]: training loss : 0.8735460710525512 TRAIN  loss dict:  {'classification_loss': 0.8735460710525512}
2025-01-13 10:39:42,297 [INFO] Step[3300/4329]: training loss : 0.8640845263004303 TRAIN  loss dict:  {'classification_loss': 0.8640845263004303}
2025-01-13 10:39:53,919 [INFO] Step[3350/4329]: training loss : 0.8607735729217529 TRAIN  loss dict:  {'classification_loss': 0.8607735729217529}
2025-01-13 10:40:05,564 [INFO] Step[3400/4329]: training loss : 0.860802788734436 TRAIN  loss dict:  {'classification_loss': 0.860802788734436}
2025-01-13 10:40:17,250 [INFO] Step[3450/4329]: training loss : 0.8688394320011139 TRAIN  loss dict:  {'classification_loss': 0.8688394320011139}
2025-01-13 10:40:28,881 [INFO] Step[3500/4329]: training loss : 0.8705987930297852 TRAIN  loss dict:  {'classification_loss': 0.8705987930297852}
2025-01-13 10:40:40,480 [INFO] Step[3550/4329]: training loss : 0.876702766418457 TRAIN  loss dict:  {'classification_loss': 0.876702766418457}
2025-01-13 10:40:52,067 [INFO] Step[3600/4329]: training loss : 0.8661844253540039 TRAIN  loss dict:  {'classification_loss': 0.8661844253540039}
2025-01-13 10:41:03,682 [INFO] Step[3650/4329]: training loss : 0.8612495732307434 TRAIN  loss dict:  {'classification_loss': 0.8612495732307434}
2025-01-13 10:41:15,263 [INFO] Step[3700/4329]: training loss : 0.8932914471626282 TRAIN  loss dict:  {'classification_loss': 0.8932914471626282}
2025-01-13 10:41:26,962 [INFO] Step[3750/4329]: training loss : 0.8618315720558166 TRAIN  loss dict:  {'classification_loss': 0.8618315720558166}
2025-01-13 10:41:38,620 [INFO] Step[3800/4329]: training loss : 0.8615599763393402 TRAIN  loss dict:  {'classification_loss': 0.8615599763393402}
2025-01-13 10:41:50,263 [INFO] Step[3850/4329]: training loss : 0.8619612503051758 TRAIN  loss dict:  {'classification_loss': 0.8619612503051758}
2025-01-13 10:42:01,863 [INFO] Step[3900/4329]: training loss : 0.8590982377529144 TRAIN  loss dict:  {'classification_loss': 0.8590982377529144}
2025-01-13 10:42:13,477 [INFO] Step[3950/4329]: training loss : 0.8622286236286163 TRAIN  loss dict:  {'classification_loss': 0.8622286236286163}
2025-01-13 10:42:25,109 [INFO] Step[4000/4329]: training loss : 0.8583899211883544 TRAIN  loss dict:  {'classification_loss': 0.8583899211883544}
2025-01-13 10:42:36,788 [INFO] Step[4050/4329]: training loss : 0.8671882784366608 TRAIN  loss dict:  {'classification_loss': 0.8671882784366608}
2025-01-13 10:42:48,418 [INFO] Step[4100/4329]: training loss : 0.8658834528923035 TRAIN  loss dict:  {'classification_loss': 0.8658834528923035}
2025-01-13 10:43:00,027 [INFO] Step[4150/4329]: training loss : 0.8631309366226196 TRAIN  loss dict:  {'classification_loss': 0.8631309366226196}
2025-01-13 10:43:11,690 [INFO] Step[4200/4329]: training loss : 0.8755222618579864 TRAIN  loss dict:  {'classification_loss': 0.8755222618579864}
2025-01-13 10:43:23,303 [INFO] Step[4250/4329]: training loss : 0.8605606210231781 TRAIN  loss dict:  {'classification_loss': 0.8605606210231781}
2025-01-13 10:43:34,930 [INFO] Step[4300/4329]: training loss : 0.8603674244880676 TRAIN  loss dict:  {'classification_loss': 0.8603674244880676}
2025-01-13 10:45:33,958 [INFO] Label accuracies statistics:
2025-01-13 10:45:33,958 [INFO] {0: 0.5555555555555556, 1: 1.0, 2: 0.6666666666666666, 3: 0.75, 4: 0.4166666666666667, 5: 0.8333333333333334, 6: 0.6666666666666666, 7: 0.5833333333333334, 8: 0.75, 9: 1.0, 10: 1.0, 11: 0.9166666666666666, 12: 0.3333333333333333, 13: 0.4166666666666667, 14: 0.75, 15: 0.7777777777777778, 16: 0.5, 17: 0.6666666666666666, 18: 0.5, 19: 0.75, 20: 0.6666666666666666, 21: 0.75, 22: 0.6666666666666666, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.9166666666666666, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.6666666666666666, 31: 0.8333333333333334, 32: 0.5833333333333334, 33: 0.9166666666666666, 34: 1.0, 35: 1.0, 36: 0.6666666666666666, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.8333333333333334, 41: 0.5833333333333334, 42: 0.8333333333333334, 43: 0.9166666666666666, 44: 0.6666666666666666, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.4166666666666667, 55: 0.75, 56: 0.8333333333333334, 57: 0.75, 58: 0.5833333333333334, 59: 0.75, 60: 0.6666666666666666, 61: 1.0, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.75, 69: 0.75, 70: 0.3333333333333333, 71: 0.5833333333333334, 72: 1.0, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 0.9166666666666666, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.6666666666666666, 83: 0.6666666666666666, 84: 0.6666666666666666, 85: 0.6666666666666666, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.5833333333333334, 89: 0.5833333333333334, 90: 0.8333333333333334, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 1.0, 96: 0.5833333333333334, 97: 0.8333333333333334, 98: 0.8333333333333334, 99: 1.0, 100: 0.8333333333333334, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.9166666666666666, 106: 0.9166666666666666, 107: 0.5, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 1.0, 111: 1.0, 112: 0.9166666666666666, 113: 0.5833333333333334, 114: 0.5833333333333334, 115: 1.0, 116: 0.8333333333333334, 117: 0.8333333333333334, 118: 0.9166666666666666, 119: 0.8333333333333334, 120: 0.75, 121: 0.75, 122: 0.8333333333333334, 123: 1.0, 124: 1.0, 125: 0.6666666666666666, 126: 1.0, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.8333333333333334, 132: 0.75, 133: 1.0, 134: 0.9166666666666666, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 0.9166666666666666, 142: 0.8333333333333334, 143: 1.0, 144: 0.5833333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.5833333333333334, 151: 0.8333333333333334, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 0.9166666666666666, 156: 0.75, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.5, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.9166666666666666, 166: 0.8333333333333334, 167: 0.8333333333333334, 168: 0.9166666666666666, 169: 0.9166666666666666, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.8333333333333334, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.4444444444444444, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.8333333333333334, 183: 0.9166666666666666, 184: 0.8333333333333334, 185: 1.0, 186: 0.8333333333333334, 187: 0.9166666666666666, 188: 0.8333333333333334, 189: 0.9166666666666666, 190: 0.5833333333333334, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.6666666666666666}

2025-01-13 10:45:35,834 [INFO] [63] TRAIN  loss: 0.8643055899117333 acc: 0.9989219159094409
2025-01-13 10:45:35,834 [INFO] [63] TRAIN  loss dict: {'classification_loss': 0.8643055899117333}
2025-01-13 10:45:35,834 [INFO] [63] VALIDATION loss: 1.5433195266458724 VALIDATION acc: 0.8232323232323232
2025-01-13 10:45:35,834 [INFO] [63] VALIDATION loss dict: {'classification_loss': 1.5433195266458724}
2025-01-13 10:45:35,834 [INFO] 
2025-01-13 10:45:52,485 [INFO] Step[50/4329]: training loss : 0.8596081459522247 TRAIN  loss dict:  {'classification_loss': 0.8596081459522247}
2025-01-13 10:46:04,041 [INFO] Step[100/4329]: training loss : 0.8630927610397339 TRAIN  loss dict:  {'classification_loss': 0.8630927610397339}
2025-01-13 10:46:15,669 [INFO] Step[150/4329]: training loss : 0.8594889855384826 TRAIN  loss dict:  {'classification_loss': 0.8594889855384826}
2025-01-13 10:46:27,310 [INFO] Step[200/4329]: training loss : 0.8609536159038543 TRAIN  loss dict:  {'classification_loss': 0.8609536159038543}
2025-01-13 10:46:38,956 [INFO] Step[250/4329]: training loss : 0.8606052768230438 TRAIN  loss dict:  {'classification_loss': 0.8606052768230438}
2025-01-13 10:46:50,559 [INFO] Step[300/4329]: training loss : 0.858492488861084 TRAIN  loss dict:  {'classification_loss': 0.858492488861084}
2025-01-13 10:47:02,221 [INFO] Step[350/4329]: training loss : 0.8642734229564667 TRAIN  loss dict:  {'classification_loss': 0.8642734229564667}
2025-01-13 10:47:13,812 [INFO] Step[400/4329]: training loss : 0.8717267429828643 TRAIN  loss dict:  {'classification_loss': 0.8717267429828643}
2025-01-13 10:47:25,516 [INFO] Step[450/4329]: training loss : 0.871367962360382 TRAIN  loss dict:  {'classification_loss': 0.871367962360382}
2025-01-13 10:47:37,169 [INFO] Step[500/4329]: training loss : 0.8621495008468628 TRAIN  loss dict:  {'classification_loss': 0.8621495008468628}
2025-01-13 10:47:48,858 [INFO] Step[550/4329]: training loss : 0.8604738438129425 TRAIN  loss dict:  {'classification_loss': 0.8604738438129425}
2025-01-13 10:48:00,528 [INFO] Step[600/4329]: training loss : 0.8591648614406586 TRAIN  loss dict:  {'classification_loss': 0.8591648614406586}
2025-01-13 10:48:12,150 [INFO] Step[650/4329]: training loss : 0.8589676153659821 TRAIN  loss dict:  {'classification_loss': 0.8589676153659821}
2025-01-13 10:48:23,816 [INFO] Step[700/4329]: training loss : 0.8669121158123017 TRAIN  loss dict:  {'classification_loss': 0.8669121158123017}
2025-01-13 10:48:35,469 [INFO] Step[750/4329]: training loss : 0.8627486193180084 TRAIN  loss dict:  {'classification_loss': 0.8627486193180084}
2025-01-13 10:48:47,051 [INFO] Step[800/4329]: training loss : 0.8598990797996521 TRAIN  loss dict:  {'classification_loss': 0.8598990797996521}
2025-01-13 10:48:58,684 [INFO] Step[850/4329]: training loss : 0.8600436925888062 TRAIN  loss dict:  {'classification_loss': 0.8600436925888062}
2025-01-13 10:49:10,335 [INFO] Step[900/4329]: training loss : 0.8634144389629363 TRAIN  loss dict:  {'classification_loss': 0.8634144389629363}
2025-01-13 10:49:21,996 [INFO] Step[950/4329]: training loss : 0.8596506583690643 TRAIN  loss dict:  {'classification_loss': 0.8596506583690643}
2025-01-13 10:49:33,662 [INFO] Step[1000/4329]: training loss : 0.8627279734611512 TRAIN  loss dict:  {'classification_loss': 0.8627279734611512}
2025-01-13 10:49:45,352 [INFO] Step[1050/4329]: training loss : 0.8595192039012909 TRAIN  loss dict:  {'classification_loss': 0.8595192039012909}
2025-01-13 10:49:57,452 [INFO] Step[1100/4329]: training loss : 0.8643376922607422 TRAIN  loss dict:  {'classification_loss': 0.8643376922607422}
2025-01-13 10:50:09,787 [INFO] Step[1150/4329]: training loss : 0.8607460379600524 TRAIN  loss dict:  {'classification_loss': 0.8607460379600524}
2025-01-13 10:50:22,455 [INFO] Step[1200/4329]: training loss : 0.8593295061588287 TRAIN  loss dict:  {'classification_loss': 0.8593295061588287}
2025-01-13 10:50:36,045 [INFO] Step[1250/4329]: training loss : 0.8758331024646759 TRAIN  loss dict:  {'classification_loss': 0.8758331024646759}
2025-01-13 10:50:49,518 [INFO] Step[1300/4329]: training loss : 0.8621400594711304 TRAIN  loss dict:  {'classification_loss': 0.8621400594711304}
2025-01-13 10:51:01,534 [INFO] Step[1350/4329]: training loss : 0.8606391298770905 TRAIN  loss dict:  {'classification_loss': 0.8606391298770905}
2025-01-13 10:51:13,548 [INFO] Step[1400/4329]: training loss : 0.8607121670246124 TRAIN  loss dict:  {'classification_loss': 0.8607121670246124}
2025-01-13 10:51:25,280 [INFO] Step[1450/4329]: training loss : 0.8593502449989319 TRAIN  loss dict:  {'classification_loss': 0.8593502449989319}
2025-01-13 10:51:36,860 [INFO] Step[1500/4329]: training loss : 0.8613655459880829 TRAIN  loss dict:  {'classification_loss': 0.8613655459880829}
2025-01-13 10:51:48,528 [INFO] Step[1550/4329]: training loss : 0.8641825211048126 TRAIN  loss dict:  {'classification_loss': 0.8641825211048126}
2025-01-13 10:52:00,166 [INFO] Step[1600/4329]: training loss : 0.8630778431892395 TRAIN  loss dict:  {'classification_loss': 0.8630778431892395}
2025-01-13 10:52:11,814 [INFO] Step[1650/4329]: training loss : 0.8604904675483703 TRAIN  loss dict:  {'classification_loss': 0.8604904675483703}
2025-01-13 10:52:23,486 [INFO] Step[1700/4329]: training loss : 0.8595546102523803 TRAIN  loss dict:  {'classification_loss': 0.8595546102523803}
2025-01-13 10:52:35,135 [INFO] Step[1750/4329]: training loss : 0.8594197678565979 TRAIN  loss dict:  {'classification_loss': 0.8594197678565979}
2025-01-13 10:52:46,786 [INFO] Step[1800/4329]: training loss : 0.8609651827812195 TRAIN  loss dict:  {'classification_loss': 0.8609651827812195}
2025-01-13 10:52:58,414 [INFO] Step[1850/4329]: training loss : 0.858707321882248 TRAIN  loss dict:  {'classification_loss': 0.858707321882248}
2025-01-13 10:53:10,021 [INFO] Step[1900/4329]: training loss : 0.8649534785747528 TRAIN  loss dict:  {'classification_loss': 0.8649534785747528}
2025-01-13 10:53:21,669 [INFO] Step[1950/4329]: training loss : 0.869858740568161 TRAIN  loss dict:  {'classification_loss': 0.869858740568161}
2025-01-13 10:53:33,293 [INFO] Step[2000/4329]: training loss : 0.8614598798751831 TRAIN  loss dict:  {'classification_loss': 0.8614598798751831}
2025-01-13 10:53:44,945 [INFO] Step[2050/4329]: training loss : 0.8600923454761505 TRAIN  loss dict:  {'classification_loss': 0.8600923454761505}
2025-01-13 10:53:56,530 [INFO] Step[2100/4329]: training loss : 0.8736406874656677 TRAIN  loss dict:  {'classification_loss': 0.8736406874656677}
2025-01-13 10:54:08,167 [INFO] Step[2150/4329]: training loss : 0.8596396780014038 TRAIN  loss dict:  {'classification_loss': 0.8596396780014038}
2025-01-13 10:54:19,775 [INFO] Step[2200/4329]: training loss : 0.8614038455486298 TRAIN  loss dict:  {'classification_loss': 0.8614038455486298}
2025-01-13 10:54:31,425 [INFO] Step[2250/4329]: training loss : 0.8585608422756195 TRAIN  loss dict:  {'classification_loss': 0.8585608422756195}
2025-01-13 10:54:43,015 [INFO] Step[2300/4329]: training loss : 0.8621895837783814 TRAIN  loss dict:  {'classification_loss': 0.8621895837783814}
2025-01-13 10:54:54,621 [INFO] Step[2350/4329]: training loss : 0.8601949322223663 TRAIN  loss dict:  {'classification_loss': 0.8601949322223663}
2025-01-13 10:55:06,270 [INFO] Step[2400/4329]: training loss : 0.861221045255661 TRAIN  loss dict:  {'classification_loss': 0.861221045255661}
2025-01-13 10:55:17,945 [INFO] Step[2450/4329]: training loss : 0.8761032783985138 TRAIN  loss dict:  {'classification_loss': 0.8761032783985138}
2025-01-13 10:55:29,552 [INFO] Step[2500/4329]: training loss : 0.8608292579650879 TRAIN  loss dict:  {'classification_loss': 0.8608292579650879}
2025-01-13 10:55:41,205 [INFO] Step[2550/4329]: training loss : 0.8610619056224823 TRAIN  loss dict:  {'classification_loss': 0.8610619056224823}
2025-01-13 10:55:52,859 [INFO] Step[2600/4329]: training loss : 0.86113112449646 TRAIN  loss dict:  {'classification_loss': 0.86113112449646}
2025-01-13 10:56:04,521 [INFO] Step[2650/4329]: training loss : 0.8606046235561371 TRAIN  loss dict:  {'classification_loss': 0.8606046235561371}
2025-01-13 10:56:16,156 [INFO] Step[2700/4329]: training loss : 0.8613799977302551 TRAIN  loss dict:  {'classification_loss': 0.8613799977302551}
2025-01-13 10:56:27,806 [INFO] Step[2750/4329]: training loss : 0.860930644273758 TRAIN  loss dict:  {'classification_loss': 0.860930644273758}
2025-01-13 10:56:39,445 [INFO] Step[2800/4329]: training loss : 0.8596731030941009 TRAIN  loss dict:  {'classification_loss': 0.8596731030941009}
2025-01-13 10:56:51,056 [INFO] Step[2850/4329]: training loss : 0.8586941003799439 TRAIN  loss dict:  {'classification_loss': 0.8586941003799439}
2025-01-13 10:57:02,709 [INFO] Step[2900/4329]: training loss : 0.8752709972858429 TRAIN  loss dict:  {'classification_loss': 0.8752709972858429}
2025-01-13 10:57:14,360 [INFO] Step[2950/4329]: training loss : 0.8653668355941773 TRAIN  loss dict:  {'classification_loss': 0.8653668355941773}
2025-01-13 10:57:25,998 [INFO] Step[3000/4329]: training loss : 0.8598801636695862 TRAIN  loss dict:  {'classification_loss': 0.8598801636695862}
2025-01-13 10:57:37,657 [INFO] Step[3050/4329]: training loss : 0.8860771906375885 TRAIN  loss dict:  {'classification_loss': 0.8860771906375885}
2025-01-13 10:57:49,284 [INFO] Step[3100/4329]: training loss : 0.8634631645679474 TRAIN  loss dict:  {'classification_loss': 0.8634631645679474}
2025-01-13 10:58:00,977 [INFO] Step[3150/4329]: training loss : 0.8632339429855347 TRAIN  loss dict:  {'classification_loss': 0.8632339429855347}
2025-01-13 10:58:12,634 [INFO] Step[3200/4329]: training loss : 0.8589870953559875 TRAIN  loss dict:  {'classification_loss': 0.8589870953559875}
2025-01-13 10:58:24,256 [INFO] Step[3250/4329]: training loss : 0.8603413605690002 TRAIN  loss dict:  {'classification_loss': 0.8603413605690002}
2025-01-13 10:58:35,879 [INFO] Step[3300/4329]: training loss : 0.862110481262207 TRAIN  loss dict:  {'classification_loss': 0.862110481262207}
2025-01-13 10:58:47,486 [INFO] Step[3350/4329]: training loss : 0.8618622517585754 TRAIN  loss dict:  {'classification_loss': 0.8618622517585754}
2025-01-13 10:58:59,119 [INFO] Step[3400/4329]: training loss : 0.8610611140727997 TRAIN  loss dict:  {'classification_loss': 0.8610611140727997}
2025-01-13 10:59:10,741 [INFO] Step[3450/4329]: training loss : 0.8741398465633392 TRAIN  loss dict:  {'classification_loss': 0.8741398465633392}
2025-01-13 10:59:22,407 [INFO] Step[3500/4329]: training loss : 0.8612490618228912 TRAIN  loss dict:  {'classification_loss': 0.8612490618228912}
2025-01-13 10:59:34,069 [INFO] Step[3550/4329]: training loss : 0.8596650588512421 TRAIN  loss dict:  {'classification_loss': 0.8596650588512421}
2025-01-13 10:59:45,727 [INFO] Step[3600/4329]: training loss : 0.8612037396430969 TRAIN  loss dict:  {'classification_loss': 0.8612037396430969}
2025-01-13 10:59:57,391 [INFO] Step[3650/4329]: training loss : 0.8592500054836273 TRAIN  loss dict:  {'classification_loss': 0.8592500054836273}
2025-01-13 11:00:09,008 [INFO] Step[3700/4329]: training loss : 0.8612778103351593 TRAIN  loss dict:  {'classification_loss': 0.8612778103351593}
2025-01-13 11:00:20,657 [INFO] Step[3750/4329]: training loss : 0.8664259457588196 TRAIN  loss dict:  {'classification_loss': 0.8664259457588196}
2025-01-13 11:00:32,290 [INFO] Step[3800/4329]: training loss : 0.8642735755443574 TRAIN  loss dict:  {'classification_loss': 0.8642735755443574}
2025-01-13 11:00:43,948 [INFO] Step[3850/4329]: training loss : 0.8597547245025635 TRAIN  loss dict:  {'classification_loss': 0.8597547245025635}
2025-01-13 11:00:55,585 [INFO] Step[3900/4329]: training loss : 0.8625608122348786 TRAIN  loss dict:  {'classification_loss': 0.8625608122348786}
2025-01-13 11:01:07,219 [INFO] Step[3950/4329]: training loss : 0.8602419447898865 TRAIN  loss dict:  {'classification_loss': 0.8602419447898865}
2025-01-13 11:01:18,879 [INFO] Step[4000/4329]: training loss : 0.8600073659420013 TRAIN  loss dict:  {'classification_loss': 0.8600073659420013}
2025-01-13 11:01:30,519 [INFO] Step[4050/4329]: training loss : 0.8600106918811798 TRAIN  loss dict:  {'classification_loss': 0.8600106918811798}
2025-01-13 11:01:42,143 [INFO] Step[4100/4329]: training loss : 0.8622070562839508 TRAIN  loss dict:  {'classification_loss': 0.8622070562839508}
2025-01-13 11:01:53,790 [INFO] Step[4150/4329]: training loss : 0.8600410163402558 TRAIN  loss dict:  {'classification_loss': 0.8600410163402558}
2025-01-13 11:02:05,650 [INFO] Step[4200/4329]: training loss : 0.8596263945102691 TRAIN  loss dict:  {'classification_loss': 0.8596263945102691}
2025-01-13 11:02:17,880 [INFO] Step[4250/4329]: training loss : 0.8636272931098938 TRAIN  loss dict:  {'classification_loss': 0.8636272931098938}
2025-01-13 11:02:30,118 [INFO] Step[4300/4329]: training loss : 0.8605359768867493 TRAIN  loss dict:  {'classification_loss': 0.8605359768867493}
2025-01-13 11:04:49,680 [INFO] Label accuracies statistics:
2025-01-13 11:04:49,680 [INFO] {0: 0.7777777777777778, 1: 1.0, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.5, 8: 0.6666666666666666, 9: 1.0, 10: 1.0, 11: 0.8333333333333334, 12: 0.5, 13: 0.5, 14: 0.75, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.5, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.8333333333333334, 24: 0.9166666666666666, 25: 0.75, 26: 0.8333333333333334, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.9166666666666666, 32: 0.6666666666666666, 33: 0.9166666666666666, 34: 1.0, 35: 1.0, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.5833333333333334, 42: 0.8333333333333334, 43: 0.9166666666666666, 44: 0.6666666666666666, 45: 0.5833333333333334, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.8333333333333334, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.4166666666666667, 55: 0.75, 56: 0.8333333333333334, 57: 0.75, 58: 0.4166666666666667, 59: 0.6666666666666666, 60: 0.75, 61: 0.8333333333333334, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.9166666666666666, 68: 0.75, 69: 0.75, 70: 0.5833333333333334, 71: 0.6666666666666666, 72: 0.9166666666666666, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.8333333333333334, 78: 0.9166666666666666, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.9166666666666666, 83: 0.5833333333333334, 84: 0.5, 85: 0.8333333333333334, 86: 0.75, 87: 0.75, 88: 0.5833333333333334, 89: 0.5833333333333334, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.5, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.75, 101: 1.0, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.5, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 1.0, 111: 1.0, 112: 0.9166666666666666, 113: 0.75, 114: 0.3333333333333333, 115: 0.9166666666666666, 116: 0.8333333333333334, 117: 0.75, 118: 0.9166666666666666, 119: 0.75, 120: 0.9166666666666666, 121: 0.75, 122: 0.8333333333333334, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.9166666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.8333333333333334, 132: 0.75, 133: 1.0, 134: 0.8333333333333334, 135: 1.0, 136: 0.9166666666666666, 137: 1.0, 138: 0.9166666666666666, 139: 0.8333333333333334, 140: 1.0, 141: 1.0, 142: 0.9166666666666666, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.6666666666666666, 149: 1.0, 150: 0.5, 151: 0.9166666666666666, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 0.9166666666666666, 156: 0.75, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.25, 161: 0.9166666666666666, 162: 1.0, 163: 0.9166666666666666, 164: 0.8333333333333334, 165: 0.8333333333333334, 166: 0.8333333333333334, 167: 0.8333333333333334, 168: 0.9166666666666666, 169: 1.0, 170: 0.9166666666666666, 171: 0.5, 172: 1.0, 173: 0.6666666666666666, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.4444444444444444, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.6666666666666666, 183: 0.9166666666666666, 184: 0.8333333333333334, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.6666666666666666, 189: 0.9166666666666666, 190: 0.75, 191: 0.4166666666666667, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 1.0, 197: 0.8333333333333334, 198: 0.6666666666666666}

2025-01-13 11:04:49,682 [INFO] [64] TRAIN  loss: 0.8625718362613923 acc: 0.9989219159094409
2025-01-13 11:04:49,682 [INFO] [64] TRAIN  loss dict: {'classification_loss': 0.8625718362613923}
2025-01-13 11:04:49,682 [INFO] [64] VALIDATION loss: 1.5852714489505748 VALIDATION acc: 0.8177609427609428
2025-01-13 11:04:49,682 [INFO] [64] VALIDATION loss dict: {'classification_loss': 1.5852714489505748}
2025-01-13 11:04:49,682 [INFO] 
2025-01-13 11:05:07,753 [INFO] Step[50/4329]: training loss : 0.86206906914711 TRAIN  loss dict:  {'classification_loss': 0.86206906914711}
2025-01-13 11:05:19,284 [INFO] Step[100/4329]: training loss : 0.8647619700431823 TRAIN  loss dict:  {'classification_loss': 0.8647619700431823}
2025-01-13 11:05:30,869 [INFO] Step[150/4329]: training loss : 0.8611467063426972 TRAIN  loss dict:  {'classification_loss': 0.8611467063426972}
2025-01-13 11:05:42,532 [INFO] Step[200/4329]: training loss : 0.861544543504715 TRAIN  loss dict:  {'classification_loss': 0.861544543504715}
2025-01-13 11:05:54,176 [INFO] Step[250/4329]: training loss : 0.8690386998653412 TRAIN  loss dict:  {'classification_loss': 0.8690386998653412}
2025-01-13 11:06:05,789 [INFO] Step[300/4329]: training loss : 0.8623449468612671 TRAIN  loss dict:  {'classification_loss': 0.8623449468612671}
2025-01-13 11:06:17,447 [INFO] Step[350/4329]: training loss : 0.8769944477081298 TRAIN  loss dict:  {'classification_loss': 0.8769944477081298}
2025-01-13 11:06:29,045 [INFO] Step[400/4329]: training loss : 0.8626550316810608 TRAIN  loss dict:  {'classification_loss': 0.8626550316810608}
2025-01-13 11:06:40,741 [INFO] Step[450/4329]: training loss : 0.8610354578495025 TRAIN  loss dict:  {'classification_loss': 0.8610354578495025}
2025-01-13 11:06:52,352 [INFO] Step[500/4329]: training loss : 0.8627652060985566 TRAIN  loss dict:  {'classification_loss': 0.8627652060985566}
2025-01-13 11:07:03,981 [INFO] Step[550/4329]: training loss : 0.869091808795929 TRAIN  loss dict:  {'classification_loss': 0.869091808795929}
2025-01-13 11:07:15,618 [INFO] Step[600/4329]: training loss : 0.8659053695201874 TRAIN  loss dict:  {'classification_loss': 0.8659053695201874}
2025-01-13 11:07:27,240 [INFO] Step[650/4329]: training loss : 0.8588100516796112 TRAIN  loss dict:  {'classification_loss': 0.8588100516796112}
2025-01-13 11:07:38,889 [INFO] Step[700/4329]: training loss : 0.8605875372886658 TRAIN  loss dict:  {'classification_loss': 0.8605875372886658}
2025-01-13 11:07:50,504 [INFO] Step[750/4329]: training loss : 0.8605860412120819 TRAIN  loss dict:  {'classification_loss': 0.8605860412120819}
2025-01-13 11:08:02,150 [INFO] Step[800/4329]: training loss : 0.8591726279258728 TRAIN  loss dict:  {'classification_loss': 0.8591726279258728}
2025-01-13 11:08:13,804 [INFO] Step[850/4329]: training loss : 0.8594352293014527 TRAIN  loss dict:  {'classification_loss': 0.8594352293014527}
2025-01-13 11:08:25,388 [INFO] Step[900/4329]: training loss : 0.8626566970348358 TRAIN  loss dict:  {'classification_loss': 0.8626566970348358}
2025-01-13 11:08:37,045 [INFO] Step[950/4329]: training loss : 0.8606911981105805 TRAIN  loss dict:  {'classification_loss': 0.8606911981105805}
2025-01-13 11:08:48,663 [INFO] Step[1000/4329]: training loss : 0.8613800299167633 TRAIN  loss dict:  {'classification_loss': 0.8613800299167633}
2025-01-13 11:09:00,344 [INFO] Step[1050/4329]: training loss : 0.8613978052139282 TRAIN  loss dict:  {'classification_loss': 0.8613978052139282}
2025-01-13 11:09:11,983 [INFO] Step[1100/4329]: training loss : 0.8671325802803039 TRAIN  loss dict:  {'classification_loss': 0.8671325802803039}
2025-01-13 11:09:23,616 [INFO] Step[1150/4329]: training loss : 0.8597160255908967 TRAIN  loss dict:  {'classification_loss': 0.8597160255908967}
2025-01-13 11:09:35,226 [INFO] Step[1200/4329]: training loss : 0.8581359720230103 TRAIN  loss dict:  {'classification_loss': 0.8581359720230103}
2025-01-13 11:09:46,848 [INFO] Step[1250/4329]: training loss : 0.8673673522472382 TRAIN  loss dict:  {'classification_loss': 0.8673673522472382}
2025-01-13 11:09:58,460 [INFO] Step[1300/4329]: training loss : 0.8588673090934753 TRAIN  loss dict:  {'classification_loss': 0.8588673090934753}
2025-01-13 11:10:10,099 [INFO] Step[1350/4329]: training loss : 0.8618811357021332 TRAIN  loss dict:  {'classification_loss': 0.8618811357021332}
2025-01-13 11:10:21,768 [INFO] Step[1400/4329]: training loss : 0.8601793646812439 TRAIN  loss dict:  {'classification_loss': 0.8601793646812439}
2025-01-13 11:10:33,342 [INFO] Step[1450/4329]: training loss : 0.8584398543834686 TRAIN  loss dict:  {'classification_loss': 0.8584398543834686}
2025-01-13 11:10:45,009 [INFO] Step[1500/4329]: training loss : 0.8592741549015045 TRAIN  loss dict:  {'classification_loss': 0.8592741549015045}
2025-01-13 11:10:56,629 [INFO] Step[1550/4329]: training loss : 0.860521525144577 TRAIN  loss dict:  {'classification_loss': 0.860521525144577}
2025-01-13 11:11:08,291 [INFO] Step[1600/4329]: training loss : 0.8598820888996124 TRAIN  loss dict:  {'classification_loss': 0.8598820888996124}
2025-01-13 11:11:19,916 [INFO] Step[1650/4329]: training loss : 0.8628110063076019 TRAIN  loss dict:  {'classification_loss': 0.8628110063076019}
2025-01-13 11:11:31,553 [INFO] Step[1700/4329]: training loss : 0.8619161546230316 TRAIN  loss dict:  {'classification_loss': 0.8619161546230316}
2025-01-13 11:11:43,201 [INFO] Step[1750/4329]: training loss : 0.8612681615352631 TRAIN  loss dict:  {'classification_loss': 0.8612681615352631}
2025-01-13 11:11:54,833 [INFO] Step[1800/4329]: training loss : 0.8655119347572326 TRAIN  loss dict:  {'classification_loss': 0.8655119347572326}
2025-01-13 11:12:06,447 [INFO] Step[1850/4329]: training loss : 0.8593934237957 TRAIN  loss dict:  {'classification_loss': 0.8593934237957}
2025-01-13 11:12:18,106 [INFO] Step[1900/4329]: training loss : 0.8575226604938507 TRAIN  loss dict:  {'classification_loss': 0.8575226604938507}
2025-01-13 11:12:29,745 [INFO] Step[1950/4329]: training loss : 0.861716822385788 TRAIN  loss dict:  {'classification_loss': 0.861716822385788}
2025-01-13 11:12:41,360 [INFO] Step[2000/4329]: training loss : 0.8701738238334655 TRAIN  loss dict:  {'classification_loss': 0.8701738238334655}
2025-01-13 11:12:53,034 [INFO] Step[2050/4329]: training loss : 0.8629490852355957 TRAIN  loss dict:  {'classification_loss': 0.8629490852355957}
2025-01-13 11:13:04,649 [INFO] Step[2100/4329]: training loss : 0.8589317440986634 TRAIN  loss dict:  {'classification_loss': 0.8589317440986634}
2025-01-13 11:13:16,285 [INFO] Step[2150/4329]: training loss : 0.8645411515235901 TRAIN  loss dict:  {'classification_loss': 0.8645411515235901}
2025-01-13 11:13:27,949 [INFO] Step[2200/4329]: training loss : 0.8742681562900543 TRAIN  loss dict:  {'classification_loss': 0.8742681562900543}
2025-01-13 11:13:39,572 [INFO] Step[2250/4329]: training loss : 0.8606595575809479 TRAIN  loss dict:  {'classification_loss': 0.8606595575809479}
2025-01-13 11:13:51,231 [INFO] Step[2300/4329]: training loss : 0.8605304002761841 TRAIN  loss dict:  {'classification_loss': 0.8605304002761841}
2025-01-13 11:14:02,875 [INFO] Step[2350/4329]: training loss : 0.8600557637214661 TRAIN  loss dict:  {'classification_loss': 0.8600557637214661}
2025-01-13 11:14:14,461 [INFO] Step[2400/4329]: training loss : 0.8597789633274079 TRAIN  loss dict:  {'classification_loss': 0.8597789633274079}
2025-01-13 11:14:26,158 [INFO] Step[2450/4329]: training loss : 0.8593756687641144 TRAIN  loss dict:  {'classification_loss': 0.8593756687641144}
2025-01-13 11:14:38,065 [INFO] Step[2500/4329]: training loss : 0.8612972640991211 TRAIN  loss dict:  {'classification_loss': 0.8612972640991211}
2025-01-13 11:14:50,433 [INFO] Step[2550/4329]: training loss : 0.8655038595199585 TRAIN  loss dict:  {'classification_loss': 0.8655038595199585}
2025-01-13 11:15:02,759 [INFO] Step[2600/4329]: training loss : 0.8597998642921447 TRAIN  loss dict:  {'classification_loss': 0.8597998642921447}
2025-01-13 11:15:15,763 [INFO] Step[2650/4329]: training loss : 0.862349202632904 TRAIN  loss dict:  {'classification_loss': 0.862349202632904}
2025-01-13 11:15:29,479 [INFO] Step[2700/4329]: training loss : 0.8672905743122101 TRAIN  loss dict:  {'classification_loss': 0.8672905743122101}
2025-01-13 11:15:41,541 [INFO] Step[2750/4329]: training loss : 0.8614082312583924 TRAIN  loss dict:  {'classification_loss': 0.8614082312583924}
2025-01-13 11:15:53,468 [INFO] Step[2800/4329]: training loss : 0.8602145099639893 TRAIN  loss dict:  {'classification_loss': 0.8602145099639893}
2025-01-13 11:16:05,266 [INFO] Step[2850/4329]: training loss : 0.861867389678955 TRAIN  loss dict:  {'classification_loss': 0.861867389678955}
2025-01-13 11:16:16,931 [INFO] Step[2900/4329]: training loss : 0.8706301724910737 TRAIN  loss dict:  {'classification_loss': 0.8706301724910737}
2025-01-13 11:16:28,584 [INFO] Step[2950/4329]: training loss : 0.8594007182121277 TRAIN  loss dict:  {'classification_loss': 0.8594007182121277}
2025-01-13 11:16:40,192 [INFO] Step[3000/4329]: training loss : 0.8602776980400085 TRAIN  loss dict:  {'classification_loss': 0.8602776980400085}
2025-01-13 11:16:51,853 [INFO] Step[3050/4329]: training loss : 0.8793762743473053 TRAIN  loss dict:  {'classification_loss': 0.8793762743473053}
2025-01-13 11:17:03,503 [INFO] Step[3100/4329]: training loss : 0.8667072606086731 TRAIN  loss dict:  {'classification_loss': 0.8667072606086731}
2025-01-13 11:17:15,106 [INFO] Step[3150/4329]: training loss : 0.8642123639583588 TRAIN  loss dict:  {'classification_loss': 0.8642123639583588}
2025-01-13 11:17:26,767 [INFO] Step[3200/4329]: training loss : 0.8612853753566742 TRAIN  loss dict:  {'classification_loss': 0.8612853753566742}
2025-01-13 11:17:38,383 [INFO] Step[3250/4329]: training loss : 0.8645021283626556 TRAIN  loss dict:  {'classification_loss': 0.8645021283626556}
2025-01-13 11:17:49,999 [INFO] Step[3300/4329]: training loss : 0.8618360507488251 TRAIN  loss dict:  {'classification_loss': 0.8618360507488251}
2025-01-13 11:18:01,632 [INFO] Step[3350/4329]: training loss : 0.8635097122192383 TRAIN  loss dict:  {'classification_loss': 0.8635097122192383}
2025-01-13 11:18:13,292 [INFO] Step[3400/4329]: training loss : 0.8655684745311737 TRAIN  loss dict:  {'classification_loss': 0.8655684745311737}
2025-01-13 11:18:24,946 [INFO] Step[3450/4329]: training loss : 0.8684774482250214 TRAIN  loss dict:  {'classification_loss': 0.8684774482250214}
2025-01-13 11:18:36,531 [INFO] Step[3500/4329]: training loss : 0.8614959621429443 TRAIN  loss dict:  {'classification_loss': 0.8614959621429443}
2025-01-13 11:18:48,145 [INFO] Step[3550/4329]: training loss : 0.8611819350719452 TRAIN  loss dict:  {'classification_loss': 0.8611819350719452}
2025-01-13 11:18:59,799 [INFO] Step[3600/4329]: training loss : 0.86201624751091 TRAIN  loss dict:  {'classification_loss': 0.86201624751091}
2025-01-13 11:19:11,381 [INFO] Step[3650/4329]: training loss : 0.8609670698642731 TRAIN  loss dict:  {'classification_loss': 0.8609670698642731}
2025-01-13 11:19:22,969 [INFO] Step[3700/4329]: training loss : 0.8599251365661621 TRAIN  loss dict:  {'classification_loss': 0.8599251365661621}
2025-01-13 11:19:34,600 [INFO] Step[3750/4329]: training loss : 0.8646579372882843 TRAIN  loss dict:  {'classification_loss': 0.8646579372882843}
2025-01-13 11:19:46,203 [INFO] Step[3800/4329]: training loss : 0.864305636882782 TRAIN  loss dict:  {'classification_loss': 0.864305636882782}
2025-01-13 11:19:57,857 [INFO] Step[3850/4329]: training loss : 0.8592663300037384 TRAIN  loss dict:  {'classification_loss': 0.8592663300037384}
2025-01-13 11:20:09,512 [INFO] Step[3900/4329]: training loss : 0.8633350765705109 TRAIN  loss dict:  {'classification_loss': 0.8633350765705109}
2025-01-13 11:20:21,186 [INFO] Step[3950/4329]: training loss : 0.8665184164047242 TRAIN  loss dict:  {'classification_loss': 0.8665184164047242}
2025-01-13 11:20:32,795 [INFO] Step[4000/4329]: training loss : 0.861523871421814 TRAIN  loss dict:  {'classification_loss': 0.861523871421814}
2025-01-13 11:20:44,452 [INFO] Step[4050/4329]: training loss : 0.8646177470684051 TRAIN  loss dict:  {'classification_loss': 0.8646177470684051}
2025-01-13 11:20:56,082 [INFO] Step[4100/4329]: training loss : 0.8611563003063202 TRAIN  loss dict:  {'classification_loss': 0.8611563003063202}
2025-01-13 11:21:07,732 [INFO] Step[4150/4329]: training loss : 0.8686379623413086 TRAIN  loss dict:  {'classification_loss': 0.8686379623413086}
2025-01-13 11:21:19,368 [INFO] Step[4200/4329]: training loss : 0.8604239678382873 TRAIN  loss dict:  {'classification_loss': 0.8604239678382873}
2025-01-13 11:21:31,006 [INFO] Step[4250/4329]: training loss : 0.8654356372356414 TRAIN  loss dict:  {'classification_loss': 0.8654356372356414}
2025-01-13 11:21:42,676 [INFO] Step[4300/4329]: training loss : 0.8605255258083343 TRAIN  loss dict:  {'classification_loss': 0.8605255258083343}
2025-01-13 11:23:42,317 [INFO] Label accuracies statistics:
2025-01-13 11:23:42,317 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.25, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.6666666666666666, 8: 0.6666666666666666, 9: 0.8333333333333334, 10: 1.0, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.5, 14: 0.75, 15: 0.7777777777777778, 16: 0.6666666666666666, 17: 0.5833333333333334, 18: 0.5, 19: 0.75, 20: 0.5, 21: 0.8333333333333334, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.9166666666666666, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.5833333333333334, 31: 0.8333333333333334, 32: 0.75, 33: 0.9166666666666666, 34: 1.0, 35: 1.0, 36: 0.6666666666666666, 37: 0.9166666666666666, 38: 1.0, 39: 1.0, 40: 0.8333333333333334, 41: 0.4166666666666667, 42: 1.0, 43: 0.9166666666666666, 44: 0.6666666666666666, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5833333333333334, 55: 0.75, 56: 0.9166666666666666, 57: 0.75, 58: 0.5833333333333334, 59: 0.8333333333333334, 60: 0.75, 61: 0.9166666666666666, 62: 0.75, 63: 0.6666666666666666, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.75, 69: 0.6666666666666666, 70: 0.4166666666666667, 71: 0.5, 72: 1.0, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 1.0, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.8333333333333334, 83: 0.6666666666666666, 84: 0.5833333333333334, 85: 0.75, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.75, 89: 0.5833333333333334, 90: 0.6666666666666666, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.5, 97: 0.6666666666666666, 98: 0.8333333333333334, 99: 1.0, 100: 0.75, 101: 0.9166666666666666, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 0.9166666666666666, 106: 1.0, 107: 0.6666666666666666, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 1.0, 111: 0.9166666666666666, 112: 0.8333333333333334, 113: 0.5833333333333334, 114: 0.3333333333333333, 115: 1.0, 116: 0.8333333333333334, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.9166666666666666, 121: 0.9166666666666666, 122: 0.9166666666666666, 123: 1.0, 124: 1.0, 125: 0.9166666666666666, 126: 0.9166666666666666, 127: 0.6666666666666666, 128: 1.0, 129: 1.0, 130: 0.9166666666666666, 131: 0.8333333333333334, 132: 0.6666666666666666, 133: 1.0, 134: 0.8333333333333334, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.8333333333333334, 140: 0.9166666666666666, 141: 1.0, 142: 0.8333333333333334, 143: 1.0, 144: 0.5833333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.5, 151: 0.9166666666666666, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.8333333333333334, 157: 0.6666666666666666, 158: 0.7777777777777778, 159: 1.0, 160: 0.16666666666666666, 161: 0.9166666666666666, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.8333333333333334, 166: 0.8333333333333334, 167: 0.8333333333333334, 168: 0.9166666666666666, 169: 1.0, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.9166666666666666, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 0.8333333333333334, 177: 0.8333333333333334, 178: 1.0, 179: 0.4444444444444444, 180: 1.0, 181: 0.75, 182: 0.6666666666666666, 183: 0.9166666666666666, 184: 0.9166666666666666, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.8333333333333334, 189: 0.9166666666666666, 190: 0.6666666666666666, 191: 0.4166666666666667, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.75}

2025-01-13 11:23:44,268 [INFO] [65] TRAIN  loss: 0.862856051530263 acc: 0.9993069459417835
2025-01-13 11:23:44,268 [INFO] [65] TRAIN  loss dict: {'classification_loss': 0.862856051530263}
2025-01-13 11:23:44,268 [INFO] [65] VALIDATION loss: 1.5419277729410115 VALIDATION acc: 0.8253367003367004
2025-01-13 11:23:44,268 [INFO] [65] VALIDATION loss dict: {'classification_loss': 1.5419277729410115}
2025-01-13 11:23:44,269 [INFO] 
2025-01-13 11:24:01,718 [INFO] Step[50/4329]: training loss : 0.8609608352184296 TRAIN  loss dict:  {'classification_loss': 0.8609608352184296}
2025-01-13 11:24:13,255 [INFO] Step[100/4329]: training loss : 0.8929879784584045 TRAIN  loss dict:  {'classification_loss': 0.8929879784584045}
2025-01-13 11:24:24,897 [INFO] Step[150/4329]: training loss : 0.8584395122528076 TRAIN  loss dict:  {'classification_loss': 0.8584395122528076}
2025-01-13 11:24:36,497 [INFO] Step[200/4329]: training loss : 0.8577382349967957 TRAIN  loss dict:  {'classification_loss': 0.8577382349967957}
2025-01-13 11:24:48,101 [INFO] Step[250/4329]: training loss : 0.8595444476604461 TRAIN  loss dict:  {'classification_loss': 0.8595444476604461}
2025-01-13 11:24:59,717 [INFO] Step[300/4329]: training loss : 0.8594248473644257 TRAIN  loss dict:  {'classification_loss': 0.8594248473644257}
2025-01-13 11:25:11,374 [INFO] Step[350/4329]: training loss : 0.8617447304725647 TRAIN  loss dict:  {'classification_loss': 0.8617447304725647}
2025-01-13 11:25:23,022 [INFO] Step[400/4329]: training loss : 0.8591732037067413 TRAIN  loss dict:  {'classification_loss': 0.8591732037067413}
2025-01-13 11:25:34,637 [INFO] Step[450/4329]: training loss : 0.8631921684741974 TRAIN  loss dict:  {'classification_loss': 0.8631921684741974}
2025-01-13 11:25:46,275 [INFO] Step[500/4329]: training loss : 0.8672906959056854 TRAIN  loss dict:  {'classification_loss': 0.8672906959056854}
2025-01-13 11:25:57,964 [INFO] Step[550/4329]: training loss : 0.8587936818599701 TRAIN  loss dict:  {'classification_loss': 0.8587936818599701}
2025-01-13 11:26:09,620 [INFO] Step[600/4329]: training loss : 0.86290567278862 TRAIN  loss dict:  {'classification_loss': 0.86290567278862}
2025-01-13 11:26:21,266 [INFO] Step[650/4329]: training loss : 0.8583810830116272 TRAIN  loss dict:  {'classification_loss': 0.8583810830116272}
2025-01-13 11:26:32,970 [INFO] Step[700/4329]: training loss : 0.8606840479373932 TRAIN  loss dict:  {'classification_loss': 0.8606840479373932}
2025-01-13 11:26:44,620 [INFO] Step[750/4329]: training loss : 0.871178115606308 TRAIN  loss dict:  {'classification_loss': 0.871178115606308}
2025-01-13 11:26:56,372 [INFO] Step[800/4329]: training loss : 0.8644267117977142 TRAIN  loss dict:  {'classification_loss': 0.8644267117977142}
2025-01-13 11:27:08,627 [INFO] Step[850/4329]: training loss : 0.8702381920814514 TRAIN  loss dict:  {'classification_loss': 0.8702381920814514}
2025-01-13 11:27:20,791 [INFO] Step[900/4329]: training loss : 0.8613593316078186 TRAIN  loss dict:  {'classification_loss': 0.8613593316078186}
2025-01-13 11:27:33,407 [INFO] Step[950/4329]: training loss : 0.8613342893123627 TRAIN  loss dict:  {'classification_loss': 0.8613342893123627}
2025-01-13 11:27:47,035 [INFO] Step[1000/4329]: training loss : 0.8718031883239746 TRAIN  loss dict:  {'classification_loss': 0.8718031883239746}
2025-01-13 11:28:00,051 [INFO] Step[1050/4329]: training loss : 0.8608282935619355 TRAIN  loss dict:  {'classification_loss': 0.8608282935619355}
2025-01-13 11:28:12,004 [INFO] Step[1100/4329]: training loss : 0.8601514959335327 TRAIN  loss dict:  {'classification_loss': 0.8601514959335327}
2025-01-13 11:28:24,008 [INFO] Step[1150/4329]: training loss : 0.8678794598579407 TRAIN  loss dict:  {'classification_loss': 0.8678794598579407}
2025-01-13 11:28:35,722 [INFO] Step[1200/4329]: training loss : 0.8619570708274842 TRAIN  loss dict:  {'classification_loss': 0.8619570708274842}
2025-01-13 11:28:47,447 [INFO] Step[1250/4329]: training loss : 0.8598513686656952 TRAIN  loss dict:  {'classification_loss': 0.8598513686656952}
2025-01-13 11:28:59,080 [INFO] Step[1300/4329]: training loss : 0.8619644165039062 TRAIN  loss dict:  {'classification_loss': 0.8619644165039062}
2025-01-13 11:29:10,729 [INFO] Step[1350/4329]: training loss : 0.8599017322063446 TRAIN  loss dict:  {'classification_loss': 0.8599017322063446}
2025-01-13 11:29:22,422 [INFO] Step[1400/4329]: training loss : 0.8700222980976104 TRAIN  loss dict:  {'classification_loss': 0.8700222980976104}
2025-01-13 11:29:34,122 [INFO] Step[1450/4329]: training loss : 0.8644478690624237 TRAIN  loss dict:  {'classification_loss': 0.8644478690624237}
2025-01-13 11:29:45,817 [INFO] Step[1500/4329]: training loss : 0.9031056141853333 TRAIN  loss dict:  {'classification_loss': 0.9031056141853333}
2025-01-13 11:29:57,490 [INFO] Step[1550/4329]: training loss : 0.861313420534134 TRAIN  loss dict:  {'classification_loss': 0.861313420534134}
2025-01-13 11:30:09,167 [INFO] Step[1600/4329]: training loss : 0.8619996511936188 TRAIN  loss dict:  {'classification_loss': 0.8619996511936188}
2025-01-13 11:30:20,835 [INFO] Step[1650/4329]: training loss : 0.8593211817741394 TRAIN  loss dict:  {'classification_loss': 0.8593211817741394}
2025-01-13 11:30:32,512 [INFO] Step[1700/4329]: training loss : 0.861059410572052 TRAIN  loss dict:  {'classification_loss': 0.861059410572052}
2025-01-13 11:30:44,194 [INFO] Step[1750/4329]: training loss : 0.8766581082344055 TRAIN  loss dict:  {'classification_loss': 0.8766581082344055}
2025-01-13 11:30:55,863 [INFO] Step[1800/4329]: training loss : 0.8602968132495881 TRAIN  loss dict:  {'classification_loss': 0.8602968132495881}
2025-01-13 11:31:07,541 [INFO] Step[1850/4329]: training loss : 0.8619883525371551 TRAIN  loss dict:  {'classification_loss': 0.8619883525371551}
2025-01-13 11:31:19,240 [INFO] Step[1900/4329]: training loss : 0.8601339817047119 TRAIN  loss dict:  {'classification_loss': 0.8601339817047119}
2025-01-13 11:31:30,980 [INFO] Step[1950/4329]: training loss : 0.8630192971229553 TRAIN  loss dict:  {'classification_loss': 0.8630192971229553}
2025-01-13 11:31:42,653 [INFO] Step[2000/4329]: training loss : 0.8596255159378052 TRAIN  loss dict:  {'classification_loss': 0.8596255159378052}
2025-01-13 11:31:54,351 [INFO] Step[2050/4329]: training loss : 0.8609989202022552 TRAIN  loss dict:  {'classification_loss': 0.8609989202022552}
2025-01-13 11:32:06,005 [INFO] Step[2100/4329]: training loss : 0.8591168880462646 TRAIN  loss dict:  {'classification_loss': 0.8591168880462646}
2025-01-13 11:32:17,680 [INFO] Step[2150/4329]: training loss : 0.8586809813976288 TRAIN  loss dict:  {'classification_loss': 0.8586809813976288}
2025-01-13 11:32:29,397 [INFO] Step[2200/4329]: training loss : 0.8586401879787445 TRAIN  loss dict:  {'classification_loss': 0.8586401879787445}
2025-01-13 11:32:41,077 [INFO] Step[2250/4329]: training loss : 0.8619726908206939 TRAIN  loss dict:  {'classification_loss': 0.8619726908206939}
2025-01-13 11:32:52,748 [INFO] Step[2300/4329]: training loss : 0.861543128490448 TRAIN  loss dict:  {'classification_loss': 0.861543128490448}
2025-01-13 11:33:04,470 [INFO] Step[2350/4329]: training loss : 0.8599871838092804 TRAIN  loss dict:  {'classification_loss': 0.8599871838092804}
2025-01-13 11:33:16,122 [INFO] Step[2400/4329]: training loss : 0.8609031105041504 TRAIN  loss dict:  {'classification_loss': 0.8609031105041504}
2025-01-13 11:33:27,805 [INFO] Step[2450/4329]: training loss : 0.8599643170833587 TRAIN  loss dict:  {'classification_loss': 0.8599643170833587}
2025-01-13 11:33:39,448 [INFO] Step[2500/4329]: training loss : 0.8592141127586365 TRAIN  loss dict:  {'classification_loss': 0.8592141127586365}
2025-01-13 11:33:51,120 [INFO] Step[2550/4329]: training loss : 0.8633333802223205 TRAIN  loss dict:  {'classification_loss': 0.8633333802223205}
2025-01-13 11:34:02,816 [INFO] Step[2600/4329]: training loss : 0.8602184545993805 TRAIN  loss dict:  {'classification_loss': 0.8602184545993805}
2025-01-13 11:34:14,496 [INFO] Step[2650/4329]: training loss : 0.8587453389167785 TRAIN  loss dict:  {'classification_loss': 0.8587453389167785}
2025-01-13 11:34:26,151 [INFO] Step[2700/4329]: training loss : 0.8621378147602081 TRAIN  loss dict:  {'classification_loss': 0.8621378147602081}
2025-01-13 11:34:37,797 [INFO] Step[2750/4329]: training loss : 0.8600528860092163 TRAIN  loss dict:  {'classification_loss': 0.8600528860092163}
2025-01-13 11:34:49,454 [INFO] Step[2800/4329]: training loss : 0.8607637822628021 TRAIN  loss dict:  {'classification_loss': 0.8607637822628021}
2025-01-13 11:35:01,186 [INFO] Step[2850/4329]: training loss : 0.8632420969009399 TRAIN  loss dict:  {'classification_loss': 0.8632420969009399}
2025-01-13 11:35:12,837 [INFO] Step[2900/4329]: training loss : 0.8614662313461303 TRAIN  loss dict:  {'classification_loss': 0.8614662313461303}
2025-01-13 11:35:24,521 [INFO] Step[2950/4329]: training loss : 0.8605580675601959 TRAIN  loss dict:  {'classification_loss': 0.8605580675601959}
2025-01-13 11:35:36,159 [INFO] Step[3000/4329]: training loss : 0.8604329252243041 TRAIN  loss dict:  {'classification_loss': 0.8604329252243041}
2025-01-13 11:35:47,855 [INFO] Step[3050/4329]: training loss : 0.8633780157566071 TRAIN  loss dict:  {'classification_loss': 0.8633780157566071}
2025-01-13 11:35:59,570 [INFO] Step[3100/4329]: training loss : 0.859776667356491 TRAIN  loss dict:  {'classification_loss': 0.859776667356491}
2025-01-13 11:36:11,246 [INFO] Step[3150/4329]: training loss : 0.8632603824138642 TRAIN  loss dict:  {'classification_loss': 0.8632603824138642}
2025-01-13 11:36:22,921 [INFO] Step[3200/4329]: training loss : 0.8757184207439422 TRAIN  loss dict:  {'classification_loss': 0.8757184207439422}
2025-01-13 11:36:34,597 [INFO] Step[3250/4329]: training loss : 0.8595366632938385 TRAIN  loss dict:  {'classification_loss': 0.8595366632938385}
2025-01-13 11:36:46,263 [INFO] Step[3300/4329]: training loss : 0.859464659690857 TRAIN  loss dict:  {'classification_loss': 0.859464659690857}
2025-01-13 11:36:57,931 [INFO] Step[3350/4329]: training loss : 0.862375590801239 TRAIN  loss dict:  {'classification_loss': 0.862375590801239}
2025-01-13 11:37:09,591 [INFO] Step[3400/4329]: training loss : 0.8620868957042694 TRAIN  loss dict:  {'classification_loss': 0.8620868957042694}
2025-01-13 11:37:21,247 [INFO] Step[3450/4329]: training loss : 0.8607678365707397 TRAIN  loss dict:  {'classification_loss': 0.8607678365707397}
2025-01-13 11:37:32,886 [INFO] Step[3500/4329]: training loss : 0.8598425841331482 TRAIN  loss dict:  {'classification_loss': 0.8598425841331482}
2025-01-13 11:37:44,591 [INFO] Step[3550/4329]: training loss : 0.869537137746811 TRAIN  loss dict:  {'classification_loss': 0.869537137746811}
2025-01-13 11:37:56,234 [INFO] Step[3600/4329]: training loss : 0.8679957747459411 TRAIN  loss dict:  {'classification_loss': 0.8679957747459411}
2025-01-13 11:38:07,916 [INFO] Step[3650/4329]: training loss : 0.8633583664894104 TRAIN  loss dict:  {'classification_loss': 0.8633583664894104}
2025-01-13 11:38:19,534 [INFO] Step[3700/4329]: training loss : 0.8620892798900605 TRAIN  loss dict:  {'classification_loss': 0.8620892798900605}
2025-01-13 11:38:31,181 [INFO] Step[3750/4329]: training loss : 0.8639592218399048 TRAIN  loss dict:  {'classification_loss': 0.8639592218399048}
2025-01-13 11:38:42,816 [INFO] Step[3800/4329]: training loss : 0.8610011911392212 TRAIN  loss dict:  {'classification_loss': 0.8610011911392212}
2025-01-13 11:38:54,521 [INFO] Step[3850/4329]: training loss : 0.8641591799259186 TRAIN  loss dict:  {'classification_loss': 0.8641591799259186}
2025-01-13 11:39:06,153 [INFO] Step[3900/4329]: training loss : 0.8595354223251342 TRAIN  loss dict:  {'classification_loss': 0.8595354223251342}
2025-01-13 11:39:17,974 [INFO] Step[3950/4329]: training loss : 0.8612136089801788 TRAIN  loss dict:  {'classification_loss': 0.8612136089801788}
2025-01-13 11:39:30,344 [INFO] Step[4000/4329]: training loss : 0.8770062589645385 TRAIN  loss dict:  {'classification_loss': 0.8770062589645385}
2025-01-13 11:39:42,588 [INFO] Step[4050/4329]: training loss : 0.8616550028324127 TRAIN  loss dict:  {'classification_loss': 0.8616550028324127}
2025-01-13 11:39:55,792 [INFO] Step[4100/4329]: training loss : 0.8658933389186859 TRAIN  loss dict:  {'classification_loss': 0.8658933389186859}
2025-01-13 11:40:11,568 [INFO] Step[4150/4329]: training loss : 0.8833516895771026 TRAIN  loss dict:  {'classification_loss': 0.8833516895771026}
2025-01-13 11:40:24,474 [INFO] Step[4200/4329]: training loss : 0.8610449278354645 TRAIN  loss dict:  {'classification_loss': 0.8610449278354645}
2025-01-13 11:40:36,344 [INFO] Step[4250/4329]: training loss : 0.8637773072719575 TRAIN  loss dict:  {'classification_loss': 0.8637773072719575}
2025-01-13 11:40:48,229 [INFO] Step[4300/4329]: training loss : 0.8622327733039856 TRAIN  loss dict:  {'classification_loss': 0.8622327733039856}
2025-01-13 11:42:48,312 [INFO] Label accuracies statistics:
2025-01-13 11:42:48,312 [INFO] {0: 0.5555555555555556, 1: 0.7777777777777778, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5, 7: 0.5, 8: 0.75, 9: 0.9166666666666666, 10: 1.0, 11: 0.8333333333333334, 12: 0.4166666666666667, 13: 0.3333333333333333, 14: 0.6666666666666666, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.5, 18: 0.5, 19: 0.75, 20: 0.6666666666666666, 21: 0.75, 22: 0.75, 23: 0.9166666666666666, 24: 1.0, 25: 0.9166666666666666, 26: 0.9166666666666666, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.6666666666666666, 31: 0.9166666666666666, 32: 0.75, 33: 0.9166666666666666, 34: 1.0, 35: 0.9166666666666666, 36: 0.4166666666666667, 37: 1.0, 38: 1.0, 39: 0.9166666666666666, 40: 0.9166666666666666, 41: 0.5, 42: 1.0, 43: 0.9166666666666666, 44: 0.5833333333333334, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.75, 51: 0.8333333333333334, 52: 1.0, 53: 0.5, 54: 0.5833333333333334, 55: 0.6666666666666666, 56: 0.9166666666666666, 57: 0.75, 58: 0.5833333333333334, 59: 0.9166666666666666, 60: 0.6666666666666666, 61: 0.9166666666666666, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.75, 69: 0.6666666666666666, 70: 0.4166666666666667, 71: 0.5, 72: 0.75, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 1.0, 79: 0.8333333333333334, 80: 1.0, 81: 1.0, 82: 0.9166666666666666, 83: 0.5, 84: 0.75, 85: 0.8333333333333334, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.5, 89: 0.5833333333333334, 90: 0.8333333333333334, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 0.9166666666666666, 96: 0.75, 97: 0.75, 98: 0.9166666666666666, 99: 1.0, 100: 0.75, 101: 0.9166666666666666, 102: 0.9166666666666666, 103: 0.8333333333333334, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.5833333333333334, 108: 0.8333333333333334, 109: 0.9166666666666666, 110: 1.0, 111: 1.0, 112: 0.9166666666666666, 113: 0.4166666666666667, 114: 0.5, 115: 1.0, 116: 0.9166666666666666, 117: 0.8333333333333334, 118: 1.0, 119: 0.75, 120: 0.8333333333333334, 121: 0.75, 122: 0.8333333333333334, 123: 1.0, 124: 1.0, 125: 0.8333333333333334, 126: 1.0, 127: 0.8333333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.9166666666666666, 132: 0.5833333333333334, 133: 1.0, 134: 0.8333333333333334, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.8333333333333334, 140: 0.9166666666666666, 141: 0.8333333333333334, 142: 0.9166666666666666, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.9166666666666666, 148: 0.6666666666666666, 149: 1.0, 150: 0.5, 151: 0.8333333333333334, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.8333333333333334, 156: 0.6666666666666666, 157: 0.6666666666666666, 158: 0.7777777777777778, 159: 1.0, 160: 0.4166666666666667, 161: 0.9166666666666666, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.75, 166: 0.8333333333333334, 167: 0.8333333333333334, 168: 0.9166666666666666, 169: 1.0, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.9166666666666666, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.4444444444444444, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.75, 183: 0.75, 184: 0.6666666666666666, 185: 0.9166666666666666, 186: 0.9166666666666666, 187: 1.0, 188: 0.5833333333333334, 189: 1.0, 190: 0.5833333333333334, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.8333333333333334, 196: 1.0, 197: 0.8333333333333334, 198: 0.6666666666666666}

2025-01-13 11:42:48,314 [INFO] [66] TRAIN  loss: 0.8635118857050196 acc: 0.9991529339288464
2025-01-13 11:42:48,314 [INFO] [66] TRAIN  loss dict: {'classification_loss': 0.8635118857050196}
2025-01-13 11:42:48,315 [INFO] [66] VALIDATION loss: 1.5802398758253666 VALIDATION acc: 0.8148148148148148
2025-01-13 11:42:48,315 [INFO] [66] VALIDATION loss dict: {'classification_loss': 1.5802398758253666}
2025-01-13 11:42:48,315 [INFO] 
2025-01-13 11:43:05,749 [INFO] Step[50/4329]: training loss : 0.8583887839317321 TRAIN  loss dict:  {'classification_loss': 0.8583887839317321}
2025-01-13 11:43:17,286 [INFO] Step[100/4329]: training loss : 0.8608176779747009 TRAIN  loss dict:  {'classification_loss': 0.8608176779747009}
2025-01-13 11:43:28,871 [INFO] Step[150/4329]: training loss : 0.859797397851944 TRAIN  loss dict:  {'classification_loss': 0.859797397851944}
2025-01-13 11:43:40,500 [INFO] Step[200/4329]: training loss : 0.8610293889045715 TRAIN  loss dict:  {'classification_loss': 0.8610293889045715}
2025-01-13 11:43:52,065 [INFO] Step[250/4329]: training loss : 0.8598111617565155 TRAIN  loss dict:  {'classification_loss': 0.8598111617565155}
2025-01-13 11:44:03,679 [INFO] Step[300/4329]: training loss : 0.8652389740943909 TRAIN  loss dict:  {'classification_loss': 0.8652389740943909}
2025-01-13 11:44:15,318 [INFO] Step[350/4329]: training loss : 0.8599228608608246 TRAIN  loss dict:  {'classification_loss': 0.8599228608608246}
2025-01-13 11:44:26,935 [INFO] Step[400/4329]: training loss : 0.8754538762569427 TRAIN  loss dict:  {'classification_loss': 0.8754538762569427}
2025-01-13 11:44:38,595 [INFO] Step[450/4329]: training loss : 0.858312338590622 TRAIN  loss dict:  {'classification_loss': 0.858312338590622}
2025-01-13 11:44:50,225 [INFO] Step[500/4329]: training loss : 0.8629712581634521 TRAIN  loss dict:  {'classification_loss': 0.8629712581634521}
2025-01-13 11:45:01,847 [INFO] Step[550/4329]: training loss : 0.8611758804321289 TRAIN  loss dict:  {'classification_loss': 0.8611758804321289}
2025-01-13 11:45:13,481 [INFO] Step[600/4329]: training loss : 0.8605919229984283 TRAIN  loss dict:  {'classification_loss': 0.8605919229984283}
2025-01-13 11:45:25,136 [INFO] Step[650/4329]: training loss : 0.8584510624408722 TRAIN  loss dict:  {'classification_loss': 0.8584510624408722}
2025-01-13 11:45:36,771 [INFO] Step[700/4329]: training loss : 0.8582457780838013 TRAIN  loss dict:  {'classification_loss': 0.8582457780838013}
2025-01-13 11:45:48,358 [INFO] Step[750/4329]: training loss : 0.8609246897697449 TRAIN  loss dict:  {'classification_loss': 0.8609246897697449}
2025-01-13 11:46:00,128 [INFO] Step[800/4329]: training loss : 0.8603798031806946 TRAIN  loss dict:  {'classification_loss': 0.8603798031806946}
2025-01-13 11:46:12,796 [INFO] Step[850/4329]: training loss : 0.85853968501091 TRAIN  loss dict:  {'classification_loss': 0.85853968501091}
2025-01-13 11:46:31,478 [INFO] Step[900/4329]: training loss : 0.8608302628993988 TRAIN  loss dict:  {'classification_loss': 0.8608302628993988}
2025-01-13 11:46:50,646 [INFO] Step[950/4329]: training loss : 0.863991664648056 TRAIN  loss dict:  {'classification_loss': 0.863991664648056}
2025-01-13 11:47:13,351 [INFO] Step[1000/4329]: training loss : 0.8837588393688202 TRAIN  loss dict:  {'classification_loss': 0.8837588393688202}
2025-01-13 11:47:32,237 [INFO] Step[1050/4329]: training loss : 0.8667735922336578 TRAIN  loss dict:  {'classification_loss': 0.8667735922336578}
2025-01-13 11:47:49,279 [INFO] Step[1100/4329]: training loss : 0.8596100413799286 TRAIN  loss dict:  {'classification_loss': 0.8596100413799286}
2025-01-13 11:48:06,683 [INFO] Step[1150/4329]: training loss : 0.8623053801059722 TRAIN  loss dict:  {'classification_loss': 0.8623053801059722}
2025-01-13 11:48:22,657 [INFO] Step[1200/4329]: training loss : 0.8626894640922547 TRAIN  loss dict:  {'classification_loss': 0.8626894640922547}
2025-01-13 11:48:42,098 [INFO] Step[1250/4329]: training loss : 0.8574598264694214 TRAIN  loss dict:  {'classification_loss': 0.8574598264694214}
2025-01-13 11:49:02,881 [INFO] Step[1300/4329]: training loss : 0.859088442325592 TRAIN  loss dict:  {'classification_loss': 0.859088442325592}
2025-01-13 11:49:25,002 [INFO] Step[1350/4329]: training loss : 0.8642927873134613 TRAIN  loss dict:  {'classification_loss': 0.8642927873134613}
2025-01-13 11:49:40,949 [INFO] Step[1400/4329]: training loss : 0.8599236690998078 TRAIN  loss dict:  {'classification_loss': 0.8599236690998078}
2025-01-13 11:49:58,540 [INFO] Step[1450/4329]: training loss : 0.8586440026760102 TRAIN  loss dict:  {'classification_loss': 0.8586440026760102}
2025-01-13 11:50:13,905 [INFO] Step[1500/4329]: training loss : 0.8645533692836761 TRAIN  loss dict:  {'classification_loss': 0.8645533692836761}
2025-01-13 11:50:33,023 [INFO] Step[1550/4329]: training loss : 0.8633383405208588 TRAIN  loss dict:  {'classification_loss': 0.8633383405208588}
2025-01-13 11:50:53,207 [INFO] Step[1600/4329]: training loss : 0.8672864437103271 TRAIN  loss dict:  {'classification_loss': 0.8672864437103271}
2025-01-13 11:51:15,850 [INFO] Step[1650/4329]: training loss : 0.8588684153556824 TRAIN  loss dict:  {'classification_loss': 0.8588684153556824}
2025-01-13 11:51:33,881 [INFO] Step[1700/4329]: training loss : 0.8576308250427246 TRAIN  loss dict:  {'classification_loss': 0.8576308250427246}
2025-01-13 11:51:51,149 [INFO] Step[1750/4329]: training loss : 0.8592544579505921 TRAIN  loss dict:  {'classification_loss': 0.8592544579505921}
2025-01-13 11:52:06,527 [INFO] Step[1800/4329]: training loss : 0.8593569040298462 TRAIN  loss dict:  {'classification_loss': 0.8593569040298462}
2025-01-13 11:52:26,517 [INFO] Step[1850/4329]: training loss : 0.861344164609909 TRAIN  loss dict:  {'classification_loss': 0.861344164609909}
2025-01-13 11:52:44,762 [INFO] Step[1900/4329]: training loss : 0.8851079916954041 TRAIN  loss dict:  {'classification_loss': 0.8851079916954041}
2025-01-13 11:53:07,058 [INFO] Step[1950/4329]: training loss : 0.8835426867008209 TRAIN  loss dict:  {'classification_loss': 0.8835426867008209}
2025-01-13 11:53:25,099 [INFO] Step[2000/4329]: training loss : 0.8620860016345978 TRAIN  loss dict:  {'classification_loss': 0.8620860016345978}
2025-01-13 11:53:42,136 [INFO] Step[2050/4329]: training loss : 0.8619713616371155 TRAIN  loss dict:  {'classification_loss': 0.8619713616371155}
2025-01-13 11:53:57,759 [INFO] Step[2100/4329]: training loss : 0.8626377308368682 TRAIN  loss dict:  {'classification_loss': 0.8626377308368682}
2025-01-13 11:54:15,898 [INFO] Step[2150/4329]: training loss : 0.8594977021217346 TRAIN  loss dict:  {'classification_loss': 0.8594977021217346}
2025-01-13 11:54:29,802 [INFO] Step[2200/4329]: training loss : 0.8652355599403382 TRAIN  loss dict:  {'classification_loss': 0.8652355599403382}
2025-01-13 11:54:49,352 [INFO] Step[2250/4329]: training loss : 0.8593770051002503 TRAIN  loss dict:  {'classification_loss': 0.8593770051002503}
2025-01-13 11:55:10,591 [INFO] Step[2300/4329]: training loss : 0.8605468082427978 TRAIN  loss dict:  {'classification_loss': 0.8605468082427978}
2025-01-13 11:55:33,317 [INFO] Step[2350/4329]: training loss : 0.8652950608730317 TRAIN  loss dict:  {'classification_loss': 0.8652950608730317}
2025-01-13 11:55:50,728 [INFO] Step[2400/4329]: training loss : 0.8646210885047912 TRAIN  loss dict:  {'classification_loss': 0.8646210885047912}
2025-01-13 11:56:07,874 [INFO] Step[2450/4329]: training loss : 0.861188735961914 TRAIN  loss dict:  {'classification_loss': 0.861188735961914}
2025-01-13 11:56:23,110 [INFO] Step[2500/4329]: training loss : 0.8607025742530823 TRAIN  loss dict:  {'classification_loss': 0.8607025742530823}
2025-01-13 11:56:41,951 [INFO] Step[2550/4329]: training loss : 0.8719080150127411 TRAIN  loss dict:  {'classification_loss': 0.8719080150127411}
2025-01-13 11:57:01,995 [INFO] Step[2600/4329]: training loss : 0.8599941146373749 TRAIN  loss dict:  {'classification_loss': 0.8599941146373749}
2025-01-13 11:57:25,446 [INFO] Step[2650/4329]: training loss : 0.8589339280128478 TRAIN  loss dict:  {'classification_loss': 0.8589339280128478}
2025-01-13 11:57:43,421 [INFO] Step[2700/4329]: training loss : 0.8593500995635986 TRAIN  loss dict:  {'classification_loss': 0.8593500995635986}
2025-01-13 11:57:59,744 [INFO] Step[2750/4329]: training loss : 0.8596537673473358 TRAIN  loss dict:  {'classification_loss': 0.8596537673473358}
2025-01-13 11:58:16,424 [INFO] Step[2800/4329]: training loss : 0.8613623774051666 TRAIN  loss dict:  {'classification_loss': 0.8613623774051666}
2025-01-13 11:58:32,655 [INFO] Step[2850/4329]: training loss : 0.8614072346687317 TRAIN  loss dict:  {'classification_loss': 0.8614072346687317}
2025-01-13 11:58:52,208 [INFO] Step[2900/4329]: training loss : 0.8583690631389618 TRAIN  loss dict:  {'classification_loss': 0.8583690631389618}
2025-01-13 11:59:13,903 [INFO] Step[2950/4329]: training loss : 0.8651987278461456 TRAIN  loss dict:  {'classification_loss': 0.8651987278461456}
2025-01-13 11:59:35,067 [INFO] Step[3000/4329]: training loss : 0.8592038595676422 TRAIN  loss dict:  {'classification_loss': 0.8592038595676422}
2025-01-13 11:59:52,053 [INFO] Step[3050/4329]: training loss : 0.8598798763751984 TRAIN  loss dict:  {'classification_loss': 0.8598798763751984}
2025-01-13 12:00:09,869 [INFO] Step[3100/4329]: training loss : 0.8588132333755493 TRAIN  loss dict:  {'classification_loss': 0.8588132333755493}
2025-01-13 12:00:24,410 [INFO] Step[3150/4329]: training loss : 0.8770534539222717 TRAIN  loss dict:  {'classification_loss': 0.8770534539222717}
2025-01-13 12:00:43,290 [INFO] Step[3200/4329]: training loss : 0.8602458000183105 TRAIN  loss dict:  {'classification_loss': 0.8602458000183105}
2025-01-13 12:01:04,612 [INFO] Step[3250/4329]: training loss : 0.8606279850006103 TRAIN  loss dict:  {'classification_loss': 0.8606279850006103}
2025-01-13 12:01:27,413 [INFO] Step[3300/4329]: training loss : 0.8584403657913208 TRAIN  loss dict:  {'classification_loss': 0.8584403657913208}
2025-01-13 12:01:43,870 [INFO] Step[3350/4329]: training loss : 0.8613166785240174 TRAIN  loss dict:  {'classification_loss': 0.8613166785240174}
2025-01-13 12:02:01,467 [INFO] Step[3400/4329]: training loss : 0.8611698698997498 TRAIN  loss dict:  {'classification_loss': 0.8611698698997498}
2025-01-13 12:02:16,308 [INFO] Step[3450/4329]: training loss : 0.860436646938324 TRAIN  loss dict:  {'classification_loss': 0.860436646938324}
2025-01-13 12:02:34,343 [INFO] Step[3500/4329]: training loss : 0.860967972278595 TRAIN  loss dict:  {'classification_loss': 0.860967972278595}
2025-01-13 12:02:54,673 [INFO] Step[3550/4329]: training loss : 0.8607120347023011 TRAIN  loss dict:  {'classification_loss': 0.8607120347023011}
2025-01-13 12:03:16,781 [INFO] Step[3600/4329]: training loss : 0.8674537301063537 TRAIN  loss dict:  {'classification_loss': 0.8674537301063537}
2025-01-13 12:03:35,908 [INFO] Step[3650/4329]: training loss : 0.8702674031257629 TRAIN  loss dict:  {'classification_loss': 0.8702674031257629}
2025-01-13 12:03:52,704 [INFO] Step[3700/4329]: training loss : 0.8607891297340393 TRAIN  loss dict:  {'classification_loss': 0.8607891297340393}
2025-01-13 12:04:09,187 [INFO] Step[3750/4329]: training loss : 0.8647676706314087 TRAIN  loss dict:  {'classification_loss': 0.8647676706314087}
2025-01-13 12:04:26,478 [INFO] Step[3800/4329]: training loss : 0.859922661781311 TRAIN  loss dict:  {'classification_loss': 0.859922661781311}
2025-01-13 12:04:47,160 [INFO] Step[3850/4329]: training loss : 0.8590406584739685 TRAIN  loss dict:  {'classification_loss': 0.8590406584739685}
2025-01-13 12:05:09,595 [INFO] Step[3900/4329]: training loss : 0.8617481744289398 TRAIN  loss dict:  {'classification_loss': 0.8617481744289398}
2025-01-13 12:05:28,520 [INFO] Step[3950/4329]: training loss : 0.8587549877166748 TRAIN  loss dict:  {'classification_loss': 0.8587549877166748}
2025-01-13 12:05:45,635 [INFO] Step[4000/4329]: training loss : 0.8581838083267211 TRAIN  loss dict:  {'classification_loss': 0.8581838083267211}
2025-01-13 12:06:02,178 [INFO] Step[4050/4329]: training loss : 0.8589009642601013 TRAIN  loss dict:  {'classification_loss': 0.8589009642601013}
2025-01-13 12:06:13,847 [INFO] Step[4100/4329]: training loss : 0.8624257814884185 TRAIN  loss dict:  {'classification_loss': 0.8624257814884185}
2025-01-13 12:06:25,479 [INFO] Step[4150/4329]: training loss : 0.8607580614089966 TRAIN  loss dict:  {'classification_loss': 0.8607580614089966}
2025-01-13 12:06:37,348 [INFO] Step[4200/4329]: training loss : 0.8609274864196778 TRAIN  loss dict:  {'classification_loss': 0.8609274864196778}
2025-01-13 12:06:49,758 [INFO] Step[4250/4329]: training loss : 0.859816951751709 TRAIN  loss dict:  {'classification_loss': 0.859816951751709}
2025-01-13 12:07:02,052 [INFO] Step[4300/4329]: training loss : 0.8659919166564941 TRAIN  loss dict:  {'classification_loss': 0.8659919166564941}
2025-01-13 12:09:20,169 [INFO] Label accuracies statistics:
2025-01-13 12:09:20,169 [INFO] {0: 0.6666666666666666, 1: 0.8888888888888888, 2: 0.6666666666666666, 3: 0.75, 4: 0.25, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.5, 8: 0.5833333333333334, 9: 0.9166666666666666, 10: 1.0, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.5833333333333334, 14: 0.6666666666666666, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.6666666666666666, 18: 0.5, 19: 0.75, 20: 0.6666666666666666, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 1.0, 24: 1.0, 25: 0.6666666666666666, 26: 0.9166666666666666, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.5833333333333334, 31: 0.8333333333333334, 32: 0.75, 33: 0.9166666666666666, 34: 1.0, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 0.9166666666666666, 38: 1.0, 39: 1.0, 40: 0.9166666666666666, 41: 0.5, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.75, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.4166666666666667, 54: 0.5, 55: 0.6666666666666666, 56: 0.9166666666666666, 57: 0.75, 58: 0.5833333333333334, 59: 0.8333333333333334, 60: 0.75, 61: 0.9166666666666666, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.75, 69: 0.5833333333333334, 70: 0.4166666666666667, 71: 0.5833333333333334, 72: 0.75, 73: 1.0, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 0.9166666666666666, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.9166666666666666, 83: 0.6666666666666666, 84: 0.5833333333333334, 85: 0.6666666666666666, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.75, 89: 0.6666666666666666, 90: 0.6666666666666666, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 0.9166666666666666, 96: 0.4166666666666667, 97: 0.75, 98: 0.8333333333333334, 99: 1.0, 100: 0.8333333333333334, 101: 1.0, 102: 0.8333333333333334, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 1.0, 111: 0.9166666666666666, 112: 0.8333333333333334, 113: 0.3333333333333333, 114: 0.5833333333333334, 115: 1.0, 116: 0.75, 117: 0.75, 118: 0.9166666666666666, 119: 0.8333333333333334, 120: 0.8333333333333334, 121: 0.8333333333333334, 122: 0.8333333333333334, 123: 1.0, 124: 1.0, 125: 0.5833333333333334, 126: 0.9166666666666666, 127: 0.8333333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.9166666666666666, 132: 0.5833333333333334, 133: 1.0, 134: 0.8333333333333334, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 0.9166666666666666, 143: 1.0, 144: 0.5833333333333334, 145: 0.9166666666666666, 146: 1.0, 147: 0.9166666666666666, 148: 0.75, 149: 1.0, 150: 0.5, 151: 0.8333333333333334, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.6666666666666666, 157: 0.6666666666666666, 158: 0.7777777777777778, 159: 1.0, 160: 0.3333333333333333, 161: 0.9166666666666666, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.75, 166: 0.8333333333333334, 167: 0.8333333333333334, 168: 0.8333333333333334, 169: 1.0, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.6666666666666666, 178: 1.0, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.4166666666666667, 183: 0.8333333333333334, 184: 0.5833333333333334, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.5833333333333334, 189: 0.8333333333333334, 190: 0.5, 191: 0.6666666666666666, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.6666666666666666, 198: 0.75}

2025-01-13 12:09:20,172 [INFO] [67] TRAIN  loss: 0.8623894871066035 acc: 0.999229939935315
2025-01-13 12:09:20,172 [INFO] [67] TRAIN  loss dict: {'classification_loss': 0.8623894871066035}
2025-01-13 12:09:20,172 [INFO] [67] VALIDATION loss: 1.6241152001300243 VALIDATION acc: 0.8072390572390572
2025-01-13 12:09:20,172 [INFO] [67] VALIDATION loss dict: {'classification_loss': 1.6241152001300243}
2025-01-13 12:09:20,172 [INFO] 
2025-01-13 12:09:37,202 [INFO] Step[50/4329]: training loss : 0.8619034385681152 TRAIN  loss dict:  {'classification_loss': 0.8619034385681152}
2025-01-13 12:09:48,790 [INFO] Step[100/4329]: training loss : 0.8689915490150452 TRAIN  loss dict:  {'classification_loss': 0.8689915490150452}
2025-01-13 12:10:00,377 [INFO] Step[150/4329]: training loss : 0.8619538140296936 TRAIN  loss dict:  {'classification_loss': 0.8619538140296936}
2025-01-13 12:10:11,987 [INFO] Step[200/4329]: training loss : 0.8588539671897888 TRAIN  loss dict:  {'classification_loss': 0.8588539671897888}
2025-01-13 12:10:23,600 [INFO] Step[250/4329]: training loss : 0.8580058944225312 TRAIN  loss dict:  {'classification_loss': 0.8580058944225312}
2025-01-13 12:10:35,249 [INFO] Step[300/4329]: training loss : 0.8594067406654358 TRAIN  loss dict:  {'classification_loss': 0.8594067406654358}
2025-01-13 12:10:46,904 [INFO] Step[350/4329]: training loss : 0.8585826313495636 TRAIN  loss dict:  {'classification_loss': 0.8585826313495636}
2025-01-13 12:10:58,557 [INFO] Step[400/4329]: training loss : 0.8590709447860718 TRAIN  loss dict:  {'classification_loss': 0.8590709447860718}
2025-01-13 12:11:10,230 [INFO] Step[450/4329]: training loss : 0.8592415797710419 TRAIN  loss dict:  {'classification_loss': 0.8592415797710419}
2025-01-13 12:11:21,858 [INFO] Step[500/4329]: training loss : 0.8595363938808441 TRAIN  loss dict:  {'classification_loss': 0.8595363938808441}
2025-01-13 12:11:33,495 [INFO] Step[550/4329]: training loss : 0.860388662815094 TRAIN  loss dict:  {'classification_loss': 0.860388662815094}
2025-01-13 12:11:45,141 [INFO] Step[600/4329]: training loss : 0.8606499445438385 TRAIN  loss dict:  {'classification_loss': 0.8606499445438385}
2025-01-13 12:11:56,815 [INFO] Step[650/4329]: training loss : 0.8598618710041046 TRAIN  loss dict:  {'classification_loss': 0.8598618710041046}
2025-01-13 12:12:08,428 [INFO] Step[700/4329]: training loss : 0.8584940075874329 TRAIN  loss dict:  {'classification_loss': 0.8584940075874329}
2025-01-13 12:12:20,089 [INFO] Step[750/4329]: training loss : 0.8582311725616455 TRAIN  loss dict:  {'classification_loss': 0.8582311725616455}
2025-01-13 12:12:31,698 [INFO] Step[800/4329]: training loss : 0.8594919741153717 TRAIN  loss dict:  {'classification_loss': 0.8594919741153717}
2025-01-13 12:12:43,341 [INFO] Step[850/4329]: training loss : 0.8632833874225616 TRAIN  loss dict:  {'classification_loss': 0.8632833874225616}
2025-01-13 12:12:55,004 [INFO] Step[900/4329]: training loss : 0.8604686820507049 TRAIN  loss dict:  {'classification_loss': 0.8604686820507049}
2025-01-13 12:13:06,645 [INFO] Step[950/4329]: training loss : 0.8600327157974244 TRAIN  loss dict:  {'classification_loss': 0.8600327157974244}
2025-01-13 12:13:18,275 [INFO] Step[1000/4329]: training loss : 0.8596961736679077 TRAIN  loss dict:  {'classification_loss': 0.8596961736679077}
2025-01-13 12:13:29,913 [INFO] Step[1050/4329]: training loss : 0.8588830888271332 TRAIN  loss dict:  {'classification_loss': 0.8588830888271332}
2025-01-13 12:13:41,543 [INFO] Step[1100/4329]: training loss : 0.8578555715084076 TRAIN  loss dict:  {'classification_loss': 0.8578555715084076}
2025-01-13 12:13:53,202 [INFO] Step[1150/4329]: training loss : 0.8584229791164398 TRAIN  loss dict:  {'classification_loss': 0.8584229791164398}
2025-01-13 12:14:04,825 [INFO] Step[1200/4329]: training loss : 0.8583369660377502 TRAIN  loss dict:  {'classification_loss': 0.8583369660377502}
2025-01-13 12:14:16,468 [INFO] Step[1250/4329]: training loss : 0.8590975105762482 TRAIN  loss dict:  {'classification_loss': 0.8590975105762482}
2025-01-13 12:14:28,141 [INFO] Step[1300/4329]: training loss : 0.8587433063983917 TRAIN  loss dict:  {'classification_loss': 0.8587433063983917}
2025-01-13 12:14:39,792 [INFO] Step[1350/4329]: training loss : 0.8577407920360565 TRAIN  loss dict:  {'classification_loss': 0.8577407920360565}
2025-01-13 12:14:51,468 [INFO] Step[1400/4329]: training loss : 0.8656557834148407 TRAIN  loss dict:  {'classification_loss': 0.8656557834148407}
2025-01-13 12:15:03,119 [INFO] Step[1450/4329]: training loss : 0.8719872140884399 TRAIN  loss dict:  {'classification_loss': 0.8719872140884399}
2025-01-13 12:15:14,723 [INFO] Step[1500/4329]: training loss : 0.8643406641483307 TRAIN  loss dict:  {'classification_loss': 0.8643406641483307}
2025-01-13 12:15:26,365 [INFO] Step[1550/4329]: training loss : 0.8602489256858825 TRAIN  loss dict:  {'classification_loss': 0.8602489256858825}
2025-01-13 12:15:37,956 [INFO] Step[1600/4329]: training loss : 0.8651544177532196 TRAIN  loss dict:  {'classification_loss': 0.8651544177532196}
2025-01-13 12:15:49,615 [INFO] Step[1650/4329]: training loss : 0.8597431075572968 TRAIN  loss dict:  {'classification_loss': 0.8597431075572968}
2025-01-13 12:16:01,243 [INFO] Step[1700/4329]: training loss : 0.862453670501709 TRAIN  loss dict:  {'classification_loss': 0.862453670501709}
2025-01-13 12:16:12,828 [INFO] Step[1750/4329]: training loss : 0.8713429164886475 TRAIN  loss dict:  {'classification_loss': 0.8713429164886475}
2025-01-13 12:16:24,530 [INFO] Step[1800/4329]: training loss : 0.8580416738986969 TRAIN  loss dict:  {'classification_loss': 0.8580416738986969}
2025-01-13 12:16:36,155 [INFO] Step[1850/4329]: training loss : 0.8659089541435242 TRAIN  loss dict:  {'classification_loss': 0.8659089541435242}
2025-01-13 12:16:47,762 [INFO] Step[1900/4329]: training loss : 0.8596035659313201 TRAIN  loss dict:  {'classification_loss': 0.8596035659313201}
2025-01-13 12:16:59,396 [INFO] Step[1950/4329]: training loss : 0.8640389668941498 TRAIN  loss dict:  {'classification_loss': 0.8640389668941498}
2025-01-13 12:17:11,081 [INFO] Step[2000/4329]: training loss : 0.8614102470874786 TRAIN  loss dict:  {'classification_loss': 0.8614102470874786}
2025-01-13 12:17:22,670 [INFO] Step[2050/4329]: training loss : 0.8577574026584626 TRAIN  loss dict:  {'classification_loss': 0.8577574026584626}
2025-01-13 12:17:34,314 [INFO] Step[2100/4329]: training loss : 0.8717456662654877 TRAIN  loss dict:  {'classification_loss': 0.8717456662654877}
2025-01-13 12:17:45,930 [INFO] Step[2150/4329]: training loss : 0.8594518196582794 TRAIN  loss dict:  {'classification_loss': 0.8594518196582794}
2025-01-13 12:17:57,538 [INFO] Step[2200/4329]: training loss : 0.8589323842525483 TRAIN  loss dict:  {'classification_loss': 0.8589323842525483}
2025-01-13 12:18:09,165 [INFO] Step[2250/4329]: training loss : 0.8608561778068542 TRAIN  loss dict:  {'classification_loss': 0.8608561778068542}
2025-01-13 12:18:20,793 [INFO] Step[2300/4329]: training loss : 0.8602372205257416 TRAIN  loss dict:  {'classification_loss': 0.8602372205257416}
2025-01-13 12:18:32,476 [INFO] Step[2350/4329]: training loss : 0.8604156494140625 TRAIN  loss dict:  {'classification_loss': 0.8604156494140625}
2025-01-13 12:18:44,109 [INFO] Step[2400/4329]: training loss : 0.8588829982280731 TRAIN  loss dict:  {'classification_loss': 0.8588829982280731}
2025-01-13 12:18:55,924 [INFO] Step[2450/4329]: training loss : 0.8591521894931793 TRAIN  loss dict:  {'classification_loss': 0.8591521894931793}
2025-01-13 12:19:08,225 [INFO] Step[2500/4329]: training loss : 0.8602633380889892 TRAIN  loss dict:  {'classification_loss': 0.8602633380889892}
2025-01-13 12:19:20,499 [INFO] Step[2550/4329]: training loss : 0.8718248033523559 TRAIN  loss dict:  {'classification_loss': 0.8718248033523559}
2025-01-13 12:19:33,269 [INFO] Step[2600/4329]: training loss : 0.8704610085487365 TRAIN  loss dict:  {'classification_loss': 0.8704610085487365}
2025-01-13 12:19:46,612 [INFO] Step[2650/4329]: training loss : 0.861047911643982 TRAIN  loss dict:  {'classification_loss': 0.861047911643982}
2025-01-13 12:19:59,159 [INFO] Step[2700/4329]: training loss : 0.8587623250484466 TRAIN  loss dict:  {'classification_loss': 0.8587623250484466}
2025-01-13 12:20:11,078 [INFO] Step[2750/4329]: training loss : 0.858134936094284 TRAIN  loss dict:  {'classification_loss': 0.858134936094284}
2025-01-13 12:20:22,935 [INFO] Step[2800/4329]: training loss : 0.8593937432765961 TRAIN  loss dict:  {'classification_loss': 0.8593937432765961}
2025-01-13 12:20:34,609 [INFO] Step[2850/4329]: training loss : 0.8633105790615082 TRAIN  loss dict:  {'classification_loss': 0.8633105790615082}
2025-01-13 12:20:46,244 [INFO] Step[2900/4329]: training loss : 0.8602441251277924 TRAIN  loss dict:  {'classification_loss': 0.8602441251277924}
2025-01-13 12:20:57,849 [INFO] Step[2950/4329]: training loss : 0.8617435121536254 TRAIN  loss dict:  {'classification_loss': 0.8617435121536254}
2025-01-13 12:21:09,460 [INFO] Step[3000/4329]: training loss : 0.8618462884426117 TRAIN  loss dict:  {'classification_loss': 0.8618462884426117}
2025-01-13 12:21:21,095 [INFO] Step[3050/4329]: training loss : 0.8618145728111267 TRAIN  loss dict:  {'classification_loss': 0.8618145728111267}
2025-01-13 12:21:32,727 [INFO] Step[3100/4329]: training loss : 0.8614856481552124 TRAIN  loss dict:  {'classification_loss': 0.8614856481552124}
2025-01-13 12:21:44,388 [INFO] Step[3150/4329]: training loss : 0.8576278460025787 TRAIN  loss dict:  {'classification_loss': 0.8576278460025787}
2025-01-13 12:21:55,959 [INFO] Step[3200/4329]: training loss : 0.8583725082874298 TRAIN  loss dict:  {'classification_loss': 0.8583725082874298}
2025-01-13 12:22:07,616 [INFO] Step[3250/4329]: training loss : 0.8675496780872345 TRAIN  loss dict:  {'classification_loss': 0.8675496780872345}
2025-01-13 12:22:19,226 [INFO] Step[3300/4329]: training loss : 0.8595384800434113 TRAIN  loss dict:  {'classification_loss': 0.8595384800434113}
2025-01-13 12:22:30,852 [INFO] Step[3350/4329]: training loss : 0.8590996277332306 TRAIN  loss dict:  {'classification_loss': 0.8590996277332306}
2025-01-13 12:22:42,474 [INFO] Step[3400/4329]: training loss : 0.8596640193462372 TRAIN  loss dict:  {'classification_loss': 0.8596640193462372}
2025-01-13 12:22:54,088 [INFO] Step[3450/4329]: training loss : 0.8585146546363831 TRAIN  loss dict:  {'classification_loss': 0.8585146546363831}
2025-01-13 12:23:05,725 [INFO] Step[3500/4329]: training loss : 0.8591162121295929 TRAIN  loss dict:  {'classification_loss': 0.8591162121295929}
2025-01-13 12:23:17,316 [INFO] Step[3550/4329]: training loss : 0.8638335251808167 TRAIN  loss dict:  {'classification_loss': 0.8638335251808167}
2025-01-13 12:23:28,920 [INFO] Step[3600/4329]: training loss : 0.8663541269302368 TRAIN  loss dict:  {'classification_loss': 0.8663541269302368}
2025-01-13 12:23:40,554 [INFO] Step[3650/4329]: training loss : 0.858490332365036 TRAIN  loss dict:  {'classification_loss': 0.858490332365036}
2025-01-13 12:23:52,160 [INFO] Step[3700/4329]: training loss : 0.8609020125865936 TRAIN  loss dict:  {'classification_loss': 0.8609020125865936}
2025-01-13 12:24:03,781 [INFO] Step[3750/4329]: training loss : 0.8672141873836517 TRAIN  loss dict:  {'classification_loss': 0.8672141873836517}
2025-01-13 12:24:15,421 [INFO] Step[3800/4329]: training loss : 0.8588454568386078 TRAIN  loss dict:  {'classification_loss': 0.8588454568386078}
2025-01-13 12:24:27,106 [INFO] Step[3850/4329]: training loss : 0.8611973524093628 TRAIN  loss dict:  {'classification_loss': 0.8611973524093628}
2025-01-13 12:24:38,691 [INFO] Step[3900/4329]: training loss : 0.8762059557437897 TRAIN  loss dict:  {'classification_loss': 0.8762059557437897}
2025-01-13 12:24:50,326 [INFO] Step[3950/4329]: training loss : 0.858993272781372 TRAIN  loss dict:  {'classification_loss': 0.858993272781372}
2025-01-13 12:25:01,933 [INFO] Step[4000/4329]: training loss : 0.8584656286239624 TRAIN  loss dict:  {'classification_loss': 0.8584656286239624}
2025-01-13 12:25:13,567 [INFO] Step[4050/4329]: training loss : 0.8663504076004028 TRAIN  loss dict:  {'classification_loss': 0.8663504076004028}
2025-01-13 12:25:25,191 [INFO] Step[4100/4329]: training loss : 0.8609034287929535 TRAIN  loss dict:  {'classification_loss': 0.8609034287929535}
2025-01-13 12:25:36,848 [INFO] Step[4150/4329]: training loss : 0.8588880360126495 TRAIN  loss dict:  {'classification_loss': 0.8588880360126495}
2025-01-13 12:25:48,457 [INFO] Step[4200/4329]: training loss : 0.8593757927417756 TRAIN  loss dict:  {'classification_loss': 0.8593757927417756}
2025-01-13 12:26:00,159 [INFO] Step[4250/4329]: training loss : 0.8755694186687469 TRAIN  loss dict:  {'classification_loss': 0.8755694186687469}
2025-01-13 12:26:11,799 [INFO] Step[4300/4329]: training loss : 0.8622585809230805 TRAIN  loss dict:  {'classification_loss': 0.8622585809230805}
2025-01-13 12:28:12,957 [INFO] Label accuracies statistics:
2025-01-13 12:28:12,957 [INFO] {0: 0.4444444444444444, 1: 1.0, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5, 7: 0.5833333333333334, 8: 0.6666666666666666, 9: 0.9166666666666666, 10: 1.0, 11: 0.9166666666666666, 12: 0.5, 13: 0.5833333333333334, 14: 0.75, 15: 0.5555555555555556, 16: 0.6666666666666666, 17: 0.5833333333333334, 18: 0.5833333333333334, 19: 0.6666666666666666, 20: 0.5833333333333334, 21: 0.75, 22: 0.6666666666666666, 23: 0.9166666666666666, 24: 0.9166666666666666, 25: 0.8333333333333334, 26: 1.0, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.5833333333333334, 31: 0.8333333333333334, 32: 0.75, 33: 0.9166666666666666, 34: 1.0, 35: 0.8333333333333334, 36: 0.6666666666666666, 37: 0.9166666666666666, 38: 0.9166666666666666, 39: 1.0, 40: 0.8333333333333334, 41: 0.5, 42: 1.0, 43: 0.8333333333333334, 44: 0.5, 45: 0.5833333333333334, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.4166666666666667, 55: 0.6666666666666666, 56: 0.9166666666666666, 57: 0.75, 58: 0.5833333333333334, 59: 0.9166666666666666, 60: 0.8333333333333334, 61: 0.9166666666666666, 62: 0.75, 63: 0.6666666666666666, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.4166666666666667, 69: 0.6666666666666666, 70: 0.3333333333333333, 71: 0.5833333333333334, 72: 0.8333333333333334, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.6666666666666666, 78: 0.9166666666666666, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.8333333333333334, 83: 0.5, 84: 0.5833333333333334, 85: 0.6666666666666666, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.6666666666666666, 89: 0.5833333333333334, 90: 0.8333333333333334, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.6666666666666666, 97: 0.75, 98: 0.8333333333333334, 99: 1.0, 100: 0.8333333333333334, 101: 0.9166666666666666, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 0.9166666666666666, 106: 0.9166666666666666, 107: 0.75, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.9166666666666666, 111: 1.0, 112: 0.9166666666666666, 113: 0.5, 114: 0.5833333333333334, 115: 1.0, 116: 0.8333333333333334, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.8333333333333334, 121: 0.8333333333333334, 122: 0.9166666666666666, 123: 1.0, 124: 0.9166666666666666, 125: 0.8333333333333334, 126: 0.9166666666666666, 127: 0.9166666666666666, 128: 1.0, 129: 0.8333333333333334, 130: 0.75, 131: 0.9166666666666666, 132: 0.9166666666666666, 133: 1.0, 134: 0.75, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 0.9166666666666666, 142: 0.75, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.5833333333333334, 151: 0.9166666666666666, 152: 0.9166666666666666, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.4166666666666667, 161: 0.9166666666666666, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.9166666666666666, 169: 1.0, 170: 1.0, 171: 0.6666666666666666, 172: 1.0, 173: 0.6666666666666666, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 1.0, 177: 0.6666666666666666, 178: 1.0, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.6666666666666666, 183: 0.8333333333333334, 184: 0.75, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.6666666666666666, 189: 1.0, 190: 0.6666666666666666, 191: 0.6666666666666666, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.9166666666666666, 198: 0.75}

2025-01-13 12:28:12,959 [INFO] [68] TRAIN  loss: 0.8615643729456415 acc: 0.9993839519482519
2025-01-13 12:28:12,959 [INFO] [68] TRAIN  loss dict: {'classification_loss': 0.8615643729456415}
2025-01-13 12:28:12,959 [INFO] [68] VALIDATION loss: 1.606179420619902 VALIDATION acc: 0.8160774410774411
2025-01-13 12:28:12,959 [INFO] [68] VALIDATION loss dict: {'classification_loss': 1.606179420619902}
2025-01-13 12:28:12,959 [INFO] 
2025-01-13 12:28:48,031 [INFO] Step[50/4329]: training loss : 0.8593213939666748 TRAIN  loss dict:  {'classification_loss': 0.8593213939666748}
2025-01-13 12:29:02,424 [INFO] Step[100/4329]: training loss : 0.8592899131774903 TRAIN  loss dict:  {'classification_loss': 0.8592899131774903}
2025-01-13 12:29:16,816 [INFO] Step[150/4329]: training loss : 0.8614391410350799 TRAIN  loss dict:  {'classification_loss': 0.8614391410350799}
2025-01-13 12:29:31,352 [INFO] Step[200/4329]: training loss : 0.8609153878688812 TRAIN  loss dict:  {'classification_loss': 0.8609153878688812}
2025-01-13 12:29:46,156 [INFO] Step[250/4329]: training loss : 0.8623126339912415 TRAIN  loss dict:  {'classification_loss': 0.8623126339912415}
2025-01-13 12:30:00,642 [INFO] Step[300/4329]: training loss : 0.8591671574115753 TRAIN  loss dict:  {'classification_loss': 0.8591671574115753}
2025-01-13 12:30:14,864 [INFO] Step[350/4329]: training loss : 0.8607316195964814 TRAIN  loss dict:  {'classification_loss': 0.8607316195964814}
2025-01-13 12:30:29,019 [INFO] Step[400/4329]: training loss : 0.8588728511333465 TRAIN  loss dict:  {'classification_loss': 0.8588728511333465}
2025-01-13 12:30:43,537 [INFO] Step[450/4329]: training loss : 0.8589409339427948 TRAIN  loss dict:  {'classification_loss': 0.8589409339427948}
2025-01-13 12:30:57,944 [INFO] Step[500/4329]: training loss : 0.8576971924304962 TRAIN  loss dict:  {'classification_loss': 0.8576971924304962}
2025-01-13 12:31:12,705 [INFO] Step[550/4329]: training loss : 0.8592316508293152 TRAIN  loss dict:  {'classification_loss': 0.8592316508293152}
2025-01-13 12:31:27,319 [INFO] Step[600/4329]: training loss : 0.8669630455970764 TRAIN  loss dict:  {'classification_loss': 0.8669630455970764}
2025-01-13 12:31:41,165 [INFO] Step[650/4329]: training loss : 0.8585849082469941 TRAIN  loss dict:  {'classification_loss': 0.8585849082469941}
2025-01-13 12:31:54,953 [INFO] Step[700/4329]: training loss : 0.8609488940238953 TRAIN  loss dict:  {'classification_loss': 0.8609488940238953}
2025-01-13 12:32:08,805 [INFO] Step[750/4329]: training loss : 0.8592353475093841 TRAIN  loss dict:  {'classification_loss': 0.8592353475093841}
2025-01-13 12:32:25,463 [INFO] Step[800/4329]: training loss : 0.8616969883441925 TRAIN  loss dict:  {'classification_loss': 0.8616969883441925}
2025-01-13 12:32:39,374 [INFO] Step[850/4329]: training loss : 0.8596356749534607 TRAIN  loss dict:  {'classification_loss': 0.8596356749534607}
2025-01-13 12:32:53,123 [INFO] Step[900/4329]: training loss : 0.8651879119873047 TRAIN  loss dict:  {'classification_loss': 0.8651879119873047}
2025-01-13 12:33:07,279 [INFO] Step[950/4329]: training loss : 0.8603800201416015 TRAIN  loss dict:  {'classification_loss': 0.8603800201416015}
2025-01-13 12:33:21,804 [INFO] Step[1000/4329]: training loss : 0.8637770926952362 TRAIN  loss dict:  {'classification_loss': 0.8637770926952362}
2025-01-13 12:33:36,542 [INFO] Step[1050/4329]: training loss : 0.8594115948677064 TRAIN  loss dict:  {'classification_loss': 0.8594115948677064}
2025-01-13 12:33:51,237 [INFO] Step[1100/4329]: training loss : 0.8872154068946838 TRAIN  loss dict:  {'classification_loss': 0.8872154068946838}
2025-01-13 12:34:05,962 [INFO] Step[1150/4329]: training loss : 0.8610260951519012 TRAIN  loss dict:  {'classification_loss': 0.8610260951519012}
2025-01-13 12:34:20,360 [INFO] Step[1200/4329]: training loss : 0.8620048582553863 TRAIN  loss dict:  {'classification_loss': 0.8620048582553863}
2025-01-13 12:34:34,723 [INFO] Step[1250/4329]: training loss : 0.863661277294159 TRAIN  loss dict:  {'classification_loss': 0.863661277294159}
2025-01-13 12:34:48,975 [INFO] Step[1300/4329]: training loss : 0.8591609084606171 TRAIN  loss dict:  {'classification_loss': 0.8591609084606171}
2025-01-13 12:35:03,329 [INFO] Step[1350/4329]: training loss : 0.861875274181366 TRAIN  loss dict:  {'classification_loss': 0.861875274181366}
2025-01-13 12:35:16,337 [INFO] Step[1400/4329]: training loss : 0.8604591071605683 TRAIN  loss dict:  {'classification_loss': 0.8604591071605683}
2025-01-13 12:35:29,303 [INFO] Step[1450/4329]: training loss : 0.8589361190795899 TRAIN  loss dict:  {'classification_loss': 0.8589361190795899}
2025-01-13 12:35:43,279 [INFO] Step[1500/4329]: training loss : 0.8588086974620819 TRAIN  loss dict:  {'classification_loss': 0.8588086974620819}
2025-01-13 12:35:57,546 [INFO] Step[1550/4329]: training loss : 0.8630535995960236 TRAIN  loss dict:  {'classification_loss': 0.8630535995960236}
2025-01-13 12:36:12,022 [INFO] Step[1600/4329]: training loss : 0.8938428163528442 TRAIN  loss dict:  {'classification_loss': 0.8938428163528442}
2025-01-13 12:36:26,503 [INFO] Step[1650/4329]: training loss : 0.8580282831192017 TRAIN  loss dict:  {'classification_loss': 0.8580282831192017}
2025-01-13 12:36:40,976 [INFO] Step[1700/4329]: training loss : 0.858403422832489 TRAIN  loss dict:  {'classification_loss': 0.858403422832489}
2025-01-13 12:36:55,174 [INFO] Step[1750/4329]: training loss : 0.8586765801906586 TRAIN  loss dict:  {'classification_loss': 0.8586765801906586}
2025-01-13 12:37:09,674 [INFO] Step[1800/4329]: training loss : 0.8625428664684296 TRAIN  loss dict:  {'classification_loss': 0.8625428664684296}
2025-01-13 12:37:24,069 [INFO] Step[1850/4329]: training loss : 0.8590611302852631 TRAIN  loss dict:  {'classification_loss': 0.8590611302852631}
2025-01-13 12:37:38,657 [INFO] Step[1900/4329]: training loss : 0.8577353942394257 TRAIN  loss dict:  {'classification_loss': 0.8577353942394257}
2025-01-13 12:37:52,911 [INFO] Step[1950/4329]: training loss : 0.8624957263469696 TRAIN  loss dict:  {'classification_loss': 0.8624957263469696}
2025-01-13 12:38:07,477 [INFO] Step[2000/4329]: training loss : 0.8588534843921661 TRAIN  loss dict:  {'classification_loss': 0.8588534843921661}
2025-01-13 12:38:21,981 [INFO] Step[2050/4329]: training loss : 0.8599590992927552 TRAIN  loss dict:  {'classification_loss': 0.8599590992927552}
2025-01-13 12:38:36,259 [INFO] Step[2100/4329]: training loss : 0.8614273262023926 TRAIN  loss dict:  {'classification_loss': 0.8614273262023926}
2025-01-13 12:38:50,690 [INFO] Step[2150/4329]: training loss : 0.8613558518886566 TRAIN  loss dict:  {'classification_loss': 0.8613558518886566}
2025-01-13 12:39:04,890 [INFO] Step[2200/4329]: training loss : 0.858660444021225 TRAIN  loss dict:  {'classification_loss': 0.858660444021225}
2025-01-13 12:39:19,100 [INFO] Step[2250/4329]: training loss : 0.8602323400974273 TRAIN  loss dict:  {'classification_loss': 0.8602323400974273}
2025-01-13 12:39:33,591 [INFO] Step[2300/4329]: training loss : 0.8584597289562226 TRAIN  loss dict:  {'classification_loss': 0.8584597289562226}
2025-01-13 12:39:47,782 [INFO] Step[2350/4329]: training loss : 0.8604243695735931 TRAIN  loss dict:  {'classification_loss': 0.8604243695735931}
2025-01-13 12:40:02,279 [INFO] Step[2400/4329]: training loss : 0.8596481490135193 TRAIN  loss dict:  {'classification_loss': 0.8596481490135193}
2025-01-13 12:40:17,014 [INFO] Step[2450/4329]: training loss : 0.8712270045280457 TRAIN  loss dict:  {'classification_loss': 0.8712270045280457}
2025-01-13 12:40:31,565 [INFO] Step[2500/4329]: training loss : 0.8651394093036652 TRAIN  loss dict:  {'classification_loss': 0.8651394093036652}
2025-01-13 12:40:46,240 [INFO] Step[2550/4329]: training loss : 0.8648154509067535 TRAIN  loss dict:  {'classification_loss': 0.8648154509067535}
2025-01-13 12:41:00,688 [INFO] Step[2600/4329]: training loss : 0.8676287710666657 TRAIN  loss dict:  {'classification_loss': 0.8676287710666657}
2025-01-13 12:41:15,161 [INFO] Step[2650/4329]: training loss : 0.8622930765151977 TRAIN  loss dict:  {'classification_loss': 0.8622930765151977}
2025-01-13 12:41:29,606 [INFO] Step[2700/4329]: training loss : 0.8608712697029114 TRAIN  loss dict:  {'classification_loss': 0.8608712697029114}
2025-01-13 12:41:43,824 [INFO] Step[2750/4329]: training loss : 0.8625499665737152 TRAIN  loss dict:  {'classification_loss': 0.8625499665737152}
2025-01-13 12:41:58,537 [INFO] Step[2800/4329]: training loss : 0.8609505152702331 TRAIN  loss dict:  {'classification_loss': 0.8609505152702331}
2025-01-13 12:42:13,254 [INFO] Step[2850/4329]: training loss : 0.8694837665557862 TRAIN  loss dict:  {'classification_loss': 0.8694837665557862}
2025-01-13 12:42:27,543 [INFO] Step[2900/4329]: training loss : 0.8612070286273956 TRAIN  loss dict:  {'classification_loss': 0.8612070286273956}
2025-01-13 12:42:42,235 [INFO] Step[2950/4329]: training loss : 0.8582822215557099 TRAIN  loss dict:  {'classification_loss': 0.8582822215557099}
2025-01-13 12:42:56,526 [INFO] Step[3000/4329]: training loss : 0.8608138942718506 TRAIN  loss dict:  {'classification_loss': 0.8608138942718506}
2025-01-13 12:43:10,562 [INFO] Step[3050/4329]: training loss : 0.864602358341217 TRAIN  loss dict:  {'classification_loss': 0.864602358341217}
2025-01-13 12:43:23,503 [INFO] Step[3100/4329]: training loss : 0.8687012135982514 TRAIN  loss dict:  {'classification_loss': 0.8687012135982514}
2025-01-13 12:43:36,421 [INFO] Step[3150/4329]: training loss : 0.8639466416835785 TRAIN  loss dict:  {'classification_loss': 0.8639466416835785}
2025-01-13 12:43:50,895 [INFO] Step[3200/4329]: training loss : 0.859013774394989 TRAIN  loss dict:  {'classification_loss': 0.859013774394989}
2025-01-13 12:44:05,407 [INFO] Step[3250/4329]: training loss : 0.8595608270168305 TRAIN  loss dict:  {'classification_loss': 0.8595608270168305}
2025-01-13 12:44:19,697 [INFO] Step[3300/4329]: training loss : 0.8602547419071197 TRAIN  loss dict:  {'classification_loss': 0.8602547419071197}
2025-01-13 12:44:34,189 [INFO] Step[3350/4329]: training loss : 0.8586199343204498 TRAIN  loss dict:  {'classification_loss': 0.8586199343204498}
2025-01-13 12:44:48,470 [INFO] Step[3400/4329]: training loss : 0.869529333114624 TRAIN  loss dict:  {'classification_loss': 0.869529333114624}
2025-01-13 12:45:03,087 [INFO] Step[3450/4329]: training loss : 0.8610868334770203 TRAIN  loss dict:  {'classification_loss': 0.8610868334770203}
2025-01-13 12:45:16,670 [INFO] Step[3500/4329]: training loss : 0.8591562044620514 TRAIN  loss dict:  {'classification_loss': 0.8591562044620514}
2025-01-13 12:45:30,482 [INFO] Step[3550/4329]: training loss : 0.8595493113994599 TRAIN  loss dict:  {'classification_loss': 0.8595493113994599}
2025-01-13 12:45:44,888 [INFO] Step[3600/4329]: training loss : 0.8613111793994903 TRAIN  loss dict:  {'classification_loss': 0.8613111793994903}
2025-01-13 12:45:59,163 [INFO] Step[3650/4329]: training loss : 0.8604740691184998 TRAIN  loss dict:  {'classification_loss': 0.8604740691184998}
2025-01-13 12:46:13,468 [INFO] Step[3700/4329]: training loss : 0.8601603865623474 TRAIN  loss dict:  {'classification_loss': 0.8601603865623474}
2025-01-13 12:46:27,382 [INFO] Step[3750/4329]: training loss : 0.8605148100852966 TRAIN  loss dict:  {'classification_loss': 0.8605148100852966}
2025-01-13 12:46:41,669 [INFO] Step[3800/4329]: training loss : 0.8631553959846496 TRAIN  loss dict:  {'classification_loss': 0.8631553959846496}
2025-01-13 12:46:56,198 [INFO] Step[3850/4329]: training loss : 0.8650463473796844 TRAIN  loss dict:  {'classification_loss': 0.8650463473796844}
2025-01-13 12:47:10,729 [INFO] Step[3900/4329]: training loss : 0.858857445716858 TRAIN  loss dict:  {'classification_loss': 0.858857445716858}
2025-01-13 12:47:25,519 [INFO] Step[3950/4329]: training loss : 0.8709075129032136 TRAIN  loss dict:  {'classification_loss': 0.8709075129032136}
2025-01-13 12:47:40,209 [INFO] Step[4000/4329]: training loss : 0.8584045267105103 TRAIN  loss dict:  {'classification_loss': 0.8584045267105103}
2025-01-13 12:47:54,503 [INFO] Step[4050/4329]: training loss : 0.859569787979126 TRAIN  loss dict:  {'classification_loss': 0.859569787979126}
2025-01-13 12:48:08,701 [INFO] Step[4100/4329]: training loss : 0.8594505119323731 TRAIN  loss dict:  {'classification_loss': 0.8594505119323731}
2025-01-13 12:48:23,162 [INFO] Step[4150/4329]: training loss : 0.8614804148674011 TRAIN  loss dict:  {'classification_loss': 0.8614804148674011}
2025-01-13 12:48:37,869 [INFO] Step[4200/4329]: training loss : 0.858873485326767 TRAIN  loss dict:  {'classification_loss': 0.858873485326767}
2025-01-13 12:48:52,398 [INFO] Step[4250/4329]: training loss : 0.8766155612468719 TRAIN  loss dict:  {'classification_loss': 0.8766155612468719}
2025-01-13 12:49:06,938 [INFO] Step[4300/4329]: training loss : 0.8607491862773895 TRAIN  loss dict:  {'classification_loss': 0.8607491862773895}
2025-01-13 12:51:33,485 [INFO] Label accuracies statistics:
2025-01-13 12:51:33,485 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.5833333333333334, 8: 0.6666666666666666, 9: 1.0, 10: 1.0, 11: 0.8333333333333334, 12: 0.4166666666666667, 13: 0.5833333333333334, 14: 0.75, 15: 0.6666666666666666, 16: 0.5833333333333334, 17: 0.4166666666666667, 18: 0.5833333333333334, 19: 0.6666666666666666, 20: 0.6666666666666666, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.8333333333333334, 26: 0.75, 27: 0.5833333333333334, 28: 0.8333333333333334, 29: 1.0, 30: 0.6666666666666666, 31: 0.6666666666666666, 32: 0.75, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.8333333333333334, 41: 0.5, 42: 0.9166666666666666, 43: 1.0, 44: 0.4166666666666667, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.8333333333333334, 51: 0.75, 52: 1.0, 53: 0.5833333333333334, 54: 0.5, 55: 0.75, 56: 0.8333333333333334, 57: 0.6666666666666666, 58: 0.4166666666666667, 59: 0.9166666666666666, 60: 0.6666666666666666, 61: 1.0, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.75, 69: 0.6666666666666666, 70: 0.5, 71: 0.5833333333333334, 72: 0.9166666666666666, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 1.0, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5833333333333334, 85: 0.8333333333333334, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.8333333333333334, 89: 0.5833333333333334, 90: 0.6666666666666666, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.4166666666666667, 97: 0.75, 98: 0.8333333333333334, 99: 1.0, 100: 0.9166666666666666, 101: 0.9166666666666666, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.9166666666666666, 106: 0.8333333333333334, 107: 0.6666666666666666, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 0.9166666666666666, 111: 1.0, 112: 1.0, 113: 0.75, 114: 0.4166666666666667, 115: 0.8333333333333334, 116: 0.8333333333333334, 117: 0.9166666666666666, 118: 0.9166666666666666, 119: 0.75, 120: 0.75, 121: 0.9166666666666666, 122: 0.75, 123: 1.0, 124: 1.0, 125: 0.8333333333333334, 126: 1.0, 127: 0.8333333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.8333333333333334, 132: 0.4166666666666667, 133: 1.0, 134: 0.9166666666666666, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 1.0, 141: 0.9166666666666666, 142: 0.9166666666666666, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.5, 151: 0.8333333333333334, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 0.9166666666666666, 156: 0.5833333333333334, 157: 0.8333333333333334, 158: 0.7777777777777778, 159: 1.0, 160: 0.4166666666666667, 161: 0.8333333333333334, 162: 1.0, 163: 0.9166666666666666, 164: 0.8333333333333334, 165: 0.75, 166: 0.8333333333333334, 167: 0.8333333333333334, 168: 0.9166666666666666, 169: 0.8333333333333334, 170: 1.0, 171: 0.5833333333333334, 172: 1.0, 173: 0.75, 174: 0.8333333333333334, 175: 0.8333333333333334, 176: 0.9166666666666666, 177: 0.8333333333333334, 178: 0.9166666666666666, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.75, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.8333333333333334, 189: 1.0, 190: 0.6666666666666666, 191: 0.6666666666666666, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.75}

2025-01-13 12:51:33,488 [INFO] [69] TRAIN  loss: 0.8621274412270368 acc: 0.999537963961189
2025-01-13 12:51:33,488 [INFO] [69] TRAIN  loss dict: {'classification_loss': 0.8621274412270368}
2025-01-13 12:51:33,488 [INFO] [69] VALIDATION loss: 1.5942326504925284 VALIDATION acc: 0.819023569023569
2025-01-13 12:51:33,488 [INFO] [69] VALIDATION loss dict: {'classification_loss': 1.5942326504925284}
2025-01-13 12:51:33,488 [INFO] 
2025-01-13 12:51:54,239 [INFO] Step[50/4329]: training loss : 0.8583942341804505 TRAIN  loss dict:  {'classification_loss': 0.8583942341804505}
2025-01-13 12:52:08,806 [INFO] Step[100/4329]: training loss : 0.8653704357147217 TRAIN  loss dict:  {'classification_loss': 0.8653704357147217}
2025-01-13 12:52:23,031 [INFO] Step[150/4329]: training loss : 0.8605138230323791 TRAIN  loss dict:  {'classification_loss': 0.8605138230323791}
2025-01-13 12:52:37,715 [INFO] Step[200/4329]: training loss : 0.8739151871204376 TRAIN  loss dict:  {'classification_loss': 0.8739151871204376}
2025-01-13 12:52:52,156 [INFO] Step[250/4329]: training loss : 0.8800538516044617 TRAIN  loss dict:  {'classification_loss': 0.8800538516044617}
2025-01-13 12:53:06,518 [INFO] Step[300/4329]: training loss : 0.8602668225765229 TRAIN  loss dict:  {'classification_loss': 0.8602668225765229}
2025-01-13 12:53:21,147 [INFO] Step[350/4329]: training loss : 0.8595704925060272 TRAIN  loss dict:  {'classification_loss': 0.8595704925060272}
2025-01-13 12:53:35,507 [INFO] Step[400/4329]: training loss : 0.859758906364441 TRAIN  loss dict:  {'classification_loss': 0.859758906364441}
2025-01-13 12:53:50,244 [INFO] Step[450/4329]: training loss : 0.860635975599289 TRAIN  loss dict:  {'classification_loss': 0.860635975599289}
2025-01-13 12:54:04,746 [INFO] Step[500/4329]: training loss : 0.859259557723999 TRAIN  loss dict:  {'classification_loss': 0.859259557723999}
2025-01-13 12:54:19,172 [INFO] Step[550/4329]: training loss : 0.8635714209079742 TRAIN  loss dict:  {'classification_loss': 0.8635714209079742}
2025-01-13 12:54:33,469 [INFO] Step[600/4329]: training loss : 0.8681689131259919 TRAIN  loss dict:  {'classification_loss': 0.8681689131259919}
2025-01-13 12:54:48,175 [INFO] Step[650/4329]: training loss : 0.8598632431030273 TRAIN  loss dict:  {'classification_loss': 0.8598632431030273}
2025-01-13 12:55:02,508 [INFO] Step[700/4329]: training loss : 0.8608466041088104 TRAIN  loss dict:  {'classification_loss': 0.8608466041088104}
2025-01-13 12:55:16,958 [INFO] Step[750/4329]: training loss : 0.8600883519649506 TRAIN  loss dict:  {'classification_loss': 0.8600883519649506}
2025-01-13 12:55:31,217 [INFO] Step[800/4329]: training loss : 0.8593439447879792 TRAIN  loss dict:  {'classification_loss': 0.8593439447879792}
2025-01-13 12:55:45,706 [INFO] Step[850/4329]: training loss : 0.8613913869857788 TRAIN  loss dict:  {'classification_loss': 0.8613913869857788}
2025-01-13 12:56:00,384 [INFO] Step[900/4329]: training loss : 0.8594992518424988 TRAIN  loss dict:  {'classification_loss': 0.8594992518424988}
2025-01-13 12:56:14,850 [INFO] Step[950/4329]: training loss : 0.8620404005050659 TRAIN  loss dict:  {'classification_loss': 0.8620404005050659}
2025-01-13 12:56:29,621 [INFO] Step[1000/4329]: training loss : 0.8615323948860169 TRAIN  loss dict:  {'classification_loss': 0.8615323948860169}
2025-01-13 12:56:44,116 [INFO] Step[1050/4329]: training loss : 0.8646798205375671 TRAIN  loss dict:  {'classification_loss': 0.8646798205375671}
2025-01-13 12:56:58,557 [INFO] Step[1100/4329]: training loss : 0.8659689176082611 TRAIN  loss dict:  {'classification_loss': 0.8659689176082611}
2025-01-13 12:57:13,339 [INFO] Step[1150/4329]: training loss : 0.8591616082191468 TRAIN  loss dict:  {'classification_loss': 0.8591616082191468}
2025-01-13 12:57:28,036 [INFO] Step[1200/4329]: training loss : 0.8616882991790772 TRAIN  loss dict:  {'classification_loss': 0.8616882991790772}
2025-01-13 12:57:42,246 [INFO] Step[1250/4329]: training loss : 0.8588163614273071 TRAIN  loss dict:  {'classification_loss': 0.8588163614273071}
2025-01-13 12:57:56,755 [INFO] Step[1300/4329]: training loss : 0.8623691380023957 TRAIN  loss dict:  {'classification_loss': 0.8623691380023957}
2025-01-13 12:58:10,965 [INFO] Step[1350/4329]: training loss : 0.8621443712711334 TRAIN  loss dict:  {'classification_loss': 0.8621443712711334}
2025-01-13 12:58:25,545 [INFO] Step[1400/4329]: training loss : 0.861195033788681 TRAIN  loss dict:  {'classification_loss': 0.861195033788681}
2025-01-13 12:58:39,433 [INFO] Step[1450/4329]: training loss : 0.8602317094802856 TRAIN  loss dict:  {'classification_loss': 0.8602317094802856}
2025-01-13 12:58:53,244 [INFO] Step[1500/4329]: training loss : 0.8604657328128815 TRAIN  loss dict:  {'classification_loss': 0.8604657328128815}
2025-01-13 12:59:07,342 [INFO] Step[1550/4329]: training loss : 0.8593087840080261 TRAIN  loss dict:  {'classification_loss': 0.8593087840080261}
2025-01-13 12:59:21,323 [INFO] Step[1600/4329]: training loss : 0.8600952517986298 TRAIN  loss dict:  {'classification_loss': 0.8600952517986298}
2025-01-13 12:59:35,586 [INFO] Step[1650/4329]: training loss : 0.859065010547638 TRAIN  loss dict:  {'classification_loss': 0.859065010547638}
2025-01-13 12:59:49,661 [INFO] Step[1700/4329]: training loss : 0.8585141825675965 TRAIN  loss dict:  {'classification_loss': 0.8585141825675965}
2025-01-13 13:00:04,094 [INFO] Step[1750/4329]: training loss : 0.8586398410797119 TRAIN  loss dict:  {'classification_loss': 0.8586398410797119}
2025-01-13 13:00:18,689 [INFO] Step[1800/4329]: training loss : 0.8614010846614838 TRAIN  loss dict:  {'classification_loss': 0.8614010846614838}
2025-01-13 13:00:33,444 [INFO] Step[1850/4329]: training loss : 0.8580495655536652 TRAIN  loss dict:  {'classification_loss': 0.8580495655536652}
2025-01-13 13:00:48,086 [INFO] Step[1900/4329]: training loss : 0.8680199122428894 TRAIN  loss dict:  {'classification_loss': 0.8680199122428894}
2025-01-13 13:01:02,666 [INFO] Step[1950/4329]: training loss : 0.8623124301433563 TRAIN  loss dict:  {'classification_loss': 0.8623124301433563}
2025-01-13 13:01:17,442 [INFO] Step[2000/4329]: training loss : 0.87074951171875 TRAIN  loss dict:  {'classification_loss': 0.87074951171875}
2025-01-13 13:01:32,198 [INFO] Step[2050/4329]: training loss : 0.857807092666626 TRAIN  loss dict:  {'classification_loss': 0.857807092666626}
2025-01-13 13:01:46,750 [INFO] Step[2100/4329]: training loss : 0.8679581034183502 TRAIN  loss dict:  {'classification_loss': 0.8679581034183502}
2025-01-13 13:02:01,378 [INFO] Step[2150/4329]: training loss : 0.8596920478343963 TRAIN  loss dict:  {'classification_loss': 0.8596920478343963}
2025-01-13 13:02:15,541 [INFO] Step[2200/4329]: training loss : 0.8596112775802612 TRAIN  loss dict:  {'classification_loss': 0.8596112775802612}
2025-01-13 13:02:29,925 [INFO] Step[2250/4329]: training loss : 0.8596157252788543 TRAIN  loss dict:  {'classification_loss': 0.8596157252788543}
2025-01-13 13:02:44,518 [INFO] Step[2300/4329]: training loss : 0.8576040422916412 TRAIN  loss dict:  {'classification_loss': 0.8576040422916412}
2025-01-13 13:02:58,823 [INFO] Step[2350/4329]: training loss : 0.8585157406330108 TRAIN  loss dict:  {'classification_loss': 0.8585157406330108}
2025-01-13 13:03:13,361 [INFO] Step[2400/4329]: training loss : 0.857894504070282 TRAIN  loss dict:  {'classification_loss': 0.857894504070282}
2025-01-13 13:03:28,051 [INFO] Step[2450/4329]: training loss : 0.8598046529293061 TRAIN  loss dict:  {'classification_loss': 0.8598046529293061}
2025-01-13 13:03:42,533 [INFO] Step[2500/4329]: training loss : 0.8605997943878174 TRAIN  loss dict:  {'classification_loss': 0.8605997943878174}
2025-01-13 13:03:56,985 [INFO] Step[2550/4329]: training loss : 0.8593978428840637 TRAIN  loss dict:  {'classification_loss': 0.8593978428840637}
2025-01-13 13:04:11,447 [INFO] Step[2600/4329]: training loss : 0.8593309259414673 TRAIN  loss dict:  {'classification_loss': 0.8593309259414673}
2025-01-13 13:04:26,067 [INFO] Step[2650/4329]: training loss : 0.8596587145328521 TRAIN  loss dict:  {'classification_loss': 0.8596587145328521}
2025-01-13 13:04:40,284 [INFO] Step[2700/4329]: training loss : 0.8664280581474304 TRAIN  loss dict:  {'classification_loss': 0.8664280581474304}
2025-01-13 13:04:54,737 [INFO] Step[2750/4329]: training loss : 0.8672605073451995 TRAIN  loss dict:  {'classification_loss': 0.8672605073451995}
2025-01-13 13:05:09,124 [INFO] Step[2800/4329]: training loss : 0.8594955027103424 TRAIN  loss dict:  {'classification_loss': 0.8594955027103424}
2025-01-13 13:05:23,829 [INFO] Step[2850/4329]: training loss : 0.8629058337211609 TRAIN  loss dict:  {'classification_loss': 0.8629058337211609}
2025-01-13 13:05:38,259 [INFO] Step[2900/4329]: training loss : 0.8605958795547486 TRAIN  loss dict:  {'classification_loss': 0.8605958795547486}
2025-01-13 13:05:52,442 [INFO] Step[2950/4329]: training loss : 0.8615662443637848 TRAIN  loss dict:  {'classification_loss': 0.8615662443637848}
2025-01-13 13:06:06,801 [INFO] Step[3000/4329]: training loss : 0.8583668637275695 TRAIN  loss dict:  {'classification_loss': 0.8583668637275695}
2025-01-13 13:06:21,341 [INFO] Step[3050/4329]: training loss : 0.8576011693477631 TRAIN  loss dict:  {'classification_loss': 0.8576011693477631}
2025-01-13 13:06:35,716 [INFO] Step[3100/4329]: training loss : 0.8591026341915131 TRAIN  loss dict:  {'classification_loss': 0.8591026341915131}
2025-01-13 13:06:50,339 [INFO] Step[3150/4329]: training loss : 0.8602722585201263 TRAIN  loss dict:  {'classification_loss': 0.8602722585201263}
2025-01-13 13:07:05,084 [INFO] Step[3200/4329]: training loss : 0.8606414949893951 TRAIN  loss dict:  {'classification_loss': 0.8606414949893951}
2025-01-13 13:07:19,516 [INFO] Step[3250/4329]: training loss : 0.8600989818572998 TRAIN  loss dict:  {'classification_loss': 0.8600989818572998}
2025-01-13 13:07:33,686 [INFO] Step[3300/4329]: training loss : 0.8592501151561737 TRAIN  loss dict:  {'classification_loss': 0.8592501151561737}
2025-01-13 13:07:48,154 [INFO] Step[3350/4329]: training loss : 0.8609860527515412 TRAIN  loss dict:  {'classification_loss': 0.8609860527515412}
2025-01-13 13:08:02,794 [INFO] Step[3400/4329]: training loss : 0.8984546780586242 TRAIN  loss dict:  {'classification_loss': 0.8984546780586242}
2025-01-13 13:08:17,474 [INFO] Step[3450/4329]: training loss : 0.8579787886142731 TRAIN  loss dict:  {'classification_loss': 0.8579787886142731}
2025-01-13 13:08:32,061 [INFO] Step[3500/4329]: training loss : 0.860372724533081 TRAIN  loss dict:  {'classification_loss': 0.860372724533081}
2025-01-13 13:08:46,588 [INFO] Step[3550/4329]: training loss : 0.8621323704719543 TRAIN  loss dict:  {'classification_loss': 0.8621323704719543}
2025-01-13 13:09:01,218 [INFO] Step[3600/4329]: training loss : 0.862409679889679 TRAIN  loss dict:  {'classification_loss': 0.862409679889679}
2025-01-13 13:09:15,966 [INFO] Step[3650/4329]: training loss : 0.8603702640533447 TRAIN  loss dict:  {'classification_loss': 0.8603702640533447}
2025-01-13 13:09:30,458 [INFO] Step[3700/4329]: training loss : 0.8669657278060913 TRAIN  loss dict:  {'classification_loss': 0.8669657278060913}
2025-01-13 13:09:44,264 [INFO] Step[3750/4329]: training loss : 0.8656666696071624 TRAIN  loss dict:  {'classification_loss': 0.8656666696071624}
2025-01-13 13:09:57,146 [INFO] Step[3800/4329]: training loss : 0.8662365067005158 TRAIN  loss dict:  {'classification_loss': 0.8662365067005158}
2025-01-13 13:10:10,842 [INFO] Step[3850/4329]: training loss : 0.8595293307304382 TRAIN  loss dict:  {'classification_loss': 0.8595293307304382}
2025-01-13 13:10:25,275 [INFO] Step[3900/4329]: training loss : 0.858402191400528 TRAIN  loss dict:  {'classification_loss': 0.858402191400528}
2025-01-13 13:10:39,999 [INFO] Step[3950/4329]: training loss : 0.8586374914646149 TRAIN  loss dict:  {'classification_loss': 0.8586374914646149}
2025-01-13 13:10:54,686 [INFO] Step[4000/4329]: training loss : 0.8618919801712036 TRAIN  loss dict:  {'classification_loss': 0.8618919801712036}
2025-01-13 13:11:08,866 [INFO] Step[4050/4329]: training loss : 0.859131531715393 TRAIN  loss dict:  {'classification_loss': 0.859131531715393}
2025-01-13 13:11:23,473 [INFO] Step[4100/4329]: training loss : 0.8617873513698577 TRAIN  loss dict:  {'classification_loss': 0.8617873513698577}
2025-01-13 13:11:37,889 [INFO] Step[4150/4329]: training loss : 0.8586303865909577 TRAIN  loss dict:  {'classification_loss': 0.8586303865909577}
2025-01-13 13:11:52,075 [INFO] Step[4200/4329]: training loss : 0.8593182456493378 TRAIN  loss dict:  {'classification_loss': 0.8593182456493378}
2025-01-13 13:12:05,831 [INFO] Step[4250/4329]: training loss : 0.8609906327724457 TRAIN  loss dict:  {'classification_loss': 0.8609906327724457}
2025-01-13 13:12:19,834 [INFO] Step[4300/4329]: training loss : 0.8591535055637359 TRAIN  loss dict:  {'classification_loss': 0.8591535055637359}
2025-01-13 13:15:00,983 [INFO] Label accuracies statistics:
2025-01-13 13:15:00,983 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.5, 8: 0.75, 9: 0.8333333333333334, 10: 1.0, 11: 0.8333333333333334, 12: 0.4166666666666667, 13: 0.5, 14: 0.75, 15: 0.7777777777777778, 16: 0.6666666666666666, 17: 0.5, 18: 0.6666666666666666, 19: 0.75, 20: 0.5, 21: 0.6666666666666666, 22: 0.75, 23: 0.9166666666666666, 24: 0.9166666666666666, 25: 0.6666666666666666, 26: 0.8333333333333334, 27: 0.5833333333333334, 28: 1.0, 29: 1.0, 30: 0.5833333333333334, 31: 0.8333333333333334, 32: 0.6666666666666666, 33: 0.9166666666666666, 34: 1.0, 35: 1.0, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.9166666666666666, 41: 0.5833333333333334, 42: 0.9166666666666666, 43: 0.8333333333333334, 44: 0.6666666666666666, 45: 0.5833333333333334, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.9166666666666666, 52: 1.0, 53: 0.6666666666666666, 54: 0.4166666666666667, 55: 0.6666666666666666, 56: 0.8333333333333334, 57: 0.6666666666666666, 58: 0.5833333333333334, 59: 0.9166666666666666, 60: 0.9166666666666666, 61: 0.9166666666666666, 62: 0.75, 63: 0.6666666666666666, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.75, 69: 0.6666666666666666, 70: 0.3333333333333333, 71: 0.5833333333333334, 72: 0.8333333333333334, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.9166666666666666, 82: 0.6666666666666666, 83: 0.8333333333333334, 84: 0.6666666666666666, 85: 0.75, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.75, 89: 0.5, 90: 0.8333333333333334, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 1.0, 96: 0.3333333333333333, 97: 0.8333333333333334, 98: 1.0, 99: 0.9333333333333333, 100: 0.75, 101: 0.9166666666666666, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 0.9166666666666666, 106: 1.0, 107: 0.5, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.9166666666666666, 111: 0.9166666666666666, 112: 0.9166666666666666, 113: 0.5, 114: 0.5, 115: 0.9166666666666666, 116: 0.75, 117: 0.8333333333333334, 118: 0.9166666666666666, 119: 0.6666666666666666, 120: 0.8333333333333334, 121: 0.8333333333333334, 122: 0.8333333333333334, 123: 0.9166666666666666, 124: 1.0, 125: 0.75, 126: 0.8333333333333334, 127: 0.8333333333333334, 128: 1.0, 129: 0.8333333333333334, 130: 0.75, 131: 0.8333333333333334, 132: 0.5, 133: 1.0, 134: 0.5833333333333334, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.6666666666666666, 145: 1.0, 146: 1.0, 147: 0.9166666666666666, 148: 0.8333333333333334, 149: 1.0, 150: 0.5, 151: 0.9166666666666666, 152: 0.9166666666666666, 153: 0.8333333333333334, 154: 1.0, 155: 1.0, 156: 0.6666666666666666, 157: 0.8333333333333334, 158: 0.5555555555555556, 159: 1.0, 160: 0.4166666666666667, 161: 0.9166666666666666, 162: 1.0, 163: 0.9166666666666666, 164: 0.8333333333333334, 165: 0.75, 166: 0.8333333333333334, 167: 0.75, 168: 0.9166666666666666, 169: 1.0, 170: 0.9166666666666666, 171: 0.5, 172: 1.0, 173: 0.6666666666666666, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.6666666666666666, 183: 0.8333333333333334, 184: 0.8333333333333334, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 1.0, 190: 0.5833333333333334, 191: 0.6666666666666666, 192: 0.9166666666666666, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 1.0, 197: 0.9166666666666666, 198: 0.75}

2025-01-13 13:15:00,985 [INFO] [70] TRAIN  loss: 0.8618094538617944 acc: 0.9994609579547205
2025-01-13 13:15:00,985 [INFO] [70] TRAIN  loss dict: {'classification_loss': 0.8618094538617944}
2025-01-13 13:15:00,986 [INFO] [70] VALIDATION loss: 1.6055557207778246 VALIDATION acc: 0.8114478114478114
2025-01-13 13:15:00,986 [INFO] [70] VALIDATION loss dict: {'classification_loss': 1.6055557207778246}
2025-01-13 13:15:00,986 [INFO] 
2025-01-13 13:15:21,727 [INFO] Step[50/4329]: training loss : 0.8637381601333618 TRAIN  loss dict:  {'classification_loss': 0.8637381601333618}
2025-01-13 13:15:36,403 [INFO] Step[100/4329]: training loss : 0.8678458094596863 TRAIN  loss dict:  {'classification_loss': 0.8678458094596863}
2025-01-13 13:15:50,975 [INFO] Step[150/4329]: training loss : 0.8614123332500457 TRAIN  loss dict:  {'classification_loss': 0.8614123332500457}
2025-01-13 13:16:05,280 [INFO] Step[200/4329]: training loss : 0.8611090850830078 TRAIN  loss dict:  {'classification_loss': 0.8611090850830078}
2025-01-13 13:16:19,895 [INFO] Step[250/4329]: training loss : 0.8605478024482727 TRAIN  loss dict:  {'classification_loss': 0.8605478024482727}
2025-01-13 13:16:34,257 [INFO] Step[300/4329]: training loss : 0.8588181483745575 TRAIN  loss dict:  {'classification_loss': 0.8588181483745575}
2025-01-13 13:16:48,561 [INFO] Step[350/4329]: training loss : 0.8589660608768463 TRAIN  loss dict:  {'classification_loss': 0.8589660608768463}
2025-01-13 13:17:03,023 [INFO] Step[400/4329]: training loss : 0.8595231807231903 TRAIN  loss dict:  {'classification_loss': 0.8595231807231903}
2025-01-13 13:17:17,794 [INFO] Step[450/4329]: training loss : 0.8600288200378418 TRAIN  loss dict:  {'classification_loss': 0.8600288200378418}
2025-01-13 13:17:31,986 [INFO] Step[500/4329]: training loss : 0.8597646284103394 TRAIN  loss dict:  {'classification_loss': 0.8597646284103394}
2025-01-13 13:17:46,223 [INFO] Step[550/4329]: training loss : 0.863608980178833 TRAIN  loss dict:  {'classification_loss': 0.863608980178833}
2025-01-13 13:18:00,653 [INFO] Step[600/4329]: training loss : 0.8590238475799561 TRAIN  loss dict:  {'classification_loss': 0.8590238475799561}
2025-01-13 13:18:15,332 [INFO] Step[650/4329]: training loss : 0.8603867721557618 TRAIN  loss dict:  {'classification_loss': 0.8603867721557618}
2025-01-13 13:18:29,558 [INFO] Step[700/4329]: training loss : 0.8681281018257141 TRAIN  loss dict:  {'classification_loss': 0.8681281018257141}
2025-01-13 13:18:43,730 [INFO] Step[750/4329]: training loss : 0.8685482156276703 TRAIN  loss dict:  {'classification_loss': 0.8685482156276703}
2025-01-13 13:18:58,229 [INFO] Step[800/4329]: training loss : 0.8646362519264221 TRAIN  loss dict:  {'classification_loss': 0.8646362519264221}
2025-01-13 13:19:12,656 [INFO] Step[850/4329]: training loss : 0.8630248820781707 TRAIN  loss dict:  {'classification_loss': 0.8630248820781707}
2025-01-13 13:19:27,344 [INFO] Step[900/4329]: training loss : 0.8597242760658265 TRAIN  loss dict:  {'classification_loss': 0.8597242760658265}
2025-01-13 13:19:42,090 [INFO] Step[950/4329]: training loss : 0.8624790894985199 TRAIN  loss dict:  {'classification_loss': 0.8624790894985199}
2025-01-13 13:19:56,514 [INFO] Step[1000/4329]: training loss : 0.8596178078651429 TRAIN  loss dict:  {'classification_loss': 0.8596178078651429}
2025-01-13 13:20:11,003 [INFO] Step[1050/4329]: training loss : 0.8588116073608398 TRAIN  loss dict:  {'classification_loss': 0.8588116073608398}
2025-01-13 13:20:25,299 [INFO] Step[1100/4329]: training loss : 0.8602307045459747 TRAIN  loss dict:  {'classification_loss': 0.8602307045459747}
2025-01-13 13:20:39,979 [INFO] Step[1150/4329]: training loss : 0.8586927390098572 TRAIN  loss dict:  {'classification_loss': 0.8586927390098572}
2025-01-13 13:20:54,688 [INFO] Step[1200/4329]: training loss : 0.8589084529876709 TRAIN  loss dict:  {'classification_loss': 0.8589084529876709}
2025-01-13 13:21:09,376 [INFO] Step[1250/4329]: training loss : 0.8610251367092132 TRAIN  loss dict:  {'classification_loss': 0.8610251367092132}
2025-01-13 13:21:24,031 [INFO] Step[1300/4329]: training loss : 0.864634428024292 TRAIN  loss dict:  {'classification_loss': 0.864634428024292}
2025-01-13 13:21:38,715 [INFO] Step[1350/4329]: training loss : 0.8633582627773285 TRAIN  loss dict:  {'classification_loss': 0.8633582627773285}
2025-01-13 13:21:53,171 [INFO] Step[1400/4329]: training loss : 0.8605663061141968 TRAIN  loss dict:  {'classification_loss': 0.8605663061141968}
2025-01-13 13:22:07,488 [INFO] Step[1450/4329]: training loss : 0.8735769665241242 TRAIN  loss dict:  {'classification_loss': 0.8735769665241242}
2025-01-13 13:22:22,220 [INFO] Step[1500/4329]: training loss : 0.8610655844211579 TRAIN  loss dict:  {'classification_loss': 0.8610655844211579}
2025-01-13 13:22:36,571 [INFO] Step[1550/4329]: training loss : 0.8607312405109405 TRAIN  loss dict:  {'classification_loss': 0.8607312405109405}
2025-01-13 13:22:51,013 [INFO] Step[1600/4329]: training loss : 0.8616378009319305 TRAIN  loss dict:  {'classification_loss': 0.8616378009319305}
2025-01-13 13:23:05,768 [INFO] Step[1650/4329]: training loss : 0.860238049030304 TRAIN  loss dict:  {'classification_loss': 0.860238049030304}
2025-01-13 13:23:20,543 [INFO] Step[1700/4329]: training loss : 0.8634015834331512 TRAIN  loss dict:  {'classification_loss': 0.8634015834331512}
2025-01-13 13:23:35,231 [INFO] Step[1750/4329]: training loss : 0.858973754644394 TRAIN  loss dict:  {'classification_loss': 0.858973754644394}
2025-01-13 13:23:49,597 [INFO] Step[1800/4329]: training loss : 0.8597643828392029 TRAIN  loss dict:  {'classification_loss': 0.8597643828392029}
2025-01-13 13:24:04,347 [INFO] Step[1850/4329]: training loss : 0.8586594295501709 TRAIN  loss dict:  {'classification_loss': 0.8586594295501709}
2025-01-13 13:24:19,016 [INFO] Step[1900/4329]: training loss : 0.8616509556770324 TRAIN  loss dict:  {'classification_loss': 0.8616509556770324}
2025-01-13 13:24:33,661 [INFO] Step[1950/4329]: training loss : 0.8601425790786743 TRAIN  loss dict:  {'classification_loss': 0.8601425790786743}
2025-01-13 13:24:48,069 [INFO] Step[2000/4329]: training loss : 0.862156320810318 TRAIN  loss dict:  {'classification_loss': 0.862156320810318}
2025-01-13 13:25:02,791 [INFO] Step[2050/4329]: training loss : 0.8581409347057343 TRAIN  loss dict:  {'classification_loss': 0.8581409347057343}
2025-01-13 13:25:17,250 [INFO] Step[2100/4329]: training loss : 0.8612381339073181 TRAIN  loss dict:  {'classification_loss': 0.8612381339073181}
2025-01-13 13:25:31,123 [INFO] Step[2150/4329]: training loss : 0.86104945063591 TRAIN  loss dict:  {'classification_loss': 0.86104945063591}
2025-01-13 13:25:45,002 [INFO] Step[2200/4329]: training loss : 0.8591254675388336 TRAIN  loss dict:  {'classification_loss': 0.8591254675388336}
2025-01-13 13:25:59,048 [INFO] Step[2250/4329]: training loss : 0.8603603839874268 TRAIN  loss dict:  {'classification_loss': 0.8603603839874268}
2025-01-13 13:26:13,603 [INFO] Step[2300/4329]: training loss : 0.857415521144867 TRAIN  loss dict:  {'classification_loss': 0.857415521144867}
2025-01-13 13:26:27,483 [INFO] Step[2350/4329]: training loss : 0.8583054387569428 TRAIN  loss dict:  {'classification_loss': 0.8583054387569428}
2025-01-13 13:26:40,792 [INFO] Step[2400/4329]: training loss : 0.8603508579730987 TRAIN  loss dict:  {'classification_loss': 0.8603508579730987}
2025-01-13 13:26:54,017 [INFO] Step[2450/4329]: training loss : 0.8574509167671204 TRAIN  loss dict:  {'classification_loss': 0.8574509167671204}
2025-01-13 13:27:08,066 [INFO] Step[2500/4329]: training loss : 0.8594356715679169 TRAIN  loss dict:  {'classification_loss': 0.8594356715679169}
2025-01-13 13:27:22,307 [INFO] Step[2550/4329]: training loss : 0.860977110862732 TRAIN  loss dict:  {'classification_loss': 0.860977110862732}
2025-01-13 13:27:36,875 [INFO] Step[2600/4329]: training loss : 0.8629221141338348 TRAIN  loss dict:  {'classification_loss': 0.8629221141338348}
2025-01-13 13:27:51,591 [INFO] Step[2650/4329]: training loss : 0.858446615934372 TRAIN  loss dict:  {'classification_loss': 0.858446615934372}
2025-01-13 13:28:06,098 [INFO] Step[2700/4329]: training loss : 0.8606813371181488 TRAIN  loss dict:  {'classification_loss': 0.8606813371181488}
2025-01-13 13:28:20,305 [INFO] Step[2750/4329]: training loss : 0.8583618700504303 TRAIN  loss dict:  {'classification_loss': 0.8583618700504303}
2025-01-13 13:28:34,913 [INFO] Step[2800/4329]: training loss : 0.8624318754673004 TRAIN  loss dict:  {'classification_loss': 0.8624318754673004}
2025-01-13 13:28:49,613 [INFO] Step[2850/4329]: training loss : 0.8630376839637757 TRAIN  loss dict:  {'classification_loss': 0.8630376839637757}
2025-01-13 13:29:04,296 [INFO] Step[2900/4329]: training loss : 0.8587445724010467 TRAIN  loss dict:  {'classification_loss': 0.8587445724010467}
2025-01-13 13:29:18,125 [INFO] Step[2950/4329]: training loss : 0.8649442541599274 TRAIN  loss dict:  {'classification_loss': 0.8649442541599274}
2025-01-13 13:29:31,058 [INFO] Step[3000/4329]: training loss : 0.8584037303924561 TRAIN  loss dict:  {'classification_loss': 0.8584037303924561}
2025-01-13 13:29:44,004 [INFO] Step[3050/4329]: training loss : 0.8597504377365113 TRAIN  loss dict:  {'classification_loss': 0.8597504377365113}
2025-01-13 13:29:57,910 [INFO] Step[3100/4329]: training loss : 0.8739371752738953 TRAIN  loss dict:  {'classification_loss': 0.8739371752738953}
2025-01-13 13:30:12,408 [INFO] Step[3150/4329]: training loss : 0.8583387744426727 TRAIN  loss dict:  {'classification_loss': 0.8583387744426727}
2025-01-13 13:30:26,827 [INFO] Step[3200/4329]: training loss : 0.8582275974750518 TRAIN  loss dict:  {'classification_loss': 0.8582275974750518}
2025-01-13 13:30:41,286 [INFO] Step[3250/4329]: training loss : 0.8687674987316132 TRAIN  loss dict:  {'classification_loss': 0.8687674987316132}
2025-01-13 13:30:55,791 [INFO] Step[3300/4329]: training loss : 0.8575270533561706 TRAIN  loss dict:  {'classification_loss': 0.8575270533561706}
2025-01-13 13:31:10,027 [INFO] Step[3350/4329]: training loss : 0.8583774387836456 TRAIN  loss dict:  {'classification_loss': 0.8583774387836456}
2025-01-13 13:31:24,486 [INFO] Step[3400/4329]: training loss : 0.8594578373432159 TRAIN  loss dict:  {'classification_loss': 0.8594578373432159}
2025-01-13 13:31:38,727 [INFO] Step[3450/4329]: training loss : 0.859259979724884 TRAIN  loss dict:  {'classification_loss': 0.859259979724884}
2025-01-13 13:31:53,127 [INFO] Step[3500/4329]: training loss : 0.8584522497653961 TRAIN  loss dict:  {'classification_loss': 0.8584522497653961}
2025-01-13 13:32:07,411 [INFO] Step[3550/4329]: training loss : 0.8696213030815124 TRAIN  loss dict:  {'classification_loss': 0.8696213030815124}
2025-01-13 13:32:21,870 [INFO] Step[3600/4329]: training loss : 0.8581398010253907 TRAIN  loss dict:  {'classification_loss': 0.8581398010253907}
2025-01-13 13:32:36,167 [INFO] Step[3650/4329]: training loss : 0.8604876589775086 TRAIN  loss dict:  {'classification_loss': 0.8604876589775086}
2025-01-13 13:32:50,593 [INFO] Step[3700/4329]: training loss : 0.8575015163421631 TRAIN  loss dict:  {'classification_loss': 0.8575015163421631}
2025-01-13 13:33:05,095 [INFO] Step[3750/4329]: training loss : 0.8572497677803039 TRAIN  loss dict:  {'classification_loss': 0.8572497677803039}
2025-01-13 13:33:19,532 [INFO] Step[3800/4329]: training loss : 0.8605004501342773 TRAIN  loss dict:  {'classification_loss': 0.8605004501342773}
2025-01-13 13:33:34,203 [INFO] Step[3850/4329]: training loss : 0.8581165409088135 TRAIN  loss dict:  {'classification_loss': 0.8581165409088135}
2025-01-13 13:33:48,669 [INFO] Step[3900/4329]: training loss : 0.8582042706012726 TRAIN  loss dict:  {'classification_loss': 0.8582042706012726}
2025-01-13 13:34:03,083 [INFO] Step[3950/4329]: training loss : 0.8595869445800781 TRAIN  loss dict:  {'classification_loss': 0.8595869445800781}
2025-01-13 13:34:17,406 [INFO] Step[4000/4329]: training loss : 0.8585424864292145 TRAIN  loss dict:  {'classification_loss': 0.8585424864292145}
2025-01-13 13:34:32,192 [INFO] Step[4050/4329]: training loss : 0.8579574275016785 TRAIN  loss dict:  {'classification_loss': 0.8579574275016785}
2025-01-13 13:34:46,496 [INFO] Step[4100/4329]: training loss : 0.8619757330417633 TRAIN  loss dict:  {'classification_loss': 0.8619757330417633}
2025-01-13 13:35:01,028 [INFO] Step[4150/4329]: training loss : 0.8592684698104859 TRAIN  loss dict:  {'classification_loss': 0.8592684698104859}
2025-01-13 13:35:15,502 [INFO] Step[4200/4329]: training loss : 0.8592100691795349 TRAIN  loss dict:  {'classification_loss': 0.8592100691795349}
2025-01-13 13:35:29,816 [INFO] Step[4250/4329]: training loss : 0.8584777843952179 TRAIN  loss dict:  {'classification_loss': 0.8584777843952179}
2025-01-13 13:35:44,575 [INFO] Step[4300/4329]: training loss : 0.8573650395870209 TRAIN  loss dict:  {'classification_loss': 0.8573650395870209}
2025-01-13 13:38:10,728 [INFO] Label accuracies statistics:
2025-01-13 13:38:10,728 [INFO] {0: 0.7777777777777778, 1: 1.0, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.6666666666666666, 7: 0.5, 8: 0.5833333333333334, 9: 0.8333333333333334, 10: 1.0, 11: 0.9166666666666666, 12: 0.6666666666666666, 13: 0.5, 14: 0.6666666666666666, 15: 0.6666666666666666, 16: 0.5833333333333334, 17: 0.16666666666666666, 18: 0.5833333333333334, 19: 0.75, 20: 0.6666666666666666, 21: 0.75, 22: 0.75, 23: 0.9166666666666666, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.6666666666666666, 28: 0.8333333333333334, 29: 1.0, 30: 0.5833333333333334, 31: 0.6666666666666666, 32: 0.6666666666666666, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 1.0, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.9166666666666666, 41: 0.5, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.5, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.8333333333333334, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.6666666666666666, 56: 0.8333333333333334, 57: 0.6666666666666666, 58: 0.5833333333333334, 59: 0.8333333333333334, 60: 0.9166666666666666, 61: 0.9166666666666666, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.6666666666666666, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.8333333333333334, 78: 0.9166666666666666, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.6666666666666666, 83: 0.75, 84: 0.5833333333333334, 85: 0.8333333333333334, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.75, 89: 0.5, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.6666666666666666, 97: 0.75, 98: 0.8333333333333334, 99: 1.0, 100: 0.9166666666666666, 101: 1.0, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.5, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.9166666666666666, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 0.9166666666666666, 116: 0.8333333333333334, 117: 0.9166666666666666, 118: 0.9166666666666666, 119: 0.8333333333333334, 120: 0.8333333333333334, 121: 0.8333333333333334, 122: 0.8333333333333334, 123: 1.0, 124: 1.0, 125: 0.75, 126: 0.9166666666666666, 127: 0.8333333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.8333333333333334, 132: 0.4166666666666667, 133: 1.0, 134: 0.75, 135: 1.0, 136: 0.9166666666666666, 137: 1.0, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 1.0, 141: 0.9166666666666666, 142: 0.8333333333333334, 143: 1.0, 144: 0.75, 145: 1.0, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.5, 151: 0.9166666666666666, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.6666666666666666, 158: 0.6666666666666666, 159: 1.0, 160: 0.4166666666666667, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.75, 166: 0.8333333333333334, 167: 0.6666666666666666, 168: 0.9166666666666666, 169: 1.0, 170: 1.0, 171: 0.4166666666666667, 172: 1.0, 173: 0.6666666666666666, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.9166666666666666, 181: 0.8333333333333334, 182: 0.75, 183: 0.8333333333333334, 184: 0.9166666666666666, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.5833333333333334, 189: 1.0, 190: 0.5833333333333334, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.9166666666666666, 198: 0.75}

2025-01-13 13:38:10,730 [INFO] [71] TRAIN  loss: 0.8609441523740297 acc: 0.9994609579547205
2025-01-13 13:38:10,730 [INFO] [71] TRAIN  loss dict: {'classification_loss': 0.8609441523740297}
2025-01-13 13:38:10,731 [INFO] [71] VALIDATION loss: 1.603742176986704 VALIDATION acc: 0.8177609427609428
2025-01-13 13:38:10,731 [INFO] [71] VALIDATION loss dict: {'classification_loss': 1.603742176986704}
2025-01-13 13:38:10,731 [INFO] 
2025-01-13 13:38:31,148 [INFO] Step[50/4329]: training loss : 0.859101345539093 TRAIN  loss dict:  {'classification_loss': 0.859101345539093}
2025-01-13 13:38:45,523 [INFO] Step[100/4329]: training loss : 0.8649272394180297 TRAIN  loss dict:  {'classification_loss': 0.8649272394180297}
2025-01-13 13:39:00,038 [INFO] Step[150/4329]: training loss : 0.8639181387424469 TRAIN  loss dict:  {'classification_loss': 0.8639181387424469}
2025-01-13 13:39:13,748 [INFO] Step[200/4329]: training loss : 0.8664368855953216 TRAIN  loss dict:  {'classification_loss': 0.8664368855953216}
2025-01-13 13:39:27,653 [INFO] Step[250/4329]: training loss : 0.8573600709438324 TRAIN  loss dict:  {'classification_loss': 0.8573600709438324}
2025-01-13 13:39:42,166 [INFO] Step[300/4329]: training loss : 0.8589912962913513 TRAIN  loss dict:  {'classification_loss': 0.8589912962913513}
2025-01-13 13:39:56,114 [INFO] Step[350/4329]: training loss : 0.8585940062999725 TRAIN  loss dict:  {'classification_loss': 0.8585940062999725}
2025-01-13 13:40:10,431 [INFO] Step[400/4329]: training loss : 0.8597396862506866 TRAIN  loss dict:  {'classification_loss': 0.8597396862506866}
2025-01-13 13:40:24,668 [INFO] Step[450/4329]: training loss : 0.8584675168991089 TRAIN  loss dict:  {'classification_loss': 0.8584675168991089}
2025-01-13 13:40:38,984 [INFO] Step[500/4329]: training loss : 0.8578487157821655 TRAIN  loss dict:  {'classification_loss': 0.8578487157821655}
2025-01-13 13:40:53,640 [INFO] Step[550/4329]: training loss : 0.8598605835437775 TRAIN  loss dict:  {'classification_loss': 0.8598605835437775}
2025-01-13 13:41:08,444 [INFO] Step[600/4329]: training loss : 0.8616017091274262 TRAIN  loss dict:  {'classification_loss': 0.8616017091274262}
2025-01-13 13:41:23,208 [INFO] Step[650/4329]: training loss : 0.8587707602977752 TRAIN  loss dict:  {'classification_loss': 0.8587707602977752}
2025-01-13 13:41:37,653 [INFO] Step[700/4329]: training loss : 0.8585637211799622 TRAIN  loss dict:  {'classification_loss': 0.8585637211799622}
2025-01-13 13:41:51,939 [INFO] Step[750/4329]: training loss : 0.8667017960548401 TRAIN  loss dict:  {'classification_loss': 0.8667017960548401}
2025-01-13 13:42:06,640 [INFO] Step[800/4329]: training loss : 0.8636472272872925 TRAIN  loss dict:  {'classification_loss': 0.8636472272872925}
2025-01-13 13:42:20,814 [INFO] Step[850/4329]: training loss : 0.8579622447490692 TRAIN  loss dict:  {'classification_loss': 0.8579622447490692}
2025-01-13 13:42:35,067 [INFO] Step[900/4329]: training loss : 0.8602539312839508 TRAIN  loss dict:  {'classification_loss': 0.8602539312839508}
2025-01-13 13:42:49,534 [INFO] Step[950/4329]: training loss : 0.8576203787326813 TRAIN  loss dict:  {'classification_loss': 0.8576203787326813}
2025-01-13 13:43:03,819 [INFO] Step[1000/4329]: training loss : 0.8591628742218017 TRAIN  loss dict:  {'classification_loss': 0.8591628742218017}
2025-01-13 13:43:18,183 [INFO] Step[1050/4329]: training loss : 0.8601845359802246 TRAIN  loss dict:  {'classification_loss': 0.8601845359802246}
2025-01-13 13:43:32,459 [INFO] Step[1100/4329]: training loss : 0.8575842702388763 TRAIN  loss dict:  {'classification_loss': 0.8575842702388763}
2025-01-13 13:43:47,046 [INFO] Step[1150/4329]: training loss : 0.8576702165603638 TRAIN  loss dict:  {'classification_loss': 0.8576702165603638}
2025-01-13 13:44:01,244 [INFO] Step[1200/4329]: training loss : 0.859070782661438 TRAIN  loss dict:  {'classification_loss': 0.859070782661438}
2025-01-13 13:44:15,505 [INFO] Step[1250/4329]: training loss : 0.8667551910877228 TRAIN  loss dict:  {'classification_loss': 0.8667551910877228}
2025-01-13 13:44:29,942 [INFO] Step[1300/4329]: training loss : 0.8578052723407745 TRAIN  loss dict:  {'classification_loss': 0.8578052723407745}
2025-01-13 13:44:44,391 [INFO] Step[1350/4329]: training loss : 0.8583699905872345 TRAIN  loss dict:  {'classification_loss': 0.8583699905872345}
2025-01-13 13:44:59,072 [INFO] Step[1400/4329]: training loss : 0.8579070842266083 TRAIN  loss dict:  {'classification_loss': 0.8579070842266083}
2025-01-13 13:45:13,746 [INFO] Step[1450/4329]: training loss : 0.8577613711357117 TRAIN  loss dict:  {'classification_loss': 0.8577613711357117}
2025-01-13 13:45:28,144 [INFO] Step[1500/4329]: training loss : 0.8580341935157776 TRAIN  loss dict:  {'classification_loss': 0.8580341935157776}
2025-01-13 13:45:42,376 [INFO] Step[1550/4329]: training loss : 0.8586837410926819 TRAIN  loss dict:  {'classification_loss': 0.8586837410926819}
2025-01-13 13:45:56,798 [INFO] Step[1600/4329]: training loss : 0.8593310189247131 TRAIN  loss dict:  {'classification_loss': 0.8593310189247131}
2025-01-13 13:46:11,247 [INFO] Step[1650/4329]: training loss : 0.8580324101448059 TRAIN  loss dict:  {'classification_loss': 0.8580324101448059}
2025-01-13 13:46:25,432 [INFO] Step[1700/4329]: training loss : 0.8579173839092255 TRAIN  loss dict:  {'classification_loss': 0.8579173839092255}
2025-01-13 13:46:39,693 [INFO] Step[1750/4329]: training loss : 0.8572032761573791 TRAIN  loss dict:  {'classification_loss': 0.8572032761573791}
2025-01-13 13:46:54,351 [INFO] Step[1800/4329]: training loss : 0.8582371139526367 TRAIN  loss dict:  {'classification_loss': 0.8582371139526367}
2025-01-13 13:47:08,877 [INFO] Step[1850/4329]: training loss : 0.8592708480358123 TRAIN  loss dict:  {'classification_loss': 0.8592708480358123}
2025-01-13 13:47:23,473 [INFO] Step[1900/4329]: training loss : 0.8573866999149322 TRAIN  loss dict:  {'classification_loss': 0.8573866999149322}
2025-01-13 13:47:37,882 [INFO] Step[1950/4329]: training loss : 0.8589333748817444 TRAIN  loss dict:  {'classification_loss': 0.8589333748817444}
2025-01-13 13:47:52,091 [INFO] Step[2000/4329]: training loss : 0.8585115230083465 TRAIN  loss dict:  {'classification_loss': 0.8585115230083465}
2025-01-13 13:48:06,333 [INFO] Step[2050/4329]: training loss : 0.8578634119033813 TRAIN  loss dict:  {'classification_loss': 0.8578634119033813}
2025-01-13 13:48:21,092 [INFO] Step[2100/4329]: training loss : 0.8579944241046905 TRAIN  loss dict:  {'classification_loss': 0.8579944241046905}
2025-01-13 13:48:35,415 [INFO] Step[2150/4329]: training loss : 0.8593611764907837 TRAIN  loss dict:  {'classification_loss': 0.8593611764907837}
2025-01-13 13:48:49,654 [INFO] Step[2200/4329]: training loss : 0.8592807483673096 TRAIN  loss dict:  {'classification_loss': 0.8592807483673096}
2025-01-13 13:49:03,869 [INFO] Step[2250/4329]: training loss : 0.8843744575977326 TRAIN  loss dict:  {'classification_loss': 0.8843744575977326}
2025-01-13 13:49:18,555 [INFO] Step[2300/4329]: training loss : 0.8575458085536957 TRAIN  loss dict:  {'classification_loss': 0.8575458085536957}
2025-01-13 13:49:32,971 [INFO] Step[2350/4329]: training loss : 0.858215366601944 TRAIN  loss dict:  {'classification_loss': 0.858215366601944}
2025-01-13 13:49:47,126 [INFO] Step[2400/4329]: training loss : 0.8571328806877136 TRAIN  loss dict:  {'classification_loss': 0.8571328806877136}
2025-01-13 13:50:01,410 [INFO] Step[2450/4329]: training loss : 0.8569248139858245 TRAIN  loss dict:  {'classification_loss': 0.8569248139858245}
2025-01-13 13:50:15,769 [INFO] Step[2500/4329]: training loss : 0.8597300136089325 TRAIN  loss dict:  {'classification_loss': 0.8597300136089325}
2025-01-13 13:50:30,220 [INFO] Step[2550/4329]: training loss : 0.8584005916118622 TRAIN  loss dict:  {'classification_loss': 0.8584005916118622}
2025-01-13 13:50:44,610 [INFO] Step[2600/4329]: training loss : 0.8578675985336304 TRAIN  loss dict:  {'classification_loss': 0.8578675985336304}
2025-01-13 13:50:59,197 [INFO] Step[2650/4329]: training loss : 0.8584386420249939 TRAIN  loss dict:  {'classification_loss': 0.8584386420249939}
2025-01-13 13:51:13,899 [INFO] Step[2700/4329]: training loss : 0.859220609664917 TRAIN  loss dict:  {'classification_loss': 0.859220609664917}
2025-01-13 13:51:28,586 [INFO] Step[2750/4329]: training loss : 0.8595328831672668 TRAIN  loss dict:  {'classification_loss': 0.8595328831672668}
2025-01-13 13:51:42,947 [INFO] Step[2800/4329]: training loss : 0.8699205255508423 TRAIN  loss dict:  {'classification_loss': 0.8699205255508423}
2025-01-13 13:51:57,392 [INFO] Step[2850/4329]: training loss : 0.8580668234825134 TRAIN  loss dict:  {'classification_loss': 0.8580668234825134}
2025-01-13 13:52:12,094 [INFO] Step[2900/4329]: training loss : 0.8581691217422486 TRAIN  loss dict:  {'classification_loss': 0.8581691217422486}
2025-01-13 13:52:26,484 [INFO] Step[2950/4329]: training loss : 0.8573967099189759 TRAIN  loss dict:  {'classification_loss': 0.8573967099189759}
2025-01-13 13:52:40,245 [INFO] Step[3000/4329]: training loss : 0.8591869807243347 TRAIN  loss dict:  {'classification_loss': 0.8591869807243347}
2025-01-13 13:52:54,009 [INFO] Step[3050/4329]: training loss : 0.8592814755439758 TRAIN  loss dict:  {'classification_loss': 0.8592814755439758}
2025-01-13 13:53:08,046 [INFO] Step[3100/4329]: training loss : 0.8574371647834778 TRAIN  loss dict:  {'classification_loss': 0.8574371647834778}
2025-01-13 13:53:22,374 [INFO] Step[3150/4329]: training loss : 0.8585467040538788 TRAIN  loss dict:  {'classification_loss': 0.8585467040538788}
2025-01-13 13:53:36,493 [INFO] Step[3200/4329]: training loss : 0.8585620665550232 TRAIN  loss dict:  {'classification_loss': 0.8585620665550232}
2025-01-13 13:53:50,286 [INFO] Step[3250/4329]: training loss : 0.8644843399524689 TRAIN  loss dict:  {'classification_loss': 0.8644843399524689}
2025-01-13 13:54:04,525 [INFO] Step[3300/4329]: training loss : 0.8573620247840882 TRAIN  loss dict:  {'classification_loss': 0.8573620247840882}
2025-01-13 13:54:19,003 [INFO] Step[3350/4329]: training loss : 0.8615052199363709 TRAIN  loss dict:  {'classification_loss': 0.8615052199363709}
2025-01-13 13:54:33,662 [INFO] Step[3400/4329]: training loss : 0.8574576151371002 TRAIN  loss dict:  {'classification_loss': 0.8574576151371002}
2025-01-13 13:54:48,204 [INFO] Step[3450/4329]: training loss : 0.8610584306716919 TRAIN  loss dict:  {'classification_loss': 0.8610584306716919}
2025-01-13 13:55:02,863 [INFO] Step[3500/4329]: training loss : 0.8746107006072998 TRAIN  loss dict:  {'classification_loss': 0.8746107006072998}
2025-01-13 13:55:17,092 [INFO] Step[3550/4329]: training loss : 0.8584693229198456 TRAIN  loss dict:  {'classification_loss': 0.8584693229198456}
2025-01-13 13:55:31,778 [INFO] Step[3600/4329]: training loss : 0.8578546214103698 TRAIN  loss dict:  {'classification_loss': 0.8578546214103698}
2025-01-13 13:55:46,259 [INFO] Step[3650/4329]: training loss : 0.8600479185581207 TRAIN  loss dict:  {'classification_loss': 0.8600479185581207}
2025-01-13 13:56:00,499 [INFO] Step[3700/4329]: training loss : 0.8624234127998353 TRAIN  loss dict:  {'classification_loss': 0.8624234127998353}
2025-01-13 13:56:15,239 [INFO] Step[3750/4329]: training loss : 0.8591587269306182 TRAIN  loss dict:  {'classification_loss': 0.8591587269306182}
2025-01-13 13:56:29,535 [INFO] Step[3800/4329]: training loss : 0.8578672337532044 TRAIN  loss dict:  {'classification_loss': 0.8578672337532044}
2025-01-13 13:56:43,735 [INFO] Step[3850/4329]: training loss : 0.866959433555603 TRAIN  loss dict:  {'classification_loss': 0.866959433555603}
2025-01-13 13:56:58,484 [INFO] Step[3900/4329]: training loss : 0.8574923312664032 TRAIN  loss dict:  {'classification_loss': 0.8574923312664032}
2025-01-13 13:57:13,079 [INFO] Step[3950/4329]: training loss : 0.8594774234294892 TRAIN  loss dict:  {'classification_loss': 0.8594774234294892}
2025-01-13 13:57:27,626 [INFO] Step[4000/4329]: training loss : 0.8579890191555023 TRAIN  loss dict:  {'classification_loss': 0.8579890191555023}
2025-01-13 13:57:42,301 [INFO] Step[4050/4329]: training loss : 0.8638240849971771 TRAIN  loss dict:  {'classification_loss': 0.8638240849971771}
2025-01-13 13:57:56,836 [INFO] Step[4100/4329]: training loss : 0.8573675572872161 TRAIN  loss dict:  {'classification_loss': 0.8573675572872161}
2025-01-13 13:58:11,082 [INFO] Step[4150/4329]: training loss : 0.8599739110469818 TRAIN  loss dict:  {'classification_loss': 0.8599739110469818}
2025-01-13 13:58:25,653 [INFO] Step[4200/4329]: training loss : 0.8605407094955444 TRAIN  loss dict:  {'classification_loss': 0.8605407094955444}
2025-01-13 13:58:40,336 [INFO] Step[4250/4329]: training loss : 0.858753616809845 TRAIN  loss dict:  {'classification_loss': 0.858753616809845}
2025-01-13 13:58:54,809 [INFO] Step[4300/4329]: training loss : 0.8606928741931915 TRAIN  loss dict:  {'classification_loss': 0.8606928741931915}
2025-01-13 14:01:19,655 [INFO] Label accuracies statistics:
2025-01-13 14:01:19,655 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.5, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.5833333333333334, 8: 0.5833333333333334, 9: 0.8333333333333334, 10: 1.0, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.5833333333333334, 14: 0.6666666666666666, 15: 0.6666666666666666, 16: 0.75, 17: 0.6666666666666666, 18: 0.5833333333333334, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.9166666666666666, 24: 1.0, 25: 0.6666666666666666, 26: 0.9166666666666666, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.8333333333333334, 32: 0.75, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 0.9166666666666666, 36: 0.6666666666666666, 37: 1.0, 38: 0.75, 39: 1.0, 40: 0.9166666666666666, 41: 0.5, 42: 0.8333333333333334, 43: 0.8333333333333334, 44: 0.5833333333333334, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.8333333333333334, 52: 1.0, 53: 0.6666666666666666, 54: 0.25, 55: 0.6666666666666666, 56: 0.8333333333333334, 57: 0.75, 58: 0.5, 59: 0.8333333333333334, 60: 0.9166666666666666, 61: 1.0, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.6666666666666666, 69: 0.6666666666666666, 70: 0.5833333333333334, 71: 0.5833333333333334, 72: 1.0, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 1.0, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.6666666666666666, 84: 0.4166666666666667, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.75, 89: 0.5, 90: 0.8333333333333334, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 0.9166666666666666, 96: 0.6666666666666666, 97: 0.8333333333333334, 98: 0.8333333333333334, 99: 1.0, 100: 0.9166666666666666, 101: 1.0, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.4166666666666667, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.9166666666666666, 111: 1.0, 112: 0.9166666666666666, 113: 0.5, 114: 0.5, 115: 0.9166666666666666, 116: 0.8333333333333334, 117: 0.8333333333333334, 118: 0.9166666666666666, 119: 0.8333333333333334, 120: 0.8333333333333334, 121: 0.8333333333333334, 122: 0.8333333333333334, 123: 0.9166666666666666, 124: 1.0, 125: 0.8333333333333334, 126: 0.8333333333333334, 127: 0.9166666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.8333333333333334, 132: 0.6666666666666666, 133: 1.0, 134: 0.9166666666666666, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 1.0, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 1.0, 141: 0.9166666666666666, 142: 0.6666666666666666, 143: 1.0, 144: 0.75, 145: 0.9166666666666666, 146: 1.0, 147: 0.9166666666666666, 148: 0.6666666666666666, 149: 1.0, 150: 0.5, 151: 0.8333333333333334, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 0.9166666666666666, 156: 0.75, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.4166666666666667, 161: 0.8333333333333334, 162: 1.0, 163: 0.9166666666666666, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.9166666666666666, 168: 0.9166666666666666, 169: 1.0, 170: 0.9166666666666666, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.6666666666666666, 178: 1.0, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.6666666666666666, 183: 0.75, 184: 0.6666666666666666, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.8333333333333334, 189: 0.9166666666666666, 190: 0.6666666666666666, 191: 0.6666666666666666, 192: 0.9166666666666666, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.75, 196: 0.8333333333333334, 197: 0.9166666666666666, 198: 0.6666666666666666}

2025-01-13 14:01:19,657 [INFO] [72] TRAIN  loss: 0.8599605832922731 acc: 0.999537963961189
2025-01-13 14:01:19,657 [INFO] [72] TRAIN  loss dict: {'classification_loss': 0.8599605832922731}
2025-01-13 14:01:19,658 [INFO] [72] VALIDATION loss: 1.5768381579205244 VALIDATION acc: 0.8169191919191919
2025-01-13 14:01:19,658 [INFO] [72] VALIDATION loss dict: {'classification_loss': 1.5768381579205244}
2025-01-13 14:01:19,658 [INFO] 
2025-01-13 14:01:40,221 [INFO] Step[50/4329]: training loss : 0.8569513559341431 TRAIN  loss dict:  {'classification_loss': 0.8569513559341431}
2025-01-13 14:01:54,589 [INFO] Step[100/4329]: training loss : 0.8578958106040955 TRAIN  loss dict:  {'classification_loss': 0.8578958106040955}
2025-01-13 14:02:09,320 [INFO] Step[150/4329]: training loss : 0.862319952249527 TRAIN  loss dict:  {'classification_loss': 0.862319952249527}
2025-01-13 14:02:23,658 [INFO] Step[200/4329]: training loss : 0.8587187135219574 TRAIN  loss dict:  {'classification_loss': 0.8587187135219574}
2025-01-13 14:02:37,855 [INFO] Step[250/4329]: training loss : 0.8588767206668854 TRAIN  loss dict:  {'classification_loss': 0.8588767206668854}
2025-01-13 14:02:52,084 [INFO] Step[300/4329]: training loss : 0.8587208580970764 TRAIN  loss dict:  {'classification_loss': 0.8587208580970764}
2025-01-13 14:03:06,572 [INFO] Step[350/4329]: training loss : 0.8578194117546082 TRAIN  loss dict:  {'classification_loss': 0.8578194117546082}
2025-01-13 14:03:21,227 [INFO] Step[400/4329]: training loss : 0.8572487688064575 TRAIN  loss dict:  {'classification_loss': 0.8572487688064575}
2025-01-13 14:03:36,005 [INFO] Step[450/4329]: training loss : 0.8582643938064575 TRAIN  loss dict:  {'classification_loss': 0.8582643938064575}
2025-01-13 14:03:50,327 [INFO] Step[500/4329]: training loss : 0.8575869834423065 TRAIN  loss dict:  {'classification_loss': 0.8575869834423065}
2025-01-13 14:04:04,483 [INFO] Step[550/4329]: training loss : 0.8679349625110626 TRAIN  loss dict:  {'classification_loss': 0.8679349625110626}
2025-01-13 14:04:19,035 [INFO] Step[600/4329]: training loss : 0.8578149604797364 TRAIN  loss dict:  {'classification_loss': 0.8578149604797364}
2025-01-13 14:04:33,807 [INFO] Step[650/4329]: training loss : 0.8576020359992981 TRAIN  loss dict:  {'classification_loss': 0.8576020359992981}
2025-01-13 14:04:48,396 [INFO] Step[700/4329]: training loss : 0.8567235267162323 TRAIN  loss dict:  {'classification_loss': 0.8567235267162323}
2025-01-13 14:05:02,927 [INFO] Step[750/4329]: training loss : 0.860389689207077 TRAIN  loss dict:  {'classification_loss': 0.860389689207077}
2025-01-13 14:05:17,577 [INFO] Step[800/4329]: training loss : 0.8584482789039611 TRAIN  loss dict:  {'classification_loss': 0.8584482789039611}
2025-01-13 14:05:31,294 [INFO] Step[850/4329]: training loss : 0.8606700956821441 TRAIN  loss dict:  {'classification_loss': 0.8606700956821441}
2025-01-13 14:05:44,245 [INFO] Step[900/4329]: training loss : 0.8608749496936798 TRAIN  loss dict:  {'classification_loss': 0.8608749496936798}
2025-01-13 14:05:58,294 [INFO] Step[950/4329]: training loss : 0.8578980255126953 TRAIN  loss dict:  {'classification_loss': 0.8578980255126953}
2025-01-13 14:06:11,986 [INFO] Step[1000/4329]: training loss : 0.8575285911560059 TRAIN  loss dict:  {'classification_loss': 0.8575285911560059}
2025-01-13 14:06:25,920 [INFO] Step[1050/4329]: training loss : 0.8587965881824493 TRAIN  loss dict:  {'classification_loss': 0.8587965881824493}
2025-01-13 14:06:39,780 [INFO] Step[1100/4329]: training loss : 0.8579873025417328 TRAIN  loss dict:  {'classification_loss': 0.8579873025417328}
2025-01-13 14:06:53,787 [INFO] Step[1150/4329]: training loss : 0.8616114485263825 TRAIN  loss dict:  {'classification_loss': 0.8616114485263825}
2025-01-13 14:07:07,900 [INFO] Step[1200/4329]: training loss : 0.8572398459911347 TRAIN  loss dict:  {'classification_loss': 0.8572398459911347}
2025-01-13 14:07:21,690 [INFO] Step[1250/4329]: training loss : 0.8581126821041107 TRAIN  loss dict:  {'classification_loss': 0.8581126821041107}
2025-01-13 14:07:35,816 [INFO] Step[1300/4329]: training loss : 0.8609125244617463 TRAIN  loss dict:  {'classification_loss': 0.8609125244617463}
2025-01-13 14:07:50,327 [INFO] Step[1350/4329]: training loss : 0.8581856524944306 TRAIN  loss dict:  {'classification_loss': 0.8581856524944306}
2025-01-13 14:08:04,725 [INFO] Step[1400/4329]: training loss : 0.8657604908943176 TRAIN  loss dict:  {'classification_loss': 0.8657604908943176}
2025-01-13 14:08:19,258 [INFO] Step[1450/4329]: training loss : 0.8709731900691986 TRAIN  loss dict:  {'classification_loss': 0.8709731900691986}
2025-01-13 14:08:33,438 [INFO] Step[1500/4329]: training loss : 0.8670406985282898 TRAIN  loss dict:  {'classification_loss': 0.8670406985282898}
2025-01-13 14:08:47,796 [INFO] Step[1550/4329]: training loss : 0.8598370683193207 TRAIN  loss dict:  {'classification_loss': 0.8598370683193207}
2025-01-13 14:09:02,193 [INFO] Step[1600/4329]: training loss : 0.8608077025413513 TRAIN  loss dict:  {'classification_loss': 0.8608077025413513}
2025-01-13 14:09:16,686 [INFO] Step[1650/4329]: training loss : 0.8576735997200012 TRAIN  loss dict:  {'classification_loss': 0.8576735997200012}
2025-01-13 14:09:31,306 [INFO] Step[1700/4329]: training loss : 0.8584870707988739 TRAIN  loss dict:  {'classification_loss': 0.8584870707988739}
2025-01-13 14:09:45,850 [INFO] Step[1750/4329]: training loss : 0.8577479803562165 TRAIN  loss dict:  {'classification_loss': 0.8577479803562165}
2025-01-13 14:10:00,301 [INFO] Step[1800/4329]: training loss : 0.8588004720211029 TRAIN  loss dict:  {'classification_loss': 0.8588004720211029}
2025-01-13 14:10:14,760 [INFO] Step[1850/4329]: training loss : 0.8575861072540283 TRAIN  loss dict:  {'classification_loss': 0.8575861072540283}
2025-01-13 14:10:28,994 [INFO] Step[1900/4329]: training loss : 0.8595396697521209 TRAIN  loss dict:  {'classification_loss': 0.8595396697521209}
2025-01-13 14:10:43,500 [INFO] Step[1950/4329]: training loss : 0.8588154542446137 TRAIN  loss dict:  {'classification_loss': 0.8588154542446137}
2025-01-13 14:10:57,744 [INFO] Step[2000/4329]: training loss : 0.8581408488750458 TRAIN  loss dict:  {'classification_loss': 0.8581408488750458}
2025-01-13 14:11:12,385 [INFO] Step[2050/4329]: training loss : 0.860101283788681 TRAIN  loss dict:  {'classification_loss': 0.860101283788681}
2025-01-13 14:11:26,617 [INFO] Step[2100/4329]: training loss : 0.8588459849357605 TRAIN  loss dict:  {'classification_loss': 0.8588459849357605}
2025-01-13 14:11:41,190 [INFO] Step[2150/4329]: training loss : 0.8571219515800476 TRAIN  loss dict:  {'classification_loss': 0.8571219515800476}
2025-01-13 14:11:55,915 [INFO] Step[2200/4329]: training loss : 0.85856107711792 TRAIN  loss dict:  {'classification_loss': 0.85856107711792}
2025-01-13 14:12:10,377 [INFO] Step[2250/4329]: training loss : 0.859625518321991 TRAIN  loss dict:  {'classification_loss': 0.859625518321991}
2025-01-13 14:12:24,661 [INFO] Step[2300/4329]: training loss : 0.8570966720581055 TRAIN  loss dict:  {'classification_loss': 0.8570966720581055}
2025-01-13 14:12:39,426 [INFO] Step[2350/4329]: training loss : 0.8578282558917999 TRAIN  loss dict:  {'classification_loss': 0.8578282558917999}
2025-01-13 14:12:53,850 [INFO] Step[2400/4329]: training loss : 0.8595674192905426 TRAIN  loss dict:  {'classification_loss': 0.8595674192905426}
2025-01-13 14:13:08,425 [INFO] Step[2450/4329]: training loss : 0.8575544393062592 TRAIN  loss dict:  {'classification_loss': 0.8575544393062592}
2025-01-13 14:13:23,143 [INFO] Step[2500/4329]: training loss : 0.8577324974536896 TRAIN  loss dict:  {'classification_loss': 0.8577324974536896}
2025-01-13 14:13:37,565 [INFO] Step[2550/4329]: training loss : 0.856115483045578 TRAIN  loss dict:  {'classification_loss': 0.856115483045578}
2025-01-13 14:13:51,752 [INFO] Step[2600/4329]: training loss : 0.8603160083293915 TRAIN  loss dict:  {'classification_loss': 0.8603160083293915}
2025-01-13 14:14:06,226 [INFO] Step[2650/4329]: training loss : 0.8594002842903137 TRAIN  loss dict:  {'classification_loss': 0.8594002842903137}
2025-01-13 14:14:20,515 [INFO] Step[2700/4329]: training loss : 0.8589181339740753 TRAIN  loss dict:  {'classification_loss': 0.8589181339740753}
2025-01-13 14:14:34,782 [INFO] Step[2750/4329]: training loss : 0.8582145035266876 TRAIN  loss dict:  {'classification_loss': 0.8582145035266876}
2025-01-13 14:14:49,060 [INFO] Step[2800/4329]: training loss : 0.8577995824813843 TRAIN  loss dict:  {'classification_loss': 0.8577995824813843}
2025-01-13 14:15:03,676 [INFO] Step[2850/4329]: training loss : 0.858270993232727 TRAIN  loss dict:  {'classification_loss': 0.858270993232727}
2025-01-13 14:15:18,113 [INFO] Step[2900/4329]: training loss : 0.8596582686901093 TRAIN  loss dict:  {'classification_loss': 0.8596582686901093}
2025-01-13 14:15:32,541 [INFO] Step[2950/4329]: training loss : 0.8581581604480744 TRAIN  loss dict:  {'classification_loss': 0.8581581604480744}
2025-01-13 14:15:46,895 [INFO] Step[3000/4329]: training loss : 0.8586184799671173 TRAIN  loss dict:  {'classification_loss': 0.8586184799671173}
2025-01-13 14:16:01,396 [INFO] Step[3050/4329]: training loss : 0.8569232964515686 TRAIN  loss dict:  {'classification_loss': 0.8569232964515686}
2025-01-13 14:16:15,828 [INFO] Step[3100/4329]: training loss : 0.8602719914913177 TRAIN  loss dict:  {'classification_loss': 0.8602719914913177}
2025-01-13 14:16:30,243 [INFO] Step[3150/4329]: training loss : 0.8607580888271332 TRAIN  loss dict:  {'classification_loss': 0.8607580888271332}
2025-01-13 14:16:44,749 [INFO] Step[3200/4329]: training loss : 0.859663348197937 TRAIN  loss dict:  {'classification_loss': 0.859663348197937}
2025-01-13 14:16:59,517 [INFO] Step[3250/4329]: training loss : 0.8632017076015472 TRAIN  loss dict:  {'classification_loss': 0.8632017076015472}
2025-01-13 14:17:13,868 [INFO] Step[3300/4329]: training loss : 0.8758474671840668 TRAIN  loss dict:  {'classification_loss': 0.8758474671840668}
2025-01-13 14:17:28,103 [INFO] Step[3350/4329]: training loss : 0.8584664273262024 TRAIN  loss dict:  {'classification_loss': 0.8584664273262024}
2025-01-13 14:17:42,272 [INFO] Step[3400/4329]: training loss : 0.8577090513706207 TRAIN  loss dict:  {'classification_loss': 0.8577090513706207}
2025-01-13 14:17:56,881 [INFO] Step[3450/4329]: training loss : 0.8574949681758881 TRAIN  loss dict:  {'classification_loss': 0.8574949681758881}
2025-01-13 14:18:11,295 [INFO] Step[3500/4329]: training loss : 0.857509913444519 TRAIN  loss dict:  {'classification_loss': 0.857509913444519}
2025-01-13 14:18:25,412 [INFO] Step[3550/4329]: training loss : 0.8627502703666687 TRAIN  loss dict:  {'classification_loss': 0.8627502703666687}
2025-01-13 14:18:39,795 [INFO] Step[3600/4329]: training loss : 0.8592465460300446 TRAIN  loss dict:  {'classification_loss': 0.8592465460300446}
2025-01-13 14:18:54,492 [INFO] Step[3650/4329]: training loss : 0.8730428278446197 TRAIN  loss dict:  {'classification_loss': 0.8730428278446197}
2025-01-13 14:19:09,017 [INFO] Step[3700/4329]: training loss : 0.8586264526844025 TRAIN  loss dict:  {'classification_loss': 0.8586264526844025}
2025-01-13 14:19:23,382 [INFO] Step[3750/4329]: training loss : 0.8571997511386872 TRAIN  loss dict:  {'classification_loss': 0.8571997511386872}
2025-01-13 14:19:37,217 [INFO] Step[3800/4329]: training loss : 0.8582257878780365 TRAIN  loss dict:  {'classification_loss': 0.8582257878780365}
2025-01-13 14:19:51,104 [INFO] Step[3850/4329]: training loss : 0.8579571366310119 TRAIN  loss dict:  {'classification_loss': 0.8579571366310119}
2025-01-13 14:20:04,936 [INFO] Step[3900/4329]: training loss : 0.8617083740234375 TRAIN  loss dict:  {'classification_loss': 0.8617083740234375}
2025-01-13 14:20:20,509 [INFO] Step[3950/4329]: training loss : 0.8628194200992584 TRAIN  loss dict:  {'classification_loss': 0.8628194200992584}
2025-01-13 14:20:34,690 [INFO] Step[4000/4329]: training loss : 0.857823873758316 TRAIN  loss dict:  {'classification_loss': 0.857823873758316}
2025-01-13 14:20:48,764 [INFO] Step[4050/4329]: training loss : 0.8573304319381714 TRAIN  loss dict:  {'classification_loss': 0.8573304319381714}
2025-01-13 14:21:03,073 [INFO] Step[4100/4329]: training loss : 0.8597917425632476 TRAIN  loss dict:  {'classification_loss': 0.8597917425632476}
2025-01-13 14:21:17,141 [INFO] Step[4150/4329]: training loss : 0.8576461672782898 TRAIN  loss dict:  {'classification_loss': 0.8576461672782898}
2025-01-13 14:21:31,666 [INFO] Step[4200/4329]: training loss : 0.8584060490131378 TRAIN  loss dict:  {'classification_loss': 0.8584060490131378}
2025-01-13 14:21:46,406 [INFO] Step[4250/4329]: training loss : 0.857630250453949 TRAIN  loss dict:  {'classification_loss': 0.857630250453949}
2025-01-13 14:22:00,779 [INFO] Step[4300/4329]: training loss : 0.8579666757583618 TRAIN  loss dict:  {'classification_loss': 0.8579666757583618}
2025-01-13 14:24:27,736 [INFO] Label accuracies statistics:
2025-01-13 14:24:27,737 [INFO] {0: 0.5555555555555556, 1: 1.0, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.4166666666666667, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.5, 8: 0.75, 9: 0.9166666666666666, 10: 1.0, 11: 1.0, 12: 0.5833333333333334, 13: 0.5, 14: 0.75, 15: 0.7777777777777778, 16: 0.6666666666666666, 17: 0.4166666666666667, 18: 0.5, 19: 0.8333333333333334, 20: 0.6666666666666666, 21: 0.6666666666666666, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.6666666666666666, 26: 0.9166666666666666, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.6666666666666666, 31: 0.8333333333333334, 32: 0.75, 33: 0.9166666666666666, 34: 1.0, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.9166666666666666, 41: 0.5, 42: 1.0, 43: 0.9166666666666666, 44: 0.6666666666666666, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.8333333333333334, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.4166666666666667, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.9166666666666666, 60: 0.6666666666666666, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.6666666666666666, 69: 0.75, 70: 0.5, 71: 0.6666666666666666, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.6666666666666666, 78: 0.9166666666666666, 79: 0.6666666666666666, 80: 1.0, 81: 0.9166666666666666, 82: 0.6666666666666666, 83: 0.5, 84: 0.5, 85: 0.6666666666666666, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.75, 89: 0.5, 90: 0.5833333333333334, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.6666666666666666, 97: 0.5833333333333334, 98: 0.8333333333333334, 99: 1.0, 100: 0.8333333333333334, 101: 1.0, 102: 0.9166666666666666, 103: 1.0, 104: 1.0, 105: 0.9166666666666666, 106: 1.0, 107: 0.8333333333333334, 108: 1.0, 109: 0.8333333333333334, 110: 1.0, 111: 1.0, 112: 0.8333333333333334, 113: 0.5, 114: 0.5, 115: 0.9166666666666666, 116: 0.8333333333333334, 117: 0.75, 118: 0.9166666666666666, 119: 0.75, 120: 0.75, 121: 0.9166666666666666, 122: 0.75, 123: 1.0, 124: 1.0, 125: 0.9166666666666666, 126: 0.9166666666666666, 127: 0.9166666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.8333333333333334, 132: 0.8333333333333334, 133: 1.0, 134: 0.9166666666666666, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 0.9166666666666666, 142: 0.75, 143: 1.0, 144: 0.6666666666666666, 145: 1.0, 146: 1.0, 147: 0.9166666666666666, 148: 0.8333333333333334, 149: 1.0, 150: 0.5, 151: 0.9166666666666666, 152: 0.9166666666666666, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.4166666666666667, 161: 0.9166666666666666, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.9166666666666666, 169: 1.0, 170: 0.9166666666666666, 171: 0.75, 172: 1.0, 173: 0.8333333333333334, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.9166666666666666, 178: 1.0, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.6666666666666666, 183: 0.8333333333333334, 184: 0.75, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.6666666666666666, 189: 0.8333333333333334, 190: 0.6666666666666666, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.9166666666666666, 198: 0.6666666666666666}

2025-01-13 14:24:27,739 [INFO] [73] TRAIN  loss: 0.8595298238978096 acc: 0.999537963961189
2025-01-13 14:24:27,739 [INFO] [73] TRAIN  loss dict: {'classification_loss': 0.8595298238978096}
2025-01-13 14:24:27,739 [INFO] [73] VALIDATION loss: 1.5820526801275485 VALIDATION acc: 0.8211279461279462
2025-01-13 14:24:27,739 [INFO] [73] VALIDATION loss dict: {'classification_loss': 1.5820526801275485}
2025-01-13 14:24:27,739 [INFO] 
2025-01-13 14:24:49,313 [INFO] Step[50/4329]: training loss : 0.8577712166309357 TRAIN  loss dict:  {'classification_loss': 0.8577712166309357}
2025-01-13 14:25:03,787 [INFO] Step[100/4329]: training loss : 0.8734949696063995 TRAIN  loss dict:  {'classification_loss': 0.8734949696063995}
2025-01-13 14:25:18,180 [INFO] Step[150/4329]: training loss : 0.8823662996292114 TRAIN  loss dict:  {'classification_loss': 0.8823662996292114}
2025-01-13 14:25:32,528 [INFO] Step[200/4329]: training loss : 0.8771149480342865 TRAIN  loss dict:  {'classification_loss': 0.8771149480342865}
2025-01-13 14:25:46,908 [INFO] Step[250/4329]: training loss : 0.8662704193592071 TRAIN  loss dict:  {'classification_loss': 0.8662704193592071}
2025-01-13 14:26:01,088 [INFO] Step[300/4329]: training loss : 0.8618104982376099 TRAIN  loss dict:  {'classification_loss': 0.8618104982376099}
2025-01-13 14:26:15,570 [INFO] Step[350/4329]: training loss : 0.8625126445293426 TRAIN  loss dict:  {'classification_loss': 0.8625126445293426}
2025-01-13 14:26:30,157 [INFO] Step[400/4329]: training loss : 0.8575601768493653 TRAIN  loss dict:  {'classification_loss': 0.8575601768493653}
2025-01-13 14:26:44,617 [INFO] Step[450/4329]: training loss : 0.8582017612457276 TRAIN  loss dict:  {'classification_loss': 0.8582017612457276}
2025-01-13 14:26:58,831 [INFO] Step[500/4329]: training loss : 0.8580270802974701 TRAIN  loss dict:  {'classification_loss': 0.8580270802974701}
2025-01-13 14:27:13,574 [INFO] Step[550/4329]: training loss : 0.8581316339969635 TRAIN  loss dict:  {'classification_loss': 0.8581316339969635}
2025-01-13 14:27:28,321 [INFO] Step[600/4329]: training loss : 0.8581592965126038 TRAIN  loss dict:  {'classification_loss': 0.8581592965126038}
2025-01-13 14:27:42,761 [INFO] Step[650/4329]: training loss : 0.8579518294334412 TRAIN  loss dict:  {'classification_loss': 0.8579518294334412}
2025-01-13 14:27:57,255 [INFO] Step[700/4329]: training loss : 0.8585766303539276 TRAIN  loss dict:  {'classification_loss': 0.8585766303539276}
2025-01-13 14:28:11,684 [INFO] Step[750/4329]: training loss : 0.8569472479820252 TRAIN  loss dict:  {'classification_loss': 0.8569472479820252}
2025-01-13 14:28:25,986 [INFO] Step[800/4329]: training loss : 0.8581174719333649 TRAIN  loss dict:  {'classification_loss': 0.8581174719333649}
2025-01-13 14:28:40,212 [INFO] Step[850/4329]: training loss : 0.859112697839737 TRAIN  loss dict:  {'classification_loss': 0.859112697839737}
2025-01-13 14:28:54,404 [INFO] Step[900/4329]: training loss : 0.8571206271648407 TRAIN  loss dict:  {'classification_loss': 0.8571206271648407}
2025-01-13 14:29:09,073 [INFO] Step[950/4329]: training loss : 0.856870493888855 TRAIN  loss dict:  {'classification_loss': 0.856870493888855}
2025-01-13 14:29:23,439 [INFO] Step[1000/4329]: training loss : 0.8570915639400483 TRAIN  loss dict:  {'classification_loss': 0.8570915639400483}
2025-01-13 14:29:37,823 [INFO] Step[1050/4329]: training loss : 0.8567248296737671 TRAIN  loss dict:  {'classification_loss': 0.8567248296737671}
2025-01-13 14:29:52,533 [INFO] Step[1100/4329]: training loss : 0.8598873901367188 TRAIN  loss dict:  {'classification_loss': 0.8598873901367188}
2025-01-13 14:30:07,088 [INFO] Step[1150/4329]: training loss : 0.8582872045040131 TRAIN  loss dict:  {'classification_loss': 0.8582872045040131}
2025-01-13 14:30:21,605 [INFO] Step[1200/4329]: training loss : 0.8715935468673706 TRAIN  loss dict:  {'classification_loss': 0.8715935468673706}
2025-01-13 14:30:35,998 [INFO] Step[1250/4329]: training loss : 0.8614079213142395 TRAIN  loss dict:  {'classification_loss': 0.8614079213142395}
2025-01-13 14:30:50,463 [INFO] Step[1300/4329]: training loss : 0.8585616886615753 TRAIN  loss dict:  {'classification_loss': 0.8585616886615753}
2025-01-13 14:31:04,716 [INFO] Step[1350/4329]: training loss : 0.8580273735523224 TRAIN  loss dict:  {'classification_loss': 0.8580273735523224}
2025-01-13 14:31:18,956 [INFO] Step[1400/4329]: training loss : 0.8597551512718201 TRAIN  loss dict:  {'classification_loss': 0.8597551512718201}
2025-01-13 14:31:33,215 [INFO] Step[1450/4329]: training loss : 0.8604247093200683 TRAIN  loss dict:  {'classification_loss': 0.8604247093200683}
2025-01-13 14:31:47,495 [INFO] Step[1500/4329]: training loss : 0.8682483041286468 TRAIN  loss dict:  {'classification_loss': 0.8682483041286468}
2025-01-13 14:32:02,125 [INFO] Step[1550/4329]: training loss : 0.8602052748203277 TRAIN  loss dict:  {'classification_loss': 0.8602052748203277}
2025-01-13 14:32:16,701 [INFO] Step[1600/4329]: training loss : 0.8638858413696289 TRAIN  loss dict:  {'classification_loss': 0.8638858413696289}
2025-01-13 14:32:31,297 [INFO] Step[1650/4329]: training loss : 0.8571398568153381 TRAIN  loss dict:  {'classification_loss': 0.8571398568153381}
2025-01-13 14:32:45,683 [INFO] Step[1700/4329]: training loss : 0.8609260869026184 TRAIN  loss dict:  {'classification_loss': 0.8609260869026184}
2025-01-13 14:33:00,065 [INFO] Step[1750/4329]: training loss : 0.8594974601268768 TRAIN  loss dict:  {'classification_loss': 0.8594974601268768}
2025-01-13 14:33:13,959 [INFO] Step[1800/4329]: training loss : 0.8619509482383728 TRAIN  loss dict:  {'classification_loss': 0.8619509482383728}
2025-01-13 14:33:27,919 [INFO] Step[1850/4329]: training loss : 0.8581330382823944 TRAIN  loss dict:  {'classification_loss': 0.8581330382823944}
2025-01-13 14:33:42,119 [INFO] Step[1900/4329]: training loss : 0.8581625699996949 TRAIN  loss dict:  {'classification_loss': 0.8581625699996949}
2025-01-13 14:33:56,102 [INFO] Step[1950/4329]: training loss : 0.8598099565505981 TRAIN  loss dict:  {'classification_loss': 0.8598099565505981}
2025-01-13 14:34:09,977 [INFO] Step[2000/4329]: training loss : 0.8586970031261444 TRAIN  loss dict:  {'classification_loss': 0.8586970031261444}
2025-01-13 14:34:24,085 [INFO] Step[2050/4329]: training loss : 0.8579729211330414 TRAIN  loss dict:  {'classification_loss': 0.8579729211330414}
2025-01-13 14:34:38,282 [INFO] Step[2100/4329]: training loss : 0.8653859555721283 TRAIN  loss dict:  {'classification_loss': 0.8653859555721283}
2025-01-13 14:34:53,010 [INFO] Step[2150/4329]: training loss : 0.8584887492656708 TRAIN  loss dict:  {'classification_loss': 0.8584887492656708}
2025-01-13 14:35:07,709 [INFO] Step[2200/4329]: training loss : 0.8585337567329406 TRAIN  loss dict:  {'classification_loss': 0.8585337567329406}
2025-01-13 14:35:22,502 [INFO] Step[2250/4329]: training loss : 0.8584284198284149 TRAIN  loss dict:  {'classification_loss': 0.8584284198284149}
2025-01-13 14:35:36,789 [INFO] Step[2300/4329]: training loss : 0.8587635898590088 TRAIN  loss dict:  {'classification_loss': 0.8587635898590088}
2025-01-13 14:35:51,280 [INFO] Step[2350/4329]: training loss : 0.857059873342514 TRAIN  loss dict:  {'classification_loss': 0.857059873342514}
2025-01-13 14:36:05,969 [INFO] Step[2400/4329]: training loss : 0.85778391122818 TRAIN  loss dict:  {'classification_loss': 0.85778391122818}
2025-01-13 14:36:20,491 [INFO] Step[2450/4329]: training loss : 0.8592321133613586 TRAIN  loss dict:  {'classification_loss': 0.8592321133613586}
2025-01-13 14:36:35,021 [INFO] Step[2500/4329]: training loss : 0.858325926065445 TRAIN  loss dict:  {'classification_loss': 0.858325926065445}
2025-01-13 14:36:49,322 [INFO] Step[2550/4329]: training loss : 0.859899023771286 TRAIN  loss dict:  {'classification_loss': 0.859899023771286}
2025-01-13 14:37:03,559 [INFO] Step[2600/4329]: training loss : 0.8588545632362365 TRAIN  loss dict:  {'classification_loss': 0.8588545632362365}
2025-01-13 14:37:18,094 [INFO] Step[2650/4329]: training loss : 0.8594216680526734 TRAIN  loss dict:  {'classification_loss': 0.8594216680526734}
2025-01-13 14:37:32,483 [INFO] Step[2700/4329]: training loss : 0.8586164474487304 TRAIN  loss dict:  {'classification_loss': 0.8586164474487304}
2025-01-13 14:37:46,873 [INFO] Step[2750/4329]: training loss : 0.8579671716690064 TRAIN  loss dict:  {'classification_loss': 0.8579671716690064}
2025-01-13 14:38:01,257 [INFO] Step[2800/4329]: training loss : 0.8687653756141662 TRAIN  loss dict:  {'classification_loss': 0.8687653756141662}
2025-01-13 14:38:15,996 [INFO] Step[2850/4329]: training loss : 0.8582247304916382 TRAIN  loss dict:  {'classification_loss': 0.8582247304916382}
2025-01-13 14:38:30,746 [INFO] Step[2900/4329]: training loss : 0.8571741855144501 TRAIN  loss dict:  {'classification_loss': 0.8571741855144501}
2025-01-13 14:38:45,513 [INFO] Step[2950/4329]: training loss : 0.8682012665271759 TRAIN  loss dict:  {'classification_loss': 0.8682012665271759}
2025-01-13 14:38:59,883 [INFO] Step[3000/4329]: training loss : 0.858404459953308 TRAIN  loss dict:  {'classification_loss': 0.858404459953308}
2025-01-13 14:39:14,273 [INFO] Step[3050/4329]: training loss : 0.8584391701221467 TRAIN  loss dict:  {'classification_loss': 0.8584391701221467}
2025-01-13 14:39:28,985 [INFO] Step[3100/4329]: training loss : 0.8587878572940827 TRAIN  loss dict:  {'classification_loss': 0.8587878572940827}
2025-01-13 14:39:43,717 [INFO] Step[3150/4329]: training loss : 0.8582379651069642 TRAIN  loss dict:  {'classification_loss': 0.8582379651069642}
2025-01-13 14:39:58,422 [INFO] Step[3200/4329]: training loss : 0.8575183117389679 TRAIN  loss dict:  {'classification_loss': 0.8575183117389679}
2025-01-13 14:40:13,162 [INFO] Step[3250/4329]: training loss : 0.8611601746082306 TRAIN  loss dict:  {'classification_loss': 0.8611601746082306}
2025-01-13 14:40:27,455 [INFO] Step[3300/4329]: training loss : 0.8574122321605683 TRAIN  loss dict:  {'classification_loss': 0.8574122321605683}
2025-01-13 14:40:41,762 [INFO] Step[3350/4329]: training loss : 0.8582449042797089 TRAIN  loss dict:  {'classification_loss': 0.8582449042797089}
2025-01-13 14:40:56,009 [INFO] Step[3400/4329]: training loss : 0.8591204440593719 TRAIN  loss dict:  {'classification_loss': 0.8591204440593719}
2025-01-13 14:41:10,552 [INFO] Step[3450/4329]: training loss : 0.8571257424354554 TRAIN  loss dict:  {'classification_loss': 0.8571257424354554}
2025-01-13 14:41:25,223 [INFO] Step[3500/4329]: training loss : 0.8649976694583893 TRAIN  loss dict:  {'classification_loss': 0.8649976694583893}
2025-01-13 14:41:39,621 [INFO] Step[3550/4329]: training loss : 0.8598556745052338 TRAIN  loss dict:  {'classification_loss': 0.8598556745052338}
2025-01-13 14:41:53,871 [INFO] Step[3600/4329]: training loss : 0.8568897938728333 TRAIN  loss dict:  {'classification_loss': 0.8568897938728333}
2025-01-13 14:42:08,306 [INFO] Step[3650/4329]: training loss : 0.8569398820400238 TRAIN  loss dict:  {'classification_loss': 0.8569398820400238}
2025-01-13 14:42:22,976 [INFO] Step[3700/4329]: training loss : 0.859503846168518 TRAIN  loss dict:  {'classification_loss': 0.859503846168518}
2025-01-13 14:42:37,315 [INFO] Step[3750/4329]: training loss : 0.8580601620674133 TRAIN  loss dict:  {'classification_loss': 0.8580601620674133}
2025-01-13 14:42:52,017 [INFO] Step[3800/4329]: training loss : 0.8574693322181701 TRAIN  loss dict:  {'classification_loss': 0.8574693322181701}
2025-01-13 14:43:06,226 [INFO] Step[3850/4329]: training loss : 0.8625414764881134 TRAIN  loss dict:  {'classification_loss': 0.8625414764881134}
2025-01-13 14:43:20,329 [INFO] Step[3900/4329]: training loss : 0.8580028545856476 TRAIN  loss dict:  {'classification_loss': 0.8580028545856476}
2025-01-13 14:43:34,572 [INFO] Step[3950/4329]: training loss : 0.8605158376693726 TRAIN  loss dict:  {'classification_loss': 0.8605158376693726}
2025-01-13 14:43:48,965 [INFO] Step[4000/4329]: training loss : 0.860161292552948 TRAIN  loss dict:  {'classification_loss': 0.860161292552948}
2025-01-13 14:44:03,174 [INFO] Step[4050/4329]: training loss : 0.8578774535655975 TRAIN  loss dict:  {'classification_loss': 0.8578774535655975}
2025-01-13 14:44:17,461 [INFO] Step[4100/4329]: training loss : 0.8599860656261444 TRAIN  loss dict:  {'classification_loss': 0.8599860656261444}
2025-01-13 14:44:31,816 [INFO] Step[4150/4329]: training loss : 0.8595531189441681 TRAIN  loss dict:  {'classification_loss': 0.8595531189441681}
2025-01-13 14:44:46,038 [INFO] Step[4200/4329]: training loss : 0.8648565554618836 TRAIN  loss dict:  {'classification_loss': 0.8648565554618836}
2025-01-13 14:45:00,684 [INFO] Step[4250/4329]: training loss : 0.8581788671016694 TRAIN  loss dict:  {'classification_loss': 0.8581788671016694}
2025-01-13 14:45:15,027 [INFO] Step[4300/4329]: training loss : 0.8571749138832092 TRAIN  loss dict:  {'classification_loss': 0.8571749138832092}
2025-01-13 14:47:58,592 [INFO] Label accuracies statistics:
2025-01-13 14:47:58,592 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5, 7: 0.5, 8: 0.6666666666666666, 9: 1.0, 10: 1.0, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.5, 14: 0.75, 15: 0.7777777777777778, 16: 0.6666666666666666, 17: 0.5833333333333334, 18: 0.4166666666666667, 19: 0.6666666666666666, 20: 0.5833333333333334, 21: 0.75, 22: 0.75, 23: 0.9166666666666666, 24: 1.0, 25: 0.75, 26: 0.9166666666666666, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.6666666666666666, 32: 0.75, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 0.9166666666666666, 38: 0.9166666666666666, 39: 1.0, 40: 0.8333333333333334, 41: 0.5, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.75, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5833333333333334, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5833333333333334, 59: 0.9166666666666666, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.6666666666666666, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.9166666666666666, 68: 0.6666666666666666, 69: 0.5833333333333334, 70: 0.5, 71: 0.6666666666666666, 72: 0.8333333333333334, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 0.9166666666666666, 79: 0.8333333333333334, 80: 1.0, 81: 1.0, 82: 0.6666666666666666, 83: 0.5833333333333334, 84: 0.5833333333333334, 85: 0.75, 86: 0.5833333333333334, 87: 0.8333333333333334, 88: 0.8333333333333334, 89: 0.5833333333333334, 90: 0.8333333333333334, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 1.0, 96: 0.5, 97: 0.75, 98: 0.8333333333333334, 99: 0.9333333333333333, 100: 0.8333333333333334, 101: 1.0, 102: 0.9166666666666666, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.6666666666666666, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 0.9166666666666666, 111: 1.0, 112: 0.8333333333333334, 113: 0.4166666666666667, 114: 0.4166666666666667, 115: 0.9166666666666666, 116: 0.8333333333333334, 117: 0.75, 118: 1.0, 119: 0.6666666666666666, 120: 0.8333333333333334, 121: 0.8333333333333334, 122: 0.8333333333333334, 123: 0.9166666666666666, 124: 1.0, 125: 0.75, 126: 0.9166666666666666, 127: 0.8333333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.9166666666666666, 132: 0.75, 133: 1.0, 134: 0.75, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 0.9166666666666666, 143: 1.0, 144: 0.5833333333333334, 145: 1.0, 146: 1.0, 147: 0.8333333333333334, 148: 0.6666666666666666, 149: 1.0, 150: 0.4166666666666667, 151: 0.9166666666666666, 152: 0.9166666666666666, 153: 0.9166666666666666, 154: 1.0, 155: 1.0, 156: 0.5833333333333334, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.3333333333333333, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.75, 166: 0.8333333333333334, 167: 0.75, 168: 0.8333333333333334, 169: 1.0, 170: 1.0, 171: 0.6666666666666666, 172: 1.0, 173: 0.8333333333333334, 174: 1.0, 175: 0.9166666666666666, 176: 1.0, 177: 0.8333333333333334, 178: 1.0, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.5833333333333334, 183: 0.75, 184: 0.6666666666666666, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.75, 189: 0.9166666666666666, 190: 0.5, 191: 0.6666666666666666, 192: 0.9166666666666666, 193: 0.9166666666666666, 194: 0.8333333333333334, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.6666666666666666}

2025-01-13 14:47:58,599 [INFO] [74] TRAIN  loss: 0.8602075544288126 acc: 0.9993069459417835
2025-01-13 14:47:58,600 [INFO] [74] TRAIN  loss dict: {'classification_loss': 0.8602075544288126}
2025-01-13 14:47:58,600 [INFO] [74] VALIDATION loss: 1.6075632517235448 VALIDATION acc: 0.8131313131313131
2025-01-13 14:47:58,601 [INFO] [74] VALIDATION loss dict: {'classification_loss': 1.6075632517235448}
2025-01-13 14:47:58,601 [INFO] 
2025-01-13 14:48:23,404 [INFO] Step[50/4329]: training loss : 0.8574857759475708 TRAIN  loss dict:  {'classification_loss': 0.8574857759475708}
2025-01-13 14:48:37,886 [INFO] Step[100/4329]: training loss : 0.8576438403129578 TRAIN  loss dict:  {'classification_loss': 0.8576438403129578}
2025-01-13 14:48:52,636 [INFO] Step[150/4329]: training loss : 0.8587207961082458 TRAIN  loss dict:  {'classification_loss': 0.8587207961082458}
2025-01-13 14:49:06,960 [INFO] Step[200/4329]: training loss : 0.8595339298248291 TRAIN  loss dict:  {'classification_loss': 0.8595339298248291}
2025-01-13 14:49:21,230 [INFO] Step[250/4329]: training loss : 0.856899141073227 TRAIN  loss dict:  {'classification_loss': 0.856899141073227}
2025-01-13 14:49:35,736 [INFO] Step[300/4329]: training loss : 0.8570901072025299 TRAIN  loss dict:  {'classification_loss': 0.8570901072025299}
2025-01-13 14:49:50,295 [INFO] Step[350/4329]: training loss : 0.8586140441894531 TRAIN  loss dict:  {'classification_loss': 0.8586140441894531}
2025-01-13 14:50:04,600 [INFO] Step[400/4329]: training loss : 0.8819686794281005 TRAIN  loss dict:  {'classification_loss': 0.8819686794281005}
2025-01-13 14:50:18,899 [INFO] Step[450/4329]: training loss : 0.863974232673645 TRAIN  loss dict:  {'classification_loss': 0.863974232673645}
2025-01-13 14:50:33,214 [INFO] Step[500/4329]: training loss : 0.8580604290962219 TRAIN  loss dict:  {'classification_loss': 0.8580604290962219}
2025-01-13 14:50:47,870 [INFO] Step[550/4329]: training loss : 0.861392593383789 TRAIN  loss dict:  {'classification_loss': 0.861392593383789}
2025-01-13 14:51:02,621 [INFO] Step[600/4329]: training loss : 0.8934209656715393 TRAIN  loss dict:  {'classification_loss': 0.8934209656715393}
2025-01-13 14:51:17,143 [INFO] Step[650/4329]: training loss : 0.8634294211864472 TRAIN  loss dict:  {'classification_loss': 0.8634294211864472}
2025-01-13 14:51:31,621 [INFO] Step[700/4329]: training loss : 0.859020186662674 TRAIN  loss dict:  {'classification_loss': 0.859020186662674}
2025-01-13 14:51:46,105 [INFO] Step[750/4329]: training loss : 0.8573296630382538 TRAIN  loss dict:  {'classification_loss': 0.8573296630382538}
2025-01-13 14:52:00,858 [INFO] Step[800/4329]: training loss : 0.8588938689231873 TRAIN  loss dict:  {'classification_loss': 0.8588938689231873}
2025-01-13 14:52:15,300 [INFO] Step[850/4329]: training loss : 0.8575640738010406 TRAIN  loss dict:  {'classification_loss': 0.8575640738010406}
2025-01-13 14:52:29,736 [INFO] Step[900/4329]: training loss : 0.8563957262039185 TRAIN  loss dict:  {'classification_loss': 0.8563957262039185}
2025-01-13 14:52:44,070 [INFO] Step[950/4329]: training loss : 0.8594276678562164 TRAIN  loss dict:  {'classification_loss': 0.8594276678562164}
2025-01-13 14:52:58,717 [INFO] Step[1000/4329]: training loss : 0.8586227989196777 TRAIN  loss dict:  {'classification_loss': 0.8586227989196777}
2025-01-13 14:53:13,225 [INFO] Step[1050/4329]: training loss : 0.8677537214756011 TRAIN  loss dict:  {'classification_loss': 0.8677537214756011}
2025-01-13 14:53:27,809 [INFO] Step[1100/4329]: training loss : 0.8575131344795227 TRAIN  loss dict:  {'classification_loss': 0.8575131344795227}
2025-01-13 14:53:42,618 [INFO] Step[1150/4329]: training loss : 0.8576115190982818 TRAIN  loss dict:  {'classification_loss': 0.8576115190982818}
2025-01-13 14:53:57,113 [INFO] Step[1200/4329]: training loss : 0.8576064121723175 TRAIN  loss dict:  {'classification_loss': 0.8576064121723175}
2025-01-13 14:54:10,945 [INFO] Step[1250/4329]: training loss : 0.8601352775096893 TRAIN  loss dict:  {'classification_loss': 0.8601352775096893}
2025-01-13 14:54:23,864 [INFO] Step[1300/4329]: training loss : 0.8807560265064239 TRAIN  loss dict:  {'classification_loss': 0.8807560265064239}
2025-01-13 14:54:36,779 [INFO] Step[1350/4329]: training loss : 0.8573922801017761 TRAIN  loss dict:  {'classification_loss': 0.8573922801017761}
2025-01-13 14:54:50,660 [INFO] Step[1400/4329]: training loss : 0.8576885569095611 TRAIN  loss dict:  {'classification_loss': 0.8576885569095611}
2025-01-13 14:55:03,608 [INFO] Step[1450/4329]: training loss : 0.8574872076511383 TRAIN  loss dict:  {'classification_loss': 0.8574872076511383}
2025-01-13 14:55:17,696 [INFO] Step[1500/4329]: training loss : 0.8571458876132965 TRAIN  loss dict:  {'classification_loss': 0.8571458876132965}
2025-01-13 14:55:32,172 [INFO] Step[1550/4329]: training loss : 0.8580340552330017 TRAIN  loss dict:  {'classification_loss': 0.8580340552330017}
2025-01-13 14:55:46,559 [INFO] Step[1600/4329]: training loss : 0.8577277493476868 TRAIN  loss dict:  {'classification_loss': 0.8577277493476868}
2025-01-13 14:56:01,291 [INFO] Step[1650/4329]: training loss : 0.8593826305866241 TRAIN  loss dict:  {'classification_loss': 0.8593826305866241}
2025-01-13 14:56:15,653 [INFO] Step[1700/4329]: training loss : 0.8615359294414521 TRAIN  loss dict:  {'classification_loss': 0.8615359294414521}
2025-01-13 14:56:30,385 [INFO] Step[1750/4329]: training loss : 0.8616558647155762 TRAIN  loss dict:  {'classification_loss': 0.8616558647155762}
2025-01-13 14:56:45,087 [INFO] Step[1800/4329]: training loss : 0.856760505437851 TRAIN  loss dict:  {'classification_loss': 0.856760505437851}
2025-01-13 14:56:59,901 [INFO] Step[1850/4329]: training loss : 0.8569978737831115 TRAIN  loss dict:  {'classification_loss': 0.8569978737831115}
2025-01-13 14:57:14,638 [INFO] Step[1900/4329]: training loss : 0.858176052570343 TRAIN  loss dict:  {'classification_loss': 0.858176052570343}
2025-01-13 14:57:28,900 [INFO] Step[1950/4329]: training loss : 0.8588888621330262 TRAIN  loss dict:  {'classification_loss': 0.8588888621330262}
2025-01-13 14:57:43,656 [INFO] Step[2000/4329]: training loss : 0.8585966849327087 TRAIN  loss dict:  {'classification_loss': 0.8585966849327087}
2025-01-13 14:57:57,947 [INFO] Step[2050/4329]: training loss : 0.8656058716773987 TRAIN  loss dict:  {'classification_loss': 0.8656058716773987}
2025-01-13 14:58:12,598 [INFO] Step[2100/4329]: training loss : 0.8578918623924255 TRAIN  loss dict:  {'classification_loss': 0.8578918623924255}
2025-01-13 14:58:27,163 [INFO] Step[2150/4329]: training loss : 0.8830631446838378 TRAIN  loss dict:  {'classification_loss': 0.8830631446838378}
2025-01-13 14:58:41,414 [INFO] Step[2200/4329]: training loss : 0.8575185716152192 TRAIN  loss dict:  {'classification_loss': 0.8575185716152192}
2025-01-13 14:58:55,816 [INFO] Step[2250/4329]: training loss : 0.8582427287101746 TRAIN  loss dict:  {'classification_loss': 0.8582427287101746}
2025-01-13 14:59:10,216 [INFO] Step[2300/4329]: training loss : 0.8600600636005402 TRAIN  loss dict:  {'classification_loss': 0.8600600636005402}
2025-01-13 14:59:24,901 [INFO] Step[2350/4329]: training loss : 0.8569863188266754 TRAIN  loss dict:  {'classification_loss': 0.8569863188266754}
2025-01-13 14:59:39,280 [INFO] Step[2400/4329]: training loss : 0.8563914310932159 TRAIN  loss dict:  {'classification_loss': 0.8563914310932159}
2025-01-13 14:59:53,679 [INFO] Step[2450/4329]: training loss : 0.8619895470142365 TRAIN  loss dict:  {'classification_loss': 0.8619895470142365}
2025-01-13 15:00:08,339 [INFO] Step[2500/4329]: training loss : 0.8582956147193909 TRAIN  loss dict:  {'classification_loss': 0.8582956147193909}
2025-01-13 15:00:22,172 [INFO] Step[2550/4329]: training loss : 0.8589317917823791 TRAIN  loss dict:  {'classification_loss': 0.8589317917823791}
2025-01-13 15:00:35,944 [INFO] Step[2600/4329]: training loss : 0.858518807888031 TRAIN  loss dict:  {'classification_loss': 0.858518807888031}
2025-01-13 15:00:49,726 [INFO] Step[2650/4329]: training loss : 0.8570516884326935 TRAIN  loss dict:  {'classification_loss': 0.8570516884326935}
2025-01-13 15:01:03,938 [INFO] Step[2700/4329]: training loss : 0.8571154403686524 TRAIN  loss dict:  {'classification_loss': 0.8571154403686524}
2025-01-13 15:01:18,017 [INFO] Step[2750/4329]: training loss : 0.857720091342926 TRAIN  loss dict:  {'classification_loss': 0.857720091342926}
2025-01-13 15:01:31,724 [INFO] Step[2800/4329]: training loss : 0.8578105401992798 TRAIN  loss dict:  {'classification_loss': 0.8578105401992798}
2025-01-13 15:01:45,591 [INFO] Step[2850/4329]: training loss : 0.8572002017498016 TRAIN  loss dict:  {'classification_loss': 0.8572002017498016}
2025-01-13 15:01:59,814 [INFO] Step[2900/4329]: training loss : 0.8596106874942779 TRAIN  loss dict:  {'classification_loss': 0.8596106874942779}
2025-01-13 15:02:14,175 [INFO] Step[2950/4329]: training loss : 0.8583774173259735 TRAIN  loss dict:  {'classification_loss': 0.8583774173259735}
2025-01-13 15:02:27,817 [INFO] Step[3000/4329]: training loss : 0.8577508342266082 TRAIN  loss dict:  {'classification_loss': 0.8577508342266082}
2025-01-13 15:02:41,548 [INFO] Step[3050/4329]: training loss : 0.8645686483383179 TRAIN  loss dict:  {'classification_loss': 0.8645686483383179}
2025-01-13 15:02:55,092 [INFO] Step[3100/4329]: training loss : 0.8565253210067749 TRAIN  loss dict:  {'classification_loss': 0.8565253210067749}
2025-01-13 15:03:09,623 [INFO] Step[3150/4329]: training loss : 0.8585675323009491 TRAIN  loss dict:  {'classification_loss': 0.8585675323009491}
2025-01-13 15:03:23,445 [INFO] Step[3200/4329]: training loss : 0.8630489325523376 TRAIN  loss dict:  {'classification_loss': 0.8630489325523376}
2025-01-13 15:03:39,076 [INFO] Step[3250/4329]: training loss : 0.8578782117366791 TRAIN  loss dict:  {'classification_loss': 0.8578782117366791}
2025-01-13 15:03:52,772 [INFO] Step[3300/4329]: training loss : 0.8631671977043152 TRAIN  loss dict:  {'classification_loss': 0.8631671977043152}
2025-01-13 15:04:07,260 [INFO] Step[3350/4329]: training loss : 0.8690690624713898 TRAIN  loss dict:  {'classification_loss': 0.8690690624713898}
2025-01-13 15:04:20,766 [INFO] Step[3400/4329]: training loss : 0.8566282570362092 TRAIN  loss dict:  {'classification_loss': 0.8566282570362092}
2025-01-13 15:04:35,103 [INFO] Step[3450/4329]: training loss : 0.8581933796405792 TRAIN  loss dict:  {'classification_loss': 0.8581933796405792}
2025-01-13 15:04:49,672 [INFO] Step[3500/4329]: training loss : 0.8581380343437195 TRAIN  loss dict:  {'classification_loss': 0.8581380343437195}
2025-01-13 15:05:03,482 [INFO] Step[3550/4329]: training loss : 0.8631096720695496 TRAIN  loss dict:  {'classification_loss': 0.8631096720695496}
2025-01-13 15:05:17,348 [INFO] Step[3600/4329]: training loss : 0.8584726846218109 TRAIN  loss dict:  {'classification_loss': 0.8584726846218109}
2025-01-13 15:05:31,707 [INFO] Step[3650/4329]: training loss : 0.8617035031318665 TRAIN  loss dict:  {'classification_loss': 0.8617035031318665}
2025-01-13 15:05:45,200 [INFO] Step[3700/4329]: training loss : 0.8577206039428711 TRAIN  loss dict:  {'classification_loss': 0.8577206039428711}
2025-01-13 15:05:59,679 [INFO] Step[3750/4329]: training loss : 0.875788996219635 TRAIN  loss dict:  {'classification_loss': 0.875788996219635}
2025-01-13 15:06:13,590 [INFO] Step[3800/4329]: training loss : 0.8588450157642364 TRAIN  loss dict:  {'classification_loss': 0.8588450157642364}
2025-01-13 15:06:27,199 [INFO] Step[3850/4329]: training loss : 0.8618627202510833 TRAIN  loss dict:  {'classification_loss': 0.8618627202510833}
2025-01-13 15:06:40,872 [INFO] Step[3900/4329]: training loss : 0.85690194606781 TRAIN  loss dict:  {'classification_loss': 0.85690194606781}
2025-01-13 15:06:55,297 [INFO] Step[3950/4329]: training loss : 0.860356582403183 TRAIN  loss dict:  {'classification_loss': 0.860356582403183}
2025-01-13 15:07:09,124 [INFO] Step[4000/4329]: training loss : 0.8587007236480713 TRAIN  loss dict:  {'classification_loss': 0.8587007236480713}
2025-01-13 15:07:23,067 [INFO] Step[4050/4329]: training loss : 0.8622512292861938 TRAIN  loss dict:  {'classification_loss': 0.8622512292861938}
2025-01-13 15:07:37,128 [INFO] Step[4100/4329]: training loss : 0.8575696158409118 TRAIN  loss dict:  {'classification_loss': 0.8575696158409118}
2025-01-13 15:07:50,689 [INFO] Step[4150/4329]: training loss : 0.8638224995136261 TRAIN  loss dict:  {'classification_loss': 0.8638224995136261}
2025-01-13 15:08:04,349 [INFO] Step[4200/4329]: training loss : 0.8566084480285645 TRAIN  loss dict:  {'classification_loss': 0.8566084480285645}
2025-01-13 15:08:18,563 [INFO] Step[4250/4329]: training loss : 0.8578311848640442 TRAIN  loss dict:  {'classification_loss': 0.8578311848640442}
2025-01-13 15:08:32,965 [INFO] Step[4300/4329]: training loss : 0.8574811112880707 TRAIN  loss dict:  {'classification_loss': 0.8574811112880707}
2025-01-13 15:12:12,663 [INFO] Label accuracies statistics:
2025-01-13 15:12:12,664 [INFO] {0: 0.7777777777777778, 1: 1.0, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.9166666666666666, 6: 0.5833333333333334, 7: 0.5, 8: 0.5, 9: 1.0, 10: 1.0, 11: 0.8333333333333334, 12: 0.4166666666666667, 13: 0.5, 14: 0.6666666666666666, 15: 0.7777777777777778, 16: 0.5833333333333334, 17: 0.5, 18: 0.5, 19: 0.75, 20: 0.5833333333333334, 21: 0.75, 22: 0.75, 23: 0.8333333333333334, 24: 1.0, 25: 0.5, 26: 0.8333333333333334, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.6666666666666666, 32: 0.75, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 1.0, 36: 0.6666666666666666, 37: 1.0, 38: 0.9166666666666666, 39: 1.0, 40: 0.9166666666666666, 41: 0.5, 42: 0.8333333333333334, 43: 0.9166666666666666, 44: 0.5833333333333334, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.6666666666666666, 51: 0.75, 52: 1.0, 53: 0.5833333333333334, 54: 0.4166666666666667, 55: 0.6666666666666666, 56: 0.6666666666666666, 57: 0.75, 58: 0.5, 59: 0.5833333333333334, 60: 0.8333333333333334, 61: 0.9166666666666666, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.9166666666666666, 68: 0.6666666666666666, 69: 0.6666666666666666, 70: 0.4166666666666667, 71: 0.6666666666666666, 72: 0.75, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 0.9166666666666666, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.8333333333333334, 83: 0.5833333333333334, 84: 0.5, 85: 0.75, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.5833333333333334, 89: 0.5, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.5833333333333334, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.8333333333333334, 101: 1.0, 102: 0.9166666666666666, 103: 1.0, 104: 1.0, 105: 0.9166666666666666, 106: 1.0, 107: 0.4166666666666667, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 1.0, 111: 1.0, 112: 0.9166666666666666, 113: 0.5, 114: 0.5833333333333334, 115: 1.0, 116: 0.9166666666666666, 117: 0.75, 118: 1.0, 119: 0.8333333333333334, 120: 0.6666666666666666, 121: 0.8333333333333334, 122: 0.9166666666666666, 123: 1.0, 124: 1.0, 125: 0.9166666666666666, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.9166666666666666, 132: 0.75, 133: 1.0, 134: 0.8333333333333334, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 1.0, 141: 0.9166666666666666, 142: 0.75, 143: 0.9166666666666666, 144: 0.75, 145: 1.0, 146: 0.9166666666666666, 147: 0.8333333333333334, 148: 0.6666666666666666, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.6666666666666666, 158: 0.7777777777777778, 159: 1.0, 160: 0.3333333333333333, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.5833333333333334, 166: 0.8333333333333334, 167: 0.8333333333333334, 168: 0.9166666666666666, 169: 1.0, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.75, 182: 0.5833333333333334, 183: 0.8333333333333334, 184: 0.75, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.6666666666666666, 189: 0.9166666666666666, 190: 0.5833333333333334, 191: 0.6666666666666666, 192: 0.9166666666666666, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.75}

2025-01-13 15:12:12,667 [INFO] [75] TRAIN  loss: 0.8605477599933533 acc: 0.9991529339288464
2025-01-13 15:12:12,667 [INFO] [75] TRAIN  loss dict: {'classification_loss': 0.8605477599933533}
2025-01-13 15:12:12,667 [INFO] [75] VALIDATION loss: 1.6242138871339837 VALIDATION acc: 0.8068181818181818
2025-01-13 15:12:12,667 [INFO] [75] VALIDATION loss dict: {'classification_loss': 1.6242138871339837}
2025-01-13 15:12:12,667 [INFO] 
2025-01-13 15:12:39,346 [INFO] Step[50/4329]: training loss : 0.8578870081901551 TRAIN  loss dict:  {'classification_loss': 0.8578870081901551}
2025-01-13 15:12:53,352 [INFO] Step[100/4329]: training loss : 0.8600547099113465 TRAIN  loss dict:  {'classification_loss': 0.8600547099113465}
2025-01-13 15:13:07,423 [INFO] Step[150/4329]: training loss : 0.8598980808258057 TRAIN  loss dict:  {'classification_loss': 0.8598980808258057}
2025-01-13 15:13:21,117 [INFO] Step[200/4329]: training loss : 0.8568063426017761 TRAIN  loss dict:  {'classification_loss': 0.8568063426017761}
2025-01-13 15:13:36,123 [INFO] Step[250/4329]: training loss : 0.8584188532829284 TRAIN  loss dict:  {'classification_loss': 0.8584188532829284}
2025-01-13 15:13:50,482 [INFO] Step[300/4329]: training loss : 0.8588120234012604 TRAIN  loss dict:  {'classification_loss': 0.8588120234012604}
2025-01-13 15:14:04,824 [INFO] Step[350/4329]: training loss : 0.8633353006839752 TRAIN  loss dict:  {'classification_loss': 0.8633353006839752}
2025-01-13 15:14:18,753 [INFO] Step[400/4329]: training loss : 0.8571008014678955 TRAIN  loss dict:  {'classification_loss': 0.8571008014678955}
2025-01-13 15:14:32,387 [INFO] Step[450/4329]: training loss : 0.8581296992301941 TRAIN  loss dict:  {'classification_loss': 0.8581296992301941}
2025-01-13 15:14:46,007 [INFO] Step[500/4329]: training loss : 0.8584115719795227 TRAIN  loss dict:  {'classification_loss': 0.8584115719795227}
2025-01-13 15:14:59,771 [INFO] Step[550/4329]: training loss : 0.8588492286205291 TRAIN  loss dict:  {'classification_loss': 0.8588492286205291}
2025-01-13 15:15:13,957 [INFO] Step[600/4329]: training loss : 0.8607287955284119 TRAIN  loss dict:  {'classification_loss': 0.8607287955284119}
2025-01-13 15:15:28,276 [INFO] Step[650/4329]: training loss : 0.8581112349033355 TRAIN  loss dict:  {'classification_loss': 0.8581112349033355}
2025-01-13 15:15:42,025 [INFO] Step[700/4329]: training loss : 0.8564300560951232 TRAIN  loss dict:  {'classification_loss': 0.8564300560951232}
2025-01-13 15:15:56,213 [INFO] Step[750/4329]: training loss : 0.8567343485355378 TRAIN  loss dict:  {'classification_loss': 0.8567343485355378}
2025-01-13 15:16:10,049 [INFO] Step[800/4329]: training loss : 0.860979825258255 TRAIN  loss dict:  {'classification_loss': 0.860979825258255}
2025-01-13 15:16:24,025 [INFO] Step[850/4329]: training loss : 0.8573067581653595 TRAIN  loss dict:  {'classification_loss': 0.8573067581653595}
2025-01-13 15:16:37,682 [INFO] Step[900/4329]: training loss : 0.8600494682788848 TRAIN  loss dict:  {'classification_loss': 0.8600494682788848}
2025-01-13 15:16:51,494 [INFO] Step[950/4329]: training loss : 0.857810115814209 TRAIN  loss dict:  {'classification_loss': 0.857810115814209}
2025-01-13 15:17:05,632 [INFO] Step[1000/4329]: training loss : 0.8571004295349121 TRAIN  loss dict:  {'classification_loss': 0.8571004295349121}
2025-01-13 15:17:19,914 [INFO] Step[1050/4329]: training loss : 0.8568059396743775 TRAIN  loss dict:  {'classification_loss': 0.8568059396743775}
2025-01-13 15:17:33,966 [INFO] Step[1100/4329]: training loss : 0.879688274860382 TRAIN  loss dict:  {'classification_loss': 0.879688274860382}
2025-01-13 15:17:48,320 [INFO] Step[1150/4329]: training loss : 0.8617246961593628 TRAIN  loss dict:  {'classification_loss': 0.8617246961593628}
2025-01-13 15:18:02,198 [INFO] Step[1200/4329]: training loss : 0.8572818446159363 TRAIN  loss dict:  {'classification_loss': 0.8572818446159363}
2025-01-13 15:18:19,953 [INFO] Step[1250/4329]: training loss : 0.8616052496433259 TRAIN  loss dict:  {'classification_loss': 0.8616052496433259}
2025-01-13 15:18:37,355 [INFO] Step[1300/4329]: training loss : 0.8573013126850129 TRAIN  loss dict:  {'classification_loss': 0.8573013126850129}
2025-01-13 15:18:50,974 [INFO] Step[1350/4329]: training loss : 0.8584703004360199 TRAIN  loss dict:  {'classification_loss': 0.8584703004360199}
2025-01-13 15:19:04,641 [INFO] Step[1400/4329]: training loss : 0.875401839017868 TRAIN  loss dict:  {'classification_loss': 0.875401839017868}
2025-01-13 15:19:18,720 [INFO] Step[1450/4329]: training loss : 0.8586169159412385 TRAIN  loss dict:  {'classification_loss': 0.8586169159412385}
2025-01-13 15:19:32,432 [INFO] Step[1500/4329]: training loss : 0.8568751108646393 TRAIN  loss dict:  {'classification_loss': 0.8568751108646393}
2025-01-13 15:19:46,027 [INFO] Step[1550/4329]: training loss : 0.8567118501663208 TRAIN  loss dict:  {'classification_loss': 0.8567118501663208}
2025-01-13 15:20:00,851 [INFO] Step[1600/4329]: training loss : 0.8593346321582794 TRAIN  loss dict:  {'classification_loss': 0.8593346321582794}
2025-01-13 15:20:15,540 [INFO] Step[1650/4329]: training loss : 0.85887411236763 TRAIN  loss dict:  {'classification_loss': 0.85887411236763}
2025-01-13 15:20:30,865 [INFO] Step[1700/4329]: training loss : 0.8575371670722961 TRAIN  loss dict:  {'classification_loss': 0.8575371670722961}
2025-01-13 15:20:45,783 [INFO] Step[1750/4329]: training loss : 0.8647891056537628 TRAIN  loss dict:  {'classification_loss': 0.8647891056537628}
2025-01-13 15:21:00,939 [INFO] Step[1800/4329]: training loss : 0.8578718817234039 TRAIN  loss dict:  {'classification_loss': 0.8578718817234039}
2025-01-13 15:21:16,066 [INFO] Step[1850/4329]: training loss : 0.8589465749263764 TRAIN  loss dict:  {'classification_loss': 0.8589465749263764}
2025-01-13 15:21:34,273 [INFO] Step[1900/4329]: training loss : 0.8570611238479614 TRAIN  loss dict:  {'classification_loss': 0.8570611238479614}
2025-01-13 15:21:52,426 [INFO] Step[1950/4329]: training loss : 0.8583773851394654 TRAIN  loss dict:  {'classification_loss': 0.8583773851394654}
2025-01-13 15:22:07,280 [INFO] Step[2000/4329]: training loss : 0.8642406785488128 TRAIN  loss dict:  {'classification_loss': 0.8642406785488128}
2025-01-13 15:22:22,606 [INFO] Step[2050/4329]: training loss : 0.8657131028175354 TRAIN  loss dict:  {'classification_loss': 0.8657131028175354}
2025-01-13 15:22:36,595 [INFO] Step[2100/4329]: training loss : 0.8567342710494995 TRAIN  loss dict:  {'classification_loss': 0.8567342710494995}
2025-01-13 15:22:50,124 [INFO] Step[2150/4329]: training loss : 0.8588682496547699 TRAIN  loss dict:  {'classification_loss': 0.8588682496547699}
2025-01-13 15:23:04,651 [INFO] Step[2200/4329]: training loss : 0.8577310979366303 TRAIN  loss dict:  {'classification_loss': 0.8577310979366303}
2025-01-13 15:23:18,444 [INFO] Step[2250/4329]: training loss : 0.8570792818069458 TRAIN  loss dict:  {'classification_loss': 0.8570792818069458}
2025-01-13 15:23:33,363 [INFO] Step[2300/4329]: training loss : 0.8580710625648499 TRAIN  loss dict:  {'classification_loss': 0.8580710625648499}
2025-01-13 15:23:47,980 [INFO] Step[2350/4329]: training loss : 0.8632101440429687 TRAIN  loss dict:  {'classification_loss': 0.8632101440429687}
2025-01-13 15:24:02,301 [INFO] Step[2400/4329]: training loss : 0.8573168575763702 TRAIN  loss dict:  {'classification_loss': 0.8573168575763702}
2025-01-13 15:24:16,467 [INFO] Step[2450/4329]: training loss : 0.8589923179149628 TRAIN  loss dict:  {'classification_loss': 0.8589923179149628}
2025-01-13 15:24:30,332 [INFO] Step[2500/4329]: training loss : 0.859089206457138 TRAIN  loss dict:  {'classification_loss': 0.859089206457138}
2025-01-13 15:24:43,964 [INFO] Step[2550/4329]: training loss : 0.8592636036872864 TRAIN  loss dict:  {'classification_loss': 0.8592636036872864}
2025-01-13 15:24:57,744 [INFO] Step[2600/4329]: training loss : 0.8591864788532257 TRAIN  loss dict:  {'classification_loss': 0.8591864788532257}
2025-01-13 15:25:11,308 [INFO] Step[2650/4329]: training loss : 0.8646061265468598 TRAIN  loss dict:  {'classification_loss': 0.8646061265468598}
2025-01-13 15:25:24,931 [INFO] Step[2700/4329]: training loss : 0.8570737707614898 TRAIN  loss dict:  {'classification_loss': 0.8570737707614898}
2025-01-13 15:25:38,815 [INFO] Step[2750/4329]: training loss : 0.8580061292648316 TRAIN  loss dict:  {'classification_loss': 0.8580061292648316}
2025-01-13 15:25:52,810 [INFO] Step[2800/4329]: training loss : 0.8569711422920228 TRAIN  loss dict:  {'classification_loss': 0.8569711422920228}
2025-01-13 15:26:06,452 [INFO] Step[2850/4329]: training loss : 0.8645229578018189 TRAIN  loss dict:  {'classification_loss': 0.8645229578018189}
2025-01-13 15:26:20,386 [INFO] Step[2900/4329]: training loss : 0.8574619829654694 TRAIN  loss dict:  {'classification_loss': 0.8574619829654694}
2025-01-13 15:26:34,054 [INFO] Step[2950/4329]: training loss : 0.8614450323581696 TRAIN  loss dict:  {'classification_loss': 0.8614450323581696}
2025-01-13 15:26:47,920 [INFO] Step[3000/4329]: training loss : 0.8576446306705475 TRAIN  loss dict:  {'classification_loss': 0.8576446306705475}
2025-01-13 15:27:01,224 [INFO] Step[3050/4329]: training loss : 0.8603613376617432 TRAIN  loss dict:  {'classification_loss': 0.8603613376617432}
2025-01-13 15:27:15,130 [INFO] Step[3100/4329]: training loss : 0.8572615706920623 TRAIN  loss dict:  {'classification_loss': 0.8572615706920623}
2025-01-13 15:27:29,112 [INFO] Step[3150/4329]: training loss : 0.8565325546264648 TRAIN  loss dict:  {'classification_loss': 0.8565325546264648}
2025-01-13 15:27:43,037 [INFO] Step[3200/4329]: training loss : 0.857589659690857 TRAIN  loss dict:  {'classification_loss': 0.857589659690857}
2025-01-13 15:27:56,867 [INFO] Step[3250/4329]: training loss : 0.8658746922016144 TRAIN  loss dict:  {'classification_loss': 0.8658746922016144}
2025-01-13 15:28:10,876 [INFO] Step[3300/4329]: training loss : 0.8576321458816528 TRAIN  loss dict:  {'classification_loss': 0.8576321458816528}
2025-01-13 15:28:25,073 [INFO] Step[3350/4329]: training loss : 0.8565466344356537 TRAIN  loss dict:  {'classification_loss': 0.8565466344356537}
2025-01-13 15:28:40,910 [INFO] Step[3400/4329]: training loss : 0.8586311602592468 TRAIN  loss dict:  {'classification_loss': 0.8586311602592468}
2025-01-13 15:28:55,000 [INFO] Step[3450/4329]: training loss : 0.8584818112850189 TRAIN  loss dict:  {'classification_loss': 0.8584818112850189}
2025-01-13 15:29:08,704 [INFO] Step[3500/4329]: training loss : 0.856736968755722 TRAIN  loss dict:  {'classification_loss': 0.856736968755722}
2025-01-13 15:29:22,534 [INFO] Step[3550/4329]: training loss : 0.8583460211753845 TRAIN  loss dict:  {'classification_loss': 0.8583460211753845}
2025-01-13 15:29:37,084 [INFO] Step[3600/4329]: training loss : 0.8569097232818603 TRAIN  loss dict:  {'classification_loss': 0.8569097232818603}
2025-01-13 15:29:50,928 [INFO] Step[3650/4329]: training loss : 0.8570465505123138 TRAIN  loss dict:  {'classification_loss': 0.8570465505123138}
2025-01-13 15:30:06,635 [INFO] Step[3700/4329]: training loss : 0.8591470181941986 TRAIN  loss dict:  {'classification_loss': 0.8591470181941986}
2025-01-13 15:30:20,575 [INFO] Step[3750/4329]: training loss : 0.8575804698467254 TRAIN  loss dict:  {'classification_loss': 0.8575804698467254}
2025-01-13 15:30:34,707 [INFO] Step[3800/4329]: training loss : 0.8592845904827118 TRAIN  loss dict:  {'classification_loss': 0.8592845904827118}
2025-01-13 15:30:48,525 [INFO] Step[3850/4329]: training loss : 0.8763630044460297 TRAIN  loss dict:  {'classification_loss': 0.8763630044460297}
2025-01-13 15:31:02,784 [INFO] Step[3900/4329]: training loss : 0.8628553879261017 TRAIN  loss dict:  {'classification_loss': 0.8628553879261017}
2025-01-13 15:31:18,088 [INFO] Step[3950/4329]: training loss : 0.8625495052337646 TRAIN  loss dict:  {'classification_loss': 0.8625495052337646}
2025-01-13 15:31:31,942 [INFO] Step[4000/4329]: training loss : 0.8569262909889221 TRAIN  loss dict:  {'classification_loss': 0.8569262909889221}
2025-01-13 15:31:45,709 [INFO] Step[4050/4329]: training loss : 0.857778354883194 TRAIN  loss dict:  {'classification_loss': 0.857778354883194}
2025-01-13 15:31:59,325 [INFO] Step[4100/4329]: training loss : 0.8615854811668396 TRAIN  loss dict:  {'classification_loss': 0.8615854811668396}
2025-01-13 15:32:13,585 [INFO] Step[4150/4329]: training loss : 0.8585886836051941 TRAIN  loss dict:  {'classification_loss': 0.8585886836051941}
2025-01-13 15:32:27,728 [INFO] Step[4200/4329]: training loss : 0.8579078495502472 TRAIN  loss dict:  {'classification_loss': 0.8579078495502472}
2025-01-13 15:32:42,053 [INFO] Step[4250/4329]: training loss : 0.8590395951271057 TRAIN  loss dict:  {'classification_loss': 0.8590395951271057}
2025-01-13 15:32:56,375 [INFO] Step[4300/4329]: training loss : 0.8586219692230225 TRAIN  loss dict:  {'classification_loss': 0.8586219692230225}
2025-01-13 15:35:45,267 [INFO] Label accuracies statistics:
2025-01-13 15:35:45,267 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.5, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.5833333333333334, 8: 0.6666666666666666, 9: 0.9166666666666666, 10: 1.0, 11: 0.9166666666666666, 12: 0.5, 13: 0.5833333333333334, 14: 0.75, 15: 0.7777777777777778, 16: 0.6666666666666666, 17: 0.5833333333333334, 18: 0.6666666666666666, 19: 0.75, 20: 0.6666666666666666, 21: 0.75, 22: 0.75, 23: 0.9166666666666666, 24: 1.0, 25: 0.75, 26: 0.8333333333333334, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.5833333333333334, 31: 0.8333333333333334, 32: 0.6666666666666666, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 1.0, 36: 0.6666666666666666, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.9166666666666666, 41: 0.5, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.5833333333333334, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.6666666666666666, 51: 0.8333333333333334, 52: 1.0, 53: 0.5, 54: 0.4166666666666667, 55: 0.6666666666666666, 56: 0.8333333333333334, 57: 0.6666666666666666, 58: 0.5833333333333334, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 1.0, 62: 0.75, 63: 0.6666666666666666, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.6666666666666666, 69: 0.5833333333333334, 70: 0.4166666666666667, 71: 0.5, 72: 0.9166666666666666, 73: 0.8333333333333334, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.8333333333333334, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.9166666666666666, 82: 0.8333333333333334, 83: 0.75, 84: 0.5833333333333334, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.5, 89: 0.5, 90: 0.4166666666666667, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5833333333333334, 95: 0.9166666666666666, 96: 0.4166666666666667, 97: 0.75, 98: 0.8333333333333334, 99: 1.0, 100: 0.8333333333333334, 101: 1.0, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.75, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 0.9166666666666666, 111: 0.9166666666666666, 112: 0.9166666666666666, 113: 0.5, 114: 0.4166666666666667, 115: 0.9166666666666666, 116: 0.8333333333333334, 117: 0.9166666666666666, 118: 1.0, 119: 0.75, 120: 0.75, 121: 0.8333333333333334, 122: 0.8333333333333334, 123: 1.0, 124: 1.0, 125: 0.9166666666666666, 126: 0.8333333333333334, 127: 0.8333333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.8333333333333334, 132: 0.6666666666666666, 133: 1.0, 134: 0.9166666666666666, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 0.9166666666666666, 141: 1.0, 142: 0.6666666666666666, 143: 1.0, 144: 0.6666666666666666, 145: 1.0, 146: 1.0, 147: 0.8333333333333334, 148: 0.6666666666666666, 149: 1.0, 150: 0.4166666666666667, 151: 0.8333333333333334, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.8333333333333334, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.3333333333333333, 161: 0.9166666666666666, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.8333333333333334, 166: 0.75, 167: 0.75, 168: 0.9166666666666666, 169: 1.0, 170: 1.0, 171: 0.6666666666666666, 172: 1.0, 173: 0.6666666666666666, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.8333333333333334, 178: 1.0, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.5833333333333334, 183: 0.8333333333333334, 184: 0.75, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.5833333333333334, 189: 1.0, 190: 0.6666666666666666, 191: 0.5, 192: 1.0, 193: 0.9166666666666666, 194: 1.0, 195: 0.8333333333333334, 196: 0.8333333333333334, 197: 0.9166666666666666, 198: 0.6666666666666666}

2025-01-13 15:35:45,272 [INFO] [76] TRAIN  loss: 0.8595852663512041 acc: 0.9993839519482519
2025-01-13 15:35:45,273 [INFO] [76] TRAIN  loss dict: {'classification_loss': 0.8595852663512041}
2025-01-13 15:35:45,273 [INFO] [76] VALIDATION loss: 1.5995118849807315 VALIDATION acc: 0.813973063973064
2025-01-13 15:35:45,273 [INFO] [76] VALIDATION loss dict: {'classification_loss': 1.5995118849807315}
2025-01-13 15:35:45,274 [INFO] 
2025-01-13 15:36:08,737 [INFO] Step[50/4329]: training loss : 0.8591706037521363 TRAIN  loss dict:  {'classification_loss': 0.8591706037521363}
2025-01-13 15:36:22,696 [INFO] Step[100/4329]: training loss : 0.8573274528980255 TRAIN  loss dict:  {'classification_loss': 0.8573274528980255}
2025-01-13 15:36:36,848 [INFO] Step[150/4329]: training loss : 0.8584813165664673 TRAIN  loss dict:  {'classification_loss': 0.8584813165664673}
2025-01-13 15:36:50,661 [INFO] Step[200/4329]: training loss : 0.8597270762920379 TRAIN  loss dict:  {'classification_loss': 0.8597270762920379}
2025-01-13 15:37:06,685 [INFO] Step[250/4329]: training loss : 0.8572777593135834 TRAIN  loss dict:  {'classification_loss': 0.8572777593135834}
2025-01-13 15:37:20,307 [INFO] Step[300/4329]: training loss : 0.8589999663829804 TRAIN  loss dict:  {'classification_loss': 0.8589999663829804}
2025-01-13 15:37:34,042 [INFO] Step[350/4329]: training loss : 0.8569896578788757 TRAIN  loss dict:  {'classification_loss': 0.8569896578788757}
2025-01-13 15:37:47,756 [INFO] Step[400/4329]: training loss : 0.8573193323612213 TRAIN  loss dict:  {'classification_loss': 0.8573193323612213}
2025-01-13 15:38:02,942 [INFO] Step[450/4329]: training loss : 0.8578506207466126 TRAIN  loss dict:  {'classification_loss': 0.8578506207466126}
2025-01-13 15:38:17,014 [INFO] Step[500/4329]: training loss : 0.8746587121486664 TRAIN  loss dict:  {'classification_loss': 0.8746587121486664}
2025-01-13 15:38:31,056 [INFO] Step[550/4329]: training loss : 0.8599043011665344 TRAIN  loss dict:  {'classification_loss': 0.8599043011665344}
2025-01-13 15:38:45,447 [INFO] Step[600/4329]: training loss : 0.8592451393604279 TRAIN  loss dict:  {'classification_loss': 0.8592451393604279}
2025-01-13 15:38:59,474 [INFO] Step[650/4329]: training loss : 0.8578573751449585 TRAIN  loss dict:  {'classification_loss': 0.8578573751449585}
2025-01-13 15:39:13,401 [INFO] Step[700/4329]: training loss : 0.8596484613418579 TRAIN  loss dict:  {'classification_loss': 0.8596484613418579}
2025-01-13 15:39:27,115 [INFO] Step[750/4329]: training loss : 0.8592698979377746 TRAIN  loss dict:  {'classification_loss': 0.8592698979377746}
2025-01-13 15:39:41,685 [INFO] Step[800/4329]: training loss : 0.8574867618083953 TRAIN  loss dict:  {'classification_loss': 0.8574867618083953}
2025-01-13 15:39:55,816 [INFO] Step[850/4329]: training loss : 0.861080836057663 TRAIN  loss dict:  {'classification_loss': 0.861080836057663}
2025-01-13 15:40:10,334 [INFO] Step[900/4329]: training loss : 0.8574648988246918 TRAIN  loss dict:  {'classification_loss': 0.8574648988246918}
2025-01-13 15:40:27,110 [INFO] Step[950/4329]: training loss : 0.8603608226776123 TRAIN  loss dict:  {'classification_loss': 0.8603608226776123}
2025-01-13 15:40:41,117 [INFO] Step[1000/4329]: training loss : 0.85905526638031 TRAIN  loss dict:  {'classification_loss': 0.85905526638031}
2025-01-13 15:40:55,122 [INFO] Step[1050/4329]: training loss : 0.8595466423034668 TRAIN  loss dict:  {'classification_loss': 0.8595466423034668}
2025-01-13 15:41:13,094 [INFO] Step[1100/4329]: training loss : 0.8984199905395508 TRAIN  loss dict:  {'classification_loss': 0.8984199905395508}
2025-01-13 15:41:28,902 [INFO] Step[1150/4329]: training loss : 0.8580471658706665 TRAIN  loss dict:  {'classification_loss': 0.8580471658706665}
2025-01-13 15:41:49,515 [INFO] Step[1200/4329]: training loss : 0.8597136664390564 TRAIN  loss dict:  {'classification_loss': 0.8597136664390564}
2025-01-13 15:42:04,987 [INFO] Step[1250/4329]: training loss : 0.8572993421554566 TRAIN  loss dict:  {'classification_loss': 0.8572993421554566}
2025-01-13 15:42:19,538 [INFO] Step[1300/4329]: training loss : 0.8595267760753632 TRAIN  loss dict:  {'classification_loss': 0.8595267760753632}
2025-01-13 15:42:33,589 [INFO] Step[1350/4329]: training loss : 0.8591219711303711 TRAIN  loss dict:  {'classification_loss': 0.8591219711303711}
2025-01-13 15:42:50,004 [INFO] Step[1400/4329]: training loss : 0.8568164300918579 TRAIN  loss dict:  {'classification_loss': 0.8568164300918579}
2025-01-13 15:43:03,589 [INFO] Step[1450/4329]: training loss : 0.8705378973484039 TRAIN  loss dict:  {'classification_loss': 0.8705378973484039}
2025-01-13 15:43:17,802 [INFO] Step[1500/4329]: training loss : 0.8586132097244262 TRAIN  loss dict:  {'classification_loss': 0.8586132097244262}
2025-01-13 15:43:31,559 [INFO] Step[1550/4329]: training loss : 0.8573206007480622 TRAIN  loss dict:  {'classification_loss': 0.8573206007480622}
2025-01-13 15:43:45,562 [INFO] Step[1600/4329]: training loss : 0.8562356376647949 TRAIN  loss dict:  {'classification_loss': 0.8562356376647949}
2025-01-13 15:43:59,470 [INFO] Step[1650/4329]: training loss : 0.8567938911914825 TRAIN  loss dict:  {'classification_loss': 0.8567938911914825}
2025-01-13 15:44:13,666 [INFO] Step[1700/4329]: training loss : 0.8595016181468964 TRAIN  loss dict:  {'classification_loss': 0.8595016181468964}
2025-01-13 15:44:27,565 [INFO] Step[1750/4329]: training loss : 0.8574978137016296 TRAIN  loss dict:  {'classification_loss': 0.8574978137016296}
2025-01-13 15:44:41,303 [INFO] Step[1800/4329]: training loss : 0.8579512441158295 TRAIN  loss dict:  {'classification_loss': 0.8579512441158295}
2025-01-13 15:44:55,047 [INFO] Step[1850/4329]: training loss : 0.8587800526618957 TRAIN  loss dict:  {'classification_loss': 0.8587800526618957}
2025-01-13 15:45:08,730 [INFO] Step[1900/4329]: training loss : 0.8596836996078491 TRAIN  loss dict:  {'classification_loss': 0.8596836996078491}
2025-01-13 15:45:22,418 [INFO] Step[1950/4329]: training loss : 0.8572300541400909 TRAIN  loss dict:  {'classification_loss': 0.8572300541400909}
2025-01-13 15:45:36,085 [INFO] Step[2000/4329]: training loss : 0.8608044803142547 TRAIN  loss dict:  {'classification_loss': 0.8608044803142547}
2025-01-13 15:45:50,338 [INFO] Step[2050/4329]: training loss : 0.8595233869552612 TRAIN  loss dict:  {'classification_loss': 0.8595233869552612}
2025-01-13 15:46:06,267 [INFO] Step[2100/4329]: training loss : 0.8587407004833222 TRAIN  loss dict:  {'classification_loss': 0.8587407004833222}
2025-01-13 15:46:20,086 [INFO] Step[2150/4329]: training loss : 0.8808549654483795 TRAIN  loss dict:  {'classification_loss': 0.8808549654483795}
2025-01-13 15:46:35,238 [INFO] Step[2200/4329]: training loss : 0.8569642078876495 TRAIN  loss dict:  {'classification_loss': 0.8569642078876495}
2025-01-13 15:46:49,035 [INFO] Step[2250/4329]: training loss : 0.8580645191669464 TRAIN  loss dict:  {'classification_loss': 0.8580645191669464}
2025-01-13 15:47:03,403 [INFO] Step[2300/4329]: training loss : 0.8627633273601532 TRAIN  loss dict:  {'classification_loss': 0.8627633273601532}
2025-01-13 15:47:19,136 [INFO] Step[2350/4329]: training loss : 0.8579292738437653 TRAIN  loss dict:  {'classification_loss': 0.8579292738437653}
2025-01-13 15:47:33,398 [INFO] Step[2400/4329]: training loss : 0.8568691504001618 TRAIN  loss dict:  {'classification_loss': 0.8568691504001618}
2025-01-13 15:47:47,443 [INFO] Step[2450/4329]: training loss : 0.8619601047039032 TRAIN  loss dict:  {'classification_loss': 0.8619601047039032}
2025-01-13 15:48:01,502 [INFO] Step[2500/4329]: training loss : 0.8571262872219085 TRAIN  loss dict:  {'classification_loss': 0.8571262872219085}
2025-01-13 15:48:15,217 [INFO] Step[2550/4329]: training loss : 0.8573363959789276 TRAIN  loss dict:  {'classification_loss': 0.8573363959789276}
2025-01-13 15:48:28,828 [INFO] Step[2600/4329]: training loss : 0.8562682557106018 TRAIN  loss dict:  {'classification_loss': 0.8562682557106018}
2025-01-13 15:48:42,775 [INFO] Step[2650/4329]: training loss : 0.8571535265445709 TRAIN  loss dict:  {'classification_loss': 0.8571535265445709}
2025-01-13 15:48:56,536 [INFO] Step[2700/4329]: training loss : 0.8588840711116791 TRAIN  loss dict:  {'classification_loss': 0.8588840711116791}
2025-01-13 15:49:10,018 [INFO] Step[2750/4329]: training loss : 0.8576090085506439 TRAIN  loss dict:  {'classification_loss': 0.8576090085506439}
2025-01-13 15:49:24,980 [INFO] Step[2800/4329]: training loss : 0.8593866157531739 TRAIN  loss dict:  {'classification_loss': 0.8593866157531739}
2025-01-13 15:49:38,978 [INFO] Step[2850/4329]: training loss : 0.858294528722763 TRAIN  loss dict:  {'classification_loss': 0.858294528722763}
2025-01-13 15:49:52,817 [INFO] Step[2900/4329]: training loss : 0.8569792950153351 TRAIN  loss dict:  {'classification_loss': 0.8569792950153351}
2025-01-13 15:50:06,793 [INFO] Step[2950/4329]: training loss : 0.8622892224788665 TRAIN  loss dict:  {'classification_loss': 0.8622892224788665}
2025-01-13 15:50:23,102 [INFO] Step[3000/4329]: training loss : 0.8653984665870667 TRAIN  loss dict:  {'classification_loss': 0.8653984665870667}
2025-01-13 15:50:37,157 [INFO] Step[3050/4329]: training loss : 0.8573928582668304 TRAIN  loss dict:  {'classification_loss': 0.8573928582668304}
2025-01-13 15:50:51,247 [INFO] Step[3100/4329]: training loss : 0.8723250889778137 TRAIN  loss dict:  {'classification_loss': 0.8723250889778137}
2025-01-13 15:51:05,129 [INFO] Step[3150/4329]: training loss : 0.856444524526596 TRAIN  loss dict:  {'classification_loss': 0.856444524526596}
2025-01-13 15:51:19,545 [INFO] Step[3200/4329]: training loss : 0.8583477985858917 TRAIN  loss dict:  {'classification_loss': 0.8583477985858917}
2025-01-13 15:51:34,045 [INFO] Step[3250/4329]: training loss : 0.8566957604885101 TRAIN  loss dict:  {'classification_loss': 0.8566957604885101}
2025-01-13 15:51:47,999 [INFO] Step[3300/4329]: training loss : 0.8565996778011322 TRAIN  loss dict:  {'classification_loss': 0.8565996778011322}
2025-01-13 15:52:03,328 [INFO] Step[3350/4329]: training loss : 0.8576639938354492 TRAIN  loss dict:  {'classification_loss': 0.8576639938354492}
2025-01-13 15:52:17,501 [INFO] Step[3400/4329]: training loss : 0.8600186502933502 TRAIN  loss dict:  {'classification_loss': 0.8600186502933502}
2025-01-13 15:52:31,243 [INFO] Step[3450/4329]: training loss : 0.8592973816394806 TRAIN  loss dict:  {'classification_loss': 0.8592973816394806}
2025-01-13 15:52:45,133 [INFO] Step[3500/4329]: training loss : 0.8584087145328522 TRAIN  loss dict:  {'classification_loss': 0.8584087145328522}
2025-01-13 15:52:59,260 [INFO] Step[3550/4329]: training loss : 0.8601846158504486 TRAIN  loss dict:  {'classification_loss': 0.8601846158504486}
2025-01-13 15:53:15,303 [INFO] Step[3600/4329]: training loss : 0.8591424000263214 TRAIN  loss dict:  {'classification_loss': 0.8591424000263214}
2025-01-13 15:53:29,219 [INFO] Step[3650/4329]: training loss : 0.8583237934112549 TRAIN  loss dict:  {'classification_loss': 0.8583237934112549}
2025-01-13 15:53:42,806 [INFO] Step[3700/4329]: training loss : 0.8585990309715271 TRAIN  loss dict:  {'classification_loss': 0.8585990309715271}
2025-01-13 15:53:56,372 [INFO] Step[3750/4329]: training loss : 0.8573093414306641 TRAIN  loss dict:  {'classification_loss': 0.8573093414306641}
2025-01-13 15:54:10,349 [INFO] Step[3800/4329]: training loss : 0.8570364165306091 TRAIN  loss dict:  {'classification_loss': 0.8570364165306091}
2025-01-13 15:54:24,551 [INFO] Step[3850/4329]: training loss : 0.8734163951873779 TRAIN  loss dict:  {'classification_loss': 0.8734163951873779}
2025-01-13 15:54:38,313 [INFO] Step[3900/4329]: training loss : 0.8567100310325623 TRAIN  loss dict:  {'classification_loss': 0.8567100310325623}
2025-01-13 15:54:52,946 [INFO] Step[3950/4329]: training loss : 0.8676256227493286 TRAIN  loss dict:  {'classification_loss': 0.8676256227493286}
2025-01-13 15:55:06,706 [INFO] Step[4000/4329]: training loss : 0.8584124159812927 TRAIN  loss dict:  {'classification_loss': 0.8584124159812927}
2025-01-13 15:55:20,727 [INFO] Step[4050/4329]: training loss : 0.8619416725635528 TRAIN  loss dict:  {'classification_loss': 0.8619416725635528}
2025-01-13 15:55:34,646 [INFO] Step[4100/4329]: training loss : 0.856890504360199 TRAIN  loss dict:  {'classification_loss': 0.856890504360199}
2025-01-13 15:55:48,482 [INFO] Step[4150/4329]: training loss : 0.8574832558631897 TRAIN  loss dict:  {'classification_loss': 0.8574832558631897}
2025-01-13 15:56:02,463 [INFO] Step[4200/4329]: training loss : 0.8601424622535706 TRAIN  loss dict:  {'classification_loss': 0.8601424622535706}
2025-01-13 15:56:16,236 [INFO] Step[4250/4329]: training loss : 0.862938575744629 TRAIN  loss dict:  {'classification_loss': 0.862938575744629}
2025-01-13 15:56:30,437 [INFO] Step[4300/4329]: training loss : 0.8579138731956482 TRAIN  loss dict:  {'classification_loss': 0.8579138731956482}
2025-01-13 16:00:03,750 [INFO] Label accuracies statistics:
2025-01-13 16:00:03,751 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5, 7: 0.5, 8: 0.5833333333333334, 9: 0.9166666666666666, 10: 1.0, 11: 0.9166666666666666, 12: 0.5, 13: 0.5, 14: 0.75, 15: 0.6666666666666666, 16: 0.5833333333333334, 17: 0.6666666666666666, 18: 0.5, 19: 0.75, 20: 0.6666666666666666, 21: 0.75, 22: 0.75, 23: 0.9166666666666666, 24: 1.0, 25: 0.8333333333333334, 26: 0.9166666666666666, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.75, 31: 0.6666666666666666, 32: 0.6666666666666666, 33: 0.9166666666666666, 34: 1.0, 35: 1.0, 36: 0.6666666666666666, 37: 1.0, 38: 0.8333333333333334, 39: 1.0, 40: 0.8333333333333334, 41: 0.5, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.5833333333333334, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.6666666666666666, 54: 0.5, 55: 0.75, 56: 0.9166666666666666, 57: 0.75, 58: 0.4166666666666667, 59: 0.8333333333333334, 60: 0.6666666666666666, 61: 1.0, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.8333333333333334, 69: 0.6666666666666666, 70: 0.5, 71: 0.6666666666666666, 72: 0.8333333333333334, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 0.9166666666666666, 79: 0.8333333333333334, 80: 1.0, 81: 1.0, 82: 0.9166666666666666, 83: 0.6666666666666666, 84: 0.5, 85: 0.8333333333333334, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.6666666666666666, 89: 0.5, 90: 0.5833333333333334, 91: 1.0, 92: 0.9166666666666666, 93: 1.0, 94: 0.6666666666666666, 95: 0.9166666666666666, 96: 0.5, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.9166666666666666, 101: 1.0, 102: 0.9166666666666666, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.75, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 0.9166666666666666, 111: 0.9166666666666666, 112: 1.0, 113: 0.4166666666666667, 114: 0.5, 115: 1.0, 116: 0.8333333333333334, 117: 0.75, 118: 1.0, 119: 0.9166666666666666, 120: 0.75, 121: 0.9166666666666666, 122: 0.8333333333333334, 123: 0.9166666666666666, 124: 1.0, 125: 0.8333333333333334, 126: 0.9166666666666666, 127: 0.9166666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.8333333333333334, 132: 0.5833333333333334, 133: 1.0, 134: 0.8333333333333334, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 1.0, 139: 0.9166666666666666, 140: 1.0, 141: 0.9166666666666666, 142: 0.75, 143: 1.0, 144: 0.5833333333333334, 145: 1.0, 146: 1.0, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.4166666666666667, 151: 0.9166666666666666, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 1.0, 156: 0.8333333333333334, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.3333333333333333, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.9166666666666666, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.9166666666666666, 169: 1.0, 170: 1.0, 171: 0.5833333333333334, 172: 1.0, 173: 0.8333333333333334, 174: 1.0, 175: 0.9166666666666666, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.6666666666666666, 183: 0.8333333333333334, 184: 0.75, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.8333333333333334, 189: 0.9166666666666666, 190: 0.6666666666666666, 191: 0.75, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.8333333333333334, 196: 0.9166666666666666, 197: 0.9166666666666666, 198: 0.6666666666666666}

2025-01-13 16:00:03,764 [INFO] [77] TRAIN  loss: 0.8600547408556437 acc: 0.9993839519482519
2025-01-13 16:00:03,764 [INFO] [77] TRAIN  loss dict: {'classification_loss': 0.8600547408556437}
2025-01-13 16:00:03,765 [INFO] [77] VALIDATION loss: 1.5696137703277848 VALIDATION acc: 0.8228114478114478
2025-01-13 16:00:03,765 [INFO] [77] VALIDATION loss dict: {'classification_loss': 1.5696137703277848}
2025-01-13 16:00:03,765 [INFO] 
2025-01-13 16:00:30,453 [INFO] Step[50/4329]: training loss : 0.8564183974266052 TRAIN  loss dict:  {'classification_loss': 0.8564183974266052}
2025-01-13 16:00:44,118 [INFO] Step[100/4329]: training loss : 0.8619394683837891 TRAIN  loss dict:  {'classification_loss': 0.8619394683837891}
2025-01-13 16:00:57,858 [INFO] Step[150/4329]: training loss : 0.8571143770217895 TRAIN  loss dict:  {'classification_loss': 0.8571143770217895}
2025-01-13 16:01:11,533 [INFO] Step[200/4329]: training loss : 0.8579567813873291 TRAIN  loss dict:  {'classification_loss': 0.8579567813873291}
2025-01-13 16:01:25,585 [INFO] Step[250/4329]: training loss : 0.8686202621459961 TRAIN  loss dict:  {'classification_loss': 0.8686202621459961}
2025-01-13 16:01:39,687 [INFO] Step[300/4329]: training loss : 0.8602872705459594 TRAIN  loss dict:  {'classification_loss': 0.8602872705459594}
2025-01-13 16:01:55,871 [INFO] Step[350/4329]: training loss : 0.8589674031734467 TRAIN  loss dict:  {'classification_loss': 0.8589674031734467}
2025-01-13 16:02:10,188 [INFO] Step[400/4329]: training loss : 0.8614227378368378 TRAIN  loss dict:  {'classification_loss': 0.8614227378368378}
2025-01-13 16:02:24,365 [INFO] Step[450/4329]: training loss : 0.857114542722702 TRAIN  loss dict:  {'classification_loss': 0.857114542722702}
2025-01-13 16:02:40,588 [INFO] Step[500/4329]: training loss : 0.8581319773197174 TRAIN  loss dict:  {'classification_loss': 0.8581319773197174}
2025-01-13 16:02:59,660 [INFO] Step[550/4329]: training loss : 0.8572530162334442 TRAIN  loss dict:  {'classification_loss': 0.8572530162334442}
2025-01-13 16:03:20,141 [INFO] Step[600/4329]: training loss : 0.8564711165428162 TRAIN  loss dict:  {'classification_loss': 0.8564711165428162}
2025-01-13 16:03:34,593 [INFO] Step[650/4329]: training loss : 0.8581274247169495 TRAIN  loss dict:  {'classification_loss': 0.8581274247169495}
2025-01-13 16:03:48,517 [INFO] Step[700/4329]: training loss : 0.8583447003364563 TRAIN  loss dict:  {'classification_loss': 0.8583447003364563}
2025-01-13 16:04:05,154 [INFO] Step[750/4329]: training loss : 0.8586117243766784 TRAIN  loss dict:  {'classification_loss': 0.8586117243766784}
2025-01-13 16:04:19,870 [INFO] Step[800/4329]: training loss : 0.857153731584549 TRAIN  loss dict:  {'classification_loss': 0.857153731584549}
2025-01-13 16:04:34,315 [INFO] Step[850/4329]: training loss : 0.8580134844779969 TRAIN  loss dict:  {'classification_loss': 0.8580134844779969}
2025-01-13 16:04:48,812 [INFO] Step[900/4329]: training loss : 0.8562965333461762 TRAIN  loss dict:  {'classification_loss': 0.8562965333461762}
2025-01-13 16:05:02,983 [INFO] Step[950/4329]: training loss : 0.8570460045337677 TRAIN  loss dict:  {'classification_loss': 0.8570460045337677}
2025-01-13 16:05:17,473 [INFO] Step[1000/4329]: training loss : 0.8576207637786866 TRAIN  loss dict:  {'classification_loss': 0.8576207637786866}
2025-01-13 16:05:31,720 [INFO] Step[1050/4329]: training loss : 0.8579889595508575 TRAIN  loss dict:  {'classification_loss': 0.8579889595508575}
2025-01-13 16:05:46,158 [INFO] Step[1100/4329]: training loss : 0.8599802696704865 TRAIN  loss dict:  {'classification_loss': 0.8599802696704865}
2025-01-13 16:06:00,332 [INFO] Step[1150/4329]: training loss : 0.8573291003704071 TRAIN  loss dict:  {'classification_loss': 0.8573291003704071}
2025-01-13 16:06:14,928 [INFO] Step[1200/4329]: training loss : 0.8585033905506134 TRAIN  loss dict:  {'classification_loss': 0.8585033905506134}
2025-01-13 16:06:29,227 [INFO] Step[1250/4329]: training loss : 0.8567585921287537 TRAIN  loss dict:  {'classification_loss': 0.8567585921287537}
2025-01-13 16:06:43,945 [INFO] Step[1300/4329]: training loss : 0.8607181835174561 TRAIN  loss dict:  {'classification_loss': 0.8607181835174561}
2025-01-13 16:06:57,709 [INFO] Step[1350/4329]: training loss : 0.8578940594196319 TRAIN  loss dict:  {'classification_loss': 0.8578940594196319}
2025-01-13 16:07:10,659 [INFO] Step[1400/4329]: training loss : 0.8600399243831635 TRAIN  loss dict:  {'classification_loss': 0.8600399243831635}
2025-01-13 16:07:23,571 [INFO] Step[1450/4329]: training loss : 0.8562597811222077 TRAIN  loss dict:  {'classification_loss': 0.8562597811222077}
2025-01-13 16:07:38,057 [INFO] Step[1500/4329]: training loss : 0.8578029358386994 TRAIN  loss dict:  {'classification_loss': 0.8578029358386994}
2025-01-13 16:07:52,825 [INFO] Step[1550/4329]: training loss : 0.8561310803890229 TRAIN  loss dict:  {'classification_loss': 0.8561310803890229}
2025-01-13 16:08:07,046 [INFO] Step[1600/4329]: training loss : 0.8678282535076142 TRAIN  loss dict:  {'classification_loss': 0.8678282535076142}
2025-01-13 16:08:21,725 [INFO] Step[1650/4329]: training loss : 0.8592108905315399 TRAIN  loss dict:  {'classification_loss': 0.8592108905315399}
2025-01-13 16:08:36,168 [INFO] Step[1700/4329]: training loss : 0.8594117760658264 TRAIN  loss dict:  {'classification_loss': 0.8594117760658264}
2025-01-13 16:08:50,487 [INFO] Step[1750/4329]: training loss : 0.8576589965820313 TRAIN  loss dict:  {'classification_loss': 0.8576589965820313}
2025-01-13 16:09:05,110 [INFO] Step[1800/4329]: training loss : 0.8571352565288544 TRAIN  loss dict:  {'classification_loss': 0.8571352565288544}
2025-01-13 16:09:19,862 [INFO] Step[1850/4329]: training loss : 0.8582224977016449 TRAIN  loss dict:  {'classification_loss': 0.8582224977016449}
2025-01-13 16:09:34,314 [INFO] Step[1900/4329]: training loss : 0.857717570066452 TRAIN  loss dict:  {'classification_loss': 0.857717570066452}
2025-01-13 16:09:48,816 [INFO] Step[1950/4329]: training loss : 0.8563816463947296 TRAIN  loss dict:  {'classification_loss': 0.8563816463947296}
2025-01-13 16:10:03,033 [INFO] Step[2000/4329]: training loss : 0.8574135172367096 TRAIN  loss dict:  {'classification_loss': 0.8574135172367096}
2025-01-13 16:10:17,517 [INFO] Step[2050/4329]: training loss : 0.8637439608573914 TRAIN  loss dict:  {'classification_loss': 0.8637439608573914}
2025-01-13 16:10:31,973 [INFO] Step[2100/4329]: training loss : 0.8570400106906891 TRAIN  loss dict:  {'classification_loss': 0.8570400106906891}
2025-01-13 16:10:46,397 [INFO] Step[2150/4329]: training loss : 0.8566574668884277 TRAIN  loss dict:  {'classification_loss': 0.8566574668884277}
2025-01-13 16:11:00,907 [INFO] Step[2200/4329]: training loss : 0.8577924025058746 TRAIN  loss dict:  {'classification_loss': 0.8577924025058746}
2025-01-13 16:11:15,203 [INFO] Step[2250/4329]: training loss : 0.856958144903183 TRAIN  loss dict:  {'classification_loss': 0.856958144903183}
2025-01-13 16:11:29,686 [INFO] Step[2300/4329]: training loss : 0.8568289232254028 TRAIN  loss dict:  {'classification_loss': 0.8568289232254028}
2025-01-13 16:11:44,442 [INFO] Step[2350/4329]: training loss : 0.8571835386753083 TRAIN  loss dict:  {'classification_loss': 0.8571835386753083}
2025-01-13 16:11:58,943 [INFO] Step[2400/4329]: training loss : 0.8561400353908539 TRAIN  loss dict:  {'classification_loss': 0.8561400353908539}
2025-01-13 16:12:13,249 [INFO] Step[2450/4329]: training loss : 0.8588245069980621 TRAIN  loss dict:  {'classification_loss': 0.8588245069980621}
2025-01-13 16:12:27,449 [INFO] Step[2500/4329]: training loss : 0.8573581969738007 TRAIN  loss dict:  {'classification_loss': 0.8573581969738007}
2025-01-13 16:12:41,882 [INFO] Step[2550/4329]: training loss : 0.8570021283626557 TRAIN  loss dict:  {'classification_loss': 0.8570021283626557}
2025-01-13 16:12:56,279 [INFO] Step[2600/4329]: training loss : 0.8593724465370178 TRAIN  loss dict:  {'classification_loss': 0.8593724465370178}
2025-01-13 16:13:11,003 [INFO] Step[2650/4329]: training loss : 0.8591389191150666 TRAIN  loss dict:  {'classification_loss': 0.8591389191150666}
2025-01-13 16:13:25,260 [INFO] Step[2700/4329]: training loss : 0.8578284287452698 TRAIN  loss dict:  {'classification_loss': 0.8578284287452698}
2025-01-13 16:13:39,927 [INFO] Step[2750/4329]: training loss : 0.8568598628044128 TRAIN  loss dict:  {'classification_loss': 0.8568598628044128}
2025-01-13 16:13:54,669 [INFO] Step[2800/4329]: training loss : 0.8578093624114991 TRAIN  loss dict:  {'classification_loss': 0.8578093624114991}
2025-01-13 16:14:09,160 [INFO] Step[2850/4329]: training loss : 0.8600604605674743 TRAIN  loss dict:  {'classification_loss': 0.8600604605674743}
2025-01-13 16:14:23,609 [INFO] Step[2900/4329]: training loss : 0.8642876791954041 TRAIN  loss dict:  {'classification_loss': 0.8642876791954041}
2025-01-13 16:14:38,072 [INFO] Step[2950/4329]: training loss : 0.8584277164936066 TRAIN  loss dict:  {'classification_loss': 0.8584277164936066}
2025-01-13 16:14:52,824 [INFO] Step[3000/4329]: training loss : 0.858348240852356 TRAIN  loss dict:  {'classification_loss': 0.858348240852356}
2025-01-13 16:15:07,277 [INFO] Step[3050/4329]: training loss : 0.8576960825920105 TRAIN  loss dict:  {'classification_loss': 0.8576960825920105}
2025-01-13 16:15:21,889 [INFO] Step[3100/4329]: training loss : 0.8590170586109162 TRAIN  loss dict:  {'classification_loss': 0.8590170586109162}
2025-01-13 16:15:36,336 [INFO] Step[3150/4329]: training loss : 0.8586117315292359 TRAIN  loss dict:  {'classification_loss': 0.8586117315292359}
2025-01-13 16:15:50,617 [INFO] Step[3200/4329]: training loss : 0.8635194838047028 TRAIN  loss dict:  {'classification_loss': 0.8635194838047028}
2025-01-13 16:16:05,124 [INFO] Step[3250/4329]: training loss : 0.8574063324928284 TRAIN  loss dict:  {'classification_loss': 0.8574063324928284}
2025-01-13 16:16:18,720 [INFO] Step[3300/4329]: training loss : 0.8574229609966278 TRAIN  loss dict:  {'classification_loss': 0.8574229609966278}
2025-01-13 16:16:32,338 [INFO] Step[3350/4329]: training loss : 0.8571314322948456 TRAIN  loss dict:  {'classification_loss': 0.8571314322948456}
2025-01-13 16:16:46,470 [INFO] Step[3400/4329]: training loss : 0.8790681350231171 TRAIN  loss dict:  {'classification_loss': 0.8790681350231171}
2025-01-13 16:17:00,837 [INFO] Step[3450/4329]: training loss : 0.8601165771484375 TRAIN  loss dict:  {'classification_loss': 0.8601165771484375}
2025-01-13 16:17:14,906 [INFO] Step[3500/4329]: training loss : 0.9031960785388946 TRAIN  loss dict:  {'classification_loss': 0.9031960785388946}
2025-01-13 16:17:28,914 [INFO] Step[3550/4329]: training loss : 0.8592249417304992 TRAIN  loss dict:  {'classification_loss': 0.8592249417304992}
2025-01-13 16:17:42,921 [INFO] Step[3600/4329]: training loss : 0.857698837518692 TRAIN  loss dict:  {'classification_loss': 0.857698837518692}
2025-01-13 16:17:57,577 [INFO] Step[3650/4329]: training loss : 0.8603535258769989 TRAIN  loss dict:  {'classification_loss': 0.8603535258769989}
2025-01-13 16:18:12,265 [INFO] Step[3700/4329]: training loss : 0.8671850848197937 TRAIN  loss dict:  {'classification_loss': 0.8671850848197937}
2025-01-13 16:18:27,003 [INFO] Step[3750/4329]: training loss : 0.8585124588012696 TRAIN  loss dict:  {'classification_loss': 0.8585124588012696}
2025-01-13 16:18:41,717 [INFO] Step[3800/4329]: training loss : 0.8885834038257598 TRAIN  loss dict:  {'classification_loss': 0.8885834038257598}
2025-01-13 16:18:56,129 [INFO] Step[3850/4329]: training loss : 0.863386709690094 TRAIN  loss dict:  {'classification_loss': 0.863386709690094}
2025-01-13 16:19:10,631 [INFO] Step[3900/4329]: training loss : 0.8583986341953278 TRAIN  loss dict:  {'classification_loss': 0.8583986341953278}
2025-01-13 16:19:25,292 [INFO] Step[3950/4329]: training loss : 0.860706375837326 TRAIN  loss dict:  {'classification_loss': 0.860706375837326}
2025-01-13 16:19:40,029 [INFO] Step[4000/4329]: training loss : 0.8567342555522919 TRAIN  loss dict:  {'classification_loss': 0.8567342555522919}
2025-01-13 16:19:54,513 [INFO] Step[4050/4329]: training loss : 0.8582993066310882 TRAIN  loss dict:  {'classification_loss': 0.8582993066310882}
2025-01-13 16:20:09,161 [INFO] Step[4100/4329]: training loss : 0.8563051187992096 TRAIN  loss dict:  {'classification_loss': 0.8563051187992096}
2025-01-13 16:20:23,430 [INFO] Step[4150/4329]: training loss : 0.8589171171188354 TRAIN  loss dict:  {'classification_loss': 0.8589171171188354}
2025-01-13 16:20:37,786 [INFO] Step[4200/4329]: training loss : 0.8577714443206788 TRAIN  loss dict:  {'classification_loss': 0.8577714443206788}
2025-01-13 16:20:52,321 [INFO] Step[4250/4329]: training loss : 0.8573995959758759 TRAIN  loss dict:  {'classification_loss': 0.8573995959758759}
2025-01-13 16:21:06,942 [INFO] Step[4300/4329]: training loss : 0.8594400894641876 TRAIN  loss dict:  {'classification_loss': 0.8594400894641876}
2025-01-13 16:23:35,093 [INFO] Label accuracies statistics:
2025-01-13 16:23:35,093 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.6666666666666666, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.5833333333333334, 8: 0.3333333333333333, 9: 0.9166666666666666, 10: 1.0, 11: 0.9166666666666666, 12: 0.5, 13: 0.5, 14: 0.75, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.5833333333333334, 19: 0.6666666666666666, 20: 0.6666666666666666, 21: 0.75, 22: 0.75, 23: 1.0, 24: 0.9166666666666666, 25: 0.75, 26: 0.8333333333333334, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.8333333333333334, 34: 0.9166666666666666, 35: 1.0, 36: 0.4166666666666667, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.5833333333333334, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.4166666666666667, 54: 0.4166666666666667, 55: 0.75, 56: 0.75, 57: 0.6666666666666666, 58: 0.5833333333333334, 59: 0.6666666666666666, 60: 0.75, 61: 0.9166666666666666, 62: 0.75, 63: 0.6666666666666666, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.75, 69: 0.75, 70: 0.4166666666666667, 71: 0.5833333333333334, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 0.9166666666666666, 79: 0.5833333333333334, 80: 1.0, 81: 1.0, 82: 0.9166666666666666, 83: 0.6666666666666666, 84: 0.4166666666666667, 85: 0.8333333333333334, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.5, 89: 0.5833333333333334, 90: 0.9166666666666666, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 0.8333333333333334, 96: 0.4166666666666667, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.9166666666666666, 101: 1.0, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.4166666666666667, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 0.8333333333333334, 111: 1.0, 112: 0.6666666666666666, 113: 0.6666666666666666, 114: 0.25, 115: 0.9166666666666666, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.9166666666666666, 120: 0.75, 121: 1.0, 122: 0.8333333333333334, 123: 1.0, 124: 1.0, 125: 0.9166666666666666, 126: 0.9166666666666666, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.9166666666666666, 132: 0.6666666666666666, 133: 1.0, 134: 0.8333333333333334, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.4166666666666667, 151: 0.9166666666666666, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 0.9166666666666666, 156: 0.75, 157: 0.5833333333333334, 158: 0.7777777777777778, 159: 1.0, 160: 0.4166666666666667, 161: 0.9166666666666666, 162: 1.0, 163: 0.9166666666666666, 164: 0.8333333333333334, 165: 0.75, 166: 0.75, 167: 0.8333333333333334, 168: 0.9166666666666666, 169: 1.0, 170: 0.9166666666666666, 171: 0.4166666666666667, 172: 1.0, 173: 0.8333333333333334, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.7777777777777778, 180: 0.8333333333333334, 181: 0.75, 182: 0.6666666666666666, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.5833333333333334, 189: 0.9166666666666666, 190: 0.5833333333333334, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.9166666666666666, 198: 0.6666666666666666}

2025-01-13 16:23:35,096 [INFO] [78] TRAIN  loss: 0.8597858803711194 acc: 0.999537963961189
2025-01-13 16:23:35,096 [INFO] [78] TRAIN  loss dict: {'classification_loss': 0.8597858803711194}
2025-01-13 16:23:35,096 [INFO] [78] VALIDATION loss: 1.6131767699062223 VALIDATION acc: 0.8093434343434344
2025-01-13 16:23:35,096 [INFO] [78] VALIDATION loss dict: {'classification_loss': 1.6131767699062223}
2025-01-13 16:23:35,096 [INFO] 
2025-01-13 16:23:54,095 [INFO] Step[50/4329]: training loss : 0.8582128071784973 TRAIN  loss dict:  {'classification_loss': 0.8582128071784973}
2025-01-13 16:24:07,130 [INFO] Step[100/4329]: training loss : 0.8581142795085906 TRAIN  loss dict:  {'classification_loss': 0.8581142795085906}
2025-01-13 16:24:21,577 [INFO] Step[150/4329]: training loss : 0.8583790719509125 TRAIN  loss dict:  {'classification_loss': 0.8583790719509125}
2025-01-13 16:24:35,739 [INFO] Step[200/4329]: training loss : 0.8570988011360169 TRAIN  loss dict:  {'classification_loss': 0.8570988011360169}
2025-01-13 16:24:49,895 [INFO] Step[250/4329]: training loss : 0.8754398500919343 TRAIN  loss dict:  {'classification_loss': 0.8754398500919343}
2025-01-13 16:25:04,302 [INFO] Step[300/4329]: training loss : 0.8586194622516632 TRAIN  loss dict:  {'classification_loss': 0.8586194622516632}
2025-01-13 16:25:18,531 [INFO] Step[350/4329]: training loss : 0.8582521569728851 TRAIN  loss dict:  {'classification_loss': 0.8582521569728851}
2025-01-13 16:25:32,990 [INFO] Step[400/4329]: training loss : 0.8567956113815307 TRAIN  loss dict:  {'classification_loss': 0.8567956113815307}
2025-01-13 16:25:47,244 [INFO] Step[450/4329]: training loss : 0.8626572465896607 TRAIN  loss dict:  {'classification_loss': 0.8626572465896607}
2025-01-13 16:26:01,638 [INFO] Step[500/4329]: training loss : 0.8573809242248536 TRAIN  loss dict:  {'classification_loss': 0.8573809242248536}
2025-01-13 16:26:16,345 [INFO] Step[550/4329]: training loss : 0.8675867140293121 TRAIN  loss dict:  {'classification_loss': 0.8675867140293121}
2025-01-13 16:26:31,016 [INFO] Step[600/4329]: training loss : 0.8578233194351196 TRAIN  loss dict:  {'classification_loss': 0.8578233194351196}
2025-01-13 16:26:45,501 [INFO] Step[650/4329]: training loss : 0.8571885478496551 TRAIN  loss dict:  {'classification_loss': 0.8571885478496551}
2025-01-13 16:27:00,150 [INFO] Step[700/4329]: training loss : 0.8611581707000733 TRAIN  loss dict:  {'classification_loss': 0.8611581707000733}
2025-01-13 16:27:14,685 [INFO] Step[750/4329]: training loss : 0.8618849658966065 TRAIN  loss dict:  {'classification_loss': 0.8618849658966065}
2025-01-13 16:27:29,131 [INFO] Step[800/4329]: training loss : 0.8566092491149903 TRAIN  loss dict:  {'classification_loss': 0.8566092491149903}
2025-01-13 16:27:43,608 [INFO] Step[850/4329]: training loss : 0.8589881086349487 TRAIN  loss dict:  {'classification_loss': 0.8589881086349487}
2025-01-13 16:27:58,041 [INFO] Step[900/4329]: training loss : 0.863173668384552 TRAIN  loss dict:  {'classification_loss': 0.863173668384552}
2025-01-13 16:28:12,651 [INFO] Step[950/4329]: training loss : 0.8576514041423797 TRAIN  loss dict:  {'classification_loss': 0.8576514041423797}
2025-01-13 16:28:26,966 [INFO] Step[1000/4329]: training loss : 0.8565652179718017 TRAIN  loss dict:  {'classification_loss': 0.8565652179718017}
2025-01-13 16:28:41,437 [INFO] Step[1050/4329]: training loss : 0.857086147069931 TRAIN  loss dict:  {'classification_loss': 0.857086147069931}
2025-01-13 16:28:56,166 [INFO] Step[1100/4329]: training loss : 0.8581856870651245 TRAIN  loss dict:  {'classification_loss': 0.8581856870651245}
2025-01-13 16:29:10,524 [INFO] Step[1150/4329]: training loss : 0.8681965410709381 TRAIN  loss dict:  {'classification_loss': 0.8681965410709381}
2025-01-13 16:29:25,206 [INFO] Step[1200/4329]: training loss : 0.8575290191173554 TRAIN  loss dict:  {'classification_loss': 0.8575290191173554}
2025-01-13 16:29:39,620 [INFO] Step[1250/4329]: training loss : 0.8563877046108246 TRAIN  loss dict:  {'classification_loss': 0.8563877046108246}
2025-01-13 16:29:53,524 [INFO] Step[1300/4329]: training loss : 0.8578627848625183 TRAIN  loss dict:  {'classification_loss': 0.8578627848625183}
2025-01-13 16:30:07,379 [INFO] Step[1350/4329]: training loss : 0.8599072432518006 TRAIN  loss dict:  {'classification_loss': 0.8599072432518006}
2025-01-13 16:30:22,623 [INFO] Step[1400/4329]: training loss : 0.8622790455818177 TRAIN  loss dict:  {'classification_loss': 0.8622790455818177}
2025-01-13 16:30:36,962 [INFO] Step[1450/4329]: training loss : 0.8602926063537598 TRAIN  loss dict:  {'classification_loss': 0.8602926063537598}
2025-01-13 16:30:50,822 [INFO] Step[1500/4329]: training loss : 0.8567257153987885 TRAIN  loss dict:  {'classification_loss': 0.8567257153987885}
2025-01-13 16:31:04,696 [INFO] Step[1550/4329]: training loss : 0.8573420584201813 TRAIN  loss dict:  {'classification_loss': 0.8573420584201813}
2025-01-13 16:31:18,810 [INFO] Step[1600/4329]: training loss : 0.8568806326389313 TRAIN  loss dict:  {'classification_loss': 0.8568806326389313}
2025-01-13 16:31:33,045 [INFO] Step[1650/4329]: training loss : 0.8575936138629914 TRAIN  loss dict:  {'classification_loss': 0.8575936138629914}
2025-01-13 16:31:47,698 [INFO] Step[1700/4329]: training loss : 0.874904578924179 TRAIN  loss dict:  {'classification_loss': 0.874904578924179}
2025-01-13 16:32:02,223 [INFO] Step[1750/4329]: training loss : 0.8602627193927765 TRAIN  loss dict:  {'classification_loss': 0.8602627193927765}
2025-01-13 16:32:16,416 [INFO] Step[1800/4329]: training loss : 0.8563021814823151 TRAIN  loss dict:  {'classification_loss': 0.8563021814823151}
2025-01-13 16:32:30,635 [INFO] Step[1850/4329]: training loss : 0.8584179091453552 TRAIN  loss dict:  {'classification_loss': 0.8584179091453552}
2025-01-13 16:32:44,763 [INFO] Step[1900/4329]: training loss : 0.8587244045734406 TRAIN  loss dict:  {'classification_loss': 0.8587244045734406}
2025-01-13 16:32:58,977 [INFO] Step[1950/4329]: training loss : 0.8580328464508057 TRAIN  loss dict:  {'classification_loss': 0.8580328464508057}
2025-01-13 16:33:13,646 [INFO] Step[2000/4329]: training loss : 0.870208352804184 TRAIN  loss dict:  {'classification_loss': 0.870208352804184}
2025-01-13 16:33:28,026 [INFO] Step[2050/4329]: training loss : 0.8569794237613678 TRAIN  loss dict:  {'classification_loss': 0.8569794237613678}
2025-01-13 16:33:42,669 [INFO] Step[2100/4329]: training loss : 0.8575991678237915 TRAIN  loss dict:  {'classification_loss': 0.8575991678237915}
2025-01-13 16:33:57,071 [INFO] Step[2150/4329]: training loss : 0.8567856180667878 TRAIN  loss dict:  {'classification_loss': 0.8567856180667878}
2025-01-13 16:34:11,242 [INFO] Step[2200/4329]: training loss : 0.8575475203990937 TRAIN  loss dict:  {'classification_loss': 0.8575475203990937}
2025-01-13 16:34:25,677 [INFO] Step[2250/4329]: training loss : 0.8563711786270142 TRAIN  loss dict:  {'classification_loss': 0.8563711786270142}
2025-01-13 16:34:40,083 [INFO] Step[2300/4329]: training loss : 0.8571507942676544 TRAIN  loss dict:  {'classification_loss': 0.8571507942676544}
2025-01-13 16:34:54,198 [INFO] Step[2350/4329]: training loss : 0.8579278564453126 TRAIN  loss dict:  {'classification_loss': 0.8579278564453126}
2025-01-13 16:35:08,397 [INFO] Step[2400/4329]: training loss : 0.8576440608501434 TRAIN  loss dict:  {'classification_loss': 0.8576440608501434}
2025-01-13 16:35:22,507 [INFO] Step[2450/4329]: training loss : 0.8644667780399322 TRAIN  loss dict:  {'classification_loss': 0.8644667780399322}
2025-01-13 16:35:37,003 [INFO] Step[2500/4329]: training loss : 0.8593278408050538 TRAIN  loss dict:  {'classification_loss': 0.8593278408050538}
2025-01-13 16:35:51,494 [INFO] Step[2550/4329]: training loss : 0.8639680480957032 TRAIN  loss dict:  {'classification_loss': 0.8639680480957032}
2025-01-13 16:36:05,704 [INFO] Step[2600/4329]: training loss : 0.8595277190208435 TRAIN  loss dict:  {'classification_loss': 0.8595277190208435}
2025-01-13 16:36:20,052 [INFO] Step[2650/4329]: training loss : 0.8597959852218628 TRAIN  loss dict:  {'classification_loss': 0.8597959852218628}
2025-01-13 16:36:34,231 [INFO] Step[2700/4329]: training loss : 0.8626211786270142 TRAIN  loss dict:  {'classification_loss': 0.8626211786270142}
2025-01-13 16:36:48,630 [INFO] Step[2750/4329]: training loss : 0.857197105884552 TRAIN  loss dict:  {'classification_loss': 0.857197105884552}
2025-01-13 16:37:03,040 [INFO] Step[2800/4329]: training loss : 0.8674647331237793 TRAIN  loss dict:  {'classification_loss': 0.8674647331237793}
2025-01-13 16:37:17,735 [INFO] Step[2850/4329]: training loss : 0.860860539674759 TRAIN  loss dict:  {'classification_loss': 0.860860539674759}
2025-01-13 16:37:32,101 [INFO] Step[2900/4329]: training loss : 0.8577094876766205 TRAIN  loss dict:  {'classification_loss': 0.8577094876766205}
2025-01-13 16:37:46,455 [INFO] Step[2950/4329]: training loss : 0.8564716029167175 TRAIN  loss dict:  {'classification_loss': 0.8564716029167175}
2025-01-13 16:38:00,602 [INFO] Step[3000/4329]: training loss : 0.8615585172176361 TRAIN  loss dict:  {'classification_loss': 0.8615585172176361}
2025-01-13 16:38:14,854 [INFO] Step[3050/4329]: training loss : 0.8599473214149476 TRAIN  loss dict:  {'classification_loss': 0.8599473214149476}
2025-01-13 16:38:29,376 [INFO] Step[3100/4329]: training loss : 0.8598446750640869 TRAIN  loss dict:  {'classification_loss': 0.8598446750640869}
2025-01-13 16:38:43,554 [INFO] Step[3150/4329]: training loss : 0.856851886510849 TRAIN  loss dict:  {'classification_loss': 0.856851886510849}
2025-01-13 16:38:57,904 [INFO] Step[3200/4329]: training loss : 0.8569595122337341 TRAIN  loss dict:  {'classification_loss': 0.8569595122337341}
2025-01-13 16:39:12,326 [INFO] Step[3250/4329]: training loss : 0.8603311908245087 TRAIN  loss dict:  {'classification_loss': 0.8603311908245087}
2025-01-13 16:39:26,587 [INFO] Step[3300/4329]: training loss : 0.8570030057430267 TRAIN  loss dict:  {'classification_loss': 0.8570030057430267}
2025-01-13 16:39:40,799 [INFO] Step[3350/4329]: training loss : 0.8563338029384613 TRAIN  loss dict:  {'classification_loss': 0.8563338029384613}
2025-01-13 16:39:55,005 [INFO] Step[3400/4329]: training loss : 0.8564153790473938 TRAIN  loss dict:  {'classification_loss': 0.8564153790473938}
2025-01-13 16:40:09,374 [INFO] Step[3450/4329]: training loss : 0.8608864879608155 TRAIN  loss dict:  {'classification_loss': 0.8608864879608155}
2025-01-13 16:40:24,068 [INFO] Step[3500/4329]: training loss : 0.8563324987888337 TRAIN  loss dict:  {'classification_loss': 0.8563324987888337}
2025-01-13 16:40:38,780 [INFO] Step[3550/4329]: training loss : 0.8565259850025178 TRAIN  loss dict:  {'classification_loss': 0.8565259850025178}
2025-01-13 16:40:53,467 [INFO] Step[3600/4329]: training loss : 0.8595824325084687 TRAIN  loss dict:  {'classification_loss': 0.8595824325084687}
2025-01-13 16:41:07,873 [INFO] Step[3650/4329]: training loss : 0.8594099652767181 TRAIN  loss dict:  {'classification_loss': 0.8594099652767181}
2025-01-13 16:41:22,552 [INFO] Step[3700/4329]: training loss : 0.8562411141395568 TRAIN  loss dict:  {'classification_loss': 0.8562411141395568}
2025-01-13 16:41:36,979 [INFO] Step[3750/4329]: training loss : 0.8571807599067688 TRAIN  loss dict:  {'classification_loss': 0.8571807599067688}
2025-01-13 16:41:51,159 [INFO] Step[3800/4329]: training loss : 0.8569299340248108 TRAIN  loss dict:  {'classification_loss': 0.8569299340248108}
2025-01-13 16:42:05,738 [INFO] Step[3850/4329]: training loss : 0.8583525025844574 TRAIN  loss dict:  {'classification_loss': 0.8583525025844574}
2025-01-13 16:42:20,259 [INFO] Step[3900/4329]: training loss : 0.8591765916347504 TRAIN  loss dict:  {'classification_loss': 0.8591765916347504}
2025-01-13 16:42:34,648 [INFO] Step[3950/4329]: training loss : 0.8567232799530029 TRAIN  loss dict:  {'classification_loss': 0.8567232799530029}
2025-01-13 16:42:49,326 [INFO] Step[4000/4329]: training loss : 0.8816042923927307 TRAIN  loss dict:  {'classification_loss': 0.8816042923927307}
2025-01-13 16:43:03,766 [INFO] Step[4050/4329]: training loss : 0.8562575149536132 TRAIN  loss dict:  {'classification_loss': 0.8562575149536132}
2025-01-13 16:43:17,448 [INFO] Step[4100/4329]: training loss : 0.857042316198349 TRAIN  loss dict:  {'classification_loss': 0.857042316198349}
2025-01-13 16:43:31,318 [INFO] Step[4150/4329]: training loss : 0.8679510533809662 TRAIN  loss dict:  {'classification_loss': 0.8679510533809662}
2025-01-13 16:43:45,343 [INFO] Step[4200/4329]: training loss : 0.8583848071098328 TRAIN  loss dict:  {'classification_loss': 0.8583848071098328}
2025-01-13 16:44:00,915 [INFO] Step[4250/4329]: training loss : 0.8577529895305633 TRAIN  loss dict:  {'classification_loss': 0.8577529895305633}
2025-01-13 16:44:15,452 [INFO] Step[4300/4329]: training loss : 0.857747882604599 TRAIN  loss dict:  {'classification_loss': 0.857747882604599}
2025-01-13 16:46:45,523 [INFO] Label accuracies statistics:
2025-01-13 16:46:45,523 [INFO] {0: 0.6666666666666666, 1: 0.8888888888888888, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.4166666666666667, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.5833333333333334, 8: 0.4166666666666667, 9: 1.0, 10: 1.0, 11: 0.9166666666666666, 12: 0.5, 13: 0.5, 14: 0.6666666666666666, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.5, 19: 0.75, 20: 0.5833333333333334, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.8333333333333334, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.6666666666666666, 31: 0.75, 32: 0.75, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 1.0, 36: 0.5833333333333334, 37: 1.0, 38: 0.9166666666666666, 39: 0.9166666666666666, 40: 0.75, 41: 0.5, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.6666666666666666, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 0.9166666666666666, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5833333333333334, 54: 0.5, 55: 0.75, 56: 0.9166666666666666, 57: 0.75, 58: 0.5, 59: 0.8333333333333334, 60: 0.6666666666666666, 61: 0.8333333333333334, 62: 0.6666666666666666, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.6666666666666666, 69: 0.6666666666666666, 70: 0.5833333333333334, 71: 0.4166666666666667, 72: 0.8333333333333334, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.5833333333333334, 77: 0.75, 78: 0.9166666666666666, 79: 0.75, 80: 1.0, 81: 0.9166666666666666, 82: 0.6666666666666666, 83: 0.5833333333333334, 84: 0.4166666666666667, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.6666666666666666, 89: 0.5833333333333334, 90: 0.8333333333333334, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 0.9166666666666666, 96: 0.8333333333333334, 97: 0.6666666666666666, 98: 0.8333333333333334, 99: 1.0, 100: 0.75, 101: 0.9166666666666666, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.4166666666666667, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 0.9166666666666666, 111: 1.0, 112: 0.8333333333333334, 113: 0.5833333333333334, 114: 0.25, 115: 1.0, 116: 0.8333333333333334, 117: 0.75, 118: 0.9166666666666666, 119: 0.75, 120: 0.8333333333333334, 121: 0.9166666666666666, 122: 0.8333333333333334, 123: 1.0, 124: 1.0, 125: 0.8333333333333334, 126: 0.9166666666666666, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.9166666666666666, 132: 0.4166666666666667, 133: 1.0, 134: 0.9166666666666666, 135: 0.9166666666666666, 136: 1.0, 137: 0.9166666666666666, 138: 1.0, 139: 0.8333333333333334, 140: 1.0, 141: 1.0, 142: 0.6666666666666666, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.8333333333333334, 149: 1.0, 150: 0.5833333333333334, 151: 0.9166666666666666, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.9166666666666666, 156: 0.6666666666666666, 157: 0.6666666666666666, 158: 0.7777777777777778, 159: 1.0, 160: 0.3333333333333333, 161: 0.9166666666666666, 162: 0.9166666666666666, 163: 0.9166666666666666, 164: 0.8333333333333334, 165: 0.6666666666666666, 166: 0.75, 167: 0.75, 168: 0.9166666666666666, 169: 1.0, 170: 1.0, 171: 0.5833333333333334, 172: 1.0, 173: 0.8333333333333334, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.8333333333333334, 178: 1.0, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.5833333333333334, 183: 1.0, 184: 0.8333333333333334, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.6666666666666666, 189: 0.9166666666666666, 190: 0.5833333333333334, 191: 0.6666666666666666, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.9166666666666666, 198: 0.5833333333333334}

2025-01-13 16:46:45,526 [INFO] [79] TRAIN  loss: 0.8596239156055516 acc: 0.999229939935315
2025-01-13 16:46:45,526 [INFO] [79] TRAIN  loss dict: {'classification_loss': 0.8596239156055516}
2025-01-13 16:46:45,526 [INFO] [79] VALIDATION loss: 1.6186977776162552 VALIDATION acc: 0.8080808080808081
2025-01-13 16:46:45,526 [INFO] [79] VALIDATION loss dict: {'classification_loss': 1.6186977776162552}
2025-01-13 16:46:45,526 [INFO] 
2025-01-13 16:47:06,424 [INFO] Step[50/4329]: training loss : 0.8581602120399475 TRAIN  loss dict:  {'classification_loss': 0.8581602120399475}
2025-01-13 16:47:20,861 [INFO] Step[100/4329]: training loss : 0.8587396216392517 TRAIN  loss dict:  {'classification_loss': 0.8587396216392517}
2025-01-13 16:47:35,126 [INFO] Step[150/4329]: training loss : 0.8568778514862061 TRAIN  loss dict:  {'classification_loss': 0.8568778514862061}
2025-01-13 16:47:49,317 [INFO] Step[200/4329]: training loss : 0.8592865705490113 TRAIN  loss dict:  {'classification_loss': 0.8592865705490113}
2025-01-13 16:48:03,707 [INFO] Step[250/4329]: training loss : 0.8562926495075226 TRAIN  loss dict:  {'classification_loss': 0.8562926495075226}
2025-01-13 16:48:18,392 [INFO] Step[300/4329]: training loss : 0.8570060062408448 TRAIN  loss dict:  {'classification_loss': 0.8570060062408448}
2025-01-13 16:48:33,007 [INFO] Step[350/4329]: training loss : 0.8584541177749634 TRAIN  loss dict:  {'classification_loss': 0.8584541177749634}
2025-01-13 16:48:47,354 [INFO] Step[400/4329]: training loss : 0.8818170523643494 TRAIN  loss dict:  {'classification_loss': 0.8818170523643494}
2025-01-13 16:49:01,865 [INFO] Step[450/4329]: training loss : 0.8562049865722656 TRAIN  loss dict:  {'classification_loss': 0.8562049865722656}
2025-01-13 16:49:16,146 [INFO] Step[500/4329]: training loss : 0.8581582689285279 TRAIN  loss dict:  {'classification_loss': 0.8581582689285279}
2025-01-13 16:49:30,448 [INFO] Step[550/4329]: training loss : 0.8596894276142121 TRAIN  loss dict:  {'classification_loss': 0.8596894276142121}
2025-01-13 16:49:45,100 [INFO] Step[600/4329]: training loss : 0.863432742357254 TRAIN  loss dict:  {'classification_loss': 0.863432742357254}
2025-01-13 16:49:59,361 [INFO] Step[650/4329]: training loss : 0.8563350677490235 TRAIN  loss dict:  {'classification_loss': 0.8563350677490235}
2025-01-13 16:50:13,918 [INFO] Step[700/4329]: training loss : 0.8575489914417267 TRAIN  loss dict:  {'classification_loss': 0.8575489914417267}
2025-01-13 16:50:28,472 [INFO] Step[750/4329]: training loss : 0.8586279249191284 TRAIN  loss dict:  {'classification_loss': 0.8586279249191284}
2025-01-13 16:50:42,762 [INFO] Step[800/4329]: training loss : 0.8571634554862976 TRAIN  loss dict:  {'classification_loss': 0.8571634554862976}
2025-01-13 16:50:57,530 [INFO] Step[850/4329]: training loss : 0.8579542589187622 TRAIN  loss dict:  {'classification_loss': 0.8579542589187622}
2025-01-13 16:51:11,881 [INFO] Step[900/4329]: training loss : 0.8638625073432923 TRAIN  loss dict:  {'classification_loss': 0.8638625073432923}
2025-01-13 16:51:26,413 [INFO] Step[950/4329]: training loss : 0.8571904718875885 TRAIN  loss dict:  {'classification_loss': 0.8571904718875885}
2025-01-13 16:51:40,980 [INFO] Step[1000/4329]: training loss : 0.8610890746116638 TRAIN  loss dict:  {'classification_loss': 0.8610890746116638}
2025-01-13 16:51:55,301 [INFO] Step[1050/4329]: training loss : 0.8578026080131531 TRAIN  loss dict:  {'classification_loss': 0.8578026080131531}
2025-01-13 16:52:09,718 [INFO] Step[1100/4329]: training loss : 0.8589626336097718 TRAIN  loss dict:  {'classification_loss': 0.8589626336097718}
2025-01-13 16:52:24,099 [INFO] Step[1150/4329]: training loss : 0.8578867280483246 TRAIN  loss dict:  {'classification_loss': 0.8578867280483246}
2025-01-13 16:52:38,639 [INFO] Step[1200/4329]: training loss : 0.8572021532058716 TRAIN  loss dict:  {'classification_loss': 0.8572021532058716}
2025-01-13 16:52:52,850 [INFO] Step[1250/4329]: training loss : 0.8569005584716797 TRAIN  loss dict:  {'classification_loss': 0.8569005584716797}
2025-01-13 16:53:07,366 [INFO] Step[1300/4329]: training loss : 0.8599141705036163 TRAIN  loss dict:  {'classification_loss': 0.8599141705036163}
2025-01-13 16:53:22,067 [INFO] Step[1350/4329]: training loss : 0.8570679211616516 TRAIN  loss dict:  {'classification_loss': 0.8570679211616516}
2025-01-13 16:53:36,389 [INFO] Step[1400/4329]: training loss : 0.8558862042427063 TRAIN  loss dict:  {'classification_loss': 0.8558862042427063}
2025-01-13 16:53:50,851 [INFO] Step[1450/4329]: training loss : 0.8583560132980347 TRAIN  loss dict:  {'classification_loss': 0.8583560132980347}
2025-01-13 16:54:03,901 [INFO] Step[1500/4329]: training loss : 0.8577427518367767 TRAIN  loss dict:  {'classification_loss': 0.8577427518367767}
2025-01-13 16:54:17,260 [INFO] Step[1550/4329]: training loss : 0.8569599604606628 TRAIN  loss dict:  {'classification_loss': 0.8569599604606628}
2025-01-13 16:54:31,880 [INFO] Step[1600/4329]: training loss : 0.8588249397277832 TRAIN  loss dict:  {'classification_loss': 0.8588249397277832}
2025-01-13 16:54:46,543 [INFO] Step[1650/4329]: training loss : 0.8574167621135712 TRAIN  loss dict:  {'classification_loss': 0.8574167621135712}
2025-01-13 16:55:00,797 [INFO] Step[1700/4329]: training loss : 0.8577464640140533 TRAIN  loss dict:  {'classification_loss': 0.8577464640140533}
2025-01-13 16:55:15,451 [INFO] Step[1750/4329]: training loss : 0.8569247663021088 TRAIN  loss dict:  {'classification_loss': 0.8569247663021088}
2025-01-13 16:55:29,825 [INFO] Step[1800/4329]: training loss : 0.858858550786972 TRAIN  loss dict:  {'classification_loss': 0.858858550786972}
2025-01-13 16:55:44,205 [INFO] Step[1850/4329]: training loss : 0.856638640165329 TRAIN  loss dict:  {'classification_loss': 0.856638640165329}
2025-01-13 16:55:58,713 [INFO] Step[1900/4329]: training loss : 0.8561111783981323 TRAIN  loss dict:  {'classification_loss': 0.8561111783981323}
2025-01-13 16:56:13,333 [INFO] Step[1950/4329]: training loss : 0.8583542954921722 TRAIN  loss dict:  {'classification_loss': 0.8583542954921722}
2025-01-13 16:56:27,757 [INFO] Step[2000/4329]: training loss : 0.8579862284660339 TRAIN  loss dict:  {'classification_loss': 0.8579862284660339}
2025-01-13 16:56:41,979 [INFO] Step[2050/4329]: training loss : 0.8579557359218597 TRAIN  loss dict:  {'classification_loss': 0.8579557359218597}
2025-01-13 16:56:55,638 [INFO] Step[2100/4329]: training loss : 0.8570431625843048 TRAIN  loss dict:  {'classification_loss': 0.8570431625843048}
2025-01-13 16:57:09,504 [INFO] Step[2150/4329]: training loss : 0.8590066432952881 TRAIN  loss dict:  {'classification_loss': 0.8590066432952881}
2025-01-13 16:57:23,940 [INFO] Step[2200/4329]: training loss : 0.8587405729293823 TRAIN  loss dict:  {'classification_loss': 0.8587405729293823}
2025-01-13 16:57:38,208 [INFO] Step[2250/4329]: training loss : 0.8589297020435334 TRAIN  loss dict:  {'classification_loss': 0.8589297020435334}
2025-01-13 16:57:52,665 [INFO] Step[2300/4329]: training loss : 0.8591705334186553 TRAIN  loss dict:  {'classification_loss': 0.8591705334186553}
2025-01-13 16:58:06,511 [INFO] Step[2350/4329]: training loss : 0.8655921256542206 TRAIN  loss dict:  {'classification_loss': 0.8655921256542206}
2025-01-13 16:58:20,683 [INFO] Step[2400/4329]: training loss : 0.8583335387706756 TRAIN  loss dict:  {'classification_loss': 0.8583335387706756}
2025-01-13 16:58:34,683 [INFO] Step[2450/4329]: training loss : 0.8572994709014893 TRAIN  loss dict:  {'classification_loss': 0.8572994709014893}
2025-01-13 16:58:48,300 [INFO] Step[2500/4329]: training loss : 0.8590016222000122 TRAIN  loss dict:  {'classification_loss': 0.8590016222000122}
2025-01-13 16:59:02,443 [INFO] Step[2550/4329]: training loss : 0.8562700653076172 TRAIN  loss dict:  {'classification_loss': 0.8562700653076172}
2025-01-13 16:59:16,269 [INFO] Step[2600/4329]: training loss : 0.8584652352333069 TRAIN  loss dict:  {'classification_loss': 0.8584652352333069}
2025-01-13 16:59:30,054 [INFO] Step[2650/4329]: training loss : 0.8569161307811737 TRAIN  loss dict:  {'classification_loss': 0.8569161307811737}
2025-01-13 16:59:44,072 [INFO] Step[2700/4329]: training loss : 0.8567868864536285 TRAIN  loss dict:  {'classification_loss': 0.8567868864536285}
2025-01-13 16:59:57,960 [INFO] Step[2750/4329]: training loss : 0.8597624659538269 TRAIN  loss dict:  {'classification_loss': 0.8597624659538269}
2025-01-13 17:00:11,725 [INFO] Step[2800/4329]: training loss : 0.85946218252182 TRAIN  loss dict:  {'classification_loss': 0.85946218252182}
2025-01-13 17:00:25,588 [INFO] Step[2850/4329]: training loss : 0.8585485565662384 TRAIN  loss dict:  {'classification_loss': 0.8585485565662384}
2025-01-13 17:00:39,334 [INFO] Step[2900/4329]: training loss : 0.859656434059143 TRAIN  loss dict:  {'classification_loss': 0.859656434059143}
2025-01-13 17:00:53,051 [INFO] Step[2950/4329]: training loss : 0.8557783484458923 TRAIN  loss dict:  {'classification_loss': 0.8557783484458923}
2025-01-13 17:01:08,398 [INFO] Step[3000/4329]: training loss : 0.8564114367961884 TRAIN  loss dict:  {'classification_loss': 0.8564114367961884}
2025-01-13 17:01:22,654 [INFO] Step[3050/4329]: training loss : 0.8592341411113739 TRAIN  loss dict:  {'classification_loss': 0.8592341411113739}
2025-01-13 17:01:37,734 [INFO] Step[3100/4329]: training loss : 0.8592719197273254 TRAIN  loss dict:  {'classification_loss': 0.8592719197273254}
2025-01-13 17:01:52,805 [INFO] Step[3150/4329]: training loss : 0.8573111402988434 TRAIN  loss dict:  {'classification_loss': 0.8573111402988434}
2025-01-13 17:02:07,978 [INFO] Step[3200/4329]: training loss : 0.8571203589439392 TRAIN  loss dict:  {'classification_loss': 0.8571203589439392}
2025-01-13 17:02:22,735 [INFO] Step[3250/4329]: training loss : 0.8749700117111207 TRAIN  loss dict:  {'classification_loss': 0.8749700117111207}
2025-01-13 17:02:37,653 [INFO] Step[3300/4329]: training loss : 0.8617832911014557 TRAIN  loss dict:  {'classification_loss': 0.8617832911014557}
2025-01-13 17:02:52,610 [INFO] Step[3350/4329]: training loss : 0.861292610168457 TRAIN  loss dict:  {'classification_loss': 0.861292610168457}
2025-01-13 17:03:07,783 [INFO] Step[3400/4329]: training loss : 0.8577745759487152 TRAIN  loss dict:  {'classification_loss': 0.8577745759487152}
2025-01-13 17:03:22,807 [INFO] Step[3450/4329]: training loss : 0.8650358021259308 TRAIN  loss dict:  {'classification_loss': 0.8650358021259308}
2025-01-13 17:03:37,886 [INFO] Step[3500/4329]: training loss : 0.8581461536884308 TRAIN  loss dict:  {'classification_loss': 0.8581461536884308}
2025-01-13 17:03:51,514 [INFO] Step[3550/4329]: training loss : 0.8576955497264862 TRAIN  loss dict:  {'classification_loss': 0.8576955497264862}
2025-01-13 17:04:05,801 [INFO] Step[3600/4329]: training loss : 0.8612203979492188 TRAIN  loss dict:  {'classification_loss': 0.8612203979492188}
2025-01-13 17:04:20,521 [INFO] Step[3650/4329]: training loss : 0.8574270713329315 TRAIN  loss dict:  {'classification_loss': 0.8574270713329315}
2025-01-13 17:04:35,453 [INFO] Step[3700/4329]: training loss : 0.856737425327301 TRAIN  loss dict:  {'classification_loss': 0.856737425327301}
2025-01-13 17:04:50,585 [INFO] Step[3750/4329]: training loss : 0.8610341334342957 TRAIN  loss dict:  {'classification_loss': 0.8610341334342957}
2025-01-13 17:05:05,294 [INFO] Step[3800/4329]: training loss : 0.8589292228221893 TRAIN  loss dict:  {'classification_loss': 0.8589292228221893}
2025-01-13 17:05:20,426 [INFO] Step[3850/4329]: training loss : 0.856244752407074 TRAIN  loss dict:  {'classification_loss': 0.856244752407074}
2025-01-13 17:05:35,405 [INFO] Step[3900/4329]: training loss : 0.8563351690769195 TRAIN  loss dict:  {'classification_loss': 0.8563351690769195}
2025-01-13 17:05:50,135 [INFO] Step[3950/4329]: training loss : 0.8563560104370117 TRAIN  loss dict:  {'classification_loss': 0.8563560104370117}
2025-01-13 17:06:05,213 [INFO] Step[4000/4329]: training loss : 0.857364091873169 TRAIN  loss dict:  {'classification_loss': 0.857364091873169}
2025-01-13 17:06:20,278 [INFO] Step[4050/4329]: training loss : 0.8564540588855744 TRAIN  loss dict:  {'classification_loss': 0.8564540588855744}
2025-01-13 17:06:35,169 [INFO] Step[4100/4329]: training loss : 0.8572563219070435 TRAIN  loss dict:  {'classification_loss': 0.8572563219070435}
2025-01-13 17:06:49,892 [INFO] Step[4150/4329]: training loss : 0.8566694557666779 TRAIN  loss dict:  {'classification_loss': 0.8566694557666779}
2025-01-13 17:07:05,044 [INFO] Step[4200/4329]: training loss : 0.8569731032848358 TRAIN  loss dict:  {'classification_loss': 0.8569731032848358}
2025-01-13 17:07:20,244 [INFO] Step[4250/4329]: training loss : 0.8589272677898407 TRAIN  loss dict:  {'classification_loss': 0.8589272677898407}
2025-01-13 17:07:35,251 [INFO] Step[4300/4329]: training loss : 0.8573969388008118 TRAIN  loss dict:  {'classification_loss': 0.8573969388008118}
2025-01-13 17:09:25,862 [INFO] Label accuracies statistics:
2025-01-13 17:09:25,862 [INFO] {0: 0.5555555555555556, 1: 1.0, 2: 0.6666666666666666, 3: 0.75, 4: 0.5, 5: 0.8333333333333334, 6: 0.6666666666666666, 7: 0.5833333333333334, 8: 0.6666666666666666, 9: 0.9166666666666666, 10: 1.0, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.5, 14: 0.75, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.5833333333333334, 18: 0.5833333333333334, 19: 0.6666666666666666, 20: 0.6666666666666666, 21: 0.75, 22: 0.75, 23: 0.9166666666666666, 24: 1.0, 25: 0.75, 26: 0.9166666666666666, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.75, 31: 0.8333333333333334, 32: 0.75, 33: 0.9166666666666666, 34: 1.0, 35: 1.0, 36: 0.5833333333333334, 37: 0.9166666666666666, 38: 0.9166666666666666, 39: 0.9166666666666666, 40: 0.9166666666666666, 41: 0.5833333333333334, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.6666666666666666, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.6666666666666666, 54: 0.5, 55: 0.6666666666666666, 56: 0.75, 57: 0.75, 58: 0.5833333333333334, 59: 0.75, 60: 0.6666666666666666, 61: 0.9166666666666666, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.9166666666666666, 68: 0.75, 69: 0.5833333333333334, 70: 0.5, 71: 0.5, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.9166666666666666, 82: 0.8333333333333334, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.8333333333333334, 89: 0.5833333333333334, 90: 0.8333333333333334, 91: 1.0, 92: 0.9166666666666666, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.5833333333333334, 97: 0.75, 98: 0.8333333333333334, 99: 1.0, 100: 0.8333333333333334, 101: 0.9166666666666666, 102: 0.9166666666666666, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 1.0, 111: 0.9166666666666666, 112: 0.9166666666666666, 113: 0.5833333333333334, 114: 0.25, 115: 0.9166666666666666, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.9166666666666666, 120: 0.8333333333333334, 121: 0.9166666666666666, 122: 0.8333333333333334, 123: 1.0, 124: 0.9166666666666666, 125: 0.9166666666666666, 126: 0.8333333333333334, 127: 0.8333333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.9166666666666666, 131: 0.9166666666666666, 132: 0.6666666666666666, 133: 1.0, 134: 0.9166666666666666, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.5833333333333334, 145: 1.0, 146: 1.0, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.5, 151: 0.8333333333333334, 152: 1.0, 153: 0.8333333333333334, 154: 1.0, 155: 1.0, 156: 0.6666666666666666, 157: 0.8333333333333334, 158: 0.7777777777777778, 159: 1.0, 160: 0.3333333333333333, 161: 0.8333333333333334, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.6666666666666666, 166: 0.8333333333333334, 167: 0.75, 168: 0.8333333333333334, 169: 1.0, 170: 1.0, 171: 0.5833333333333334, 172: 1.0, 173: 0.8333333333333334, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 0.9166666666666666, 177: 0.75, 178: 1.0, 179: 0.2222222222222222, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.5, 183: 0.9166666666666666, 184: 0.5833333333333334, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.5833333333333334, 189: 1.0, 190: 0.6666666666666666, 191: 0.5, 192: 1.0, 193: 0.9166666666666666, 194: 0.8333333333333334, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.9166666666666666, 198: 0.5833333333333334}

2025-01-13 17:09:25,864 [INFO] [80] TRAIN  loss: 0.8587353972343353 acc: 0.9996149699676575
2025-01-13 17:09:25,864 [INFO] [80] TRAIN  loss dict: {'classification_loss': 0.8587353972343353}
2025-01-13 17:09:25,864 [INFO] [80] VALIDATION loss: 1.615780308090075 VALIDATION acc: 0.8173400673400674
2025-01-13 17:09:25,864 [INFO] [80] VALIDATION loss dict: {'classification_loss': 1.615780308090075}
2025-01-13 17:09:25,864 [INFO] 
2025-01-13 17:09:46,091 [INFO] Step[50/4329]: training loss : 0.8596876704692841 TRAIN  loss dict:  {'classification_loss': 0.8596876704692841}
2025-01-13 17:10:00,935 [INFO] Step[100/4329]: training loss : 0.8604677259922028 TRAIN  loss dict:  {'classification_loss': 0.8604677259922028}
2025-01-13 17:10:15,940 [INFO] Step[150/4329]: training loss : 0.8586573851108551 TRAIN  loss dict:  {'classification_loss': 0.8586573851108551}
2025-01-13 17:10:29,473 [INFO] Step[200/4329]: training loss : 0.8562249541282654 TRAIN  loss dict:  {'classification_loss': 0.8562249541282654}
2025-01-13 17:10:44,623 [INFO] Step[250/4329]: training loss : 0.8573854494094849 TRAIN  loss dict:  {'classification_loss': 0.8573854494094849}
2025-01-13 17:10:59,565 [INFO] Step[300/4329]: training loss : 0.8816391396522522 TRAIN  loss dict:  {'classification_loss': 0.8816391396522522}
2025-01-13 17:11:14,795 [INFO] Step[350/4329]: training loss : 0.8573591840267182 TRAIN  loss dict:  {'classification_loss': 0.8573591840267182}
2025-01-13 17:11:29,920 [INFO] Step[400/4329]: training loss : 0.8593864023685456 TRAIN  loss dict:  {'classification_loss': 0.8593864023685456}
2025-01-13 17:11:45,039 [INFO] Step[450/4329]: training loss : 0.8640355944633484 TRAIN  loss dict:  {'classification_loss': 0.8640355944633484}
2025-01-13 17:12:00,092 [INFO] Step[500/4329]: training loss : 0.8588474726676941 TRAIN  loss dict:  {'classification_loss': 0.8588474726676941}
2025-01-13 17:12:14,873 [INFO] Step[550/4329]: training loss : 0.8571535658836364 TRAIN  loss dict:  {'classification_loss': 0.8571535658836364}
2025-01-13 17:12:29,865 [INFO] Step[600/4329]: training loss : 0.858082400560379 TRAIN  loss dict:  {'classification_loss': 0.858082400560379}
2025-01-13 17:12:45,097 [INFO] Step[650/4329]: training loss : 0.8577415001392364 TRAIN  loss dict:  {'classification_loss': 0.8577415001392364}
2025-01-13 17:13:00,300 [INFO] Step[700/4329]: training loss : 0.8564647471904755 TRAIN  loss dict:  {'classification_loss': 0.8564647471904755}
2025-01-13 17:13:15,354 [INFO] Step[750/4329]: training loss : 0.8576714038848877 TRAIN  loss dict:  {'classification_loss': 0.8576714038848877}
2025-01-13 17:13:30,432 [INFO] Step[800/4329]: training loss : 0.8595009315013885 TRAIN  loss dict:  {'classification_loss': 0.8595009315013885}
2025-01-13 17:13:45,654 [INFO] Step[850/4329]: training loss : 0.856677428483963 TRAIN  loss dict:  {'classification_loss': 0.856677428483963}
2025-01-13 17:14:00,694 [INFO] Step[900/4329]: training loss : 0.8575861918926239 TRAIN  loss dict:  {'classification_loss': 0.8575861918926239}
2025-01-13 17:14:15,635 [INFO] Step[950/4329]: training loss : 0.8584559226036071 TRAIN  loss dict:  {'classification_loss': 0.8584559226036071}
2025-01-13 17:14:30,628 [INFO] Step[1000/4329]: training loss : 0.8564607083797455 TRAIN  loss dict:  {'classification_loss': 0.8564607083797455}
2025-01-13 17:14:45,369 [INFO] Step[1050/4329]: training loss : 0.8567297863960266 TRAIN  loss dict:  {'classification_loss': 0.8567297863960266}
2025-01-13 17:15:00,508 [INFO] Step[1100/4329]: training loss : 0.8568632638454438 TRAIN  loss dict:  {'classification_loss': 0.8568632638454438}
2025-01-13 17:15:15,573 [INFO] Step[1150/4329]: training loss : 0.856291298866272 TRAIN  loss dict:  {'classification_loss': 0.856291298866272}
2025-01-13 17:15:30,785 [INFO] Step[1200/4329]: training loss : 0.8598182761669159 TRAIN  loss dict:  {'classification_loss': 0.8598182761669159}
2025-01-13 17:15:46,041 [INFO] Step[1250/4329]: training loss : 0.8571038210391998 TRAIN  loss dict:  {'classification_loss': 0.8571038210391998}
2025-01-13 17:16:01,064 [INFO] Step[1300/4329]: training loss : 0.8646426296234131 TRAIN  loss dict:  {'classification_loss': 0.8646426296234131}
2025-01-13 17:16:16,059 [INFO] Step[1350/4329]: training loss : 0.8570786798000336 TRAIN  loss dict:  {'classification_loss': 0.8570786798000336}
2025-01-13 17:16:31,277 [INFO] Step[1400/4329]: training loss : 0.8558264315128327 TRAIN  loss dict:  {'classification_loss': 0.8558264315128327}
2025-01-13 17:16:46,325 [INFO] Step[1450/4329]: training loss : 0.8576671707630158 TRAIN  loss dict:  {'classification_loss': 0.8576671707630158}
2025-01-13 17:17:01,320 [INFO] Step[1500/4329]: training loss : 0.8569011151790619 TRAIN  loss dict:  {'classification_loss': 0.8569011151790619}
2025-01-13 17:17:16,426 [INFO] Step[1550/4329]: training loss : 0.8631662607192994 TRAIN  loss dict:  {'classification_loss': 0.8631662607192994}
2025-01-13 17:17:31,653 [INFO] Step[1600/4329]: training loss : 0.8562629985809326 TRAIN  loss dict:  {'classification_loss': 0.8562629985809326}
2025-01-13 17:17:46,854 [INFO] Step[1650/4329]: training loss : 0.8606997215747834 TRAIN  loss dict:  {'classification_loss': 0.8606997215747834}
2025-01-13 17:18:01,572 [INFO] Step[1700/4329]: training loss : 0.8576417493820191 TRAIN  loss dict:  {'classification_loss': 0.8576417493820191}
2025-01-13 17:18:16,406 [INFO] Step[1750/4329]: training loss : 0.8564207041263581 TRAIN  loss dict:  {'classification_loss': 0.8564207041263581}
2025-01-13 17:18:31,486 [INFO] Step[1800/4329]: training loss : 0.8568706440925599 TRAIN  loss dict:  {'classification_loss': 0.8568706440925599}
2025-01-13 17:18:46,343 [INFO] Step[1850/4329]: training loss : 0.8592195630073547 TRAIN  loss dict:  {'classification_loss': 0.8592195630073547}
2025-01-13 17:19:01,216 [INFO] Step[1900/4329]: training loss : 0.8594811582565307 TRAIN  loss dict:  {'classification_loss': 0.8594811582565307}
2025-01-13 17:19:16,376 [INFO] Step[1950/4329]: training loss : 0.8565536677837372 TRAIN  loss dict:  {'classification_loss': 0.8565536677837372}
2025-01-13 17:19:31,453 [INFO] Step[2000/4329]: training loss : 0.8570743119716644 TRAIN  loss dict:  {'classification_loss': 0.8570743119716644}
2025-01-13 17:19:46,470 [INFO] Step[2050/4329]: training loss : 0.85821408867836 TRAIN  loss dict:  {'classification_loss': 0.85821408867836}
2025-01-13 17:20:01,387 [INFO] Step[2100/4329]: training loss : 0.8802152740955352 TRAIN  loss dict:  {'classification_loss': 0.8802152740955352}
2025-01-13 17:20:16,499 [INFO] Step[2150/4329]: training loss : 0.8565724205970764 TRAIN  loss dict:  {'classification_loss': 0.8565724205970764}
2025-01-13 17:20:31,529 [INFO] Step[2200/4329]: training loss : 0.8567299807071685 TRAIN  loss dict:  {'classification_loss': 0.8567299807071685}
2025-01-13 17:20:46,799 [INFO] Step[2250/4329]: training loss : 0.8581845271587372 TRAIN  loss dict:  {'classification_loss': 0.8581845271587372}
2025-01-13 17:21:01,588 [INFO] Step[2300/4329]: training loss : 0.8571030068397522 TRAIN  loss dict:  {'classification_loss': 0.8571030068397522}
2025-01-13 17:21:16,385 [INFO] Step[2350/4329]: training loss : 0.8562940680980682 TRAIN  loss dict:  {'classification_loss': 0.8562940680980682}
2025-01-13 17:21:31,601 [INFO] Step[2400/4329]: training loss : 0.8557518947124482 TRAIN  loss dict:  {'classification_loss': 0.8557518947124482}
2025-01-13 17:21:46,495 [INFO] Step[2450/4329]: training loss : 0.8560404872894287 TRAIN  loss dict:  {'classification_loss': 0.8560404872894287}
2025-01-13 17:22:01,733 [INFO] Step[2500/4329]: training loss : 0.8569302761554718 TRAIN  loss dict:  {'classification_loss': 0.8569302761554718}
2025-01-13 17:22:16,924 [INFO] Step[2550/4329]: training loss : 0.8563513886928559 TRAIN  loss dict:  {'classification_loss': 0.8563513886928559}
2025-01-13 17:22:31,957 [INFO] Step[2600/4329]: training loss : 0.8563240563869476 TRAIN  loss dict:  {'classification_loss': 0.8563240563869476}
2025-01-13 17:22:46,848 [INFO] Step[2650/4329]: training loss : 0.8570111894607544 TRAIN  loss dict:  {'classification_loss': 0.8570111894607544}
2025-01-13 17:23:01,588 [INFO] Step[2700/4329]: training loss : 0.8561180889606476 TRAIN  loss dict:  {'classification_loss': 0.8561180889606476}
2025-01-13 17:23:16,755 [INFO] Step[2750/4329]: training loss : 0.8579646408557892 TRAIN  loss dict:  {'classification_loss': 0.8579646408557892}
2025-01-13 17:23:30,849 [INFO] Step[2800/4329]: training loss : 0.8570764374732971 TRAIN  loss dict:  {'classification_loss': 0.8570764374732971}
2025-01-13 17:23:44,737 [INFO] Step[2850/4329]: training loss : 0.8589330160617829 TRAIN  loss dict:  {'classification_loss': 0.8589330160617829}
2025-01-13 17:23:59,662 [INFO] Step[2900/4329]: training loss : 0.8578085136413575 TRAIN  loss dict:  {'classification_loss': 0.8578085136413575}
2025-01-13 17:24:14,143 [INFO] Step[2950/4329]: training loss : 0.8564740300178528 TRAIN  loss dict:  {'classification_loss': 0.8564740300178528}
2025-01-13 17:24:27,973 [INFO] Step[3000/4329]: training loss : 0.8590889823436737 TRAIN  loss dict:  {'classification_loss': 0.8590889823436737}
2025-01-13 17:24:43,213 [INFO] Step[3050/4329]: training loss : 0.855846951007843 TRAIN  loss dict:  {'classification_loss': 0.855846951007843}
2025-01-13 17:24:58,006 [INFO] Step[3100/4329]: training loss : 0.8575966620445251 TRAIN  loss dict:  {'classification_loss': 0.8575966620445251}
2025-01-13 17:25:12,965 [INFO] Step[3150/4329]: training loss : 0.8672054040431977 TRAIN  loss dict:  {'classification_loss': 0.8672054040431977}
2025-01-13 17:25:28,107 [INFO] Step[3200/4329]: training loss : 0.8581525981426239 TRAIN  loss dict:  {'classification_loss': 0.8581525981426239}
2025-01-13 17:25:43,123 [INFO] Step[3250/4329]: training loss : 0.8599285280704498 TRAIN  loss dict:  {'classification_loss': 0.8599285280704498}
2025-01-13 17:25:58,092 [INFO] Step[3300/4329]: training loss : 0.8566010653972626 TRAIN  loss dict:  {'classification_loss': 0.8566010653972626}
2025-01-13 17:26:13,035 [INFO] Step[3350/4329]: training loss : 0.8561513471603394 TRAIN  loss dict:  {'classification_loss': 0.8561513471603394}
2025-01-13 17:26:27,755 [INFO] Step[3400/4329]: training loss : 0.8579871284961701 TRAIN  loss dict:  {'classification_loss': 0.8579871284961701}
2025-01-13 17:26:42,887 [INFO] Step[3450/4329]: training loss : 0.8569147992134094 TRAIN  loss dict:  {'classification_loss': 0.8569147992134094}
2025-01-13 17:26:58,112 [INFO] Step[3500/4329]: training loss : 0.8561667907238006 TRAIN  loss dict:  {'classification_loss': 0.8561667907238006}
2025-01-13 17:27:12,892 [INFO] Step[3550/4329]: training loss : 0.857184454202652 TRAIN  loss dict:  {'classification_loss': 0.857184454202652}
2025-01-13 17:27:27,997 [INFO] Step[3600/4329]: training loss : 0.8597889685630798 TRAIN  loss dict:  {'classification_loss': 0.8597889685630798}
2025-01-13 17:27:43,093 [INFO] Step[3650/4329]: training loss : 0.8556970024108886 TRAIN  loss dict:  {'classification_loss': 0.8556970024108886}
2025-01-13 17:27:58,051 [INFO] Step[3700/4329]: training loss : 0.8572729837894439 TRAIN  loss dict:  {'classification_loss': 0.8572729837894439}
2025-01-13 17:28:12,874 [INFO] Step[3750/4329]: training loss : 0.8565240490436554 TRAIN  loss dict:  {'classification_loss': 0.8565240490436554}
2025-01-13 17:28:27,921 [INFO] Step[3800/4329]: training loss : 0.8569644260406494 TRAIN  loss dict:  {'classification_loss': 0.8569644260406494}
2025-01-13 17:28:43,150 [INFO] Step[3850/4329]: training loss : 0.8568389391899109 TRAIN  loss dict:  {'classification_loss': 0.8568389391899109}
2025-01-13 17:28:58,412 [INFO] Step[3900/4329]: training loss : 0.8573444783687592 TRAIN  loss dict:  {'classification_loss': 0.8573444783687592}
2025-01-13 17:29:13,597 [INFO] Step[3950/4329]: training loss : 0.8560357391834259 TRAIN  loss dict:  {'classification_loss': 0.8560357391834259}
2025-01-13 17:29:28,546 [INFO] Step[4000/4329]: training loss : 0.8583178520202637 TRAIN  loss dict:  {'classification_loss': 0.8583178520202637}
2025-01-13 17:29:43,510 [INFO] Step[4050/4329]: training loss : 0.8645283985137939 TRAIN  loss dict:  {'classification_loss': 0.8645283985137939}
2025-01-13 17:29:57,043 [INFO] Step[4100/4329]: training loss : 0.8564768850803375 TRAIN  loss dict:  {'classification_loss': 0.8564768850803375}
2025-01-13 17:30:11,353 [INFO] Step[4150/4329]: training loss : 0.8563565802574158 TRAIN  loss dict:  {'classification_loss': 0.8563565802574158}
2025-01-13 17:30:26,304 [INFO] Step[4200/4329]: training loss : 0.8601250243186951 TRAIN  loss dict:  {'classification_loss': 0.8601250243186951}
2025-01-13 17:30:41,212 [INFO] Step[4250/4329]: training loss : 0.8606775522232055 TRAIN  loss dict:  {'classification_loss': 0.8606775522232055}
2025-01-13 17:30:55,930 [INFO] Step[4300/4329]: training loss : 0.8557733356952667 TRAIN  loss dict:  {'classification_loss': 0.8557733356952667}
2025-01-13 17:32:47,350 [INFO] Label accuracies statistics:
2025-01-13 17:32:47,351 [INFO] {0: 0.5555555555555556, 1: 0.8888888888888888, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.75, 6: 0.5833333333333334, 7: 0.6666666666666666, 8: 0.5833333333333334, 9: 0.9166666666666666, 10: 1.0, 11: 0.8333333333333334, 12: 0.5, 13: 0.5, 14: 0.75, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.6666666666666666, 18: 0.5833333333333334, 19: 0.5833333333333334, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.8333333333333334, 26: 0.9166666666666666, 27: 0.5833333333333334, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.75, 32: 0.75, 33: 0.9166666666666666, 34: 1.0, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.9166666666666666, 41: 0.5, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.6666666666666666, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.3333333333333333, 55: 0.6666666666666666, 56: 0.8333333333333334, 57: 0.75, 58: 0.5833333333333334, 59: 0.6666666666666666, 60: 0.8333333333333334, 61: 0.9166666666666666, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 0.9166666666666666, 68: 0.6666666666666666, 69: 0.6666666666666666, 70: 0.5833333333333334, 71: 0.4166666666666667, 72: 0.8333333333333334, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 1.0, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5833333333333334, 84: 0.4166666666666667, 85: 0.8333333333333334, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.75, 89: 0.5, 90: 0.8333333333333334, 91: 0.9166666666666666, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 0.9166666666666666, 96: 0.5833333333333334, 97: 0.6666666666666666, 98: 0.75, 99: 1.0, 100: 0.75, 101: 1.0, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.6666666666666666, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.8333333333333334, 111: 0.9166666666666666, 112: 0.9166666666666666, 113: 0.5833333333333334, 114: 0.4166666666666667, 115: 0.9166666666666666, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.9166666666666666, 120: 0.8333333333333334, 121: 1.0, 122: 0.8333333333333334, 123: 1.0, 124: 0.8333333333333334, 125: 0.8333333333333334, 126: 0.8333333333333334, 127: 0.8333333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.6666666666666666, 131: 0.9166666666666666, 132: 0.6666666666666666, 133: 1.0, 134: 0.8333333333333334, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.6666666666666666, 143: 1.0, 144: 0.6666666666666666, 145: 1.0, 146: 1.0, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.4166666666666667, 151: 0.9166666666666666, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.9166666666666666, 156: 0.75, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.3333333333333333, 161: 0.9166666666666666, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.6666666666666666, 166: 0.75, 167: 0.6666666666666666, 168: 0.9166666666666666, 169: 0.9166666666666666, 170: 0.9166666666666666, 171: 0.5833333333333334, 172: 1.0, 173: 0.75, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.5, 183: 1.0, 184: 0.5833333333333334, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.6666666666666666, 189: 0.9166666666666666, 190: 0.6666666666666666, 191: 0.75, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.8333333333333334, 198: 0.6666666666666666}

2025-01-13 17:32:47,353 [INFO] [81] TRAIN  loss: 0.85842629981443 acc: 0.999537963961189
2025-01-13 17:32:47,353 [INFO] [81] TRAIN  loss dict: {'classification_loss': 0.85842629981443}
2025-01-13 17:32:47,353 [INFO] [81] VALIDATION loss: 1.631346418701037 VALIDATION acc: 0.8080808080808081
2025-01-13 17:32:47,353 [INFO] [81] VALIDATION loss dict: {'classification_loss': 1.631346418701037}
2025-01-13 17:32:47,353 [INFO] 
2025-01-13 17:33:06,989 [INFO] Step[50/4329]: training loss : 0.8560759425163269 TRAIN  loss dict:  {'classification_loss': 0.8560759425163269}
2025-01-13 17:33:22,016 [INFO] Step[100/4329]: training loss : 0.8579026758670807 TRAIN  loss dict:  {'classification_loss': 0.8579026758670807}
2025-01-13 17:33:37,243 [INFO] Step[150/4329]: training loss : 0.8564925885200501 TRAIN  loss dict:  {'classification_loss': 0.8564925885200501}
2025-01-13 17:33:52,317 [INFO] Step[200/4329]: training loss : 0.8558632016181946 TRAIN  loss dict:  {'classification_loss': 0.8558632016181946}
2025-01-13 17:34:07,120 [INFO] Step[250/4329]: training loss : 0.8607225644588471 TRAIN  loss dict:  {'classification_loss': 0.8607225644588471}
2025-01-13 17:34:22,319 [INFO] Step[300/4329]: training loss : 0.8567416775226593 TRAIN  loss dict:  {'classification_loss': 0.8567416775226593}
2025-01-13 17:34:37,251 [INFO] Step[350/4329]: training loss : 0.8582163941860199 TRAIN  loss dict:  {'classification_loss': 0.8582163941860199}
2025-01-13 17:34:52,261 [INFO] Step[400/4329]: training loss : 0.8616078782081604 TRAIN  loss dict:  {'classification_loss': 0.8616078782081604}
2025-01-13 17:35:07,490 [INFO] Step[450/4329]: training loss : 0.8572538530826569 TRAIN  loss dict:  {'classification_loss': 0.8572538530826569}
2025-01-13 17:35:22,589 [INFO] Step[500/4329]: training loss : 0.8609079813957214 TRAIN  loss dict:  {'classification_loss': 0.8609079813957214}
2025-01-13 17:35:37,427 [INFO] Step[550/4329]: training loss : 0.8559084033966065 TRAIN  loss dict:  {'classification_loss': 0.8559084033966065}
2025-01-13 17:35:52,681 [INFO] Step[600/4329]: training loss : 0.8645891058444977 TRAIN  loss dict:  {'classification_loss': 0.8645891058444977}
2025-01-13 17:36:07,845 [INFO] Step[650/4329]: training loss : 0.871028950214386 TRAIN  loss dict:  {'classification_loss': 0.871028950214386}
2025-01-13 17:36:22,722 [INFO] Step[700/4329]: training loss : 0.8594563138484955 TRAIN  loss dict:  {'classification_loss': 0.8594563138484955}
2025-01-13 17:36:37,645 [INFO] Step[750/4329]: training loss : 0.8557788705825806 TRAIN  loss dict:  {'classification_loss': 0.8557788705825806}
2025-01-13 17:36:52,360 [INFO] Step[800/4329]: training loss : 0.8573429977893829 TRAIN  loss dict:  {'classification_loss': 0.8573429977893829}
2025-01-13 17:37:07,340 [INFO] Step[850/4329]: training loss : 0.8563507616519928 TRAIN  loss dict:  {'classification_loss': 0.8563507616519928}
2025-01-13 17:37:22,095 [INFO] Step[900/4329]: training loss : 0.8582610273361206 TRAIN  loss dict:  {'classification_loss': 0.8582610273361206}
2025-01-13 17:37:36,993 [INFO] Step[950/4329]: training loss : 0.8568054699897766 TRAIN  loss dict:  {'classification_loss': 0.8568054699897766}
2025-01-13 17:37:52,171 [INFO] Step[1000/4329]: training loss : 0.8626980090141296 TRAIN  loss dict:  {'classification_loss': 0.8626980090141296}
2025-01-13 17:38:07,192 [INFO] Step[1050/4329]: training loss : 0.8555703043937684 TRAIN  loss dict:  {'classification_loss': 0.8555703043937684}
2025-01-13 17:38:22,119 [INFO] Step[1100/4329]: training loss : 0.8658536636829376 TRAIN  loss dict:  {'classification_loss': 0.8658536636829376}
2025-01-13 17:38:37,060 [INFO] Step[1150/4329]: training loss : 0.8565634858608245 TRAIN  loss dict:  {'classification_loss': 0.8565634858608245}
2025-01-13 17:38:52,088 [INFO] Step[1200/4329]: training loss : 0.857154107093811 TRAIN  loss dict:  {'classification_loss': 0.857154107093811}
2025-01-13 17:39:06,984 [INFO] Step[1250/4329]: training loss : 0.8606720614433289 TRAIN  loss dict:  {'classification_loss': 0.8606720614433289}
2025-01-13 17:39:21,956 [INFO] Step[1300/4329]: training loss : 0.8573424541950225 TRAIN  loss dict:  {'classification_loss': 0.8573424541950225}
2025-01-13 17:39:37,248 [INFO] Step[1350/4329]: training loss : 0.8559946417808533 TRAIN  loss dict:  {'classification_loss': 0.8559946417808533}
2025-01-13 17:39:52,325 [INFO] Step[1400/4329]: training loss : 0.8692488825321197 TRAIN  loss dict:  {'classification_loss': 0.8692488825321197}
2025-01-13 17:40:07,548 [INFO] Step[1450/4329]: training loss : 0.8573336315155029 TRAIN  loss dict:  {'classification_loss': 0.8573336315155029}
2025-01-13 17:40:22,508 [INFO] Step[1500/4329]: training loss : 0.8568624281883239 TRAIN  loss dict:  {'classification_loss': 0.8568624281883239}
2025-01-13 17:40:37,424 [INFO] Step[1550/4329]: training loss : 0.8561349749565125 TRAIN  loss dict:  {'classification_loss': 0.8561349749565125}
2025-01-13 17:40:52,591 [INFO] Step[1600/4329]: training loss : 0.8561036145687103 TRAIN  loss dict:  {'classification_loss': 0.8561036145687103}
2025-01-13 17:41:07,704 [INFO] Step[1650/4329]: training loss : 0.8581188201904297 TRAIN  loss dict:  {'classification_loss': 0.8581188201904297}
2025-01-13 17:41:22,725 [INFO] Step[1700/4329]: training loss : 0.8576635229587555 TRAIN  loss dict:  {'classification_loss': 0.8576635229587555}
2025-01-13 17:41:37,685 [INFO] Step[1750/4329]: training loss : 0.8599974393844605 TRAIN  loss dict:  {'classification_loss': 0.8599974393844605}
2025-01-13 17:41:52,717 [INFO] Step[1800/4329]: training loss : 0.8559561860561371 TRAIN  loss dict:  {'classification_loss': 0.8559561860561371}
2025-01-13 17:42:07,691 [INFO] Step[1850/4329]: training loss : 0.8600880742073059 TRAIN  loss dict:  {'classification_loss': 0.8600880742073059}
2025-01-13 17:42:22,763 [INFO] Step[1900/4329]: training loss : 0.8555831289291382 TRAIN  loss dict:  {'classification_loss': 0.8555831289291382}
2025-01-13 17:42:37,764 [INFO] Step[1950/4329]: training loss : 0.8563261747360229 TRAIN  loss dict:  {'classification_loss': 0.8563261747360229}
2025-01-13 17:42:52,736 [INFO] Step[2000/4329]: training loss : 0.8574053180217743 TRAIN  loss dict:  {'classification_loss': 0.8574053180217743}
2025-01-13 17:43:07,926 [INFO] Step[2050/4329]: training loss : 0.8575874388217926 TRAIN  loss dict:  {'classification_loss': 0.8575874388217926}
2025-01-13 17:43:22,726 [INFO] Step[2100/4329]: training loss : 0.8566913735866547 TRAIN  loss dict:  {'classification_loss': 0.8566913735866547}
2025-01-13 17:43:37,678 [INFO] Step[2150/4329]: training loss : 0.857534955739975 TRAIN  loss dict:  {'classification_loss': 0.857534955739975}
2025-01-13 17:43:52,904 [INFO] Step[2200/4329]: training loss : 0.8573081254959106 TRAIN  loss dict:  {'classification_loss': 0.8573081254959106}
2025-01-13 17:44:08,145 [INFO] Step[2250/4329]: training loss : 0.8567694211006165 TRAIN  loss dict:  {'classification_loss': 0.8567694211006165}
2025-01-13 17:44:23,060 [INFO] Step[2300/4329]: training loss : 0.8563972365856171 TRAIN  loss dict:  {'classification_loss': 0.8563972365856171}
2025-01-13 17:44:38,004 [INFO] Step[2350/4329]: training loss : 0.8578509843349457 TRAIN  loss dict:  {'classification_loss': 0.8578509843349457}
2025-01-13 17:44:52,856 [INFO] Step[2400/4329]: training loss : 0.8556290566921234 TRAIN  loss dict:  {'classification_loss': 0.8556290566921234}
2025-01-13 17:45:07,764 [INFO] Step[2450/4329]: training loss : 0.8565858435630799 TRAIN  loss dict:  {'classification_loss': 0.8565858435630799}
2025-01-13 17:45:22,616 [INFO] Step[2500/4329]: training loss : 0.8573348999023438 TRAIN  loss dict:  {'classification_loss': 0.8573348999023438}
2025-01-13 17:45:37,609 [INFO] Step[2550/4329]: training loss : 0.8599489533901215 TRAIN  loss dict:  {'classification_loss': 0.8599489533901215}
2025-01-13 17:45:52,724 [INFO] Step[2600/4329]: training loss : 0.8579704523086548 TRAIN  loss dict:  {'classification_loss': 0.8579704523086548}
2025-01-13 17:46:07,808 [INFO] Step[2650/4329]: training loss : 0.8561787140369416 TRAIN  loss dict:  {'classification_loss': 0.8561787140369416}
2025-01-13 17:46:22,843 [INFO] Step[2700/4329]: training loss : 0.8561402595043183 TRAIN  loss dict:  {'classification_loss': 0.8561402595043183}
2025-01-13 17:46:37,782 [INFO] Step[2750/4329]: training loss : 0.8570980548858642 TRAIN  loss dict:  {'classification_loss': 0.8570980548858642}
2025-01-13 17:46:52,684 [INFO] Step[2800/4329]: training loss : 0.8630433845520019 TRAIN  loss dict:  {'classification_loss': 0.8630433845520019}
2025-01-13 17:47:07,384 [INFO] Step[2850/4329]: training loss : 0.8571339011192322 TRAIN  loss dict:  {'classification_loss': 0.8571339011192322}
2025-01-13 17:47:22,110 [INFO] Step[2900/4329]: training loss : 0.8663626945018769 TRAIN  loss dict:  {'classification_loss': 0.8663626945018769}
2025-01-13 17:47:37,028 [INFO] Step[2950/4329]: training loss : 0.8558481812477112 TRAIN  loss dict:  {'classification_loss': 0.8558481812477112}
2025-01-13 17:47:52,297 [INFO] Step[3000/4329]: training loss : 0.8749228239059448 TRAIN  loss dict:  {'classification_loss': 0.8749228239059448}
2025-01-13 17:48:07,502 [INFO] Step[3050/4329]: training loss : 0.8565795314311981 TRAIN  loss dict:  {'classification_loss': 0.8565795314311981}
2025-01-13 17:48:22,235 [INFO] Step[3100/4329]: training loss : 0.8584785687923432 TRAIN  loss dict:  {'classification_loss': 0.8584785687923432}
2025-01-13 17:48:37,256 [INFO] Step[3150/4329]: training loss : 0.8611581468582153 TRAIN  loss dict:  {'classification_loss': 0.8611581468582153}
2025-01-13 17:48:52,281 [INFO] Step[3200/4329]: training loss : 0.8573855745792389 TRAIN  loss dict:  {'classification_loss': 0.8573855745792389}
2025-01-13 17:49:07,292 [INFO] Step[3250/4329]: training loss : 0.8564501452445984 TRAIN  loss dict:  {'classification_loss': 0.8564501452445984}
2025-01-13 17:49:22,043 [INFO] Step[3300/4329]: training loss : 0.8675463688373566 TRAIN  loss dict:  {'classification_loss': 0.8675463688373566}
2025-01-13 17:49:36,951 [INFO] Step[3350/4329]: training loss : 0.8591466987133026 TRAIN  loss dict:  {'classification_loss': 0.8591466987133026}
2025-01-13 17:49:52,129 [INFO] Step[3400/4329]: training loss : 0.8551909852027894 TRAIN  loss dict:  {'classification_loss': 0.8551909852027894}
2025-01-13 17:50:07,367 [INFO] Step[3450/4329]: training loss : 0.8571732604503631 TRAIN  loss dict:  {'classification_loss': 0.8571732604503631}
2025-01-13 17:50:22,591 [INFO] Step[3500/4329]: training loss : 0.8566413509845734 TRAIN  loss dict:  {'classification_loss': 0.8566413509845734}
2025-01-13 17:50:37,690 [INFO] Step[3550/4329]: training loss : 0.8562473344802857 TRAIN  loss dict:  {'classification_loss': 0.8562473344802857}
2025-01-13 17:50:52,847 [INFO] Step[3600/4329]: training loss : 0.8579527127742768 TRAIN  loss dict:  {'classification_loss': 0.8579527127742768}
2025-01-13 17:51:07,862 [INFO] Step[3650/4329]: training loss : 0.8562658548355102 TRAIN  loss dict:  {'classification_loss': 0.8562658548355102}
2025-01-13 17:51:23,084 [INFO] Step[3700/4329]: training loss : 0.8590615141391754 TRAIN  loss dict:  {'classification_loss': 0.8590615141391754}
2025-01-13 17:51:38,304 [INFO] Step[3750/4329]: training loss : 0.8562526559829712 TRAIN  loss dict:  {'classification_loss': 0.8562526559829712}
2025-01-13 17:51:53,082 [INFO] Step[3800/4329]: training loss : 0.8561160910129547 TRAIN  loss dict:  {'classification_loss': 0.8561160910129547}
2025-01-13 17:52:08,310 [INFO] Step[3850/4329]: training loss : 0.8558730435371399 TRAIN  loss dict:  {'classification_loss': 0.8558730435371399}
2025-01-13 17:52:23,516 [INFO] Step[3900/4329]: training loss : 0.8570625865459442 TRAIN  loss dict:  {'classification_loss': 0.8570625865459442}
2025-01-13 17:52:38,586 [INFO] Step[3950/4329]: training loss : 0.8675075399875641 TRAIN  loss dict:  {'classification_loss': 0.8675075399875641}
2025-01-13 17:52:53,270 [INFO] Step[4000/4329]: training loss : 0.8581925415992737 TRAIN  loss dict:  {'classification_loss': 0.8581925415992737}
2025-01-13 17:53:07,964 [INFO] Step[4050/4329]: training loss : 0.8563188898563385 TRAIN  loss dict:  {'classification_loss': 0.8563188898563385}
2025-01-13 17:53:22,950 [INFO] Step[4100/4329]: training loss : 0.8593996214866638 TRAIN  loss dict:  {'classification_loss': 0.8593996214866638}
2025-01-13 17:53:38,203 [INFO] Step[4150/4329]: training loss : 0.8572079730033875 TRAIN  loss dict:  {'classification_loss': 0.8572079730033875}
2025-01-13 17:53:52,994 [INFO] Step[4200/4329]: training loss : 0.8565894651412964 TRAIN  loss dict:  {'classification_loss': 0.8565894651412964}
2025-01-13 17:54:07,887 [INFO] Step[4250/4329]: training loss : 0.8586780202388763 TRAIN  loss dict:  {'classification_loss': 0.8586780202388763}
2025-01-13 17:54:22,680 [INFO] Step[4300/4329]: training loss : 0.8570807480812073 TRAIN  loss dict:  {'classification_loss': 0.8570807480812073}
2025-01-13 17:56:33,258 [INFO] Label accuracies statistics:
2025-01-13 17:56:33,258 [INFO] {0: 0.5555555555555556, 1: 1.0, 2: 0.6666666666666666, 3: 0.8333333333333334, 4: 0.4166666666666667, 5: 0.75, 6: 0.5, 7: 0.5833333333333334, 8: 0.6666666666666666, 9: 0.9166666666666666, 10: 1.0, 11: 0.9166666666666666, 12: 0.5, 13: 0.5, 14: 0.75, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.6666666666666666, 18: 0.5, 19: 0.6666666666666666, 20: 0.6666666666666666, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.8333333333333334, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.75, 31: 0.8333333333333334, 32: 0.6666666666666666, 33: 0.9166666666666666, 34: 0.9166666666666666, 35: 1.0, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.8333333333333334, 41: 0.5833333333333334, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.5, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.8333333333333334, 52: 1.0, 53: 0.6666666666666666, 54: 0.5, 55: 0.6666666666666666, 56: 0.8333333333333334, 57: 0.75, 58: 0.5833333333333334, 59: 0.8333333333333334, 60: 0.6666666666666666, 61: 1.0, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.6666666666666666, 69: 0.6666666666666666, 70: 0.5833333333333334, 71: 0.4166666666666667, 72: 0.9166666666666666, 73: 0.9166666666666666, 74: 0.6666666666666666, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 0.9166666666666666, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.8333333333333334, 83: 0.5833333333333334, 84: 0.5, 85: 0.75, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.5, 89: 0.5833333333333334, 90: 0.75, 91: 1.0, 92: 0.9166666666666666, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.5833333333333334, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.9166666666666666, 101: 1.0, 102: 0.9166666666666666, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.8333333333333334, 111: 0.9166666666666666, 112: 0.8333333333333334, 113: 0.75, 114: 0.4166666666666667, 115: 1.0, 116: 0.8333333333333334, 117: 0.75, 118: 0.9166666666666666, 119: 0.9166666666666666, 120: 0.75, 121: 0.9166666666666666, 122: 0.8333333333333334, 123: 1.0, 124: 0.9166666666666666, 125: 0.9166666666666666, 126: 0.8333333333333334, 127: 0.8333333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.9166666666666666, 132: 0.75, 133: 1.0, 134: 0.8333333333333334, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 0.6666666666666666, 143: 1.0, 144: 0.5833333333333334, 145: 1.0, 146: 1.0, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.5, 151: 0.8333333333333334, 152: 0.9166666666666666, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.8333333333333334, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.4166666666666667, 161: 0.9166666666666666, 162: 1.0, 163: 0.9166666666666666, 164: 0.8333333333333334, 165: 0.6666666666666666, 166: 0.75, 167: 0.75, 168: 0.9166666666666666, 169: 1.0, 170: 0.9166666666666666, 171: 0.5833333333333334, 172: 1.0, 173: 0.75, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.1111111111111111, 180: 0.8333333333333334, 181: 0.75, 182: 0.6666666666666666, 183: 1.0, 184: 0.8333333333333334, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.8333333333333334, 190: 0.6666666666666666, 191: 0.5833333333333334, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.8333333333333334, 196: 0.8333333333333334, 197: 0.8333333333333334, 198: 0.6666666666666666}

2025-01-13 17:56:33,261 [INFO] [82] TRAIN  loss: 0.8584959230100235 acc: 0.999229939935315
2025-01-13 17:56:33,261 [INFO] [82] TRAIN  loss dict: {'classification_loss': 0.8584959230100235}
2025-01-13 17:56:33,261 [INFO] [82] VALIDATION loss: 1.595915644081554 VALIDATION acc: 0.8152356902356902
2025-01-13 17:56:33,261 [INFO] [82] VALIDATION loss dict: {'classification_loss': 1.595915644081554}
2025-01-13 17:56:33,261 [INFO] 
2025-01-13 17:56:53,192 [INFO] Step[50/4329]: training loss : 0.8588084089756012 TRAIN  loss dict:  {'classification_loss': 0.8588084089756012}
2025-01-13 17:57:08,132 [INFO] Step[100/4329]: training loss : 0.85504070520401 TRAIN  loss dict:  {'classification_loss': 0.85504070520401}
2025-01-13 17:57:23,085 [INFO] Step[150/4329]: training loss : 0.8560562229156494 TRAIN  loss dict:  {'classification_loss': 0.8560562229156494}
2025-01-13 17:57:38,067 [INFO] Step[200/4329]: training loss : 0.8571541833877564 TRAIN  loss dict:  {'classification_loss': 0.8571541833877564}
2025-01-13 17:57:52,992 [INFO] Step[250/4329]: training loss : 0.8571738278865815 TRAIN  loss dict:  {'classification_loss': 0.8571738278865815}
2025-01-13 17:58:08,032 [INFO] Step[300/4329]: training loss : 0.8562767386436463 TRAIN  loss dict:  {'classification_loss': 0.8562767386436463}
2025-01-13 17:58:22,908 [INFO] Step[350/4329]: training loss : 0.8585630190372467 TRAIN  loss dict:  {'classification_loss': 0.8585630190372467}
2025-01-13 17:58:37,852 [INFO] Step[400/4329]: training loss : 0.8595656335353852 TRAIN  loss dict:  {'classification_loss': 0.8595656335353852}
2025-01-13 17:58:52,887 [INFO] Step[450/4329]: training loss : 0.8562021255493164 TRAIN  loss dict:  {'classification_loss': 0.8562021255493164}
2025-01-13 17:59:07,787 [INFO] Step[500/4329]: training loss : 0.8564320182800294 TRAIN  loss dict:  {'classification_loss': 0.8564320182800294}
2025-01-13 17:59:22,786 [INFO] Step[550/4329]: training loss : 0.8574098384380341 TRAIN  loss dict:  {'classification_loss': 0.8574098384380341}
2025-01-13 17:59:37,879 [INFO] Step[600/4329]: training loss : 0.8586527478694915 TRAIN  loss dict:  {'classification_loss': 0.8586527478694915}
2025-01-13 17:59:52,746 [INFO] Step[650/4329]: training loss : 0.8562506198883056 TRAIN  loss dict:  {'classification_loss': 0.8562506198883056}
2025-01-13 18:00:07,780 [INFO] Step[700/4329]: training loss : 0.856152799129486 TRAIN  loss dict:  {'classification_loss': 0.856152799129486}
2025-01-13 18:00:22,510 [INFO] Step[750/4329]: training loss : 0.858167189359665 TRAIN  loss dict:  {'classification_loss': 0.858167189359665}
2025-01-13 18:00:37,241 [INFO] Step[800/4329]: training loss : 0.8565512645244598 TRAIN  loss dict:  {'classification_loss': 0.8565512645244598}
2025-01-13 18:00:52,340 [INFO] Step[850/4329]: training loss : 0.8563612616062164 TRAIN  loss dict:  {'classification_loss': 0.8563612616062164}
2025-01-13 18:01:07,305 [INFO] Step[900/4329]: training loss : 0.8564637231826783 TRAIN  loss dict:  {'classification_loss': 0.8564637231826783}
2025-01-13 18:01:22,306 [INFO] Step[950/4329]: training loss : 0.8573184728622436 TRAIN  loss dict:  {'classification_loss': 0.8573184728622436}
2025-01-13 18:01:37,062 [INFO] Step[1000/4329]: training loss : 0.856811273097992 TRAIN  loss dict:  {'classification_loss': 0.856811273097992}
2025-01-13 18:01:52,321 [INFO] Step[1050/4329]: training loss : 0.8561657917499542 TRAIN  loss dict:  {'classification_loss': 0.8561657917499542}
2025-01-13 18:02:07,310 [INFO] Step[1100/4329]: training loss : 0.8570477843284607 TRAIN  loss dict:  {'classification_loss': 0.8570477843284607}
2025-01-13 18:02:22,250 [INFO] Step[1150/4329]: training loss : 0.8577537453174591 TRAIN  loss dict:  {'classification_loss': 0.8577537453174591}
2025-01-13 18:02:37,214 [INFO] Step[1200/4329]: training loss : 0.8570776546001434 TRAIN  loss dict:  {'classification_loss': 0.8570776546001434}
2025-01-13 18:02:52,189 [INFO] Step[1250/4329]: training loss : 0.8566937005519867 TRAIN  loss dict:  {'classification_loss': 0.8566937005519867}
2025-01-13 18:03:07,111 [INFO] Step[1300/4329]: training loss : 0.8562979412078857 TRAIN  loss dict:  {'classification_loss': 0.8562979412078857}
2025-01-13 18:03:22,312 [INFO] Step[1350/4329]: training loss : 0.8580216491222381 TRAIN  loss dict:  {'classification_loss': 0.8580216491222381}
2025-01-13 18:03:37,317 [INFO] Step[1400/4329]: training loss : 0.8560335624217987 TRAIN  loss dict:  {'classification_loss': 0.8560335624217987}
2025-01-13 18:03:52,218 [INFO] Step[1450/4329]: training loss : 0.8580610036849976 TRAIN  loss dict:  {'classification_loss': 0.8580610036849976}
2025-01-13 18:04:07,010 [INFO] Step[1500/4329]: training loss : 0.8554897606372833 TRAIN  loss dict:  {'classification_loss': 0.8554897606372833}
2025-01-13 18:04:22,040 [INFO] Step[1550/4329]: training loss : 0.8568591606616974 TRAIN  loss dict:  {'classification_loss': 0.8568591606616974}
2025-01-13 18:04:37,052 [INFO] Step[1600/4329]: training loss : 0.8569307363033295 TRAIN  loss dict:  {'classification_loss': 0.8569307363033295}
2025-01-13 18:04:51,998 [INFO] Step[1650/4329]: training loss : 0.8557767236232757 TRAIN  loss dict:  {'classification_loss': 0.8557767236232757}
2025-01-13 18:05:06,852 [INFO] Step[1700/4329]: training loss : 0.8569239604473115 TRAIN  loss dict:  {'classification_loss': 0.8569239604473115}
2025-01-13 18:05:21,862 [INFO] Step[1750/4329]: training loss : 0.8564710986614227 TRAIN  loss dict:  {'classification_loss': 0.8564710986614227}
2025-01-13 18:05:36,834 [INFO] Step[1800/4329]: training loss : 0.8573324000835418 TRAIN  loss dict:  {'classification_loss': 0.8573324000835418}
2025-01-13 18:05:52,016 [INFO] Step[1850/4329]: training loss : 0.8563322651386261 TRAIN  loss dict:  {'classification_loss': 0.8563322651386261}
2025-01-13 18:06:07,007 [INFO] Step[1900/4329]: training loss : 0.8563597226142883 TRAIN  loss dict:  {'classification_loss': 0.8563597226142883}
2025-01-13 18:06:22,104 [INFO] Step[1950/4329]: training loss : 0.8569968926906586 TRAIN  loss dict:  {'classification_loss': 0.8569968926906586}
2025-01-13 18:06:37,263 [INFO] Step[2000/4329]: training loss : 0.8576865470409394 TRAIN  loss dict:  {'classification_loss': 0.8576865470409394}
2025-01-13 18:06:52,480 [INFO] Step[2050/4329]: training loss : 0.8556334090232849 TRAIN  loss dict:  {'classification_loss': 0.8556334090232849}
2025-01-13 18:07:07,533 [INFO] Step[2100/4329]: training loss : 0.857611323595047 TRAIN  loss dict:  {'classification_loss': 0.857611323595047}
2025-01-13 18:07:22,416 [INFO] Step[2150/4329]: training loss : 0.8556910645961762 TRAIN  loss dict:  {'classification_loss': 0.8556910645961762}
2025-01-13 18:07:37,315 [INFO] Step[2200/4329]: training loss : 0.8562386667728424 TRAIN  loss dict:  {'classification_loss': 0.8562386667728424}
2025-01-13 18:07:52,537 [INFO] Step[2250/4329]: training loss : 0.8599271535873413 TRAIN  loss dict:  {'classification_loss': 0.8599271535873413}
2025-01-13 18:08:07,422 [INFO] Step[2300/4329]: training loss : 0.8582760095596313 TRAIN  loss dict:  {'classification_loss': 0.8582760095596313}
2025-01-13 18:08:22,396 [INFO] Step[2350/4329]: training loss : 0.8575527381896972 TRAIN  loss dict:  {'classification_loss': 0.8575527381896972}
2025-01-13 18:08:37,299 [INFO] Step[2400/4329]: training loss : 0.8574735045433044 TRAIN  loss dict:  {'classification_loss': 0.8574735045433044}
2025-01-13 18:08:52,429 [INFO] Step[2450/4329]: training loss : 0.8614887487888336 TRAIN  loss dict:  {'classification_loss': 0.8614887487888336}
2025-01-13 18:09:07,168 [INFO] Step[2500/4329]: training loss : 0.855828206539154 TRAIN  loss dict:  {'classification_loss': 0.855828206539154}
2025-01-13 18:09:22,328 [INFO] Step[2550/4329]: training loss : 0.8609359312057495 TRAIN  loss dict:  {'classification_loss': 0.8609359312057495}
2025-01-13 18:09:37,361 [INFO] Step[2600/4329]: training loss : 0.8567050278186799 TRAIN  loss dict:  {'classification_loss': 0.8567050278186799}
2025-01-13 18:09:52,472 [INFO] Step[2650/4329]: training loss : 0.8563126349449157 TRAIN  loss dict:  {'classification_loss': 0.8563126349449157}
2025-01-13 18:10:07,674 [INFO] Step[2700/4329]: training loss : 0.8559896123409271 TRAIN  loss dict:  {'classification_loss': 0.8559896123409271}
2025-01-13 18:10:22,917 [INFO] Step[2750/4329]: training loss : 0.8593577694892883 TRAIN  loss dict:  {'classification_loss': 0.8593577694892883}
2025-01-13 18:10:37,660 [INFO] Step[2800/4329]: training loss : 0.855506683588028 TRAIN  loss dict:  {'classification_loss': 0.855506683588028}
2025-01-13 18:10:52,694 [INFO] Step[2850/4329]: training loss : 0.8563804268836975 TRAIN  loss dict:  {'classification_loss': 0.8563804268836975}
2025-01-13 18:11:07,843 [INFO] Step[2900/4329]: training loss : 0.8572744905948639 TRAIN  loss dict:  {'classification_loss': 0.8572744905948639}
2025-01-13 18:11:22,802 [INFO] Step[2950/4329]: training loss : 0.8564761507511139 TRAIN  loss dict:  {'classification_loss': 0.8564761507511139}
2025-01-13 18:11:37,890 [INFO] Step[3000/4329]: training loss : 0.8557052779197692 TRAIN  loss dict:  {'classification_loss': 0.8557052779197692}
2025-01-13 18:11:52,870 [INFO] Step[3050/4329]: training loss : 0.8566934442520142 TRAIN  loss dict:  {'classification_loss': 0.8566934442520142}
2025-01-13 18:12:07,845 [INFO] Step[3100/4329]: training loss : 0.8559704434871673 TRAIN  loss dict:  {'classification_loss': 0.8559704434871673}
2025-01-13 18:12:22,727 [INFO] Step[3150/4329]: training loss : 0.8736455810070037 TRAIN  loss dict:  {'classification_loss': 0.8736455810070037}
2025-01-13 18:12:37,467 [INFO] Step[3200/4329]: training loss : 0.8559056270122528 TRAIN  loss dict:  {'classification_loss': 0.8559056270122528}
2025-01-13 18:12:52,443 [INFO] Step[3250/4329]: training loss : 0.8558672440052032 TRAIN  loss dict:  {'classification_loss': 0.8558672440052032}
2025-01-13 18:13:07,368 [INFO] Step[3300/4329]: training loss : 0.8590918886661529 TRAIN  loss dict:  {'classification_loss': 0.8590918886661529}
2025-01-13 18:13:22,433 [INFO] Step[3350/4329]: training loss : 0.8573329615592956 TRAIN  loss dict:  {'classification_loss': 0.8573329615592956}
2025-01-13 18:13:37,281 [INFO] Step[3400/4329]: training loss : 0.8573181188106537 TRAIN  loss dict:  {'classification_loss': 0.8573181188106537}
2025-01-13 18:13:52,502 [INFO] Step[3450/4329]: training loss : 0.8560960209369659 TRAIN  loss dict:  {'classification_loss': 0.8560960209369659}
2025-01-13 18:14:07,587 [INFO] Step[3500/4329]: training loss : 0.8710091209411621 TRAIN  loss dict:  {'classification_loss': 0.8710091209411621}
2025-01-13 18:14:22,747 [INFO] Step[3550/4329]: training loss : 0.8556396758556366 TRAIN  loss dict:  {'classification_loss': 0.8556396758556366}
2025-01-13 18:14:37,720 [INFO] Step[3600/4329]: training loss : 0.8556224513053894 TRAIN  loss dict:  {'classification_loss': 0.8556224513053894}
2025-01-13 18:14:52,745 [INFO] Step[3650/4329]: training loss : 0.8624275600910187 TRAIN  loss dict:  {'classification_loss': 0.8624275600910187}
2025-01-13 18:15:07,641 [INFO] Step[3700/4329]: training loss : 0.8572352123260498 TRAIN  loss dict:  {'classification_loss': 0.8572352123260498}
2025-01-13 18:15:22,654 [INFO] Step[3750/4329]: training loss : 0.8618818318843842 TRAIN  loss dict:  {'classification_loss': 0.8618818318843842}
2025-01-13 18:15:37,631 [INFO] Step[3800/4329]: training loss : 0.8560190939903259 TRAIN  loss dict:  {'classification_loss': 0.8560190939903259}
2025-01-13 18:15:52,606 [INFO] Step[3850/4329]: training loss : 0.8708900249004364 TRAIN  loss dict:  {'classification_loss': 0.8708900249004364}
2025-01-13 18:16:07,800 [INFO] Step[3900/4329]: training loss : 0.8562605142593384 TRAIN  loss dict:  {'classification_loss': 0.8562605142593384}
2025-01-13 18:16:22,936 [INFO] Step[3950/4329]: training loss : 0.8555995523929596 TRAIN  loss dict:  {'classification_loss': 0.8555995523929596}
2025-01-13 18:16:37,871 [INFO] Step[4000/4329]: training loss : 0.8567091405391694 TRAIN  loss dict:  {'classification_loss': 0.8567091405391694}
2025-01-13 18:16:52,580 [INFO] Step[4050/4329]: training loss : 0.8567764687538147 TRAIN  loss dict:  {'classification_loss': 0.8567764687538147}
2025-01-13 18:17:07,497 [INFO] Step[4100/4329]: training loss : 0.8567298877239228 TRAIN  loss dict:  {'classification_loss': 0.8567298877239228}
2025-01-13 18:17:22,472 [INFO] Step[4150/4329]: training loss : 0.8567432153224945 TRAIN  loss dict:  {'classification_loss': 0.8567432153224945}
2025-01-13 18:17:37,695 [INFO] Step[4200/4329]: training loss : 0.8559195983409882 TRAIN  loss dict:  {'classification_loss': 0.8559195983409882}
2025-01-13 18:17:52,851 [INFO] Step[4250/4329]: training loss : 0.8588489842414856 TRAIN  loss dict:  {'classification_loss': 0.8588489842414856}
2025-01-13 18:18:08,062 [INFO] Step[4300/4329]: training loss : 0.8583173501491547 TRAIN  loss dict:  {'classification_loss': 0.8583173501491547}
2025-01-13 18:19:59,373 [INFO] Label accuracies statistics:
2025-01-13 18:19:59,374 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5, 7: 0.5, 8: 0.5833333333333334, 9: 0.9166666666666666, 10: 1.0, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.5, 14: 0.75, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.5833333333333334, 18: 0.5833333333333334, 19: 0.5833333333333334, 20: 0.5, 21: 0.6666666666666666, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.6666666666666666, 26: 0.8333333333333334, 27: 0.6666666666666666, 28: 0.8333333333333334, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.9166666666666666, 34: 1.0, 35: 1.0, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.5833333333333334, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.5833333333333334, 45: 0.5833333333333334, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5833333333333334, 54: 0.4166666666666667, 55: 0.6666666666666666, 56: 0.75, 57: 0.75, 58: 0.5833333333333334, 59: 0.8333333333333334, 60: 0.75, 61: 0.9166666666666666, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.6666666666666666, 67: 1.0, 68: 0.8333333333333334, 69: 0.6666666666666666, 70: 0.3333333333333333, 71: 0.5, 72: 0.8333333333333334, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 1.0, 79: 0.6666666666666666, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.6666666666666666, 84: 0.5, 85: 0.75, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.6666666666666666, 89: 0.5, 90: 0.8333333333333334, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.6666666666666666, 95: 1.0, 96: 0.5833333333333334, 97: 0.75, 98: 0.75, 99: 0.9333333333333333, 100: 0.8333333333333334, 101: 1.0, 102: 1.0, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 0.9166666666666666, 111: 0.9166666666666666, 112: 0.8333333333333334, 113: 0.5, 114: 0.4166666666666667, 115: 1.0, 116: 0.8333333333333334, 117: 0.75, 118: 1.0, 119: 0.8333333333333334, 120: 0.75, 121: 0.9166666666666666, 122: 0.8333333333333334, 123: 1.0, 124: 1.0, 125: 0.8333333333333334, 126: 0.9166666666666666, 127: 0.5833333333333334, 128: 1.0, 129: 0.9166666666666666, 130: 0.9166666666666666, 131: 0.9166666666666666, 132: 0.3333333333333333, 133: 1.0, 134: 0.8333333333333334, 135: 1.0, 136: 1.0, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.5, 151: 0.9166666666666666, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.5, 161: 0.9166666666666666, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.6666666666666666, 166: 0.75, 167: 0.75, 168: 0.9166666666666666, 169: 0.9166666666666666, 170: 0.9166666666666666, 171: 0.5833333333333334, 172: 1.0, 173: 0.75, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.2222222222222222, 180: 1.0, 181: 0.8333333333333334, 182: 0.5833333333333334, 183: 0.9166666666666666, 184: 0.75, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.75, 189: 0.9166666666666666, 190: 0.5833333333333334, 191: 0.6666666666666666, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.9166666666666666, 198: 0.6666666666666666}

2025-01-13 18:19:59,376 [INFO] [83] TRAIN  loss: 0.8576064526167332 acc: 0.9997689819805945
2025-01-13 18:19:59,376 [INFO] [83] TRAIN  loss dict: {'classification_loss': 0.8576064526167332}
2025-01-13 18:19:59,376 [INFO] [83] VALIDATION loss: 1.6146052832705806 VALIDATION acc: 0.811026936026936
2025-01-13 18:19:59,376 [INFO] [83] VALIDATION loss dict: {'classification_loss': 1.6146052832705806}
2025-01-13 18:19:59,376 [INFO] 
2025-01-13 18:20:19,096 [INFO] Step[50/4329]: training loss : 0.8569472873210907 TRAIN  loss dict:  {'classification_loss': 0.8569472873210907}
2025-01-13 18:20:33,777 [INFO] Step[100/4329]: training loss : 0.8570063650608063 TRAIN  loss dict:  {'classification_loss': 0.8570063650608063}
2025-01-13 18:20:48,537 [INFO] Step[150/4329]: training loss : 0.8909232866764069 TRAIN  loss dict:  {'classification_loss': 0.8909232866764069}
2025-01-13 18:21:03,681 [INFO] Step[200/4329]: training loss : 0.8578670716285706 TRAIN  loss dict:  {'classification_loss': 0.8578670716285706}
2025-01-13 18:21:18,469 [INFO] Step[250/4329]: training loss : 0.8563412523269653 TRAIN  loss dict:  {'classification_loss': 0.8563412523269653}
2025-01-13 18:21:33,155 [INFO] Step[300/4329]: training loss : 0.8568523025512695 TRAIN  loss dict:  {'classification_loss': 0.8568523025512695}
2025-01-13 18:21:47,917 [INFO] Step[350/4329]: training loss : 0.8588615286350251 TRAIN  loss dict:  {'classification_loss': 0.8588615286350251}
2025-01-13 18:22:02,678 [INFO] Step[400/4329]: training loss : 0.8570798349380493 TRAIN  loss dict:  {'classification_loss': 0.8570798349380493}
2025-01-13 18:22:17,677 [INFO] Step[450/4329]: training loss : 0.8555662322044373 TRAIN  loss dict:  {'classification_loss': 0.8555662322044373}
2025-01-13 18:22:32,538 [INFO] Step[500/4329]: training loss : 0.8559664368629456 TRAIN  loss dict:  {'classification_loss': 0.8559664368629456}
2025-01-13 18:22:47,562 [INFO] Step[550/4329]: training loss : 0.8577287471294404 TRAIN  loss dict:  {'classification_loss': 0.8577287471294404}
2025-01-13 18:23:02,412 [INFO] Step[600/4329]: training loss : 0.8572471213340759 TRAIN  loss dict:  {'classification_loss': 0.8572471213340759}
2025-01-13 18:23:17,430 [INFO] Step[650/4329]: training loss : 0.8547124028205871 TRAIN  loss dict:  {'classification_loss': 0.8547124028205871}
2025-01-13 18:23:32,675 [INFO] Step[700/4329]: training loss : 0.8574696087837219 TRAIN  loss dict:  {'classification_loss': 0.8574696087837219}
2025-01-13 18:23:47,546 [INFO] Step[750/4329]: training loss : 0.8572891652584076 TRAIN  loss dict:  {'classification_loss': 0.8572891652584076}
2025-01-13 18:24:02,420 [INFO] Step[800/4329]: training loss : 0.857123738527298 TRAIN  loss dict:  {'classification_loss': 0.857123738527298}
2025-01-13 18:24:17,382 [INFO] Step[850/4329]: training loss : 0.8585648655891418 TRAIN  loss dict:  {'classification_loss': 0.8585648655891418}
2025-01-13 18:24:32,323 [INFO] Step[900/4329]: training loss : 0.855875209569931 TRAIN  loss dict:  {'classification_loss': 0.855875209569931}
2025-01-13 18:24:47,058 [INFO] Step[950/4329]: training loss : 0.85711865067482 TRAIN  loss dict:  {'classification_loss': 0.85711865067482}
2025-01-13 18:25:01,959 [INFO] Step[1000/4329]: training loss : 0.8564034450054169 TRAIN  loss dict:  {'classification_loss': 0.8564034450054169}
2025-01-13 18:25:17,220 [INFO] Step[1050/4329]: training loss : 0.8566788506507873 TRAIN  loss dict:  {'classification_loss': 0.8566788506507873}
2025-01-13 18:25:32,448 [INFO] Step[1100/4329]: training loss : 0.8555030262470246 TRAIN  loss dict:  {'classification_loss': 0.8555030262470246}
2025-01-13 18:25:47,711 [INFO] Step[1150/4329]: training loss : 0.8563020324707031 TRAIN  loss dict:  {'classification_loss': 0.8563020324707031}
2025-01-13 18:26:02,939 [INFO] Step[1200/4329]: training loss : 0.8561786830425262 TRAIN  loss dict:  {'classification_loss': 0.8561786830425262}
2025-01-13 18:26:18,153 [INFO] Step[1250/4329]: training loss : 0.8562990510463715 TRAIN  loss dict:  {'classification_loss': 0.8562990510463715}
2025-01-13 18:26:32,990 [INFO] Step[1300/4329]: training loss : 0.8562252414226532 TRAIN  loss dict:  {'classification_loss': 0.8562252414226532}
2025-01-13 18:26:47,974 [INFO] Step[1350/4329]: training loss : 0.8553960931301117 TRAIN  loss dict:  {'classification_loss': 0.8553960931301117}
2025-01-13 18:27:02,940 [INFO] Step[1400/4329]: training loss : 0.8584218108654023 TRAIN  loss dict:  {'classification_loss': 0.8584218108654023}
2025-01-13 18:27:17,911 [INFO] Step[1450/4329]: training loss : 0.8612033593654632 TRAIN  loss dict:  {'classification_loss': 0.8612033593654632}
2025-01-13 18:27:32,946 [INFO] Step[1500/4329]: training loss : 0.8569060516357422 TRAIN  loss dict:  {'classification_loss': 0.8569060516357422}
2025-01-13 18:27:48,161 [INFO] Step[1550/4329]: training loss : 0.8562935984134674 TRAIN  loss dict:  {'classification_loss': 0.8562935984134674}
2025-01-13 18:28:03,096 [INFO] Step[1600/4329]: training loss : 0.8580777478218079 TRAIN  loss dict:  {'classification_loss': 0.8580777478218079}
2025-01-13 18:28:18,134 [INFO] Step[1650/4329]: training loss : 0.8573364365100861 TRAIN  loss dict:  {'classification_loss': 0.8573364365100861}
2025-01-13 18:28:33,263 [INFO] Step[1700/4329]: training loss : 0.8555868375301361 TRAIN  loss dict:  {'classification_loss': 0.8555868375301361}
2025-01-13 18:28:48,133 [INFO] Step[1750/4329]: training loss : 0.8568958616256714 TRAIN  loss dict:  {'classification_loss': 0.8568958616256714}
2025-01-13 18:29:03,070 [INFO] Step[1800/4329]: training loss : 0.871117821931839 TRAIN  loss dict:  {'classification_loss': 0.871117821931839}
2025-01-13 18:29:17,898 [INFO] Step[1850/4329]: training loss : 0.8561999094486237 TRAIN  loss dict:  {'classification_loss': 0.8561999094486237}
2025-01-13 18:29:33,095 [INFO] Step[1900/4329]: training loss : 0.8571108341217041 TRAIN  loss dict:  {'classification_loss': 0.8571108341217041}
2025-01-13 18:29:48,084 [INFO] Step[1950/4329]: training loss : 0.857423335313797 TRAIN  loss dict:  {'classification_loss': 0.857423335313797}
2025-01-13 18:30:03,034 [INFO] Step[2000/4329]: training loss : 0.8570453202724457 TRAIN  loss dict:  {'classification_loss': 0.8570453202724457}
2025-01-13 18:30:17,795 [INFO] Step[2050/4329]: training loss : 0.8564569449424744 TRAIN  loss dict:  {'classification_loss': 0.8564569449424744}
2025-01-13 18:30:32,881 [INFO] Step[2100/4329]: training loss : 0.8572640597820282 TRAIN  loss dict:  {'classification_loss': 0.8572640597820282}
2025-01-13 18:30:47,930 [INFO] Step[2150/4329]: training loss : 0.855603232383728 TRAIN  loss dict:  {'classification_loss': 0.855603232383728}
2025-01-13 18:31:03,010 [INFO] Step[2200/4329]: training loss : 0.8557819557189942 TRAIN  loss dict:  {'classification_loss': 0.8557819557189942}
2025-01-13 18:31:18,195 [INFO] Step[2250/4329]: training loss : 0.8576559674739838 TRAIN  loss dict:  {'classification_loss': 0.8576559674739838}
2025-01-13 18:31:33,464 [INFO] Step[2300/4329]: training loss : 0.8619087433815003 TRAIN  loss dict:  {'classification_loss': 0.8619087433815003}
2025-01-13 18:31:48,583 [INFO] Step[2350/4329]: training loss : 0.856935338973999 TRAIN  loss dict:  {'classification_loss': 0.856935338973999}
2025-01-13 18:32:03,498 [INFO] Step[2400/4329]: training loss : 0.8565152931213379 TRAIN  loss dict:  {'classification_loss': 0.8565152931213379}
2025-01-13 18:32:18,288 [INFO] Step[2450/4329]: training loss : 0.8569669902324677 TRAIN  loss dict:  {'classification_loss': 0.8569669902324677}
2025-01-13 18:32:33,292 [INFO] Step[2500/4329]: training loss : 0.8573802793025971 TRAIN  loss dict:  {'classification_loss': 0.8573802793025971}
2025-01-13 18:32:48,251 [INFO] Step[2550/4329]: training loss : 0.855360267162323 TRAIN  loss dict:  {'classification_loss': 0.855360267162323}
2025-01-13 18:33:03,011 [INFO] Step[2600/4329]: training loss : 0.8585844862461091 TRAIN  loss dict:  {'classification_loss': 0.8585844862461091}
2025-01-13 18:33:18,076 [INFO] Step[2650/4329]: training loss : 0.8560420203208924 TRAIN  loss dict:  {'classification_loss': 0.8560420203208924}
2025-01-13 18:33:32,978 [INFO] Step[2700/4329]: training loss : 0.856129813194275 TRAIN  loss dict:  {'classification_loss': 0.856129813194275}
2025-01-13 18:33:48,072 [INFO] Step[2750/4329]: training loss : 0.863389790058136 TRAIN  loss dict:  {'classification_loss': 0.863389790058136}
2025-01-13 18:34:02,758 [INFO] Step[2800/4329]: training loss : 0.8569016182422637 TRAIN  loss dict:  {'classification_loss': 0.8569016182422637}
2025-01-13 18:34:17,667 [INFO] Step[2850/4329]: training loss : 0.8569506359100342 TRAIN  loss dict:  {'classification_loss': 0.8569506359100342}
2025-01-13 18:34:32,747 [INFO] Step[2900/4329]: training loss : 0.8565117835998535 TRAIN  loss dict:  {'classification_loss': 0.8565117835998535}
2025-01-13 18:34:47,546 [INFO] Step[2950/4329]: training loss : 0.8560437798500061 TRAIN  loss dict:  {'classification_loss': 0.8560437798500061}
2025-01-13 18:35:02,514 [INFO] Step[3000/4329]: training loss : 0.855996915102005 TRAIN  loss dict:  {'classification_loss': 0.855996915102005}
2025-01-13 18:35:17,384 [INFO] Step[3050/4329]: training loss : 0.8569380831718445 TRAIN  loss dict:  {'classification_loss': 0.8569380831718445}
2025-01-13 18:35:32,459 [INFO] Step[3100/4329]: training loss : 0.8561551296710967 TRAIN  loss dict:  {'classification_loss': 0.8561551296710967}
2025-01-13 18:35:47,543 [INFO] Step[3150/4329]: training loss : 0.8560872793197631 TRAIN  loss dict:  {'classification_loss': 0.8560872793197631}
2025-01-13 18:36:02,521 [INFO] Step[3200/4329]: training loss : 0.8599838602542877 TRAIN  loss dict:  {'classification_loss': 0.8599838602542877}
2025-01-13 18:36:17,757 [INFO] Step[3250/4329]: training loss : 0.8568961107730866 TRAIN  loss dict:  {'classification_loss': 0.8568961107730866}
2025-01-13 18:36:32,674 [INFO] Step[3300/4329]: training loss : 0.8559978461265564 TRAIN  loss dict:  {'classification_loss': 0.8559978461265564}
2025-01-13 18:36:47,483 [INFO] Step[3350/4329]: training loss : 0.8605632984638214 TRAIN  loss dict:  {'classification_loss': 0.8605632984638214}
2025-01-13 18:37:02,427 [INFO] Step[3400/4329]: training loss : 0.8563887321949005 TRAIN  loss dict:  {'classification_loss': 0.8563887321949005}
2025-01-13 18:37:17,716 [INFO] Step[3450/4329]: training loss : 0.8553017425537109 TRAIN  loss dict:  {'classification_loss': 0.8553017425537109}
2025-01-13 18:37:32,549 [INFO] Step[3500/4329]: training loss : 0.8558181214332581 TRAIN  loss dict:  {'classification_loss': 0.8558181214332581}
2025-01-13 18:37:47,471 [INFO] Step[3550/4329]: training loss : 0.855795475244522 TRAIN  loss dict:  {'classification_loss': 0.855795475244522}
2025-01-13 18:38:02,180 [INFO] Step[3600/4329]: training loss : 0.8595305144786834 TRAIN  loss dict:  {'classification_loss': 0.8595305144786834}
2025-01-13 18:38:17,170 [INFO] Step[3650/4329]: training loss : 0.8561325681209564 TRAIN  loss dict:  {'classification_loss': 0.8561325681209564}
2025-01-13 18:38:32,221 [INFO] Step[3700/4329]: training loss : 0.8573687839508056 TRAIN  loss dict:  {'classification_loss': 0.8573687839508056}
2025-01-13 18:38:47,427 [INFO] Step[3750/4329]: training loss : 0.8597287809848786 TRAIN  loss dict:  {'classification_loss': 0.8597287809848786}
2025-01-13 18:39:02,394 [INFO] Step[3800/4329]: training loss : 0.8566472971439362 TRAIN  loss dict:  {'classification_loss': 0.8566472971439362}
2025-01-13 18:39:17,330 [INFO] Step[3850/4329]: training loss : 0.8558621668815612 TRAIN  loss dict:  {'classification_loss': 0.8558621668815612}
2025-01-13 18:39:32,084 [INFO] Step[3900/4329]: training loss : 0.8574253714084625 TRAIN  loss dict:  {'classification_loss': 0.8574253714084625}
2025-01-13 18:39:47,354 [INFO] Step[3950/4329]: training loss : 0.8569467687606811 TRAIN  loss dict:  {'classification_loss': 0.8569467687606811}
2025-01-13 18:40:02,559 [INFO] Step[4000/4329]: training loss : 0.8592361557483673 TRAIN  loss dict:  {'classification_loss': 0.8592361557483673}
2025-01-13 18:40:17,299 [INFO] Step[4050/4329]: training loss : 0.859542316198349 TRAIN  loss dict:  {'classification_loss': 0.859542316198349}
2025-01-13 18:40:32,402 [INFO] Step[4100/4329]: training loss : 0.8559744083881378 TRAIN  loss dict:  {'classification_loss': 0.8559744083881378}
2025-01-13 18:40:47,516 [INFO] Step[4150/4329]: training loss : 0.8609983122348785 TRAIN  loss dict:  {'classification_loss': 0.8609983122348785}
2025-01-13 18:41:02,416 [INFO] Step[4200/4329]: training loss : 0.8565523195266723 TRAIN  loss dict:  {'classification_loss': 0.8565523195266723}
2025-01-13 18:41:17,632 [INFO] Step[4250/4329]: training loss : 0.8553980576992035 TRAIN  loss dict:  {'classification_loss': 0.8553980576992035}
2025-01-13 18:41:32,534 [INFO] Step[4300/4329]: training loss : 0.8564030456542969 TRAIN  loss dict:  {'classification_loss': 0.8564030456542969}
2025-01-13 18:43:23,420 [INFO] Label accuracies statistics:
2025-01-13 18:43:23,420 [INFO] {0: 0.7777777777777778, 1: 0.7777777777777778, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5, 7: 0.5833333333333334, 8: 0.6666666666666666, 9: 1.0, 10: 1.0, 11: 0.9166666666666666, 12: 0.5, 13: 0.5, 14: 0.75, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.75, 18: 0.5833333333333334, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.9166666666666666, 24: 1.0, 25: 0.8333333333333334, 26: 0.8333333333333334, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.75, 31: 0.6666666666666666, 32: 0.75, 33: 0.8333333333333334, 34: 0.8333333333333334, 35: 0.9166666666666666, 36: 0.5833333333333334, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.8333333333333334, 41: 0.5833333333333334, 42: 0.9166666666666666, 43: 0.9166666666666666, 44: 0.6666666666666666, 45: 0.6666666666666666, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5833333333333334, 55: 0.75, 56: 0.9166666666666666, 57: 0.75, 58: 0.3333333333333333, 59: 1.0, 60: 0.6666666666666666, 61: 1.0, 62: 0.75, 63: 0.5833333333333334, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.6666666666666666, 69: 0.6666666666666666, 70: 0.5, 71: 0.5, 72: 0.8333333333333334, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 0.9166666666666666, 79: 0.5833333333333334, 80: 1.0, 81: 1.0, 82: 0.8333333333333334, 83: 0.6666666666666666, 84: 0.5833333333333334, 85: 0.75, 86: 0.6666666666666666, 87: 0.9166666666666666, 88: 0.75, 89: 0.5833333333333334, 90: 0.9166666666666666, 91: 1.0, 92: 0.9166666666666666, 93: 1.0, 94: 0.75, 95: 0.9166666666666666, 96: 0.5833333333333334, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.9166666666666666, 101: 1.0, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 0.9166666666666666, 106: 0.9166666666666666, 107: 0.5833333333333334, 108: 0.9166666666666666, 109: 0.8333333333333334, 110: 1.0, 111: 1.0, 112: 0.8333333333333334, 113: 0.5833333333333334, 114: 0.4166666666666667, 115: 1.0, 116: 0.9166666666666666, 117: 0.75, 118: 1.0, 119: 0.8333333333333334, 120: 0.75, 121: 0.9166666666666666, 122: 0.8333333333333334, 123: 1.0, 124: 1.0, 125: 0.9166666666666666, 126: 0.8333333333333334, 127: 0.6666666666666666, 128: 1.0, 129: 0.9166666666666666, 130: 0.8333333333333334, 131: 0.9166666666666666, 132: 0.6666666666666666, 133: 1.0, 134: 0.9166666666666666, 135: 0.9166666666666666, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.8333333333333334, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 0.6666666666666666, 143: 1.0, 144: 0.6666666666666666, 145: 0.9166666666666666, 146: 1.0, 147: 0.8333333333333334, 148: 0.5833333333333334, 149: 1.0, 150: 0.5, 151: 0.9166666666666666, 152: 0.9166666666666666, 153: 0.75, 154: 1.0, 155: 0.9166666666666666, 156: 0.75, 157: 0.6666666666666666, 158: 0.7777777777777778, 159: 1.0, 160: 0.4166666666666667, 161: 0.9166666666666666, 162: 1.0, 163: 0.9166666666666666, 164: 0.8333333333333334, 165: 0.5833333333333334, 166: 0.8333333333333334, 167: 0.6666666666666666, 168: 0.9166666666666666, 169: 1.0, 170: 0.9166666666666666, 171: 0.4166666666666667, 172: 1.0, 173: 0.75, 174: 0.9166666666666666, 175: 0.9166666666666666, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.4444444444444444, 180: 0.8333333333333334, 181: 0.8333333333333334, 182: 0.6666666666666666, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.8333333333333334, 187: 1.0, 188: 0.5833333333333334, 189: 0.9166666666666666, 190: 0.6666666666666666, 191: 0.6666666666666666, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.9166666666666666, 198: 0.6666666666666666}

2025-01-13 18:43:23,422 [INFO] [84] TRAIN  loss: 0.8576572546922574 acc: 0.999691975974126
2025-01-13 18:43:23,423 [INFO] [84] TRAIN  loss dict: {'classification_loss': 0.8576572546922574}
2025-01-13 18:43:23,423 [INFO] [84] VALIDATION loss: 1.6004210311656046 VALIDATION acc: 0.8173400673400674
2025-01-13 18:43:23,423 [INFO] [84] VALIDATION loss dict: {'classification_loss': 1.6004210311656046}
2025-01-13 18:43:23,423 [INFO] 
2025-01-13 18:43:42,866 [INFO] Step[50/4329]: training loss : 0.8558745741844177 TRAIN  loss dict:  {'classification_loss': 0.8558745741844177}
2025-01-13 18:43:57,542 [INFO] Step[100/4329]: training loss : 0.8563411140441894 TRAIN  loss dict:  {'classification_loss': 0.8563411140441894}
2025-01-13 18:44:12,727 [INFO] Step[150/4329]: training loss : 0.8664818322658538 TRAIN  loss dict:  {'classification_loss': 0.8664818322658538}
2025-01-13 18:44:27,921 [INFO] Step[200/4329]: training loss : 0.8560420644283294 TRAIN  loss dict:  {'classification_loss': 0.8560420644283294}
2025-01-13 18:44:42,914 [INFO] Step[250/4329]: training loss : 0.8560203838348389 TRAIN  loss dict:  {'classification_loss': 0.8560203838348389}
2025-01-13 18:44:58,028 [INFO] Step[300/4329]: training loss : 0.8563193261623383 TRAIN  loss dict:  {'classification_loss': 0.8563193261623383}
2025-01-13 18:45:12,924 [INFO] Step[350/4329]: training loss : 0.8578716230392456 TRAIN  loss dict:  {'classification_loss': 0.8578716230392456}
2025-01-13 18:45:28,167 [INFO] Step[400/4329]: training loss : 0.8569982755184173 TRAIN  loss dict:  {'classification_loss': 0.8569982755184173}
2025-01-13 18:45:43,402 [INFO] Step[450/4329]: training loss : 0.8563847374916077 TRAIN  loss dict:  {'classification_loss': 0.8563847374916077}
2025-01-13 18:45:58,158 [INFO] Step[500/4329]: training loss : 0.8733343803882598 TRAIN  loss dict:  {'classification_loss': 0.8733343803882598}
2025-01-13 18:46:13,408 [INFO] Step[550/4329]: training loss : 0.8553053522109986 TRAIN  loss dict:  {'classification_loss': 0.8553053522109986}
2025-01-13 18:46:28,463 [INFO] Step[600/4329]: training loss : 0.8558188581466675 TRAIN  loss dict:  {'classification_loss': 0.8558188581466675}
2025-01-13 18:46:43,523 [INFO] Step[650/4329]: training loss : 0.8561937379837036 TRAIN  loss dict:  {'classification_loss': 0.8561937379837036}
2025-01-13 18:46:58,769 [INFO] Step[700/4329]: training loss : 0.8564205682277679 TRAIN  loss dict:  {'classification_loss': 0.8564205682277679}
2025-01-13 18:47:13,922 [INFO] Step[750/4329]: training loss : 0.8566852176189422 TRAIN  loss dict:  {'classification_loss': 0.8566852176189422}
2025-01-13 18:47:29,078 [INFO] Step[800/4329]: training loss : 0.8589266490936279 TRAIN  loss dict:  {'classification_loss': 0.8589266490936279}
2025-01-13 18:47:44,208 [INFO] Step[850/4329]: training loss : 0.8565347349643707 TRAIN  loss dict:  {'classification_loss': 0.8565347349643707}
2025-01-13 18:47:59,339 [INFO] Step[900/4329]: training loss : 0.8559063100814819 TRAIN  loss dict:  {'classification_loss': 0.8559063100814819}
2025-01-13 18:48:14,638 [INFO] Step[950/4329]: training loss : 0.8561983501911163 TRAIN  loss dict:  {'classification_loss': 0.8561983501911163}
2025-01-13 18:48:29,434 [INFO] Step[1000/4329]: training loss : 0.8553451144695282 TRAIN  loss dict:  {'classification_loss': 0.8553451144695282}
2025-01-13 18:48:44,387 [INFO] Step[1050/4329]: training loss : 0.8563491904735565 TRAIN  loss dict:  {'classification_loss': 0.8563491904735565}
2025-01-13 18:48:59,212 [INFO] Step[1100/4329]: training loss : 0.8578771340847016 TRAIN  loss dict:  {'classification_loss': 0.8578771340847016}
2025-01-13 18:49:13,905 [INFO] Step[1150/4329]: training loss : 0.8556396973133087 TRAIN  loss dict:  {'classification_loss': 0.8556396973133087}
2025-01-13 18:49:28,598 [INFO] Step[1200/4329]: training loss : 0.8573858869075776 TRAIN  loss dict:  {'classification_loss': 0.8573858869075776}
2025-01-13 18:49:43,330 [INFO] Step[1250/4329]: training loss : 0.8563195979595184 TRAIN  loss dict:  {'classification_loss': 0.8563195979595184}
2025-01-13 18:49:58,017 [INFO] Step[1300/4329]: training loss : 0.85632692694664 TRAIN  loss dict:  {'classification_loss': 0.85632692694664}
2025-01-13 18:50:12,787 [INFO] Step[1350/4329]: training loss : 0.85520712018013 TRAIN  loss dict:  {'classification_loss': 0.85520712018013}
2025-01-13 18:50:27,887 [INFO] Step[1400/4329]: training loss : 0.8561089408397674 TRAIN  loss dict:  {'classification_loss': 0.8561089408397674}
2025-01-13 18:50:42,804 [INFO] Step[1450/4329]: training loss : 0.8608565843105316 TRAIN  loss dict:  {'classification_loss': 0.8608565843105316}
2025-01-13 18:50:57,799 [INFO] Step[1500/4329]: training loss : 0.8562889337539673 TRAIN  loss dict:  {'classification_loss': 0.8562889337539673}
2025-01-13 18:51:12,603 [INFO] Step[1550/4329]: training loss : 0.8590778934955597 TRAIN  loss dict:  {'classification_loss': 0.8590778934955597}
2025-01-13 18:51:27,798 [INFO] Step[1600/4329]: training loss : 0.8558581256866455 TRAIN  loss dict:  {'classification_loss': 0.8558581256866455}
2025-01-13 18:51:42,987 [INFO] Step[1650/4329]: training loss : 0.856663602590561 TRAIN  loss dict:  {'classification_loss': 0.856663602590561}
2025-01-13 18:51:57,976 [INFO] Step[1700/4329]: training loss : 0.8568643367290497 TRAIN  loss dict:  {'classification_loss': 0.8568643367290497}
2025-01-13 18:52:12,808 [INFO] Step[1750/4329]: training loss : 0.8578582715988159 TRAIN  loss dict:  {'classification_loss': 0.8578582715988159}
2025-01-13 18:52:27,866 [INFO] Step[1800/4329]: training loss : 0.8607620024681091 TRAIN  loss dict:  {'classification_loss': 0.8607620024681091}
2025-01-13 18:52:42,897 [INFO] Step[1850/4329]: training loss : 0.8811736035346985 TRAIN  loss dict:  {'classification_loss': 0.8811736035346985}
2025-01-13 18:52:57,874 [INFO] Step[1900/4329]: training loss : 0.8566755032539368 TRAIN  loss dict:  {'classification_loss': 0.8566755032539368}
2025-01-13 18:53:13,116 [INFO] Step[1950/4329]: training loss : 0.8561099421977997 TRAIN  loss dict:  {'classification_loss': 0.8561099421977997}
2025-01-13 18:53:28,042 [INFO] Step[2000/4329]: training loss : 0.8567963743209839 TRAIN  loss dict:  {'classification_loss': 0.8567963743209839}
2025-01-13 18:53:42,832 [INFO] Step[2050/4329]: training loss : 0.8559961628913879 TRAIN  loss dict:  {'classification_loss': 0.8559961628913879}
2025-01-13 18:53:57,586 [INFO] Step[2100/4329]: training loss : 0.8566880631446838 TRAIN  loss dict:  {'classification_loss': 0.8566880631446838}
2025-01-13 18:54:12,279 [INFO] Step[2150/4329]: training loss : 0.8567483448982238 TRAIN  loss dict:  {'classification_loss': 0.8567483448982238}
2025-01-13 18:54:27,376 [INFO] Step[2200/4329]: training loss : 0.8591155254840851 TRAIN  loss dict:  {'classification_loss': 0.8591155254840851}
2025-01-13 18:54:42,293 [INFO] Step[2250/4329]: training loss : 0.856358276605606 TRAIN  loss dict:  {'classification_loss': 0.856358276605606}
2025-01-13 18:54:57,240 [INFO] Step[2300/4329]: training loss : 0.8556455779075622 TRAIN  loss dict:  {'classification_loss': 0.8556455779075622}
2025-01-13 18:55:12,343 [INFO] Step[2350/4329]: training loss : 0.856054744720459 TRAIN  loss dict:  {'classification_loss': 0.856054744720459}
2025-01-13 18:55:27,099 [INFO] Step[2400/4329]: training loss : 0.855857970714569 TRAIN  loss dict:  {'classification_loss': 0.855857970714569}
2025-01-13 18:55:42,183 [INFO] Step[2450/4329]: training loss : 0.8574813449382782 TRAIN  loss dict:  {'classification_loss': 0.8574813449382782}
2025-01-13 18:55:57,371 [INFO] Step[2500/4329]: training loss : 0.8559376549720764 TRAIN  loss dict:  {'classification_loss': 0.8559376549720764}
2025-01-13 18:56:12,081 [INFO] Step[2550/4329]: training loss : 0.8558259260654449 TRAIN  loss dict:  {'classification_loss': 0.8558259260654449}
2025-01-13 18:56:27,132 [INFO] Step[2600/4329]: training loss : 0.8605963170528412 TRAIN  loss dict:  {'classification_loss': 0.8605963170528412}
2025-01-13 18:56:42,344 [INFO] Step[2650/4329]: training loss : 0.8566260182857514 TRAIN  loss dict:  {'classification_loss': 0.8566260182857514}
2025-01-13 18:56:57,562 [INFO] Step[2700/4329]: training loss : 0.8555427694320679 TRAIN  loss dict:  {'classification_loss': 0.8555427694320679}
2025-01-13 18:57:12,530 [INFO] Step[2750/4329]: training loss : 0.8576356565952301 TRAIN  loss dict:  {'classification_loss': 0.8576356565952301}
2025-01-13 18:57:27,781 [INFO] Step[2800/4329]: training loss : 0.8577060747146606 TRAIN  loss dict:  {'classification_loss': 0.8577060747146606}
2025-01-13 18:57:43,042 [INFO] Step[2850/4329]: training loss : 0.8551695430278778 TRAIN  loss dict:  {'classification_loss': 0.8551695430278778}
2025-01-13 18:57:57,912 [INFO] Step[2900/4329]: training loss : 0.8562762200832367 TRAIN  loss dict:  {'classification_loss': 0.8562762200832367}
2025-01-13 18:58:12,840 [INFO] Step[2950/4329]: training loss : 0.8575462222099304 TRAIN  loss dict:  {'classification_loss': 0.8575462222099304}
2025-01-13 18:58:27,789 [INFO] Step[3000/4329]: training loss : 0.8572506535053254 TRAIN  loss dict:  {'classification_loss': 0.8572506535053254}
2025-01-13 18:58:42,733 [INFO] Step[3050/4329]: training loss : 0.8559894895553589 TRAIN  loss dict:  {'classification_loss': 0.8559894895553589}
2025-01-13 18:58:57,436 [INFO] Step[3100/4329]: training loss : 0.858230654001236 TRAIN  loss dict:  {'classification_loss': 0.858230654001236}
2025-01-13 18:59:12,372 [INFO] Step[3150/4329]: training loss : 0.8552632570266724 TRAIN  loss dict:  {'classification_loss': 0.8552632570266724}
2025-01-13 18:59:27,150 [INFO] Step[3200/4329]: training loss : 0.8639768683910369 TRAIN  loss dict:  {'classification_loss': 0.8639768683910369}
2025-01-13 18:59:42,268 [INFO] Step[3250/4329]: training loss : 0.8553653943538666 TRAIN  loss dict:  {'classification_loss': 0.8553653943538666}
2025-01-13 18:59:57,221 [INFO] Step[3300/4329]: training loss : 0.8558835983276367 TRAIN  loss dict:  {'classification_loss': 0.8558835983276367}
2025-01-13 19:00:12,272 [INFO] Step[3350/4329]: training loss : 0.8571558618545532 TRAIN  loss dict:  {'classification_loss': 0.8571558618545532}
2025-01-13 19:00:27,089 [INFO] Step[3400/4329]: training loss : 0.856030615568161 TRAIN  loss dict:  {'classification_loss': 0.856030615568161}
2025-01-13 19:00:41,867 [INFO] Step[3450/4329]: training loss : 0.8559703874588013 TRAIN  loss dict:  {'classification_loss': 0.8559703874588013}
2025-01-13 19:00:57,096 [INFO] Step[3500/4329]: training loss : 0.8776098394393921 TRAIN  loss dict:  {'classification_loss': 0.8776098394393921}
2025-01-13 19:01:12,105 [INFO] Step[3550/4329]: training loss : 0.8587463402748108 TRAIN  loss dict:  {'classification_loss': 0.8587463402748108}
2025-01-13 19:01:27,142 [INFO] Step[3600/4329]: training loss : 0.8569737422466278 TRAIN  loss dict:  {'classification_loss': 0.8569737422466278}
2025-01-13 19:01:42,312 [INFO] Step[3650/4329]: training loss : 0.8650620830059051 TRAIN  loss dict:  {'classification_loss': 0.8650620830059051}
2025-01-13 19:01:57,541 [INFO] Step[3700/4329]: training loss : 0.8565888106822968 TRAIN  loss dict:  {'classification_loss': 0.8565888106822968}
2025-01-13 19:02:12,689 [INFO] Step[3750/4329]: training loss : 0.8559834158420563 TRAIN  loss dict:  {'classification_loss': 0.8559834158420563}
2025-01-13 19:02:27,725 [INFO] Step[3800/4329]: training loss : 0.8556669092178345 TRAIN  loss dict:  {'classification_loss': 0.8556669092178345}
2025-01-13 19:02:42,947 [INFO] Step[3850/4329]: training loss : 0.8567475855350495 TRAIN  loss dict:  {'classification_loss': 0.8567475855350495}
2025-01-13 19:02:58,003 [INFO] Step[3900/4329]: training loss : 0.8563533270359039 TRAIN  loss dict:  {'classification_loss': 0.8563533270359039}
2025-01-13 19:03:12,801 [INFO] Step[3950/4329]: training loss : 0.8556365847587586 TRAIN  loss dict:  {'classification_loss': 0.8556365847587586}
2025-01-13 19:03:27,879 [INFO] Step[4000/4329]: training loss : 0.8585275495052338 TRAIN  loss dict:  {'classification_loss': 0.8585275495052338}
2025-01-13 19:03:42,935 [INFO] Step[4050/4329]: training loss : 0.8574673986434936 TRAIN  loss dict:  {'classification_loss': 0.8574673986434936}
2025-01-13 19:03:58,120 [INFO] Step[4100/4329]: training loss : 0.8555122578144073 TRAIN  loss dict:  {'classification_loss': 0.8555122578144073}
2025-01-13 19:04:13,347 [INFO] Step[4150/4329]: training loss : 0.8561326563358307 TRAIN  loss dict:  {'classification_loss': 0.8561326563358307}
2025-01-13 19:04:28,577 [INFO] Step[4200/4329]: training loss : 0.8574066054821015 TRAIN  loss dict:  {'classification_loss': 0.8574066054821015}
2025-01-13 19:04:43,744 [INFO] Step[4250/4329]: training loss : 0.8572153460979461 TRAIN  loss dict:  {'classification_loss': 0.8572153460979461}
2025-01-13 19:04:58,648 [INFO] Step[4300/4329]: training loss : 0.8656763160228729 TRAIN  loss dict:  {'classification_loss': 0.8656763160228729}
2025-01-13 19:06:50,294 [INFO] Label accuracies statistics:
2025-01-13 19:06:50,294 [INFO] {0: 0.5555555555555556, 1: 0.8888888888888888, 2: 0.6666666666666666, 3: 0.75, 4: 0.3333333333333333, 5: 0.8333333333333334, 6: 0.5833333333333334, 7: 0.5833333333333334, 8: 0.6666666666666666, 9: 0.9166666666666666, 10: 1.0, 11: 0.9166666666666666, 12: 0.4166666666666667, 13: 0.6666666666666666, 14: 0.75, 15: 0.6666666666666666, 16: 0.5833333333333334, 17: 0.5833333333333334, 18: 0.5, 19: 0.6666666666666666, 20: 0.5833333333333334, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.9166666666666666, 27: 0.6666666666666666, 28: 0.9166666666666666, 29: 1.0, 30: 0.6666666666666666, 31: 0.8333333333333334, 32: 0.75, 33: 0.9166666666666666, 34: 0.8333333333333334, 35: 0.9166666666666666, 36: 0.5, 37: 1.0, 38: 1.0, 39: 0.9166666666666666, 40: 0.9166666666666666, 41: 0.5833333333333334, 42: 0.8333333333333334, 43: 0.9166666666666666, 44: 0.5833333333333334, 45: 0.5833333333333334, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.8333333333333334, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.3333333333333333, 55: 0.6666666666666666, 56: 0.8333333333333334, 57: 0.75, 58: 0.5833333333333334, 59: 0.8333333333333334, 60: 0.75, 61: 0.9166666666666666, 62: 0.75, 63: 0.6666666666666666, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.75, 69: 0.6666666666666666, 70: 0.5833333333333334, 71: 0.5833333333333334, 72: 0.75, 73: 0.9166666666666666, 74: 0.75, 75: 1.0, 76: 0.6666666666666666, 77: 0.75, 78: 0.9166666666666666, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5833333333333334, 84: 0.5833333333333334, 85: 0.75, 86: 0.6666666666666666, 87: 0.8333333333333334, 88: 0.6666666666666666, 89: 0.5833333333333334, 90: 0.8333333333333334, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 0.9166666666666666, 96: 0.4166666666666667, 97: 0.75, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.9166666666666666, 103: 0.9166666666666666, 104: 1.0, 105: 1.0, 106: 0.9166666666666666, 107: 0.6666666666666666, 108: 0.9166666666666666, 109: 0.9166666666666666, 110: 1.0, 111: 1.0, 112: 0.9166666666666666, 113: 0.75, 114: 0.25, 115: 1.0, 116: 0.8333333333333334, 117: 0.6666666666666666, 118: 1.0, 119: 0.9166666666666666, 120: 0.75, 121: 0.8333333333333334, 122: 0.8333333333333334, 123: 0.9166666666666666, 124: 1.0, 125: 0.8333333333333334, 126: 0.8333333333333334, 127: 0.75, 128: 1.0, 129: 0.9166666666666666, 130: 0.75, 131: 0.9166666666666666, 132: 0.8333333333333334, 133: 1.0, 134: 0.9166666666666666, 135: 1.0, 136: 0.9166666666666666, 137: 0.9166666666666666, 138: 0.9166666666666666, 139: 0.9166666666666666, 140: 1.0, 141: 1.0, 142: 0.8333333333333334, 143: 1.0, 144: 0.5833333333333334, 145: 1.0, 146: 0.9166666666666666, 147: 0.8333333333333334, 148: 0.75, 149: 1.0, 150: 0.5, 151: 0.9166666666666666, 152: 0.9166666666666666, 153: 0.75, 154: 1.0, 155: 0.9166666666666666, 156: 0.75, 157: 0.75, 158: 0.7777777777777778, 159: 1.0, 160: 0.3333333333333333, 161: 1.0, 162: 1.0, 163: 1.0, 164: 0.8333333333333334, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.9166666666666666, 169: 1.0, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.9166666666666666, 175: 0.8333333333333334, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.8333333333333334, 181: 0.9166666666666666, 182: 0.6666666666666666, 183: 0.9166666666666666, 184: 0.75, 185: 1.0, 186: 0.9166666666666666, 187: 1.0, 188: 0.75, 189: 0.9166666666666666, 190: 0.6666666666666666, 191: 0.75, 192: 1.0, 193: 0.9166666666666666, 194: 0.9166666666666666, 195: 0.9166666666666666, 196: 0.9166666666666666, 197: 0.9166666666666666, 198: 0.6666666666666666}

2025-01-13 19:06:50,297 [INFO] [85] TRAIN  loss: 0.8578377178674153 acc: 0.999537963961189
2025-01-13 19:06:50,297 [INFO] [85] TRAIN  loss dict: {'classification_loss': 0.8578377178674153}
2025-01-13 19:06:50,297 [INFO] [85] VALIDATION loss: 1.6035880812189796 VALIDATION acc: 0.819023569023569
2025-01-13 19:06:50,297 [INFO] [85] VALIDATION loss dict: {'classification_loss': 1.6035880812189796}
2025-01-13 19:06:50,298 [INFO] 
2025-01-13 19:07:09,703 [INFO] Step[50/4329]: training loss : 0.8581463134288788 TRAIN  loss dict:  {'classification_loss': 0.8581463134288788}
2025-01-13 19:07:24,372 [INFO] Step[100/4329]: training loss : 0.8565252649784089 TRAIN  loss dict:  {'classification_loss': 0.8565252649784089}
2025-01-13 19:07:39,239 [INFO] Step[150/4329]: training loss : 0.8593507063388824 TRAIN  loss dict:  {'classification_loss': 0.8593507063388824}
2025-01-13 19:07:54,146 [INFO] Step[200/4329]: training loss : 0.8554043626785278 TRAIN  loss dict:  {'classification_loss': 0.8554043626785278}
2025-01-13 19:08:09,369 [INFO] Step[250/4329]: training loss : 0.8560003745555878 TRAIN  loss dict:  {'classification_loss': 0.8560003745555878}
2025-01-13 19:08:24,537 [INFO] Step[300/4329]: training loss : 0.8576485574245453 TRAIN  loss dict:  {'classification_loss': 0.8576485574245453}
2025-01-13 19:08:39,383 [INFO] Step[350/4329]: training loss : 0.855206778049469 TRAIN  loss dict:  {'classification_loss': 0.855206778049469}
2025-01-13 19:08:54,225 [INFO] Step[400/4329]: training loss : 0.8559653842449189 TRAIN  loss dict:  {'classification_loss': 0.8559653842449189}
2025-01-13 19:09:09,420 [INFO] Step[450/4329]: training loss : 0.8580017948150634 TRAIN  loss dict:  {'classification_loss': 0.8580017948150634}
2025-01-13 19:09:24,389 [INFO] Step[500/4329]: training loss : 0.8561057102680206 TRAIN  loss dict:  {'classification_loss': 0.8561057102680206}
2025-01-13 19:09:39,151 [INFO] Step[550/4329]: training loss : 0.8562720501422882 TRAIN  loss dict:  {'classification_loss': 0.8562720501422882}
2025-01-13 19:09:54,053 [INFO] Step[600/4329]: training loss : 0.8555927789211273 TRAIN  loss dict:  {'classification_loss': 0.8555927789211273}
2025-01-13 19:10:08,862 [INFO] Step[650/4329]: training loss : 0.8554105949401856 TRAIN  loss dict:  {'classification_loss': 0.8554105949401856}
2025-01-13 19:10:23,835 [INFO] Step[700/4329]: training loss : 0.8622793769836425 TRAIN  loss dict:  {'classification_loss': 0.8622793769836425}
2025-01-13 19:10:38,974 [INFO] Step[750/4329]: training loss : 0.8643313670158386 TRAIN  loss dict:  {'classification_loss': 0.8643313670158386}
2025-01-13 19:10:54,106 [INFO] Step[800/4329]: training loss : 0.8554477524757386 TRAIN  loss dict:  {'classification_loss': 0.8554477524757386}
2025-01-13 19:11:08,865 [INFO] Step[850/4329]: training loss : 0.8564545118808746 TRAIN  loss dict:  {'classification_loss': 0.8564545118808746}
2025-01-13 19:11:23,597 [INFO] Step[900/4329]: training loss : 0.8552163171768189 TRAIN  loss dict:  {'classification_loss': 0.8552163171768189}
2025-01-13 19:11:38,666 [INFO] Step[950/4329]: training loss : 0.8553238570690155 TRAIN  loss dict:  {'classification_loss': 0.8553238570690155}
2025-01-13 19:11:53,634 [INFO] Step[1000/4329]: training loss : 0.8567029428482056 TRAIN  loss dict:  {'classification_loss': 0.8567029428482056}
2025-01-13 19:12:08,608 [INFO] Step[1050/4329]: training loss : 0.8569298827648163 TRAIN  loss dict:  {'classification_loss': 0.8569298827648163}
2025-01-13 19:12:23,822 [INFO] Step[1100/4329]: training loss : 0.8580993247032166 TRAIN  loss dict:  {'classification_loss': 0.8580993247032166}
2025-01-13 19:12:38,711 [INFO] Step[1150/4329]: training loss : 0.8564137816429138 TRAIN  loss dict:  {'classification_loss': 0.8564137816429138}
2025-01-13 19:12:53,621 [INFO] Step[1200/4329]: training loss : 0.8551242053508759 TRAIN  loss dict:  {'classification_loss': 0.8551242053508759}
2025-01-13 19:13:08,640 [INFO] Step[1250/4329]: training loss : 0.8557619440555573 TRAIN  loss dict:  {'classification_loss': 0.8557619440555573}
2025-01-13 19:13:23,467 [INFO] Step[1300/4329]: training loss : 0.8564912915229798 TRAIN  loss dict:  {'classification_loss': 0.8564912915229798}
2025-01-13 19:13:38,723 [INFO] Step[1350/4329]: training loss : 0.8557376456260681 TRAIN  loss dict:  {'classification_loss': 0.8557376456260681}
2025-01-13 19:13:53,532 [INFO] Step[1400/4329]: training loss : 0.8605351340770722 TRAIN  loss dict:  {'classification_loss': 0.8605351340770722}
2025-01-13 19:14:08,255 [INFO] Step[1450/4329]: training loss : 0.8566530585289002 TRAIN  loss dict:  {'classification_loss': 0.8566530585289002}
2025-01-13 19:14:22,961 [INFO] Step[1500/4329]: training loss : 0.855294668674469 TRAIN  loss dict:  {'classification_loss': 0.855294668674469}
2025-01-13 19:14:38,149 [INFO] Step[1550/4329]: training loss : 0.8560201156139374 TRAIN  loss dict:  {'classification_loss': 0.8560201156139374}
2025-01-13 19:14:53,128 [INFO] Step[1600/4329]: training loss : 0.8567909324169158 TRAIN  loss dict:  {'classification_loss': 0.8567909324169158}
2025-01-13 19:15:07,899 [INFO] Step[1650/4329]: training loss : 0.8851617479324341 TRAIN  loss dict:  {'classification_loss': 0.8851617479324341}
2025-01-13 19:15:22,986 [INFO] Step[1700/4329]: training loss : 0.8551881694793702 TRAIN  loss dict:  {'classification_loss': 0.8551881694793702}
2025-01-13 19:15:37,656 [INFO] Step[1750/4329]: training loss : 0.8565789413452148 TRAIN  loss dict:  {'classification_loss': 0.8565789413452148}
2025-01-13 19:15:52,355 [INFO] Step[1800/4329]: training loss : 0.8610417079925538 TRAIN  loss dict:  {'classification_loss': 0.8610417079925538}
2025-01-13 19:16:07,500 [INFO] Step[1850/4329]: training loss : 0.8565287315845489 TRAIN  loss dict:  {'classification_loss': 0.8565287315845489}
2025-01-13 19:16:22,463 [INFO] Step[1900/4329]: training loss : 0.8561381936073303 TRAIN  loss dict:  {'classification_loss': 0.8561381936073303}
2025-01-13 19:16:37,419 [INFO] Step[1950/4329]: training loss : 0.8557150173187256 TRAIN  loss dict:  {'classification_loss': 0.8557150173187256}
2025-01-13 19:16:52,658 [INFO] Step[2000/4329]: training loss : 0.8560983347892761 TRAIN  loss dict:  {'classification_loss': 0.8560983347892761}
2025-01-13 19:17:07,753 [INFO] Step[2050/4329]: training loss : 0.8586235797405243 TRAIN  loss dict:  {'classification_loss': 0.8586235797405243}
2025-01-13 19:17:22,685 [INFO] Step[2100/4329]: training loss : 0.8567345929145813 TRAIN  loss dict:  {'classification_loss': 0.8567345929145813}
2025-01-13 19:17:37,612 [INFO] Step[2150/4329]: training loss : 0.8561801433563232 TRAIN  loss dict:  {'classification_loss': 0.8561801433563232}
2025-01-13 19:17:52,392 [INFO] Step[2200/4329]: training loss : 0.8558072018623352 TRAIN  loss dict:  {'classification_loss': 0.8558072018623352}
